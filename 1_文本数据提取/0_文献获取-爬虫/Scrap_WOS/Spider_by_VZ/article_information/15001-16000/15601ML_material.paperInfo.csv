,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,IFR-Net: Iterative Feature Refinement Network for Compressed Sensing MRI,6,,434-446,"Liu Yiling,Liu Qiegen,Zhang Minghui,Yang Qingxin,Wang Shanshan,Liang Dong","Liu YL,Liu QG,Zhang MH,Yang QX,Wang SS,Liang D",Zhang MH,10.1109/TCI.2019.2956877,Nanchang University,"To improve the compressive sensing MRI (CS-MRI) approaches in terms of fine structure loss under high acceleration factors, we have proposed an iterative feature refinement model (IFR-CS), equipped with fixed transforms, to restore the meaningful structures and details. Nevertheless, the proposed IFR-CS still has some limitations, such as the selection of hyper-parameters, a lengthy reconstruction time, and the fixed sparsifying transform. To alleviate these issues, we unroll the iterative feature refinement procedures in IFR-CS to a supervised model-driven network, dubbed IFR-Net. Equipped with training data pairs, both regularization parameter and the utmost feature refinement operator in IFR-CS become trainable. Additionally, inspired by the powerful representation capability of convolutional neural network (CNN), CNN-based inversion blocks are explored in the sparsity-promoting denoising module to generalize the sparsity-enforcing operator. Extensive experiments on both simulated and in vivo MR datasets have shown that the proposed network possesses a strong capability to capture image details and preserve well the structural information with fast reconstruction speed.","Compressed Sensing,deep learning,IFR-CS,model-driven network,undersampled image reconstruction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Imaging Science & Photographic Technology",,5.107,"RESONANCE,IMAGE-RECONSTRUCTION,DOMAIN",IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING,http://arxiv.org/pdf/1909.10856,
2,MRI Super-Resolution With Ensemble Learning and Complementary Priors,6,,615-624,"Lyu Qing,Shan Hongming,Wang Ge","Lyu Q,Shan HM,Wang G",Wang G,10.1109/TCI.2020.2964201,Rensselaer Polytechnic Institute,"Magnetic resonance imaging (MRI) is a widely used medical imaging modality. However, due to the limitations in hardware, scan time, and throughput, it is often clinically challenging to obtain high-quality MR images. The super-resolution approach is potentially promising to improve MR image quality without any hardware upgrade. In this article, we propose an ensemble learning and deep learning framework for MR image super-resolution. In our study, we first enlarged low resolution images using five commonly used super-resolution algorithms and obtained differentially enlarged image datasets with complementary priors. Then, a generative adversarial network (GAN) is trained with each dataset to generate super-resolution MR images. Finally, another GAN is used for ensemble learning that synergizes the outputs of GANs into the final MR super-resolution images. According to our results, the ensemble learning results outperform any single GAN output component. Compared with some state-of-the-art deep learning-based super-resolution methods, our approach is advantageous in suppressing artifacts and keeping more image details.","Deep learning,ensemble learning,generative adversarial network (GAN),magnetic resonance imaging (MRI),super-resolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Imaging Science & Photographic Technology",,5.107,"LOW-DOSE,CT,IMAGE,SUPERRESOLUTION,RECONSTRUCTION,NETWORK,RESOLUTION",IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING,http://arxiv.org/pdf/1907.03063,
3,Automatic Tissue Type Classification in Large-Scale Microscopic Images Using Zernike Moments,1051,,310-319,"Gorniak Aneta,Skubalska-Rafajlowicz Ewa","Gorniak A,Skubalska-Rafajlowicz E",Gorniak A,10.1007/978-3-030-30604-5_28,Wroclaw University of Science & Technology,"In this paper, we propose an approach in identification of histological sections of human tissue in large-scale microscopic images on the basis of sample tissue fragments from the image. The method uses pattern recognition properties of Zernike moments in the form of image descriptors consisting of sequences of Zernike moments. The goal is to acquire a robust and precise method that allows for identification of the original source of the tissue fragments in the microscopic images. The approach relies on machine learning to perform the final identification of the tissue subject from the constructed image descriptors. The method is verified by a series of experiments on a set of microscopic slides of histological sections. The results and their analysis are presented in the conclusion of the paper.","Image processing,Microscopic image,Histological sections,Tissue images,Large-scale images,Classification,Zernike moments",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
4,Role of computers in material science and design of classification model to search for the vacancy in outdoor parking lots,28,,1376-1381,"Mago Neeru,Kumar Satish","Mago N,Kumar S",Mago N,10.1016/j.matpr.2020.04.804,Panjab University,"With the rapid increase in technology, the role of computers in material science and engineering is growing gradually. For example, database, data processing, mathematical model and simulation techniques can be used in order to utilize technology effectively. Computer data analysis process can be used in materials science for establishing the mechanism model. Many technical problems in materials science and engineering can be solved by computer science technology. The day is not far away when we will overcome the problem of finding vacant lots in outdoor parking area at entry level. Since the vehicles on roads are increasing at exponential rate, the drivers find it difficult to find vacant parking lots in outdoor parking areas. We all must have experienced such situations in our routine life during searching for vacant slots in a shopping mall, multiplexes or outside any building, especially in urbanized environment. This makes it necessary to find an optimized technique to resolve the issues regarding car-parking. In simple words, an efficient technique should be developed to find the status of outdoor parking lots. In this paper, we have conducted experiments on standard dataset ""PKLot"" consisting of 695,899 images of two different parking lots captured from three different cameras containing images under different weather conditions like sunny, cloudy and rainy. We have trained and tested various machine learning techniques on the dataset and compared their experimental results. (C) 2020 Elsevier Ltd. All rights reserved.","Machine learning,Artificial neural network,K nearest neighbour,Naive Bayes classifier,Support vector machine,Parking system",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,SUPPORT,MATERIALS TODAY-PROCEEDINGS,,
5,X-Ray CT Imaging-Based and Machine Learning-Enabled Characterization of Multi-Constituent Granular Materials,,317,359-367,"Chen Qiushi,Lai Zhengshou,Chen Feiyang","Chen QS,Lai ZS,Chen FY",Chen QS,,Clemson University,"In this paper, an X-ray computed tomography (CT) imaging-based and machine learning-enabled framework is presented to characterize multi-constituent granular materials. In this framework, X-ray CT is first utilized to obtain raw CT images of a synthetic multi-constituent granular material. Then, a machine learning tool termed trainable Weka segmentation (TWS) is implemented to segment raw X-ray CT images, i.e., to classify constituents and to segregate particles in contact. This is a fundamentally different approach for image segmentation in that it predicts segmentation results based on a trained classifier model that implicitly includes multiple image features and regression functions. Subsequently, segmented images are used to quantitatively analyze microscale information of the granular material such as particle morphology, volume fractions, and spatial distribution of different constituents. The information obtained can be used in microstructure reconstruction and in developing microstructure-informed numerical models. The proposed method has promising potential to handle more complex features in CT images of natural or engineered multi-constituent granular materials.",,Proceedings Paper,"AMER SOC CIVIL ENGINEERS, UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA","Computer Science,Engineering",,,,,,
6,The Role of Computational Intelligence in Realizing Modern and Autonomous Fire Evaluation Methods,,,643-650,Naser M. Z.,Naser MZ,Naser MZ,,Clemson University,"Despite calls to adopt performance-based solutions, the structural fire engineering community continues to embrace a classical stance to tackle the problem of fire. In support of these calls, this study showcases the merit of integrating computational intelligence (CI) as a modern technology to assess performance and fire resistance of structures. This paper sheds light on the proper use of CI to develop novel approaches that outperform traditional as well as currently use advanced calculation methods. The proposed CI-based approaches are specifically developed to comprehend the complex temperature-induced physio-chemical changes to properties in construction materials; i.e., thermal, mechanical, deformational, and special, and as such do not require input of such properties nor a complex and lengthy un/coupled thermal-stress analysis. The proposed CI-based approaches can serve as simple and efficient tools to advance the practice of structural fire engineering as well as to provide researchers and practitioners with alternative means to assess fire response of structures. The outcome of this work demonstrates the merit of utilizing CI to modernize fire resistance evaluation, together with performance-based methods, given that the developed CI-based models have high degree of perception (i.e., learn from past behaviors) and ability to improve their prediction capability through independent and unsupervised learning.","Fire,Computational intelligence,Structural performance",Proceedings Paper,"AMER SOC CIVIL ENGINEERS, UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA","Construction & Building Technology,Engineering",,,NEURAL-NETWORKS,STRUCTURES CONGRESS 2020,,
7,Research on Optimization and Prediction Mechanism of Material Properties Based on Gradient and Feature Analysis in Convolution Neural Network,39,5,385-390,",,,,,,","Cao Zhuo,Dan Yabo,Li Xiang,Niu Chengcheng,Dong Rongzhi,Qian Songrong,Hu Jianjun",,,Cao Zhuo,"As a new research mode in material science,material informatics has attracted wide attention.With the rapid increase of material data,machine learning methods are more and more used in the analysis of material data to obtain instructive physical and chemical laws from a large number of material data.This paper focuses on the convolutional neural network,using data from more than 4000 materials collected from the Material Project database to predict formation energy of materials,and the prediction results are accurate.Then,the gradient of feature map is analyzed,we observe that there are some certain correlations between gradient and material properties,and under the guidance of gradient matrix,the possible distribution of feature map with target properties can be found.Finally,the patterns recognized by the convolutional neural network are analyzed,which further verifies that the convolutional neural network can achieve excellent prediction results of material property.",materials informatics; convolutional neural network; formation energy; gradient analysis; feature extraction,Article,,,,,,,,
8,Conceptualising Artificial Intelligence as a Digital Healthcare Innovation: An Introductory Review,13,,223-229,Arora Anmol,Arora A,Arora A,10.2147/MDER.S262590,University of Cambridge,"Artificial intelligence (AI) is widely recognised as a transformative innovation and is already proving capable of outperforming human clinicians in the diagnosis of specific medical conditions, especially in image analysis within dermatology and radiology. These abilities are enhanced by the capacity of AI systems to learn from patient records, genomic information and real-time patient data. Uses of AI range from integrating with robotics to creating training material for clinicians. Whilst AI research is mounting, less attention has been paid to the practical implications on healthcare services and potential barriers to implementation. AI is recognised as a ""Software as a Medical Device (SaMD)"" and is increasingly becoming a topic of interest for regulators. Unless the introduction of AI is carefully considered and gradual, there are risks of automation bias, overdependence and long-term staffing problems. This is in addition to already well-documented generic risks associated with AI, such as data privacy, algorithmic biases and corrigibility. AI is able to potentiate innovations which preceded it, using Internet of Things, digitisation of patient records and genetic data as data sources. These synergies are important in both realising the potential of AI and utilising the potential of the data. As machine learning systems begin to cross-examine an array of databases, we must ensure that clinicians retain autonomy over the diagnostic process and understand the algorithmic processes generating diagnoses. This review uses established management literature to explore artificial intelligence as a digital healthcare innovation and highlight potential risks and opportunities.","machine learning,data,diagnostic algorithms,artificial intelligence,innovation",Review,"DOVE MEDICAL PRESS LTD, PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND",Engineering,,,TECHNOLOGY,MEDICAL DEVICES-EVIDENCE AND RESEARCH,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7455610,
9,Extraction of phenotypic parameters and discrimination of beet root types based on 3D point cloud,36,10,181-188,",,,,,,,,","Chai Honghong,Shao Ke,Yu Chao,Shao Jinwang,Wang Ruili,Sui Yang,Bai Kai,Liu Yunling,Ma Yuntao",,,Chai Honghong,"Sugar beet is one of the main crops for sugar production in the world,and originated from the western and southern coasts of Europe. Selecting and breeding of varieties of sugar beet based on plant phenotyping are the key factors for the development of sugar beet industry on a large-scale cultivation. In China,sugar beet was widely planted in arid and semi-arid regions,particularly for poverty alleviation of farmers living in border areas and ethnic minority areas. The type of beet root with great different genotypes directly determines the sugar yield and mechanization efficiency in modern agriculture. The traditional classification of beet root type depends mainly on manual separation,and thereby greatly limits industry production and breeding of the sugar beet due to heavy workload and relatively large errors. In order to meet the requirements of high-throughput analysis,a three-dimensional(3D)phenotyping technique with multi-view images was recently developed to facilitate the classification of fruit and vegetable with high accuracy and efficiency. In this study,the beet roots with 207 genotypes were selected as experimental materials. Multi-view images were obtained by moving mobile phone around beet root. Three-dimensional point clouds were reconstructed in 3DF Zephyr Aerial software,which can restore position and direction from a dataset of multi-views images to extract for the matching feature points between each pair of images. After the postprocessing of the matching images,including noise reduction,rotating and segment,the detailed features of beet root shape,color,and texture can be achieved in the 3D point cloud. Ten phenotypic parameters can be used to clarify the morphological characteristics of beet roots,the maximum diameter,root length,convex hull volume,top projection area,compactness,convex index,convex angle,distal root end ratio,proximal root end ratio and root taper index. There was a good agreement between the measured maximum diameter and root length,with coefficient of determination R~2 >0.95. The K-medoids clustering algorithm with high stability was selected to classify the beet root into four groups. Group 1,namely as cone beet root,indicates that the maximum root diameter located at the middle of the root body. Group 2,namely as hammer beet root,shows the shortest body of root,the smallest root head ration while larger root tail ration. Group 3,namely as wedge beet root,has the maximum diameter of root body close to the root head,whereas,the width of root from head to tail gradually decreased. Group 4,namely as long wedge beet root,has longer root body than that in group 3,wider root head and smaller root tail. The reduction rate of root body from head to tail was the greatest. Based on the combination of phenotypic traits and experts' knowledge,Group 1(cone beet root)and Group 3(wedge beet root)were recommended due to their high sugar yield,medium root length and moderate proportion. After adjusting the categories by the experts as the true values,five prediction models were established to discriminate beet root type,including linear discrimination,random forest,support vector machine,decision tree,and naive Bayes. The results showed that the prediction accuracies of the five models were above 70.0%,where accuracy of random forest reached 81.4%. These results demonstrated that 3D point cloud reconstructed by multi-view image sequences can be used for the identification of beet root shape,and thereby to effectively improve the yield prediction of sugar beet and the selection of high-quality beet varieties. Since 207 genotypes have been selected for the classification of root types during this time,much more genotypes at different environments can be expected to enrich the 3D phenotyping library,and thereby further improve the accuracy of classification. This finding can provide a potential practical basis for the beet root type screening and breeding.","image procession; ,machine learning,; three dimensional point cloud; beet; root type; phenotype; classification",Article,,,,,,,,
10,EMPOWERING MOBILE ROBOTICS UNDERGRADUATE COURSES BY USING JUPYTER NOTEBOOKS,,,5859-5868,"Baltanas Samuel-Felipe,Ruiz-Sarmiento Jose-Raul,Gonzalez-Jimenez Javier","Baltanas SF,Ruiz-Sarmiento JR,Gonzalez-Jimenez J",Baltanas SF,,Universidad de Malaga,"Mobile robotics has surged in popularity with the emergence of applications for commercial and industrial use such as autonomous cars, drones, or warehouse robots. Accordingly, new practitioners versed both in the theoretical and the practical aspects of the field are on high demand. Supporting material is key for the training of such stakeholders, especially in a multidisciplinary field such as robotics, which includes numerous and heterogeneous concepts from mathematics, statistics, physics, etc. In this regard, these complex concepts are better understood when presented in the context in which they are applied, where the environment, goals, and actions can be clearly visualized. This fact calls for modern and quality material using methodologies and tools applied to real use cases, seamlessly introducing theoretical concepts and their implementation and moving away from the traditional theory/exercise pedagogical approach.
This paper presents a collection of educational Jupyter Notebooks for use in undergraduate robotics courses, which have been built from the ground up to meet these issues. First, they make use of the Python programming language, praised both for its ease of use and the breadth of its library support. It has gained particular relevancy in Computer and Data Science applications, which can be of use in a field increasingly reliant on machine learning approaches as mobile robotics. Second, they are implemented using the Jupyter Notebook technology, widely resorted to in well-known online learning platforms such as Coursera or Udacity. Jupyter Notebooks permit us to combine at the same place theoretical explanations through text, images, mathematical equations, videos and/or links to additional resources, as well as executable code, this way producing comprehensive and contextualized material that incorporates the interactivity, dynamic visualizations and possibilities of an application. The notebooks provide a broad view of the robotics field, with a particular emphasis on mobile robotics, as they cover aspects like: probability bases, robot motion, sensing, localization, mapping, or motion planning.
The developed notebooks are meant to be an engaging tool for mobile robotics lecturers, students and practitioners seeking to enhance their knowledge basis. Currently they are being used in undergraduate courses at the University of Malaga (Spain) with promising results. The student version (without solutions) of the presented notebooks is publicly available at https://github.com/jotaraul/jupyter-notebooks-for-robotics-courses, while the complete version can be requested individually by any interested lecturer. This learning tool welcome any contribution from the mobile robotics community.","Mobile robotics courses,undergraduate courses,Jupyter Notebook",Proceedings Paper,"IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT, LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN",Education & Educational Research,,,"HOME,LOCALIZATION",,,
11,BIOSIGNALS NOTEBOOKS: AN INNOVATIVE APPROACH FOR BIOSIGNALS EXPERIENCE SHARING,,,8194-8200,"Varandas R.,Ramos G.,Mrotzeck K.,Gamboa P.,Gamboa H.","Varandas R,Ramos G,Mrotzeck K,Gamboa P,Gamboa H",Varandas R,,"PLUX Wireless Biosignals SA, Lisbon, Portugal.","Online content creation is ever-growing, presenting an interesting way of creating learning contexts since it constitutes an opportunity for people in different time zones and with different schedules to share their knowledge. In the particular case of Biomedical Engineering training on biosignals analysis, which can be utilized in multiple applications, it might be difficult for non-specialists to understand specific content for each concrete application. The biosignalsnotebooks project emerged with the purpose of sharing the applied knowledge of specialists regarding various types of matters, such as, data collection, signal processing and its analysis, and machine learning, besides the encouragement for people to contribute with their own knowledge. Jupyter Notebooks were used to answer these needs, which provide the means to develop an open-source and open-access way to create interactive computing and interactive materials. Through Jupyter Notebooks, our own content is generated but it also enables users to contribute and create their own resources, which enriches users' experience and facilitates the learning process by having a standardized template and easily readable layout. Moreover, the notebooks allow to combine content presentation, programming and to make hands-on experiences in a single platform, easing the interaction between the users and the content. The acceptance of the proposed format was assessed in a multitude of workshops presenting the biosignalsnotebooks project and it is demonstrated by the increasing number of users.","Biosignals,Signal Processing,E-Content,Experience Sharing",Proceedings Paper,"IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT, LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN",Education & Educational Research,,,,,,
12,Computational imaging of label-free cells using lens-less digital holography,11251,,,"Chen Duofang,Luo Xixin,Wang Zhaohui,Liang Jimin,Chen Xueli","Chen DF,Luo XX,Wang ZH,Liang JM,Chen XL",Chen XL,10.1117/12.2543981,"Minist Educ, Engn Res Ctr Mol & Neuro Imaging, Xian, Shaanxi, Peoples R China.","Avoiding adverse effects of staining reagents on cellular viability and cell signaling, label-free cell imaging and analysis is essential to personalized genomics, drug development, and cancer diagnostics. By analyzing the images of cells, image-based cell analytic methodologies offer a relatively simple and economical way to understand the cell heterogeneities and developments. Owing to the developments in high-resolution image sensors and high-performance computation processors, the emerging lens-less digital holography techniques enable a simple and cost-effective approach to obtain label-free cell images with large field of view and microscopic spatial resolution. In this work, the lens-less digital holography technique is adopted for image-based cell analysis. The holograms of three kinds of cells which are MDA-MB231, EC-109 and MCF-10A respectively were recorded by a lens-less digital holography system composed of a laser diode, a sample holder, a sensor and a laptop computer. The acquired holograms are first high-pass filtered. Then the amplitude images were reconstructed using the angular spectrum method and the sample to sensor distance was determined using the autofocusing criteria based on the sparsity of image edges and corner points. The convolutional neural network (CNN) was used to classify the cells. The experiments show that an accuracy of 97.2% can be achieve for two type cell classification and 91.2% for three type cell classification. It is believed that the lens-less holography combining with machine learning holds great promise in the application of stainless cell imaging and classification.","Computational imaging,lens-less digital holography,autofocusing,label-free imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Microscopy,Optics",,,,,,
13,Deep Learning Cell Segmentation in Chondrocyte Viability Assessment using Nonlinear Optical Microscopy,11251,,,"Chen Xun,Wyman Nicole,Li Yang,Zhang Zheng,Gannon Steven,Rose Chelsea,Lutas Maria,Gao Bruce,Ye Tong","Chen X,Wyman N,Li Y,Zhang Z,Gannon S,Rose C,Lutas M,Gao B,Ye T",Ye T,10.1117/12.2547088,Clemson University,"In the recent studies of cartilage imaging with nonlinear optical microscopy, we discovered that autofluorescence of chondrocytes provided useful information for the viability assessment of articular cartilage. However, one of the hurdles to apply this technology in research or clinical applications is the lack of image processing tools that can perform automated and cell-based analysis. In this report, we present our recent effort in the cell segmentation using deep learning algorithms with the second harmonic generation images. Two traditional segmentation methods, adaptive threshold, and watershed, were used to compare the outcomes of different methods. We found that deep learning algorithms did not show a significant advantage over the traditional methods. Once the cellular area is determined, the viability index is calculated as the intensity ratio between two autofluorescence channels in the cellular area. We found the viability index correlated well with the chondrocyte viability. Again, deep learning segmentation did not show a significant difference from the traditional segmentation methods in terms of the correlation.","Deep learning,Chondrocyte viability,Label-free tissue imaging,Nonlinear optical microscopy,Second harmonic generation microscopy,Autofluorescence",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Microscopy,Optics",,,,,,
14,How to choose and optimize a classifier for your polarimetric imaging data?,11251,,,"Rehbinder Jean,Heinrich Christian,Pierangelo Angelo,Zallat Jihad","Rehbinder J,Heinrich C,Pierangelo A,Zallat J",Heinrich C,10.1117/12.2546032,Universites de Strasbourg Etablissements Associes,"Mueller polarimetry is a powerful characterization technique for a variety of samples and a promising optical-biopsy tool for early detection of cancer. Recent advances in Mueller imaging devices allow the collection of large ex-vivo and invivo image databases. Although the technique is sensitive to subtle changes in the micro-organization of tissue, the Mueller matrices of such complex media contain intertwined polarimetric effects and are difficult to interpret. To identify the polarimetric signature of a given tissue modification (cancerous or not), machine learning tools are particularly well suited. However, a statistically sound approach is needed to make the most out of these tools and avoid common pitfalls. We present a global statistical framework based on decision theory. It consists of a complete preprocessing and analysis pipeline for polarimetric bioimages. In the analysis stage, we use a loss-risk-based approach to automatically select the optimal classifier among a library of classifiers. The approach allows to determine the subset of polarimetric parameters of interest, to determine the parameters of the classifiers and to assess classifier performance using cross-validation. The proposed framework is illustrated with precancer detection on human ex-vivo cervical samples.","Biomedical optics,polarimetry,optical biopsy,cancer diagnosis",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Microscopy,Optics",,,,,,
15,Classification of Hazardous Chemicals with Raman Spectrum by Convolution Neural Network,,,24-28,"Pan Liangrui,Pipitsunthonsan Pronthep,Chongcheawchamnan Mitchai","Pan LR,Pipitsunthonsan P,Chongcheawchamnan M",Pan LR,,Prince of Songkla University,"Dangerous chemicals have always been the hidden danger of social security, how to accurately identify chemicals is very important. In this experiment, the Raman scattering instrument will provide us with the Raman spectrum signal of about 190 chemical substances, each of which has its own characteristics. However, the traditional methods of identifying and classifying chemicals are not only inefficient, but also lack of security. This study proved the feasibility of using neural network to classify chemical substances. For one-dimensional signal, the experiment mainly uses the semi-supervised learning method to establish the 1D-DCNN model and simulate the real noise environment. One-dimensional signal is used as input and then the model is trained to get the model. The experimental results show that the accuracy of toxic and toxic, flammable, corrosive, environment hazard, health hazard, safe, expansive, harmful classification is 99% 1% This shows that the 1D-DCNN model has strong anti-interference and robustness for signals in noise environments. This rapid classification method will provide reference value for the identification of chemical substances.","Raman Spectrum Signal,Hazardous Chemicals,Classification,Noise environment,1D-DCNN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,RECOGNITION,,,
16,Recognition System of Positions of Joints of Hands in an X-ray photograph to Develop an Automatic Evaluation System for Rheumatoid Arthritis Using Machine Learning,,,216-221,"Makino Koji,Koyama Kensuke,Hioki Yuri,Haro Hirotaka,Terada Hidetsugu","Makino K,Koyama K,Hioki Y,Haro H,Terada H",Makino K,,University of Yamanashi,"Rheumatoid arthritis is a disease of the joint that are destroyed, it is difficult for a patient with serious condition to live his or her everyday life. It is important to evaluate the condition of rheumatoid arthritis in order to give the suitable treatment. However, the evaluation task takes time and is necessary to experience of the doctor. Therefore, it is desirable to develop the automatic evaluation system. Our objective goal is to develop the automatic evaluation system that can be updated using the revised data obtained by the doctor. It is clear that the evaluation system of the doctor consists of the recognition system and the classification system. This paper proposes the recognition of the joint in the X-ray photograph using the machine learning. To realize the system, we separate the recognition system into four procedure; convert procedure, training procedure, validation procedure, and feedback procedure. And the effectiveness of the proposed system is investigated using the real X-ray photographs of the patients with rheumatoid arthritis. As a result, it is clear that a lot of correct data are necessary to improve the accuracy. Therefore, it is clear that the it is more effective to improve the accuracy, if the revised data obtained by the doctor are feedbacked to the training system.","rheumatoid arthritis,machine learning,evaluation system,implicit knowledge",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,DISEASE,,,
17,Gene mutation detection for breast cancer disease: A review,830,,,"Wisesty U. N.,Mengko T. R.,Purwarianti A.","Wisesty UN,Mengko TR,Purwarianti A",Wisesty UN,10.1088/1757-899X/830/3/032051,Institute Technology of Bandung,"Breast cancer is one of the most common diseases suffered, especially by women, in the world, and about two billion new cases of patients with breast cancer in 2018. Therefore, it is very important to detect cancer early. Early detection of cancer can be done through the analysis of DNA abnormalities from blood cell samples, where the sampling does not require surgery, non-invasive and painless, and can reduce the sampling cost. DNA abnormalities can occur due to heredity or gene mutation. This paper presents a systematic review that includes an explanation of DNA sequences, gene mutations that occur in breast cancer, and bioinformatics techniques for detecting breast cancer. From several studies that have been conducted in the medical field there are mutations in the BRCA1, BRCA2, and PALB2 genes, where mutations in these genes can cause an increased risk of breast cancer. Other gene mutations associated with cancer risk are ATM, BARD1, CDH1, CHEK2, MRE11A, NBN, TP53, PTEN, RAD50, RECQL, RINT1. In bioinformatics, breast cancer detection based on DNA sequence data is carried out in three phases namely data mapping, feature extraction, and prediction / classification. The methods that can be used are Voss mapping and its variations for data mapping, statistical feature representation approach and Wavelet analysis for feature extraction, and regression approaches, probability models, Support Vector Machines, Neural Networks and Deep Learning for classification.","PREDICTION,BRCA2,RISK",Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Engineering,Materials Science",,,"PREDICTION,BRCA2,RISK",,https://doi.org/10.1088/1757-899x/830/3/032051,
18,Machine learning based health assessment model for high pressure output pumps in LNG terminals,461,,,"YuyunZeng,Zhu Wenbo,Yang Jingjie,Xie Guangyao,Liu Jingquan","YuyunZeng,Zhu WB,Yang JJ,Xie GY,Liu JQ",Liu JQ,10.1088/1755-1315/461/1/012085,Tsinghua University,"High pressure output pumps are one of the critical equipment in LNG terminals. Since the health condition of high pressure output pumps has a direct influence on production capability of the terminal, health assessment for these pumps in real time plays an important role on guaranteeing efficient productivity of LNG terminals. Using condition monitoring data, a machine learning based health assessment model for high pressure output pumps is proposed. Health features are constructed based on time domain statistical analysis and wavelet packet decomposition, and a SVR model is trained to calculate a health index from extracted features. Actual operating data in Qingdao LNG terminal are used for model validation. Results show that the calculated health indices are sensitive to faults and anomalies of the pumps, and are good indicators of pump health status. The proposed model also shows capability of early warning for some sudden failures, which can be valuable in the operation and maintenance management of LNG terminal equipment.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Energy & Fuels,Engineering",,,,,https://doi.org/10.1088/1755-1315/461/1/012085,
19,Artificial Neural Network Topology Optimization using K-Fold Cross Validation for Spray Drying of Coconut Milk,778,,,"Ming Jesse Lee Kar,Taip Farah Saleena,Anuar Mohd Shamsul,Noor Samsul Bahari Mohd,Abdullah Zalizawati","Ming JLK,Taip FS,Anuar MS,Noor SBM,Abdullah Z",Taip FS,10.1088/1757-899X/778/1/012094,Universiti Putra Malaysia,"In this study, the development of an optimized topology neural network model for spray drying coconut milk is investigated using K-fold cross validation technique. Performance between standalone ANN and ANN with K-fold cross validation is compared, as K-fold cross validation method is integrated into neural network to overcome the limitations of restricted dataset. With inlet temperature (140 degrees C-180 degrees C), concentration of maltodextrin and sodium caseinate (0 w/w %- 10w/w %) are established as the input parameters, while moisture content (3.64%-5.1%), outlet temperature (76.5 degrees C-104.5 degrees C) and surface free fat percentage (0.35%-34.51%) are the output parameters for the neural network. Experimental data from the spray drying process is used to develop the neural network. Selection from the best training algorithm (gradient descent backpropagation, gradient descent with momentum, resilience backpropagation, conjugate gradient backpropagation with Polak-Riebre restarts, conjugate gradient backpropagation with Fletcher-Reeves, scaled conjugate gradient, Broyden-Flectcher-Goldfard-Shanno backpropagation algorithm and Levenberg-Marquardt backpropagation), transfer function (tansig, logsig, purelin and satlin), number of training runs (1000-5000), number of hidden layers (1-3) and nodes (5-15) have significant effect on the performance of the ANN models based on the lowest MSE values and R2 values. Overall, the optimum topology ANN model with k-fold cross validation outperformed the recorded lowest MSE value of 0.064 and highest R2 value of 0.855 compared to the optimum standalone ANN model with MSE value of 0.082 and R2 value of 0.832. The optimum ANN with K-fold cross validation implements the Levenberg-Marquart training algorithm with hyperbolic tangent sigmoid transfer function using 4500 times training runs with optimal topology configuration of 3-8-2-3. Result concludes that the developed neural network using K-fold cross validation represents the spray drying process as a highly reliable model with high degree of accuracy.","FOOD INGREDIENTS,PREDICTION,MODELS,BEWARE",Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Engineering,Operations Research & Management Science,Materials Science",,,"FOOD,INGREDIENTS,PREDICTION,MODELS,BEWARE",,https://doi.org/10.1088/1757-899x/778/1/012094,
20,A NEW METHOD FOR COMPLEXITY DETERMINATION BY USING FRACTALS AND ITS APPLICATIONS IN MATERIAL SURFACE CHARACTERISTICS,14,3,705-716,"Babic Matej,Fragassa Cristiano,Lesiuk Grzegorz,Marinkovic Dragan","Babic M,Fragassa C,Lesiuk G,Marinkovic D",Fragassa C,10.24874/IJQR14.03-04,University of Bologna,"In this article, a new method for complexity determination by using fractals in combination with an artificial intelligent approach is proposed and its application in laser hardening technology is detailed. In particular, nanoindentation tests were applied as a way to investigate the hardness properties of tool steel alloys with respect to both marginal and relevant changes in laser hardening parameters. Specifically, process duration and temperature were considered, together with nanoindentation, later related to surface characteristics by image analysis and Hurst exponent determination. Three different Machine Learning algorithms (Random Forest, Support Vector Machine and k-Nearest Neighbors) were used and predictions compared with measures in terms of mean, variability and linear correlation. Evidences confirmed the general applicability of this method, based on integrating fractals for microstructure analysis and machine learning for their deep understanding, in material science and process engineering.","Fractals,Complexity,Machine Learning,Laser Hardening,Surface Quality",Article,"UNIV MONTENENGRO, CENTER QUALITY, UNIV MONTENENGRO, CENTER QUALITY, PODGORICA, 00000, MONTENEGRO",Engineering,,,"LASER,DIMENSION",INTERNATIONAL JOURNAL FOR QUALITY RESEARCH,https://doi.org/10.24874/ijqr14.03-04,
21,Application of acidification parameter optimization method,446,,,"Liu Qilun,Cao Jiefeng,Long Changjun,Zeng Zhiguo,Liu Wenge,Zhang Yingying,Su Dandan,Zhang Xu,Jia Jiangfen,Huang Bohua","Liu QL,Cao JF,Long CJ,Zeng ZG,Liu WG,Zhang YY,Su DD,Zhang X,Jia JF,Huang BH",Liu QL,10.1088/1755-1315/446/5/052032,"Huabei Oil Co, Engn Technol Res Inst, Renqiu City, Peoples R China.","The acidification technology is an important measure to increase the production and increase the injection of oil and water wells. However, due to the complicated working conditions of the acidification measures and the difficulty in determining the construction parameters, it is necessary to establish the acidification model of the injection wells and optimize the parameters. The paper uses the grey correlation analysis method to find the correlation between each construction parameter and the daily injection volume of the injection well, establishes the BP neural network program, trains it according to the existing data and predicts the artificial controllable parameters in turn to find the best construction parameter combination. Taking a single well as an example to predict the parameters and guide the on-site construction. The results show that combining the mathematical method with the acidification construction technology of the injection well and establishing the model prediction parameters can significantly improve the injection efficiency of the injection well.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Energy & Fuels,Engineering,Environmental Sciences & Ecology",,,,,https://doi.org/10.1088/1755-1315/446/5/052032,
22,Improved population initialization method and its application in bridge optimization,446,,,"Yang Ronghao,Zhao Yunpeng,Si Haipeng,Li Zhigang,Wang Ruizheng,Peng Kai","Yang RH,Zhao YP,Si HP,Li ZG,Wang RZ,Peng K",Yang RH,10.1088/1755-1315/446/5/052013,Chang'an University,"When solving bridge optimization problems by traditional genetic algorithms, a random method is often used to generate the initial population, which can't ensure that the initial population is evenly distributed in the solution space and reasonably represents the solution space. In order to solve the shortcomings of random method, an improved population initialization method is proposed by combining random method with good point set. Based on it, aimed at the characteristic of implicit non-linear objective function or constraint function in bridge structure optimization, a BP neural network is used to simulate the relations between the objective function or constraint function and design variables. Then this paper takes a steel truss bridge as an example of optimization. Taken the allowable deflection of bridges as limit and aiming at minimizing the amount of steel, optimization model of bridge is established. Finally, the improved population initialization method is applied to solve the optimization model. The results show that the improved population initialization method can not only improve the uniformity of the population, but also be suitable for optimization design of bridges.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Energy & Fuels,Engineering,Environmental Sciences & Ecology",,,,,https://doi.org/10.1088/1755-1315/446/5/052013,
23,Anomaly Detection of Arm X-Ray Based on Deep Learning,440,,,Wang Jingchen,Wang JC,Wang JC,10.1088/1755-1315/440/4/042056,"Phillips Exeter Acad, 20 Main St, Exeter, NH 03833 USA.","The goal of this paper is to determine whether the arm has a fracture by detecting the X-ray of the human arm. This paper used the Keras deep learning framework and use the NASNetMobile model for training. The data set is MURA-v1.1, and the test accuracy on the verification set is about 70%. After downloading X-ray photographs of fractured arms, this paper performed an anomaly detection of the single image to test the accuracy of the model.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND",Environmental Sciences & Ecology,,,,,https://doi.org/10.1088/1755-1315/440/4/042056,
24,Encoding Rich Frequencies for Classification of Stroke Patients EEG Signals,8,,135811-135820,"Fawaz Sammani,Sim Kok Swee,Tan Shing Chiang","Fawaz S,Sim KS,Tan SC",Sim KS,10.1109/ACCESS.2020.3011185,Multimedia University,"The stroke, which is a sudden cut in the blood supply in the brain, has become a severe phenomenon. It has affected around 15 million people annually worldwide. Methods of stroke discovery and monitoring the patient's recovery are a long process, ranging from the analysis of medical images to frequent reporting of the patients for progress assessment. In this paper, we aim to process stroke patient EEG signals by a deep learning approach, and classify a given EEG signal into stroke/non-stroke. In particular, our model consists of several sub-modules which convert and re-model widely used signal processing techniques such as the Fast Fourier Transform (FFT), Convolution in the Frequency Domain and the Inverse Fast Fourier Transform (IFFT) to learnable and differentiable functions that are completely learned and optimized in an end-to-end manner by neural networks. We demonstrate that our model outperforms several baselines by learning rich frequency features through our proposed model. The proposed model could potentially assist a medical doctor in analyzing stroke brain images with high accuracy rates. It can also be useful for rehabilitation centers to monitor the progress of stroke patients.","Electroencephalography,Feature extraction,Brain modeling,Machine learning,Convolution,Fast Fourier transforms,Stroke,EEG,signal processing,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09145945.pdf,
25,Grain Boundary Detection Based on Multi-Level Loss From Feature and Adversarial Learning,8,,135640-135651,"Li Mingchun,Chen Dali,Liu Shixin","Li MC,Chen DL,Liu SX",Chen DL,10.1109/ACCESS.2020.3011703,Northeastern University - China,"The shape, size and distribution of grains play an important role in the quality of alloy materials. However, in the actual production process, the grain boundary is not always visible in the metallographic image observed by microscope. In this paper, we propose an end-to-end deep network named GF-RCF based on adversary network and feature learning to detect grain boundaries effectively. The network is guided by a novel multi-level loss through its three parts: base network, adversary network and metric module, which are used for boundary detection, boundary inpainting and feature learning respectively. Specifically, for base network, its architecture is based on richer convolution feature to achieve basic boundary detection by pixel-level loss. For adversary network, it employs the image-level adversary loss and feature matching loss to repair the invisible boundary. For metric module, it involves a feature learning strategy by comparing the features of unlabeled data with the labeled data to improve the generalization of the network. The multi-level loss refers to the total loss of pixel-level, image-level and feature-level obtained from the three subnetwork, respectively. From the perspective of machine learning, GF-RCF involves semi-supervised learning, transfer learning and generative adversarial network, which makes our model have more powerful learning ability. In experiments, GF-RCF achieves 0.8792 F1 score, surpassing other methods and reaching the state of the art.","Feature extraction,Grain boundaries,Generative adversarial networks,Task analysis,Machine learning,Metals,Measurement,Grain detection,boundary detection,generative adversarial network,semi-supervised learning,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SIZE,DETERMINATION,IMAGES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146826.pdf,
26,An Efficient IoT-Based Patient Monitoring and Heart Disease Prediction System Using Deep Learning Modified Neural Network,8,,135784-135797,Sarmah Simanta Shekhar,Sarmah SS,Sarmah SS,10.1109/ACCESS.2020.3007561,"Alpha Clin Syst Inc, Piscataway, NJ 08854 USA.","The leading causes of death worldwide are chronic illnesses suchlike diabetes, Heart Disease (HD), cancer as well as chronic respiratory malady. It is remarkably intricate to diagnose HD with disparate symptoms or features. With the augmentation in popularity of smart wearable gadgets, a chance to render an Internet of Things (IoT) solution has turned out to be more. Unfortunately, the survival rates are low for the people suffering from sudden heart attacks. Consequently, a patient monitoring scheme intended for heart patients utilizing IoT centered Deep Learning Modified Neural Network (DLMNN) is proposed to assist in the HD diagnosis, and medication is given accordingly. This proposed technique is executed via '3' steps: I) Authentication, ii) Encryption, and iii) Classification. First, by utilizing the substitution cipher (SC) together with the SHA-512, the heart patient of the specific hospital is authenticated. Subsequently, the wearable IoT sensor device, which is fixed to the patient's body, concurrently transmits the sensor data to the cloud. This sensor data is encrypted and securely transmitted to the cloud utilizing the PDH-AES technique. After that, the encrypted data is finally decrypted, and by employing the DLMNN classifier, the classification is done. The classified outcomes comprise '2'types of data: i) normal and ii) abnormal. It denotes the patient's heart condition and if the outcome is abnormal, an alert text is passed to the physician for treating the patient. The investigational outcomes are estimated and the DLMNN for HD diagnosis shows improvement as compared to existing algorithms. Additionally, the proposed PDH-AES used in support of secure data transmission results in the highest level of security i.e. 95.87%, and it is achieved in the lowest time for encryption along with decryption when weighted against the existent AES.","Disease prediction,healthcare monitoring system,Internet of Things (IoT),advanced encryption standard (AES),modified Huffman algorithm (MHA),deep learning modified neural network (DLMNN),Cuttlefish optimization algorithm (CFOA)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"CLOUD,ARCHITECTURE,ALGORITHM,DIAGNOSIS,INTERNET",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09133567.pdf,
27,Simulation of hyperelastic materials in real-time using deep learning,59,,,"Mendizabal Andrea,Marquez-Neila Pablo,Cotin Stephane","Mendizabal A,Marquez-Neila P,Cotin S",Cotin S,10.1016/j.media.2019.101569,Inria,"The finite element method (FEM) is among the most commonly used numerical methods for solving engineering problems. Due to its computational cost, various ideas have been introduced to reduce computation times, such as domain decomposition, parallel computing, adaptive meshing, and model order reduction. In this paper we present U-Mesh: A data-driven method based on a U-Net architecture that approximates the non-linear relation between a contact force and the displacement field computed by a FEM algorithm. We show that deep learning, one of the latest machine learning methods based on artificial neural networks, can enhance computational mechanics through its ability to encode highly nonlinear models in a compact form. Our method is applied to three benchmark examples: a cantilever beam, an L-shape and a liver model subject to moving punctual loads. A comparison between our method and proper orthogonal decomposition (POD) is done through the paper. The results show that U-Mesh can perform very fast simulations on various geometries and topologies, mesh resolutions and number of input forces with very small errors. (C) 2019 Elsevier B.V. All rights reserved.","Real-time simulation,Deep neural networks,Physics-based simulation,Finite element method,Hyperelasticity,Reduced order model",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"SOFT-TISSUES,MODEL,REDUCTION,FRAMEWORK,ALGORITHM,LIVER",MEDICAL IMAGE ANALYSIS,https://hal.inria.fr/hal-02097119/file/hal_version_media_paper.pdf,
28,'Squeeze & excite' guided few-shot segmentation of volumetric images,59,,,"Roy Abhijit Guha,Siddiqui Shayan,Poelsterl Sebastian,Navab Nassir,Wachinger Christian","Roy AG,Siddiqui S,Polsterl S,Navab N,Wachinger C",Roy AG,10.1016/j.media.2019.101587,University of Munich,"Deep neural networks enable highly accurate image segmentation, but require large amounts of manually annotated data for supervised training. Few-shot learning aims to address this shortcoming by learning a new class from a few annotated support examples. We introduce, a novel few-shot framework, for the segmentation of volumetric medical images with only a few annotated slices. Compared to other related works in computer vision, the major challenges are the absence of pre-trained networks and the volumetric nature of medical scans. We address these challenges by proposing a new architecture for few-shot segmentation that incorporates 'squeeze & excite' blocks. Our two-armed architecture consists of a conditioner arm, which processes the annotated support input and generates a task-specific representation. This representation is passed on to the segmenter arm that uses this information to segment the new query image. To facilitate efficient interaction between the conditioner and the segmenter arm, we propose to use 'channel squeeze & spatial excitation' blocks - a light-weight computational module - that enables heavy interaction between both the arms with negligible increase in model complexity. This contribution allows us to perform image segmentation without relying on a pre-trained model, which generally is unavailable for medical scans. Furthermore, we propose an efficient strategy for volumetric segmentation by optimally pairing a few slices of the support volume to all the slices of the query volume. We perform experiments for organ segmentation on whole-body contrast-enhanced CT scans from the Visceral Dataset. Our proposed model outperforms multiple baselines and existing approaches with respect to the segmentation accuracy by a significant margin. The source code is available at https://github.comiabhi4ssj/few-shot-segmentation. (C) 2019 Elsevier B.V. All rights reserved.","Few-shot learning,Squeeze & excite,Semantic segmentation,Deep learning,Organ segmentation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,EXAMPLE,MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/1902.01314,
29,Fast volumetric mapping of human brain slices,11226,,,"Pesce Luca,Laurino Annunziatina,Gavryusev Vladislav,Mazzamuto Giacomo,Sancataldo Giuseppe,Scardigli Marina,Roffilli Matteo,Silvestri Ludovico,Costantini Irene,Pavone Francesco Saverio","Pesce L,Laurino A,Gavryusev V,Mazzamuto G,Sancataldo G,Scardigli M,Roffilli M,Silvestri L,Costantini I,Pavone FS",Pavone FS,10.1117/12.2544133,University of Florence,"We still lack a detailed map of the anatomical disposition of neurons in the human brain. A complete map would be an important step for deeply understanding the brain function, providing anatomical information useful to decipher the neuronal pattern in healthy and diseased conditions. Here, we present several important advances towards this goal, obtained by combining a new clearing method, advanced Light Sheet Microscopy and automated machine-learning based image analysis. We perform volumetric imaging of large sequentially stained human brain slices, labelled for two different neuronal markers NeuN and GAD67, discriminating the inhibitory population and reconstructing the brain connectivity.","Light sheet microscopy,whole brain imaging,quantitative imaging,tissue clearing,human brain",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Neurosciences & Neurology,Optics",,,,,https://doi.org/10.1101/2020.10.27.357186,
30,Regularization Techniques for Inverse Problem in DOT Applications,1476,,,"Benfenati A.,Causing P.,Lupieri M. G.,Naldi G.","Benfenati A,Causing P,Lupieri MG,Naldi G",Benfenati A,10.1088/1742-6596/1476/1/012007,University of Milan,"Diffuse optical tomography (DOT) is an emerging diagnostic technique which uses near infra red light to investigate the optical coefficients distribution in biological tissues. The surface of the tissue is illuminated by light sources, then the outgoing light is measured by detectors placed at various locations on the surface itself. In order to reconstruct the optical coefficients, a mathematical model of light propagation is employed: such model leads to the minimization of the discrepancy between the detected data and the corresponding theoretical field. Due to severe ill conditioning, regularization techniques are required: common procedures consider mainly l(1)-norm (LASSO) and l(2)-norm (Tikhonov) regularization. In the present work we investigate two original approaches in this context: the elastic net regularization, previously used in machine learning problems, and the Bregman procedure. Numerical experiments are performed on synthetic 2D geometries and data, to evaluate the performance of these approaches. The results show that these techniques are indeed suitable choices for practical applications, where DOT is used as a cheap, first-level and almost real-time screening technique for breast cancer detection.","VARIABLE SELECTION,TOMOGRAPHY",Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Computer Science,Mathematics",,,"VARIABLE,SELECTION,TOMOGRAPHY",,https://air.unimi.it/bitstream/2434/722519/2/Benfenati_2020_J._Phys.%253A_Conf._Ser._1476_012007.pdf,
31,Restoration of Lossy JPEG-Compressed Brain MR Images Using Cross-Domain Neural Networks,27,,141-145,"Chung Kevin J.,Souza Roberto,Frayne Richard","Chung KJ,Souza R,Frayne R",Frayne R,10.1109/LSP.2019.2961072,University of Calgary,"Lossy image compression allows for efficient storage and transfer of image data with varying degrees of image degradation. However, lossy compression is not commonly used in medical imaging as the process may irreversibly remove information that defines clinically important image features. The lossy component of JPEG compression is represented as lost precision in the discrete cosine transform (DCT) domain after quantization on 8 x 8 image blocks and results in degradation of the image. We propose a cross-domain cascade of U-nets called the W-net. This network operates in the DCT domain to restore discarded DCT coefficients that leverages information from adjacent blocks, and the image domain to suppress compression artifacts at the image pixel level. For comparison, we adapted the Automated Transform by Manifold Approximation (AUTOMAP) method for JPEG decompression by learning the dequantization of individual 8 x 8 DCT coefficient blocks. These results were then transformed to the image domain and processed by a U-net. The deep learning models were able to suppress common compression artifacts at the expense of high spatial frequency detail. Both the W-net and AUTOMAP network structures were quantitatively superior to standard JPEG decompression, with the W-net outperforming AUTOMAP, suggesting that leveraging DCT coefficients from adjacent blocks improves JPEG decompression performance.","Convolutional neural network (CNN),image reconstruction,JPEG decompression,teleradiography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,,IEEE SIGNAL PROCESSING LETTERS,,
32,Accelerating small-angle scattering experiments with simulation-based machine learning,3,1,,"Kanazawa Takuya,Asahara Akinori,Morita Hidekazu","Kanazawa T,Asahara A,Morita H",Kanazawa T,10.1088/2515-7639/ab3c45,Hitachi Limited,"Making material experiments more efficient is a high priority for materials scientists who seek to discover new materials with desirable properties. In this paper, we investigate how to optimize the laborious sequential measurements of materials properties with data-driven methods, taking the small-angle neutron scattering (SANS) experiment as a test case. We propose two methods for optimizing sequential data sampling. These methods iteratively suggest the best target for the next measurement by performing a statistical analysis of the already acquired data, so that maximal information is gained at each step of an experiment. We conducted numerical simulations of SANS experiments for virtual materials and confirmed that the proposed methods significantly outperform baselines.","machine learning,small-angle scattering,indirect Fourier transform,optimal experimental design",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,,DESIGN,JOURNAL OF PHYSICS-MATERIALS,http://arxiv.org/pdf/1908.09102,
33,Fake News and Deepfakes: A Dangerous Threat for 21st Century Information Security,,,57-66,"Botha Johnny,Pieterse Heloise","Botha J,Pieterse H",Botha J,10.34190/ICCWS.20.085,"Council Sci & Ind Res CSIR, Pretoria, South Africa.","Fake news, often referred to as junk news or pseudo-news, is a form of yellow journalism or propaganda created with the purpose of distributing deliberate disinformation or false news using traditional print or online social media. Fake news has become a significant problem globally in the past few years. It has become common to find popular individuals and even members of the state using misinformation to influence individuals' actions whether consciously or subconsciously. The latest trend is using Artificial Intelligence (AI) to create fake videos known as ""deepfakes"". Deepfake, a portmanteau of "" deep learning"" and ""fake"", is an artificial intelligence-based human image synthesis technique. It is used to combine and superimpose existing images and videos onto source images or videos using a machine learning technique called a ""generative adversarial network"" (GAN). The combination of the existing and source videos results in a fake video that shows a person or persons performing an action at an event that never occurred in reality. This paper provides an overview of the currently available creation and detection techniques to identify fake news and deepfakes. The outcome of this paper provides the reader with an adequate literature review that summarises the current state of fake news and deepfakes, with special attention given to the tools and technologies that can be used to both create and detect fake news or deepfake material.","Artificial Intelligence,deepfake,detection,fake news,machine-learning",Proceedings Paper,"ACAD  CONFERENCES LTD, CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND",Computer Science,,,,,,
34,AI Embedded Transparent Health and Medicine System,1069,,18-26,Gu Yichi,Gu YC,Gu YC,10.1007/978-3-030-32520-6_2,"Cultigene Med Technol Beijing Ltd, Beijing, Peoples R China.","Along with the rapid exploration of intelligent system, AI methods have been applied in health and medicine fields to manage the fast growing medical data in recent years. Scientists and engineers started their first attempts. Medical history is collected and studied for automated diagnose, skin cancer images are deeply learned for auto judgment and classification [1], lung nodules are segmented automatically [2], and the future of medicine is debated in [3]. In this paper, we set up the transparent health and medicine AI system for the future, based on etiological analysis, construct total resolution network, provide accurate orientation and precise treatment, applying intelligent algorithms.","Artificial intelligence,Health law,Genetics,Gene,Medicine,Data analysis,Accurate and precise medicine,Machine learning,Deep learning",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
35,Making Food with the Mind: Integrating Brain-Computer Interface and 3D Food Fabrication,1069,,239-247,"Ninyawee Nutchanon,Thintawornkul Tawan,Pataranutaporn Pat,Ngamarunchot Bank,Itthipuripat Sirawaj Sean,Wilaiprasitporn Theerawit,Promnara Kotchakan,Ngamkajornwiwat Potiwat,Surareungchai Werasak","Ninyawee N,Thintawornkul T,Pataranutaporn P,Ngamarunchot B,Itthipuripat SS,Wilaiprasitporn T,Promnara K,Ngamkajornwiwat P,Surareungchai W",Pataranutaporn P,10.1007/978-3-030-32520-6_19,"Futurist Res Cluster, FREAK Lab, Bangkok 10150, Thailand.","We presented ""Mind-Controlled 3D Printer"" that translates brain signals from the user into 3D printed food. This system integrated an EEG recording device that measures neural activities in real-time with a machine learning algorithm that classify emotional valence and arousal levels, which determine the shape and size of the food fabricated by the food 3D printer. This research introduced the opportunity for combining brain-computer interface (BCI), affective computing, and additive manufacturing technology, which will ultimately enable the automation of mind to matter materialization. We demonstrated three use cases and envisioned the future research on BCI and food fabrication.","Brain-Computer Interface,3D fabrication,Food printing,Cognitive Food,Affective computing",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,STRESS,,,
36,A Local-Network Guided Linear Discriminant Analysis for Classifying Lung Cancer Subtypes using Individual Genome-Wide Methylation Profiles,1069,,676-687,Li Yanming,Li YM,Li YM,10.1007/978-3-030-32520-6_50,University of Michigan System,"Accurate and efficient prediction of lung cancer subtypes is clinically important for early diagnosis and prevention. Predictions can be made using individual genomic profiles and other patient-level covariates, such as smoking status. With the ultrahigh-dimensional genomic profiles, the most predictive biomarkers need to be first selected. Most of the current machine learning techniques only select biomarkers that are strongly correlated with the outcome disease. However, many biomarkers, even though have marginally weak correlations with the outcome disease, may execute a strong predictive effect on the disease status. In this paper, we employee an ultrahigh-dimensional classification method, which incorporates the weak signals into predictions, to predict lung cancer subtypes using individual genome-wide DNA methylation profiles. The results show that the prediction accuracy is significantly improved when the predictive weak signals are included. Our approach also detects the predictive local gene networks along with the weak signal detection. The local gene networks detected may shed lights on the cancer developing and progression mechanisms.","Cancer subtype prediction,Linear discriminant analysis,Local gene network,Ultrahigh-dimensionality",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,"COMMON,GENETIC-VARIATION,MUTATION,SUSCEPTIBILITY,RISK",,,
37,Enhanced light-matter interactions in dielectric nanostructures via machine-learning approach,2,2,,,,,,Xu Lei,"A key concept underlying the specific functionalities of metasurfaces is the use of constituent components to shape the wavefront of the light on demand. Metasurfaces are versatile, novel platforms for manipulating the scattering, color, phase, or intensity of light. Currently, one of the typical approaches for designing a metasurface is to optimize one or two variables among a vast number of fixed parameters, such as various materials' properties and coupling effects, as well as the geometrical parameters. Ideally, this would require multidimensional space optimization through direct numerical simulations. Recently, an alternative, popular approach allows for reducing the computational cost significantly based on a deep-learning-assisted method. We utilize a deep-learning approach for obtaining high-quality factor (high-Q) resonances with desired characteristics, such as linewidth, amplitude, and spectral position. We exploit such high-Q resonances for enhanced light-matter interaction in nonlinear optical metasurfaces and optomechanical vibrations, simultaneously. We demonstrate that optimized metasurfaces achieve up to 400-fold enhancement of the third-harmonic generation; at the same time, they also contribute to 100-fold enhancement of the amplitude of optomechanical vibrations. This approach can be further used to realize structures with unconventional scattering responses.","machine learning,; dielectric nanostructures; Fano resonance; third-harmonic generation; optoacoustics",Article,,,,,,,,
38,Composition Design of High Strength ODS Alloy Based on Machine Learning,54,4,678-682,",,,,,","Bai Bing,Zheng Quan,Ren Shuai,Zhang Changyi,Yang Wen,Hu Changjun",,,Bai Bing,"Based on 200-300 groups data of compositions,processes and mechanical properties,the relationship between the key parameters and tensile property of oxide dispersion strengthened(ODS)alloy was established by machine learning.The results show that the optimum value corresponding to the maximum strength exists in the relationship between the content of Cr,Y_2O_3,W and Ti and the tensile strength of ODS alloy.The addition of Al has no obvious effect on the increase of tensile strength.Therefore,several optimum compositions of ODS alloy were obtained,and the predicted tensile strength at room temperature is above 1 400 MPa.It can help to promote the optimization of ODS alloy as cladding material for fast reactor application.","ODS alloy; tensile property; ,machine learning,material, optimization",Article,,,,,,,,
39,Candidate Sentences Extraction for Machine Reading Comprehension,47,5,198-203,",,,","Guo Xin,Zhang Geng,Chen Qian,Wang Suge",,,Guo Xin,"The ultimate goal of artificial intelligence is to let machine understand human natural language in cognitive field.Machine reading comprehension raises great challenge in natural language processing which requires computer to have certain common knowledge,comprehensively understand text material,and correctly answer the corresponding questions according to that text material.With the rapid development of deep learning,machine reading comprehension becomes the current hotspot research direction in artificial intelligence,involving core technologies such as machine learning,information retrieval,semantic computing and has been widely used in chat robots,question answering systems and intelligent education.This paper focuses on micro-rea-ding mode,and answer candidate sentences containing answers are extracted from given text,which provide technology support for machine reading comprehension.Traditional feature-based methods consumes lots of manpower.This paper regards candidate sentences extracting as a semantic relevance calculation problem,and proposes an Att-BiGRU/LSTM model.First,LSTM and GRU are used to encode the semantic expressed in a sentence.Then,the dissimilarity and similarity are captured with an Atten structure for semantic correlation.Last,adam optimizer is used to learn the model parameters.Experiment results show that Att-BiGRU model exceeds the baseline method of nearly 0.67 in terms of pearson,16.8% in terms of MSE on SemEval-SICK test dataset,which proves that the combination of the bidirectional and Atten structure can greatly improve the accuracy of the candidate sentences extraction,as well as the convergence rate.",Long short term memory; Gated recurrent unit; Candidate sentences extracting; Semantic correlation calculation,Article,,,,,,,,
40,Mineral Raman Spectral Recognition Based on Siamese Network,57,9,,",,","Wu Chengwei,Shi Rujin,Zeng Wandan",,,Wu Chengwei,"Mineral identification is a critical task in geological surveys and in many engineering applications. Compared to the physical methods and chemical methods,Raman spectroscopy provides a faster qualitative and quantitative analysis,and most importantly,its damage to the original mineral is negligible in mineral analysis.But the data analysis based on Raman spectroscopy,results of traditional machine learning methods do not work well, especially in the case of minerals with a large categories.This paper proposes a similarity learning method based on Siamese network.After optimizing the negative samples by Hungarian algorithm,and compared with traditional models,we achieve the best robust results.What Siamese network computes is the similarity between minerals,in addition to the identification of minerals,it can also provide a reference for the alternative materials of the mineral to some extent.","vision; Raman spectroscopy; ,machine learning,; Siamese network; similarity learning; mineral analysis",Article,,,,,,,,
41,CNN Support to Diagnostics in Sjogren's Syndrome,1033,,72-81,"Korzynska Anna,Zak Jakub,Siemion Krzysztof,Roszkowiak Lukasz,Pijanowska Dorota","Korzynska A,Zak J,Siemion K,Roszkowiak L,Pijanowska D",Korzynska A,10.1007/978-3-030-29885-2_7,Polish Academy of Sciences,"Sjogren's Syndrome is a systemic disease. Its diagnosis can be supported by histopathological examination of minor salivary glands. The value of the focus score equal or greater than one ensures the diagnosis of this disease. Human estimation is inherently subjective, which often leads to diverging results during the process of diagnosis. The paper proposes to use U-net CNN to find area of inflammation in WSI to support pathologist in the process of diagnosis by selecting foci for detailed inspection. Proposed neural network was trained based on tiles of size 256x256 pixels in magnification 400x from 13 digital slides stained with hematoxylin and eosin from patients with labial minor salivary gland biopsies. The ground truth was established by manual annotations done by a pathology resident. The accuracy and recall of proposed neural network model on testing dataset show the potential of machine learning for classification problem solving in this field.","Digital microscopy,Deep learning,CNN,U-net,Sjogren's Syndrome",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering,Medical Laboratory Technology",,,,,,
42,"SHAPE-DRIVEN INTERPOLATION WITH DISCONTINUOUS KERNELS: ERROR ANALYSIS, EDGE EXTRACTION, AND APPLICATIONS IN MAGNETIC PARTICLE IMAGING",42,2,B472-B491,"De Marchi S.,Erb W.,Marchetti F.,Perracchione E.,Rossini M.","De Marchi S,Erb W,Marchetti F,Perracchione E,Rossini M",De Marchi S,10.1137/19M1248777,University of Padua,"Accurate interpolation and approximation techniques for functions with discontinuities are key tools in many applications, such as medical imaging. In this paper, we study a radial basis function type of method for scattered data interpolation that incorporates discontinuities via a variable scaling function. For the construction of the discontinuous basis of kernel functions, information on the edges of the interpolated function is necessary. We characterize the native space spanned by these kernel functions and study error bounds in terms of the fill distance of the node set. To extract the location of the discontinuities, we use a segmentation method based on a classification algorithm from machine learning. The results of the conducted numerical experiments are in line with the theoretically derived convergence rates in case that the discontinuities are a priori known. Further, an application to interpolation in magnetic particle imaging shows that the presented method is very promising in order to obtain edge-preserving image reconstructions in which ringing artifacts are reduced.","meshless approximation of discontinuous functions,radial basis function (RBF) interpolation,variably scaled discontinuous kernels (VSDKs),Gibbs phenomenon,segmentation and classification with kernel machines,magnetic particle imaging (MPI)",Article,"SIAM PUBLICATIONS, 3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA",Mathematics,,3.018,"BIVARIATE,LAGRANGE,INTERPOLATION,GIBBS,PHENOMENON,APPROXIMATION,POINTS,SPACES",SIAM JOURNAL ON SCIENTIFIC COMPUTING,https://www.research.unipd.it/bitstream/11577/3335134/2/SIAM2020.pdf,
43,Non-contact Continuous Blood Pressure Measurement Based on Imaging Equipment,11438,,,"Guo Ying);,Liu Xiaohua);,Kong Lingqin,Liu Ming);,Zhao Yuejin);,Dong Liquan","Guo Y,Liu XH,Kong LQ,Liu M,Zhao YJ,Dong LQ",Kong LQ,10.1117/12.2540316,Beijing Institute of Technology,"An optical and non-contact continuous measurement method to detect human blood pressure through a high-speed camera is discussed in this paper. With stable ambient light, photoplethysmographic (PPG) signals of face and palm area are obtained simultaneously from the video captured by high-speed camera, whose frame rate should be higher than 100 frames per second. Pulse transit time (PTT) is measured from the R-wave distance between the two PPG signals. The Partial least-squares regression(PLSR) model was established to train the samples, and the relationship between PTT and blood pressure, including intra-arterial systolic pressure (SBP) and diastolic pressure (DBP), was established to obtain blood pressure. Compared with the output of traditional sphygmomanometer, the blood pressure data collected from non-contact system has little error and meets the fitting conditions. We first proposed an accurate video-based method for non-contact blood pressure measurement using machine learning, and the average error of SBP is 0.148mmHg and of DBP is 0.359mmHg.","non-contact,continuous,blood pressure,PLSR,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Instruments & Instrumentation,Optics",,,"PULSE-WAVE,VELOCITY,TRANSIT-TIME,VALIDATION",,,
44,Classification of Common Recyclable Garbage Based on Hyperspectral Imaging and Deep Learning,11438,,,"Wu Rui,Bin Zhang,Zhao Dong-e","Wu R,Bin Z,Zhao DE",Zhao DE,10.1117/12.2540984,North University of China,"The differences in material properties of various common recyclable garbage will be directly mapped to the difference in spectral characteristics. While acquiring the spectral information of the garbage, the hyperspectral imaging technology can obtain the spatial information of the garbage, and realize the rapid detection and classification of garbage by using the method of ""spectral-spatial"".The classification model is established combined the spectral characteristics under the sample feature space with CNN (convolutional neural network) machine learning algorithm, and then the classification model is trained and optimized by using database training sample set. Finally, 92.10% classification accuracy is achieved after testing the sample set.","spectral characteristics,recyclable garbage,hyperspectral imaging,cnn",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Instruments & Instrumentation,Optics",,,,,,
45,Machine vision based recognition and integrity inspection of printing characters on food package,11439,,,"Jing Zekun,Liu Changjie,Jia Xinlin,Li Zixiong,Chen Dong","Jing ZK,Liu CJ,Jia XL,Li ZX,Chen D",Liu CJ,10.1117/12.2550049,Tianjin University,"Food packaging bags are fast-moving consumer products with large output and fast production speed. Instant noodle bags need to be printed on the production date and number before packaging the food. For the possible date or code printing error, character sticking, incompleteness, etc., the correctness of the characters cannot be judged in real time by the human eye. A set of automatic recognition characters and detection systems are used to binarize, filter and tilt the picture, and use image morphology and horizontal and vertical projection to segment a single character. BP neural network is used to identify the character and compare it to the template to obtain the degree of defect and compare it with the threshold to determine whether the character is qualified. The detection speed of the system can reach 3 images per second, which can realize real-time recognition and detection of characters, so as to eliminate non-conforming products in time.","machine vision,image processing,OCR,BP neural network,defect detection",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Instruments & Instrumentation,Optics",,,NEURAL-NETWORK,,,
46,Modeling of Elastic Mechanical Behavior for Composite Three Layer Panels with Cone Core,2216,,,"Golovin Danila V.,Shipunov Gleb S.,Shestakova Kseniya N.","Golovin DV,Shipunov GS,Shestakova KN",Golovin DV,10.1063/5.0003534,Perm National Research Polytechnic University,"The work is devoted to the description of the development of a mathematical model that allows simulating the process of testing the design of three-layer panels with a cone core. The developed model takes into account the layered structure of the cone core and face sheets, as well as the anisotropic characteristics and the reinforcement scheme of composite materials. The obtained simulation results made it possible to determine the values of stresses and strains in the material of the cone core under conditions of testing the panels for tensile, compression, and three-point bending in the region of elastic deformations.",,Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA","Materials Science,Mathematics,Physics",,,,,,
47,Unsupervised Motion Tracking of Left Ventricle in Echocardiography,11319,,,"Ahn Shawn S.,Ta Kevinminh,Lu Allen,Stendahl John C.,Sinusas Albert J.,Duncan James S.","Ahn SS,Ta K,Lu A,Stendahl JC,Sinusas AJ,Duncan JS",Ahn SS; Ta K,10.1117/12.2549572,Yale University,"Accurate motion tracking of the left ventricle is critical in detecting wall motion abnormalities in the heart after an injury such as a myocardial infarction. We propose an unsupervised motion tracking framework with physiological constraints to learn dense displacement fields between sequential pairs of 2-D B-mode echocardiography images. Current deep-learning motion-tracking algorithms require large amounts of data to provide ground-truth, which is difficult to obtain for in vivo datasets (such as patient data and animal studies), or are unsuccessful in tracking motion between echocardiographic images due to inherent ultrasound properties (such as low signal-to-noise ratio and various image artifacts). We design a U-Net inspired convolutional neural network that uses manually traced segmentations as a guide to learn displacement estimations between a source and target image without ground-truth displacement fields by minimizing the difference between a transformed source frame and the original target frame. We then penalize divergence in the displacement field in order to enforce incompressibility within the left ventricle. We demonstrate the performance of our model on synthetic and in vivo canine 2-D echocardiography datasets by comparing it against a non-rigid registration algorithm and a shape-tracking algorithm. Our results show favorable performance of our model against both methods.","Unsupervised motion tracking,Echocardiography,Deep learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
48,Deep Attentional GAN-based High-Resolution Ultrasound Imaging,11319,,,"He Xiuxiu);,Lei Yang);,Liu Yingzi);,Tian Zhen);,Wang Tonghe);,Curran Walter J.);,Liu Tian);,Yang Xiaofeng","He XX,Lei Y,Liu YZ,Tian Z,Wang TH,Curran WJ,Liu T,Yang XF",Yang XF,10.1117/12.2549556,Emory University,"A routine 3D transrectal ultrasound (TRUS) volume is usually captured with large slice thickness (e.g., 2-5mm). Such ultrasound images with low out-of-slice resolution affect contouring and needle/seed detection in prostate brachytherapy. The purpose of this study is to develop a deep-learning-based method to construct high-resolution images from routinely captured prostate ultrasound images for brachytherapy. We propose to integrate a deeply supervised attention model into a Generative Adversarial Network (GAN)-based framework to improve ultrasound image resolution. Deep attention GANs are introduced to enable end-to-end encoding-and-decoding learning. Next, an attention model is used to retrieve the most relevant information from the encoder. The residual network is used to learn the difference between low- and high-resolution images. This technique was validated with 20 patients. We performed a leave-one-out cross- validation method to evaluate the proposed algorithm. Our reconstructed, high-resolution TRUS images from down-sampled images were compared with the original image to evaluate the performance quantitatively. The mean absolute error (MAE) and peak signal-to-noise ratio (PSNR) of image intensity profiles between reconstructed and original images were 6.5 +/- 0.5 and 38.0 +/- 2.4dB.","3D transrectal ultrasound,high-resolution reconstruction,deep learning,attention gate",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"MRI,SEGMENTATION,TRUS,RADIOTHERAPY,CT,REGISTRATION",,,
49,Deep Learning-based Breast Tumor Detection and Segmentation in 3D Ultrasound Image,11319,,,"Lei Yang,Yao Jincao,He Xiuxiu,Xu Dong,Wang Lijing,Li Wei,Curran Walter J.,Liu Tian,Yang Xiaofeng","Lei Y,Yao JC,He XX,Xu D,Wang LJ,Li W,Curran WJ,Liu T,Yang XF",Yang XF,10.1117/12.2549157,Emory University,"Automated 3D breast ultrasound (ABUS) has substantial potential in breast imaging. ABUS appears to be beneficial because of its outstanding reproducibility and reliability, especially for screening women with dense breasts. However, due to the high number of slices in 3D ABUS, it requires lengthy screening time for radiologists, and they may miss small and subtle lesions. In this work, we propose to use a 3D Mask R-CNN method to automatically detect the location of the tumor and simultaneously segment the tumor contour. The performance of the proposed algorithm was evaluated using 25 patients' data with ABUS image and ground truth contours. To further access the performance of the proposed method, we quantified the intersection over union (IoU), Dice similarity coefficient (DSC), and center of mass distance (CMD) between the ground truth and segmentation. The resultant IoU 96% +/- 2%, DSC 84% +/- 3%, and CMD 1.95 +/- 0.89 mm respectively, which demonstrated the high accuracy of tumor detection and 3D volume segmentation of the proposed Mask R-CNN method. We have developed a novel deep learning-based method and demonstrated its capability of being used as a useful tool for computer-aided diagnosis and treatment.","3D breast ultrasound,tumor detection,deep learning,Mask R-CNN",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"MAMMOGRAPHY,WOMEN",,,
50,Guided Ultrasound Imaging using a Deep Regression Network,11319,,,"Maharjan Jenish,Mitchell Benjamin R.,Chan Vincent W. S.,Kim Edward","Maharjan J,Mitchell BR,Chan VWS,Kim E",Maharjan J,10.1117/12.2549428,Villanova University,"In this work, we present a machine learning method to guide an ultrasound operator towards a selected area of interest. Unlike other automatic medical imaging methods, ultrasound imaging is one of the few imaging modalities where the operator's skill and training are critical in obtaining high quality images. Additionally, due to recent advances in affordability and portability of ultrasound technology, its utilization by non-experts has increased. Thus, there is a growing need for intelligent systems that have the ability to assist ultrasound operators in both clinical and non-clinical scenarios. We propose a system that leverages machine learning to map real time ultrasound scans to transformation vectors that can guide a user to a target organ or anatomical structure. We present a unique training system that passively collects supervised training data from an expert sonographer and uses this data to train a deep regression network. Our results show that we are able to recognize anatomical structure through the use of ultrasound imaging and give the user guidance toward obtaining an ideal image.","deep learning,guided ultrasound imaging,transfer learning,regression",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DIAGNOSIS",,,
51,Clustering based quantitative breast density assessment using 3D transmission ultrasound,11319,,,"Malik Bilal H.,Lee Sanghyeb,Natesan Rajni,Wiskin James W.","Malik BH,Lee S,Natesan R,Wiskin JW",Malik BH,10.1117/12.2543069,"QT Ultrasound Labs, 3 Hamilton Landing,Suite 160, Novato, CA 94949 USA.","Breast density is now recognized as one of the most important independent risk factors of breast cancer. Current means to assess breast density primarily utilize mammograms which represent a series of projection images, making it difficult to estimate the true volume of the fibroglandular tissue. We present 3D transmission ultrasound as a method to visualize and differentiate fibroglandular tissue within the breast and use an unsupervised learning-based method to quantitatively assess the respective breast density. The method includes initial separation of breast from the surrounding water bath followed by segmentation of the whole breast into fibroglandular tissue and fat using fuzzy C-mean (FCM) classification. We apply these methods to both tissue phantoms (in vitro) and clinical breast images (in vivo). In the case of tissue phantoms, the agreement between the theoretical (geometric density) and experimentally calculated values was better than 90%. For density calculation in a sample size of 50 cases, the results correlate well (Spearman r = 0.93, 95% CI: 0.88-0.96, p<0.0001) with an FDA-cleared breast density assessment software, VolparaDensity. We also discuss the advantage of using FCM-based tissue classification over threshold-based tissue segmentation within the paradigm of iterative image inversion/reconstruction and show that the former method is less sensitive to variation in assessment of breast density as a function of iteration count and thus, less dependent on convergence criteria. These results imply that breast density as assessed by 3D transmission ultra-sound can be of significant clinical utility and play an important role in breast cancer risk assessment.","Breast Density,Transmission Ultrasound,Clustering,Breast Imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
52,3D ultrasound biomicroscopy (3D-UBM) imaging of the eye for unique 3D assessment of ciliary body,11319,,,"Minhaz Ahmed Tahseen,Wu Hao,Helms Richard W.,Sevgi Duriye Damla,Kim Alvin,Kwak Sunwoo,Orge Faruk H.,Wilson David L.","Minhaz AT,Wu H,Helms RW,Sevgi DD,Kim A,Kwak S,Orge FH,Wilson DL",Wilson DL,10.1117/12.2549846,Case Western Reserve University,"We developed a methodology for 3D assessment of ciliary body of the eye, an important, but understudied tissue, using our new 3D ultrasound biomicroscopy (3D-UBM) imaging system. The ciliary body produces aqueous humor, which if not drained properly, can lead to increased intraocular pressure and glaucoma, a leading cause of blindness. Most medications and some surgical procedures for glaucoma target the ciliary body. Ciliary body is also responsible for focusing-accommodation by muscle contraction and relaxation. UBM is the only imaging modality which can be used to visualize structures behind the opaque iris, such as ciliary body. Our 3D-UBM acquires several hundred high resolutions (50 MHz) 2D-UBM images and creates a 3D volume, enabling heretofore unavailable en face visualizations and quantifications. In this study, we calculated unique 3D biometrics from automated segmentation using deep learning (U-Net). Our results show accuracy of 0.93 +/- 0.01, sensitivity of 0.79 +/- 0.07 and dice score of 0.72 +/- 0.07 on deep learning segmentation of ciliary muscle. For an eye, volume of ciliary body was 67.87 mm(3), single ciliary process volumes were 0.234 +/- 0.093 mm(3) with surface areas adjacent to aqueous humor of 3.02 +/- 1.07 mm(2). Automated and manual measurements of ciliary muscle volume and cross-sectional area are compared which show overestimation in volume measurement but higher agreeability in cross-sectional area measurements.","ultrasound imaging,UBM,ciliary body,deep learning,segmentation",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"GLAUCOMA,ANGLE",,,
53,"Quantitative ultrasound successes: past, present and future",11319,,,Oelze Michael L.,Oelze ML,Oelze ML,10.1117/12.2557150,University of Illinois System,"Diagnostic ultrasound is ubiquitous in clinical practice because it is safe, portable, inexpensive, has high spatial resolution and is real time. Therefore, improving the capabilities of diagnostic ultrasound is a highly significant clinically. In this talk we will discuss different applications of quantitative ultrasound (QUS) imaging and how QUS approaches have evolved over time. Specifically, we will discuss the use of spectral-based approaches to estimate the backscatter coefficient (BSC) and attenuation slope and the use of envelope statistics to describe underlying tissue microstructure. These QUS approaches have been successful at classifying tissue state, monitoring focused ultrasound therapy, detecting early response of breast cancer to neoadjuvant chemotherapy and the automatic detection of nerves in the imaging field. We will demonstrate how QUS approaches can be incorporated on breast tomography machines, which allow an expansion of the tradeoff between spatial resolution and the variance of QUS estimates. One of the ongoing issues with QUS is the inability to properly account for losses in tissues that affect the estimates of the backscatter coefficient. We will demonstrate new calibration procedures that can improve the ability to account for tissue losses. Finally, we will discuss how machine learning approaches can further improve QUS techniques by eliminating the need for models and in some cases eliminating the need for a reference scan.","Ultrasound,Quantitative ultrasound,backscatter coefficient",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"BACKSCATTER,COEFFICIENT,MEASUREMENTS,PARAMETERS",,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11319/113190X/Quantitative-ultrasound-successes-past-present-and-future/10.1117/12.2557150.pdf,
54,Comprehensive quantitative evaluations of reconstruction method using oil-gel-based phantom in ultrasound computed tomography,11319,,,"Suzuki Atsuro,Tsubota Yushi,Wu Wenjing,Yamanaka Kazuhiro,Terada Takahide,Kawabata Kenichi","Suzuki A,Tsubota Y,Wu WJ,Yamanaka K,Terada T,Kawabata K",Suzuki A,10.1117/12.2548382,Hitachi Limited,"The performance of a reconstruction method in ultrasound computed tomography (CT) ideally should be evaluated using various kinds of phantoms at a wide range of speeds of sound when inclusions are made. However, generating real phantoms is more time consuming than generating simulated ones. In our previous study, we developed an oil-gel-based phantom by including water or salt water. In this study, we designed an evaluation method including various contrast conditions using the oil-gel-based phantom by changing the liquid and temperature. The phantom including water or salt water in 10-, 7-, 5-, or 3-mm holes was measured using our prototype ultrasound CT at temperatures of 15, 17.5, 20, 22.5, 25, 27.5, and 30 degrees C, making the number of measurements 14. For these conditions, the difference (= contrast) in the speed of sound between the inclusions and the oil gel was -37 to 92 [m/s]. The filtered back projection (FBP) and full waveform inversion (FWI) were evaluated. The mean error of the speeds of sound in inclusions with the FBP and FWI were 17.1 +/- 14.9 and 8.8 +/- 10.1 [m/s], respectively. The mean percentage error of the sizes of the phantom (51 mm) and inclusions with the FBP and FWI were 22.5 +/- 22.5% and 3.9 +/- 4.3%, respectively. A single oil-gel-based phantom provided various contrast conditions after the temperature and liquid were changed. This kind of phantom can be used for comprehensive quantitative evaluations of the reconstruction method.","Breast imaging,ultrasound computed tomography,oil-gel-based phantom,full waveform inversion",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
55,Weekly Supervised Convolutional Long Short-Term Memory Neural Networks for MR-TRUS Registration,11319,,,"Zeng Qiulan,Fu Yabo,Jeong Jiwoong J.,Tian Zhen,Wang Tonghe,Lei Yang,Mao Hui,Jani Ashesh B.,Patel Pretesh,Curran Walter J.","Zeng QL,Fu YB,Jeong JWO,Tian Z,Wang TH,Lei Y,Mao H,Jani AB,Patel P,Curran WJ",Yang XF,10.1117/12.2549760,Emory University,"We propose an approach based on a weekly supervised method for MR-TRUS image registration. Inspired by the viscous fluid physical model, we made the first attempt at combining convolutional neural network (CNN) and long short-term memory ( LSTM) Neural Network to perform deep learning-based dense deformation field prediction. Through the integration of convolutional long short-term memory (ConvLSTM) Neural Network and weakly supervised approach, we achieved accurate results in terms of Dice similarity coefficient (DSC) and target registration error (TRE) without using conventional intensity-based image similarity measures. Thirty-six sets of patient data were used in the study. Experimental results showed that our proposed ConvLSTM neural network produced a mean TRE of 2.85 +/- 1.72 mm and a mean Dice of 0.89.","weakly supervised method,MR-TRUS registration,convolutional long short-term network,prostate cancer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
56,Multi-needle Detection in 3D Ultrasound Images with Sparse Dictionary Learning,11319,,,"Zhang Yupei);,He Xiuxiu);,Tian Zhen);,Jeong Jiwoong);,Lei Yang);,Wang Tonghe);,Zeng Qiulan);,Jani Ashesh B.);,Curran Walter J.);,Patel Pretesh","Zhang YP,He XX,Tian Z,Jeong JW,Lei Y,Wang TH,Zeng QL,Jani AB,Curran WJ,Patel P",Yang XF,10.1117/12.2549005,Emory University,"Accurate and automatic multi-needle detection in three-dimensional (3D) ultrasound (US) is a key step of treatment planning for US-guided brachytherapy. However, most current studies are concentrated on single-needle detection by only using a small number of images with a needle, regardless of the massive database of US images without needles. In this paper, we propose a workflow of multi-needle detection via considering the images without needles as auxiliary. Specifically, we train position-specific dictionaries on 3D overlapping patches of auxiliary images, where we developed an enhanced sparse dictionary learning method by integrating spatial continuity of 3D US, dubbed order-graph regularized dictionary learning (ORDL). Using the learned dictionaries, target images are reconstructed to obtain residual pixels which are then clustered in every slice to determine the centers. With the obtained centers, regions of interest (ROIs) are constructed via seeking cylinders. Finally, we detect needles by using the random sample consensus algorithm (RANSAC) per ROI and then locate the tips by finding the sharp intensity drops along the detected axis for every needle. Extensive experiments are conducted on a prostate data set of 70/21 patients without/with needles. Visualization and quantitative results show the effectiveness of our proposed workflow. Specifically, our approach can correctly detect 95% needles with a tip location error of 1.01 mm on the prostate dataset. This technique could provide accurate needle detection for US-guided high-dose-rate prostate brachytherapy and facilitate the clinical workflow.","Multi-needle detection,needle tip detection,3D ultrasound images,sparse dictionary learning,position-specific dictionary,graph regularization,RANSAC,prostate brachytherapy",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,ALGORITHM,,,
57,Weakly Supervised Multi-Needle Detection in 3D Ultrasound Images with Bidirectional Convolutional Sparse Coding,11319,,,"Zhang Yupei);,Harms Joseph);,Lei Yang);,Wang Tonghe);,Liu Tian);,Jani Ashesh B.);,Curran Walter J.);,Patel Pretesh);,Yang Xiaofeng","Zhang YP,Harms J,Lei Y,Wang TH,Liu T,Jani AB,Curran WJ,Patel P,Yang XF",Yang XF,10.1117/12.2549283,Emory University,"Accurate and automatic multi-needle detection in three-dimensional (3D) ultrasound (US) is a key step of treatment planning for US-guided prostate high dose rate (HDR) brachytherapy. In this paper, we propose a workflow for multi-needle detection in 3D ultrasound (US) images with corresponding CT images used for supervision. Since the CT images do not exactly match US images, we propose a novel sparse model, dubbed Bidirectional Convolutional Sparse Coding (BiCSC), to tackle this weakly supervised problem. BiCSC aims to extract the latent features from US and CT and then formulate a relationship between them where the learned features from US yield to the features from CT. Resultant images allow for clear visualization of the needle while reducing image noise and artifacts. On the reconstructed US images, a clustering algorithm is employed to find the cluster centers which correspond to the true needle position. Finally, the random sample consensus algorithm (RANSAC) is used to model a needle per ROI. Experiments are conducted on prostate image datasets from 10 patients. Visualization and quantitative results show the efficacy of our proposed workflow. This learning-based technique could provide accurate needle detection for US-guided high-dose-rate prostate brachytherapy, and further enhance the clinical workflow for prostate HDR brachytherapy.","Multi-needle detection,3D US images,weakly supervised method,convolutional sparse coding,RANSAC,prostate cancer brachytherapy,needle tip detection,needle visualization",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"LOCALIZATION,TRACKING,RANSAC",,,
58,Deep learning radiomics for non-invasive diagnosis of benign and malignant thyroid nodules using ultrasound images,11319,,,"Zhou Hui,Wang Kun,Tian Jie","Zhou H,Wang K,Tian J",Tian J,10.1117/12.2549433,Chinese Academy of Sciences,"Background: The differential diagnosis of benign and malignant thyroid nodules from ultrasound (US) images remained challengeable in clinical practice. We aimed to develop and validate a highly automatic and objective diagnostic model named deep learning Radiomics of thyroid (DLRT) for the differential diagnosis of benign and malignant thyroid nodules from US images. Methods: We retrospectively enrolled US images and corresponding fine-needle aspiration biopsies from 1645 thyroid nodules. A basic convolutional neural network (CNN) model, a transfer learning model, and a newly designed model named deep learning Radiomics of thyroid (DLRT) were used for the investigation. Their diagnostic accuracy was further compared with human observers (one senior and one junior US radiologist). Results: AUCs of DLRT were 0.96 (95% confidence interval [CI]: 0.94-0.98) and 0.95 (95% confidence interval [CI]: 0.93-0.97) in the training and validation cohort, respectively, for the differential diagnosis of benign and malignant thyroid nodules, which were significantly better than other deep learning models (P < 0.05) and human observers (P < 0.05). Conclusions: DLRT shows the best overall performance comparing with other deep learning models and human observers. It holds great promise for improving the differential diagnosis of benign and malignant thyroid nodules.","Thyroid Nodules,Thyroid Ultrasound,Deep Learning,Ultrasound Radiomics,Diagnosis",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"CLASSIFICATION,CARCINOMA,FEATURES,CANCER,RISK,US",,,
59,The accurate non-invasive staging of liver fibrosis using deep learning radiomics based on transfer learning of shear wave elastography,11319,,,"Zhou Hui,Wang Kun,Tian Jie","Zhou H,Wang K,Tian J",Tian J,10.1117/12.2549425,Chinese Academy of Sciences,"Background: We developed the deep learning Radiomics of elastography (DLRE) which adopted Convolutional Neural Network ( CNN) based on transfer learning as a noninvasive method to assess liver fibrosis stages, which is essential for prognosis, surveillance of chronic hepatitis B (CHB) patients. Methods: 297 patients were prospectively enrolled from 4 hospitals, and finally 1485 images were included into analysis randomly. DLRE adopted the Convolutional Neural Network ( CNN) based on transfer learning, one of the deep learning radiomic techniques, for the automatic analysis of 2D-SWE images. This study was conducted to assess the accuracy of DLRE in comparison with 2D-SWE, transient elastography (TE), transaminase-to-platelet ratio index (APRI), and fibrosis index based on the four factors (FIB-4), by using liver biopsy as the gold standard. Results: AUCs of DLRE were both 0.98 for cirrhosis (95% confidence interval [CI]: 0.95-0.99) and advanced fibrosis (95% CI: 0.94-0.99), which were significantly better than other methods, as well as 0.76 (95% CI: 0.72-0.81) for significance fibrosis (significantly better than APRI and FIB-4). Conclusions: DLRE shows the best overall performance in predicting liver fibrosis stages comparing with 2D-SWE, TE, and serological examinations.","Liver Fibrosis,Elastography,Deep Learning,Ultrasound Radiomics,Transfer Learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
60,Comparison of Classification Methods of Barret's and Dysplasia in the Esophagus from In Vivo Optical Coherence Tomography Images,11228,,,"Photiou Christos,Plastiras George,Tearney Guillermo,Pitris Costas","Photiou C,Plastiras G,Tearney G,Pitris C",Photiou C,10.1117/12.2546299,University of Cyprus,"Endoscopic Optical Coherence Tomography (EOCT) systems can perform in vivo, real-time, high-resolution imaging of the human esophagus and, thus, play an important role in the earlier diagnosis and better prognosis of esophageal diseases such as Barrett's, dysplasia and adenocarcinoma. However, the high image throughput and massive data volumes make manual evaluation of the generated information extremely difficult. Unfortunately, the algorithms, developed thus far, have not been able to provide effective computer-aided diagnosis. In this study, we compare different machine learning methods for tissue segmentation and classification of esophageal tissue in in vivo OCT images. An automated algorithm was developed, capable of discriminating normal tissue from Barrett's Esophagus (BE) and dysplasia. The classification was based on various features of the epithelium, extracted from EOCT images, such as intensity-based statistics, the group velocity dispersion (GVD), estimated from the image speckle, and the scatterer size, calculated using the bandwidth of the correlation of the derivative (COD) method. The comparison and evaluation of various machine learning techniques has shown that a neural network based approach provided the best performance, classifying Barret's esophagus and dysplasia, for individual A-Scans, with an accuracy of 89%.",HIGH-GRADE DYSPLASIA,Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"HIGH-GRADE,DYSPLASIA",,https://zenodo.org/record/4442088/files/Classification%20of%20Esophagus%20-%20FINAL_manuscript.pdf,
61,A deep learning method based on U-Net for quantitative photoacoustic imaging,11240,,,"Chen Tingting,Lu Tong,Song Shaoze,Miao Shichao,Gao Feng,Li Jiao","Chen TT,Lu T,Song SZ,Miao SC,Gao F,Li J",Li J,10.1117/12.2543173,Tianjin University,"Quantitative photoacoustic imaging (QPAI) is a hybrid imaging technique aimed at reconstructing optical parameters from photoacoustic signals detected around the biological tissues. The recovery of optical parameters is a nonlinear, ill-posed inverse problem which is usually solved by iterative optimization methods based on the error minimization strategy. Most of the iterative algorithms are empirical and computationally expensive, leading to inadequate performance in practical application. In this work, we propose a deep learning-based QPAI approach to efficiently recover the optical absorption coefficient of biological tissues from the reconstructed result of initial pressure. The method involves a U-Net architecture based on the fully convolutional neural network. The Monte Carlo simulation with the wide-field illumination has been used to generate simulation data for the network training. The feasibility of the proposed method was demonstrated through numerical simulations, and its applicability to quantitatively reconstruct the distribution of optical absorption in the practical situation is further verified in phantom experiments. High image performance of this method in accuracy, efficiency and fidelity from both simulated and experimental results, suggests the enormous potential in biomedical applications in the future.","Quantitative photoacoustic imaging,optical inverse problem,deep learning,U-Net,experimental validation",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,TOMOGRAPHY,,,
62,Unsupervised deep learning approach for Photoacoustic spectral unmixing,11240,,,"Durairaj Deepit Abhishek,Agrawal Sumit,Johnstonbaugh Kerrick,Chen Haoyang,Karri Sri Phani Krishna,Kothapalli Sri-Rajasekhar","Durairaj DA,Agrawal S,Johnstonbaugh K,Chen HY,Karri PK,Kothapalli SR",Kothapalli SR,10.1117/12.2546964,Pennsylvania Commonwealth System of Higher Education (PCSHE),"In photoacoustic imaging, accurate spectral unmixing is required for revealing functional and molecular information of the tissue using multispectral photoacoustic imaging data. A significant challenge in deep-tissue photoacoustic imaging is the nonlinear dependence of the received photoacoustic signals on the local optical fluence and molecular distribution. To overcome this, we have deployed an end-to-end unsupervised neural network based on autoencoders. The proposed method employs the physical properties as the constraints to the neural network which effectively performs the unmixing and outputs the individual molecular concentration maps without a-priori knowledge of their absorption spectra. The algorithm is tested on a set of simulated multispectral photoacoustic images comprising of oxyhemoglobin, deoxy-hemoglobin and indocyanine green targets embedded inside a tissue mimicking medium. These in silico experiments demonstrated promising photoacoustic spectral unmixing results using a completely unsupervised deep learning approach.","Spectral unmixing,photoacoustic imaging,deep learning,unsupervised learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
63,Deep Learning-based Speed of Sound Aberration Correction in Photoacoustic Images,11240,,,"Jeon Seungwan,Kim Chulhong","Jeon S,Kim C",Kim C,10.1117/12.2543440,Pohang University of Science & Technology (POSTECH),"Beamforming algorithms are widely used for photoacoustic (PA) imaging to reconstruct the initial pressure map. In the reconstruction process, they typically assumed that the imaged biological tissue was a homogeneous medium. However, as biological tissue is generally heterogeneous, the misassumption causes suboptimal image reconstruction. Because it is difficult to predict the heterogeneity of a medium, it was still common to reconstruct images assuming a uniform medium. To solve this problem, we introduce a deep learning-based algorithm that can correct the speed of sound (SoS) aberration in the PA image. We trained a neural network with the multiple simulation datasets and successfully corrected SoS aberrations in a PA in vivo image of the human forearm. We observed that the proposed algorithm effectively suppressed side lobes and noise in the PA image and greatly improves image quality.","Photoacoustic imaging,neural network,deep learning,image reconstruction,and image correction",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,COMPUTED-TOMOGRAPHY,,,
64,Deep learning-enhanced LED-based photoacoustic imaging,11240,,,"Singh Mithun Kuniyil Ajith,Sivasubramanian Kathyayini,Sato Naoto,Ichihashi Fumiyuki,Sankai Yoshiyuki,Xing Lei","Singh MKA,Sivasubramanian K,Sato N,Ichihashi F,Sankai Y,Xing L",Singh MKA,10.1117/12.2545654,"CYBERDYNE INC, Cambridge Innovat Ctr, Res & Business Dev Div, Stationspl 45,A4-004, NL-3013 AK Rotterdam, Netherlands.","Photoacoustic imaging holds promise in wide range of clinical and preclinical applications. Since photoacoustic imaging can be implemented in a conventional ultrasound scanner by adding light illumination, it is straight forward to realize dual-mode imaging offering complementary contrast. We recently developed an LED-based photoacoustic and ultrasound imaging system (AcousticX) with unprecedented 2D and 3D functional and structural imaging capabilities. Pulse energy offered by our LED arrays is orders of magnitude lower than conventional lasers and we perform frame averaging to keep up with the SNR, reducing the display frame rate. Even though the pulse repetition frequency of our LED arrays is 4 KHz, image frame rate we can achieve is limited by the large number of frame averages used to improve SNR. In this work, we present a deep learning-based approach to reduce the frame averaging in LED-based photoacoustic imaging without compromising the SNR. We have used convolutional neural network (U-Net) model in deep learning for improving the images with less averaging. When compared with traditional denoising methods, deep learning enables us to optimize parameters through network training. We used images from various other photoacoustic imaging systems with higher laser energy and broadband ultrasound transducers, which can generate PA images with high resolution and SNR with minimal or no averaging as training data. We validate our algorithm using LED-based photoacoustic images of phantoms utilizing Indocyanine green and methylene blue as contrast agents. In all cases, we achieved improvement in the SNR by denoising the images with lesser averaging, thereby increasing the framerate. Results demonstrate the potential of deep learning algorithms in improving temporal resolution and SNR in LED-based photoacoustic imaging.","LED,photoacoustic imaging,ultrasound imaging,deep learning,image contrast,CNN",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
65,Uncovering the eutectics design by machine learning in the Al-Co-Cr-Fe-Ni high entropy system,182,,278-286,"Wu Qingfeng,Wang Zhijun,Hu Xiaobing,Zheng Tao,Yang Zhongsheng,He Feng,Li Junjie,Wang Jincheng","Wu QF,Wang ZJ,Hu XB,Zheng T,Yang ZS,He F,Li JJ,Wang JC",Wang ZJ; Wang JC,10.1016/j.actamat.2019.10.043,Northwestern Polytechnical University,"Eutectics in high entropy alloys (HEAs) have shown excellent properties and promising applications. With empirical rules, various of eutectic high entropy alloys (EHEAs) have been proposed. The current design strategies shed light on the formation of eutectics in HEAs, but they are incapable of confirming multiple variables quantitatively in the selection of a specific system. In the present study, the eutectic formation in the multi-principal element systems is uncovered via data mining with machine learning (ML), where the critical elements and strongly associated elements were discovered. Taking the Al-Co-Cr-Fe-Ni system as an example, Al is confirmed to be the critical element for the eutectic formation and Cr is the strongly associated element with Al, Ni, Co, Fe and minor additions with comparably large solid solubility can be considered overall. With these understandings, a three-step approach can be summarized for designing EHEAs in a given system. Within the designed EHEAs, properties can be tested for optimization of application orientated design. The findings can not only accelerate the exploitation of EHEAs with better performance but also provide new ideas for designing compositionally complex alloys. (C) 2019 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","Eutectic high entropy alloys,Machine learning,Alloy design,Mechanical properties",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,9.277,"MECHANICAL-PROPERTIES,ALLOYS,MICROSTRUCTURE,DUCTILITY,STRENGTH,STRATEGY,BEHAVIORS,EVOLUTION,ELEMENTS",ACTA MATERIALIA,,
66,P300 based character recognition using convolutional neural network and support vector machine,55,,,"Kundu Sourav,Ari Samit","Kundu S,Ari S",Ari S,10.1016/j.bspc.2019.101645,National Institute of Technology (NIT System),"In this work, a brain-computer interface (BCI) system for character recognition has been proposed based on the P300 signal. P300 signal classification is the most challenging task in electroencephalography signal processing as it is affected by the surrounding noise and low signal-to-noise ratio (SNR). Feature extraction and feature selection are essential steps for any classification task. Most of the earlier techniques reported hand-crafted features for detection of P300 signal. However, the hand-crafted features are not efficient to represent the signal properly due to surrounding environment and subject variability. Motivated by this, convolutional neural network (CNN) has been proposed for automatic high-level feature extraction to detect P300 signal. In general, CNN model consists of convolutional and fully-connected layers followed by a softmax layer. In the developed system, two different convolutional layers are used to extract the spatial and temporal features from the dataset. Also, a 2D convolutional layer based CNN architecture has been proposed where spatio-temporal feature is extracted in a single layer. To mitigate the over-fitting problem, dropout is employed in CNN architecture, which improves the network performance. After extracting high-level features, Fisher ratio (F-ratio) based feature selection is proposed to find the optimal features. The optimal features are used in the ensemble of support vector machine (ESVM) classifier for P300 detection. ESVM has been adopted in this work to minimize the classifier variability. The models are tested on two widely used datasets, and the experimental results show better or comparable performance compared to the earlier reported techniques. (C) 2019 Elsevier Ltd. All rights reserved.","Brain-computer interface (BCI),Convolutional neural network (CNN),Ensemble of support vector machines,Fisher ratio,P300 speller",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"BCI,COMPETITION,2003,DATA,SET,IIB,ENSEMBLE",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
67,Low-dose chest X-ray image super-resolution using generative adversarial nets with spectral normalization,55,,,"Xu Liming,Zeng Xianhua,Huang Zhiwei,Li Weisheng,Zhang He","Xu LM,Zeng XH,Huang ZW,Li WS,Zhang H",Zeng XH,10.1016/j.bspc.2019.101600,Chongqing University of Posts & Telecommunications,"Chest X-ray (CXR) imaging is one of the most widely-used and cost-effective technology for chest screening and diagnosis of Pulmonary diseases. An always concerned improvement about CXR is to reduce X-ray radiation while achieving ultra-high quality imaging with fine structural details since CXR involves ionizing radiation and tolerance of different populations. In this paper, we present a supervised generative adversarial nets approach to accurately recover high-resolution (HR) CXR images from low-resolution (LR) counterparts while keep pathological invariance. Specifically, the auxiliary label information is introduced to constrain the feature generation to attack the potential risk of pathological variance. Then, spectral normalization is designed to control the performance of discriminative network with the guarantee of theoretical demonstration in controlling Lipschitz bound of discriminator. Results from quantitative and qualitative evaluations demonstrate that our method delivers more authentic improvement for CXR super-resolution (SR) compared to recent state-of-the-art methods. The proposed method has outperformed average 13.0%, 12.2% in FSIM and 13.7%, 12.5% in MSIM on two datasets, respectively. Besides, the index of generative performance GAN-train and GAN-test have achieved average increment 9.3% and 10.5% on CXR2 dataset. Subjective evaluation on SR CXR has outperformed average score 0.425 and 0.525 in terms of pathological invariance and acceptability, respectively. (C) 2019 Published by Elsevier Ltd.","Auxiliary information,Pathological invariance,Generative adversarial nets,Spectral normalization",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,,BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
68,Orthogonal convolutional neural networks for automatic sleep stage classification based on single-channel EEG,183,,,"Zhang Junming,Yao Ruxian,Ge Wengeng,Gao Jinfeng","Zhang JM,Yao RX,Ge WG,Gao JF",Gao JF,10.1016/j.cmpb.2019.105089,Huanghuai University,"Background and objective: In recent years, several automatic sleep stage classification methods based on convolutional neural networks (CNN) by learning hierarchical feature representation automatically from raw EEG data have been proposed. However, the state-of-the-art of such methods are quite complex. Using a simple CNN architecture to classify sleep stages is important for portable sleep devices. In addition, employing CNNs to learn rich and diverse representations remains a challenge. Therefore, we propose a novel CNN model for sleep stage classification.
Methods: Generally, EEG signals are better described in the frequency domain; thus, we convert EEG data to a time-frequency representation via Hilbert-Huang transform. To learn rich and effective feature representations, we propose an orthogonal convolutional neural network (OCNN). First, we construct an orthogonal initialization of weights. Second, to avoid destroying the orthogonality of the weights in the training process, orthogonality regularizations are proposed to maintain the orthogonality of weights. Simultaneously, a squeeze-and-excitation (SE) block is employed to perform feature recalibration across different channels.
Results: The proposed method achieved a total classification accuracy of 88.4% and 87.6% on two public datasets, respectively. The classification performances of different convolutional neural networks models were compared to that of the proposed method. The experiment results demonstrated that the proposed method is effective for sleep stage classification.
Conclusions: Experiment results indicate that the proposed OCNN can learn rich and diverse feature representations from time-frequency images of EEG data, which is important for deep learning. In addition, the proposed orthogonality regularization is simple and can be easily adapted to other architectures. (C) 2019 Elsevier B.V. All rights reserved.","Convolutional neural networks,Orthogonal weight,Electroencephalography,Feature extraction,Sleep stage",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"SYSTEM,SIGNALS,FEATURES,ECG",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
69,Deep learning acceleration of Total Lagrangian Explicit Dynamics for soft tissue mechanics,358,,,"Meister Felix,Passerini Tiziano,Mihalef Viorel,Tuysuzoglu Ahmet,Maier Andreas,Mansi Tommaso","Meister F,Passerini T,Mihalef V,Tuysuzoglu A,Maier A,Mansi T",Meister F,10.1016/j.cma.2019.112628,Siemens AG,"Simulating complex soft tissue deformations has been an intense research area in the fields of computer graphics or computational physiology for instance. A desired property is the ability to perform fast, if not real-time, simulations while being physically accurate. Numerical schemes have been explored to speed up finite element methods, like the Total Lagrangian Explicit Dynamics (TLED). However, real-time applications still come at the price of accuracy and fidelity. In this work, we explore the use of neural networks as function approximators to accelerate the time integration of TLED, while being generic enough to handle various geometries, motion and materials without having to retrain the neural network model. The method is evaluated on a set of experiment, showing promising accuracy at time steps up to 20 times larger than the ""breaking"" time step, as well as in a simple medical application. Such an approach could pave the way to very fast but accurate acceleration strategies for computational biomechanics. (C) 2019 Elsevier B.V. All rights reserved.","Data-driven computational modeling,Soft tissue biomechanics,Deep learning,Finite element method,Total Lagrangian Explicit Dynamics",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,,COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,,
70,Breast Cancer Computer-Aided Diagnosis System Using k-NN Algorithm Based on Hausdorff Distance,1033,,179-188,"Skobel Marcin,Kowal Marek,Korbicz Jozef","Skobel M,Kowal M,Korbicz J",Skobel M,10.1007/978-3-030-29885-2_16,University of Zielona Gora,"World statistics indicate that the breast cancer is the most common worldwide type of cancer among women. The development of computer-aided diagnosis techniques may contribute to a more effective therapy against this type of cancer. In this work, we present preliminary research regarding cell nuclei classification based on the Hausdorff distance. The obtained results indicate that using only Hausdorff distance to the classification of individual cell nuclei allows us to achieve 75% accuracy. Moreover, the speed of calculations and the possibility of using additional features describing cell nuclei open new paths to computer-aided diagnosis support systems development.","Breast cancer,k-Nearest neighbour,Classification,Hausdorff distance,Computer-aided diagnosis",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering,Medical Laboratory Technology",,,"NUCLEI,SEGMENTATION,CLASSIFICATION",,,
71,EEG-Based Semantic Vigilance Level Classification Using Directed Connectivity Patterns and Graph Theory Analysis,8,,115941-115956,"Al-Shargie Fares Mohammed,Hassanin Omnia,Tariq Usman,Al-Nashash Hasan","Al-Shargie FM,Hassanin O,Tariq U,Al-Nashash H",Al-Shargie FM,10.1109/ACCESS.2020.3004504,American University of Sharjah,"This paper proposes two novel methods to classify semantic vigilance levels by utilizing EEG directed connectivity patterns with their corresponding graphical network measures. We estimate the directed connectivity using relative wavelet transform entropy (RWTE) and partial directed coherence (PDC) and the graphical network measures by graph theory analysis (GTA) at four frequency bands. The RWTE and PDC quantify the strength and directionality of information flow between EEG nodes. On the other hand, the GTA of the complex network measures summarizes the topological structure of the network. We then evaluate the proposed methods using machine learning classifiers. We carried out an experiment on nine subjects performing semantic vigilance task (Stroop color word test (SCWT)) for approximately 45 minutes. Behaviorally, all subjects demonstrated vigilance decrement as reflected by the significant increase in response time and reduced accuracy. The strength and directionality of information flow in the connectivity network by RWTE/PDC and the GTA measures significantly decrease with vigilance decrement, p<0.05. The classification results show that the proposed methods outperform other related and competitive methods available in the literature and achieve 100% accuracy in subject-dependent and above 89% in subject-independent level in each of the four frequency bands. The overall results indicate that the proposed methods of directed connectivity patterns and GTA provide a complementary aspect of functional connectivity. Our study suggests directed functional connectivity with GTA as informative features and highlight Support Vector Machine as the suitable classifier for classifying semantic vigilance levels.","Vigilance decrement,electroencephalogram,relative wavelet transform entropy,partial directed coherence,graph theory analysis,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MENTAL,FATIGUE,FUNCTIONAL,CONNECTIVITY,ENTROPY,FEATURE,PERFORMANCE,SYSTEM,DROWSINESS,COMPONENT,VARIANCE,TOOLBOX,RHYTHMS",IEEE ACCESS,https://doi.org/10.1109/access.2020.3004504,
72,Voxel Weight Matrix-Based Feature Extraction for Biomedical Applications,8,,121451-121459,"Albalawi Fahad,Alshehri Sultan,Chahid Abderrazak,Laleg-Kirati Taous-Meriem","Albalawi F,Alshehri S,Chahid A,Laleg-Kirati TM",Laleg-Kirati TM,10.1109/ACCESS.2020.3006521,King Abdullah University of Science & Technology,"Functional Magnetic Resonance Imaging (fMRI) is an emerging medical tool used to measure brain activities that were induced normally such as cognitive states (e.g., reading a sentence or viewing a picture) or abnormally (e.g., brain activity occurs after a stroke or brain injury). These measured data can be used to construct a model via machine learning techniques to predict the occurrence of a certain cognitive behavior or brain disease. The difficulty of this prediction problem can be summarized in two points: first, the size of the dataset is very small due to the small number of subjects (i.e., patients) who can contribute to these research-based experiments. Second, the size of the feature vector resulted from these medical tools is very large compared to the few number of samples that were collected. One possible way to overcome these obstacles is to develop a feature generation methodology that can produce a small-sized and descriptive feature vector that may improve the overall prediction performance. Motivated by these considerations, this paper proposes a novel feature generation methodology termed Voxel Weight Matrix (VWM) method. This feature generation technique can transform the original high-dimensional feature vector to a two-dimensional discriminative feature domain. The main contribution of this feature generation technique is its ability to represent the statistical measures of the original feature vector via two-dimensional feature vector. After generating the VWM-based feature set, various classification tools such as logistic regression (LR) models and Support Vector Machine (SVM) are used for cognitive state prediction based on publicly available fMRI dataset called state/plus dataset. The classification models with the proposed VWM features outperformed the best two reported prediction models associated with the star/plus dataset with an average accuracy of 99.8%. To further illustrate the effectiveness of the proposed feature generation methodology, another publicly available Electroencephalography (EEG) dataset are used for Epileptic Seizure Prediction.","Feature extraction,fMRI,voxel weight matrix (VWM),quantization,classification,EEG and cognitive state",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COGNITIVE,STATES,BRAIN,CLASSIFICATION,SEQUENCE,MRI",IEEE ACCESS,https://repository.kaust.edu.sa/bitstream/10754/663991/1/voxel.pdf,
73,Motor Imagery Classification for Brain Computer Interface Using Deep Metric Learning,8,,109949-109963,"Alwasiti Haider,Yusoff Mohd Zuki,Raza Kamran","Alwasiti H,Yusoff MZ,Raza K",Alwasiti H,10.1109/ACCESS.2020.3002459,Universiti Teknologi Petronas,"Deep metric learning (DML) has achieved state-of-the-art results in several deep learning applications. However, this type of deep learning models has not been tested on the classification of electrical brain waves (EEG) for brain computer interface (BCI) applications. For the first time, we propose a triplet network to classify motor imagery (MI) EEG signals. Stockwell Transform has been used for converting the EEG signals in the time domain into the frequency domain, which resulted in improved DML classification accuracy in comparison to DML with Short Term Fourier Transform (0.647 vs. 0.431). DML model was trained with a topogram of concatenated 64 EEG channel spectrograms. The training batch was comprised of triplet pairs of the anchor, positive, and negative labeled epochs. The triplet network was able to train an embedding feature space that minimized the Euclidean distance between the embeddings of spectrograms of the same class and increased the distance between the embeddings of different labeled images. The proposed method has been tested on an EEG dataset of 109 untrained subjects. We showed that the DML classifier is able to converge with an extremely small number of training samples (similar to 120 EEG trials) for only one subject per model, mitigating the well-known issue of the large inter-individual variability of human MI-BCI EEG which degrades the classification performance. The proposed preprocessing pipeline and the Triplet Network provide a promising method to classify MI-BCI EEG signals with much less training samples than the previous methods.","Electroencephalography,Brain modeling,Training,Feature extraction,Deep learning,Data models,BCI,metric learning,EEG,Stockwell transform",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CENTRAL,PATTERN,GENERATORS,NEURAL-NETWORKS,BCI,MOVEMENTS,ALGORITHM,SELECTION,SIGNALS,CORTEX,RHYTHM,HAND",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09116935.pdf,
74,Cognitive Intelligence for Monitoring Fractured Post-Surgery Ankle Activity Using Channel Information,8,,112113-112129,"Barua Arnab,Zhang Zhi-Ya,Al-Turjman Fadi,Yang Xiaodong","Barua A,Zhang ZY,Al-Turjman F,Yang XD",Zhang ZY; Yang XD,10.1109/ACCESS.2020.3000599,Xidian University,"In the past decades, cognitive computing and communication densely used in lots of networking areas. Current improvement in deep learning (DL) and big data analysis create great potential to analyze cognitive intelligence (CI) for many applications such as human activity monitoring and recognition through wireless communication. Cognitive intelligence and wireless communication are using to establish smart healthcare systems. Healthcare monitoring systems turn into interesting research subjects where monitoring post-operative surgical patients are the current focal point to the researcher. In this paper, we argue that deep learning along with the wireless communication technique introduces cognitive intelligence for the healthcare monitoring system. We present a deep learning based convolutional neural network (CNN) model to classify image data and a convenient and multi-functional software-defined radio (SDR) platform to detect movement of the ankle of patients who underwent ankle fracture surgery. Capturing wireless channel state information (WCSI) in the presence of the human body and classifying using CNN to observe distinct movements is the key idea of this study. A universal software radio peripheral (USRP) platform used to capture WCSI data and used for classification. AlexNet and ZFNet both are the famous architecture of CNN and used in a parallel way to classify captured WCSI-based images that converted from numeric data. The classification established on the ankles movements after surgery and classification results show that CNN provides satisfying results where test accuracy is 98.98%.","Monitoring,Wireless communication,Hardware,Wireless sensor networks,Cameras,Computational modeling,Deep learning,Cognitive intelligence,DL,CNN,USRP,WCSI,AlexNet,ZFNet,post-surgery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HEALTH-CARE,NEURAL-NETWORKS,DEEP,RADAR,IDENTIFICATION,RECOGNITION,INJURIES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09110589.pdf,
75,Machine Learning-Based Automatic Classification of Knee Osteoarthritis Severity Using Gait Data and Radiographic Images,8,,120597-120603,"Bin Kwon Soon,Han Hyuk-Soo,Lee Myung Chul,Kim Hee Chan,Ku Yunseo,Ro Du Hyun","Bin Kwon S,Han HS,Lee MC,Kim HC,Ku Y,Ro D",Ro D,10.1109/ACCESS.2020.3006335,Seoul National University (SNU),"Knee osteoarthritis (KOA) is a leading cause of disability among elderly adults, and it causes pain and discomfort and limits the functional independence of such adults. The aim of this study was the development of an automated classification model for KOA, based on the Kellgren-Lawrence (KL) grading system, using radiographic imaging and gait analysis data. Gait features highly associated with the radiological severity of KOA identified from our previous study, in addition to radiographic image features extracted from a deep learning network, namely, Inception-ResNet-v2, were exploited using a support vector machine for KOA multi-classification. The area under the curve (AUC) of the receiver operating characteristic curve from KL Grades 0-4 were 0.93, 0.82, 0.83, 0.88, and 0.97, respectively. The sensitivity, precision, and F1-score of the model were 0.70, 0.76, and 0.71, respectively. The proposed model outperformed a common deep learning approach that is based on using only radiographic images as the input data. This result indicates that gait data and radiographic images are complementary with respect to KOA classification, and the use of both data can improve the accuracy of the automated diagnosis of multiclass KOA.","Deep learning,gait data,knee osteoarthritis,machine learning,radiographic images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ADDUCTION,MOMENT,UNITED-STATES,DISEASE,PREVALENCE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09130657.pdf,
76,A Predictor-Corrector Algorithm Based on Laurent Series for Biological Signals in the Internet of Medical Things,8,,109360-109371,"Bordel Borja,Alcarria Ramon,Robles Tomas,You Ilsun","Bordel B,Alcarria R,Robles T,You I",You I,10.1109/ACCESS.2020.3001275,Soonchunhyang University,"In future engineered systems for medical applications, a tight real-time integration between physical and computational processes will be required. That integration is achieved using feedback control loops which need high quality input data streams. However, hardware platforms can barely provide such high-quality data sequences (especially if mobile nodes are considered), and mechanisms to improve and polish physical and biological signals are then necessary. This paper proposes a predictor-corrector algorithm to improve the quality and precision of data (biological) signals in Internet of Medical Things deployments, especially if composed of mobile nodes. The proposed algorithm employs an Artificial Intelligence approach and statistical learning techniques to predict future data samples and correct errors in received information. Employed mathematical models follow a prediction-correction scheme and are based on complex functions, Laurent series and the idea of complex envelope. Simulation techniques are used to evaluate the performance of the proposed solution, showing that it improves the precision of traditional linear interpolation techniques up to 85%, and cubic splines up to 20% Processing delay during operation is, for the referred precision, around 200ms.","Artificial intelligence,Prediction algorithms,Signal processing algorithms,Real-time systems,Classification algorithms,Biology,Signal processing,Data prediction,Internet-of-Medical-Things,statistical learning,artificial intelligence,Laurent series",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"BIG,DATA,NEURAL-NETWORK",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09114882.pdf,
77,Transfer Learning Benchmark for Cardiovascular Disease Recognition,8,,109475-109491,"Boulares Mehrez,Alafif Tarik,Barnawi Ahmed","Boulares M,Alafif T,Barnawi A",Boulares M,10.1109/ACCESS.2020.3002151,King Abdulaziz University,"The cardiac auscultation using the classical stethoscope (PCG: phonological cardiogram) is known as the most famous method to detect Cardiovascular Disease (CVD). However, this exam requires a qualified cardiologist which relies on the cardiac cycle vibration sound (heart muscle contractions and valves closure) to detect abnormalities in heart during the pumping action. Many research works have been conducted for detecting CVD from PCG signals by using public and private datasets. Due to the lack of CVD recognition benchmark, classification results are very heterogeneous and can not be compared objectively. In this paper, we apply transfer learning to Pascal public dataset and provide an experimental benchmark without any denoising or cleaning steps. The main goal is to generate a set of experimental results which can be used as starting reference for future CVD recognition research based on PCG.","Phonocardiography,Training,Benchmark testing,Cardiovascular diseases,Mel frequency cepstral coefficient,Heart rate,Cardiovascular disease recognition,convolutional neural network,pre-trained model,deep learning,transfer learning,benchmark",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,HEART,SOUNDS,CLASSIFICATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09115633.pdf,
78,Multi-ECGNet for ECG Arrythmia Multi-Label Classification,8,,110848-110858,"Cai Junxian,Sun Weiwei,Guan Jianfeng,You Ilsun","Cai JX,Sun WW,Guan JF,You S",You S,10.1109/ACCESS.2020.3001284,Soonchunhyang University,"With the development of various deep learning algorithms, the importance and potential of AI + medical treatment are increasingly prominent. Electrocardiogram (ECG) as a common auxiliary diagnostic index of heart diseases, has been widely applied in the pre-screening and physical examination of heart diseases due to its low price and non-invasive characteristics. Currently, the multi-lead ECG equipments have been used in the clinic, and some of them have the automatic analysis and diagnosis functions. However, the automatic analysis is not accurate enough for the discrimination of abnormal events of ECG, which needs to be further checked by doctors. We therefore develop a deep-learning-based approach for multi-label classification of ECG named Multi-ECGNet, which can effectively identify patients with multiple heart diseases at the same time. The experimental results show that the performance of our methods can get a high score of 0.863 (micro-F1-score) in classifying 55 kinds of arrythmias, which is beyond the level of ordinary human experts.","Electrocardiography,Feature extraction,Deep learning,Heart,Diseases,Convolution,Electrodes,ECG,arrythmia,multi-label classification,depthwise separable convolution,SE module",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09113436.pdf,
79,Telemonitoring System for Infectious Disease Prediction in Elderly People Based on a Novel Microservice Architecture,8,,118340-118354,"Calderon-Gomez Huriviades,Mendoza-Pitti Luis,Vargas-Lombardo Miguel,Gomez-Pulido Jose Manuel,Castillo-Sequera Jose Luis,Sanz-Moreno Jose,Sencion Gloria","Calderon-Gomez H,Mendoza-Pitti L,Vargas-Lombardo M,Gomez-Pulido JM,Castillo-Sequera JL,Sanz-Moreno J,Sencion G",Vargas-Lombardo M,10.1109/ACCESS.2020.3005638,Universidad Tecnologica de Panama,"This article describes the design, development and implementation of a set of microservices based on an architecture that enables detection and assisted clinical diagnosis within the field of infectious diseases of elderly patients, via a telemonitoring system. The proposed system is designed to continuously update a medical database fed with vital signs from biosensor kits applied by nurses to elderly people on a daily basis. The database is hosted in the cloud and is managed by a flexible microservices software architecture. The computational paradigms of the edge and the cloud were used in the implementation of a hybrid cloud architecture in order to support versatile high-performance applications under the microservices pattern for the pre-diagnosis of infectious diseases in elderly patients. The results of an analysis of the usability of the equipment, the performance of the architecture and the service concept show that the proposed e-health system is feasible and innovative. The system components are also selected to give a cost-effective implementation for people living in disadvantaged areas. The proposed e-health system is also suitable for distributed computing, big data and NoSQL structures, thus allowing the immediate application of machine learning and AI algorithms to discover knowledge patterns from the overall population.","Artificial intelligence,e-health,elderly people,infectious diseases,microservice architecture,microservices,telemonitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DEPLOYMENT,FRAMEWORK,DOCKER,DESIGN,MODEL",IEEE ACCESS,https://ebuah.uah.es/dspace/bitstream/10017/43609/3/Telemonitoring_Calderon_IEEE_Access_2020.pdf,
80,Dual Machine-Learning System to Aid Glaucoma Diagnosis Using Disc and Cup Feature Extraction,8,,127519-127529,"Civit-Masot Javier,Dominguez-Morales Manuel J.,Vicente-Diaz Saturnino,Civit Anton","Civit-Masot J,Dominguez-Morales MJ,Vicente-Diaz S,Civit A",Civit-Masot J,10.1109/ACCESS.2020.3008539,University of Sevilla,"Glaucoma is a degenerative disease that affects vision, causing damage to the optic nerve that ends in vision loss. The classic techniques to detect it have undergone a great change since the intrusion of machine learning techniques into the processing of eye fundus images. Several works focus on training a convolutional neural network (CNN) by brute force, while others use segmentation and feature extraction techniques to detect glaucoma. In this work, a diagnostic aid tool to detect glaucoma using eye fundus images is developed, trained and tested. It consists of two subsystems that are independently trained and tested, combining their results to improve glaucoma detection. The first subsystem applies machine learning and segmentation techniques to detect optic disc and cup independently, combine them and extract their physical and positional features. The second one applies transfer learning techniques to a pre-trained CNN to detect glaucoma through the analysis of the complete eye fundus images. The results of both systems are combined to discriminate positive cases of glaucoma and improve final detection. The results show that this system achieves a higher classification rate than previous works. The system also provides information on the basis for the proposed diagnosis suggestion that can help the ophthalmologist to accept or modify it.","Glaucoma,ensemble networks,medical diagnostic aids,medical imaging,explainable AI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"OPTIC,DISC,SEGMENTATION",IEEE ACCESS,https://idus.us.es/bitstream/11441/105491/1/Dual%20Machine-Learning%20system%20to%20aid%20Glaucoma.pdf,
81,A Novel Method for Damage Prediction of Stuffed Protective Structure Under Hypervelocity Impact by Stacking Multiple Models,8,,130136-130158,"Ding Wenzhe,Li Xinhong,Yang Hong,An Jiping,Zhang Zhibin","Ding WZ,Li XH,Yang H,An JP,Zhang ZB",Ding WZ,10.1109/ACCESS.2020.3009160,Aerospace Engineering University,"Adopting appropriate protective structures to resist the impact of micrometeoroid or space debris on spacecraft is a valuable research content of space engineering. After the single-layer board and Whipple protective structure, the stuffed protective structure has become one of the research focuses in recent years. However, due to the different filling materials and filling modes, the prediction of hypervelocity impact damage of projectile by using the explicit ballistic limit equation of the stuffed protective structure will lead to some deviation between the predicted results and the measured data. In this paper, the problem is transformed into a binary classification problem, which is characterized by projectile impact parameters and protective structure parameters. And a novel method is proposed to predict the hypervelocity impact damage of the stuffed protective structure under the stacking ensemble learning framework. In this method, the hypervelocity impact damage data set of the stuffed protective structure is firstly divided into specific data subsets. Extreme Gradient Boosting (XGBoost), Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) are taken as the base models of the stacking ensemble learning framework. And each base model is trained by using the divided sub-datasets. Thus the meta-features with stronger generalization ability are extracted. Then, the Long Short Term Memory (LSTM) network is used as the meta-model of the stacking ensemble learning framework, and the meta-features extracted before are used to train it. In this way, the high-precision prediction of the impact damage of the stuffed protective structure is realized under the small data set. The experimental results show that the stacking ensemble learning model has a good prediction effect on the impact damage of the stuffed protective structure. The cross-validation under different training sample sizes further proves that the stacking ensemble learning model has excellent robustness and accuracy.","Mathematical model,Space vehicles,Projectiles,Classification algorithms,Prediction algorithms,Stacking,Predictive models,Stuffed protective structure,hypervelocity impact damage,small data set,stacking ensemble learning framework",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,EQUATIONS,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139979.pdf,
82,Just-in-Time Learning-Based Soft Sensor for Mechanical Properties of Strip Steel via Multi-Block Weighted Semisupervised Models,8,,123869-123881,"Dong Jie,Tian Yingze,Peng Kaixiang","Dong J,Tian YZ,Peng KX",Peng KX,10.1109/ACCESS.2020.3005716,University of Science & Technology Beijing,"Mechanical properties are important indexes to evaluate the quality of hot rolling strips. It is a research hotspot in the field of hot rolling that realizing timely and accurate soft sensing of mechanical properties. Traditional soft sensing methods have poor performance in the application of strong nonlinearity and multiple working conditions. Moreover, the utilization rate of data is relatively low, which limit the improvement of prediction accuracy. To solve the problems above, a just-in-time learning (JITL) based multi-block weighted semisupervised Gaussian mixture regression (JMWSSGMR) soft sensor is proposed in the paper. There are two stages in the soft sensor: off-line variable blocking and on-line local modeling. In the off-line phase, process variables are divided into different sub-blocks by partial least square (PLS) according to distinct principal component directions. In each sub-block, original variables with high contribution rate are retained. In the on-line phase, optimized Mahalanobis distance is constructed to select the most similar historical samples to the query sample. Next, various real-time semisupervised sub-models are built to estimate the output of the query sample. Finally, predicted values of sub-models are fused and ultimate prediction of mechanical properties is obtained. Case studies are carried out on a numerical example and a hot rolling process. The feasibility and effectiveness of proposed soft sensor are verified by the predicted results.","Soft sensor,just-in-time learning (JITL),semi-supervised learning,hot-rolling process",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PARTIAL,LEAST-SQUARES,QUALITY,PREDICTION,ROLLING,PROCESS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09127931.pdf,
83,Liver Cancer Detection Using Hybridized Fully Convolutional Neural Network Based on Deep Learning Framework,8,,129889-129898,"Dong Xin,Zhou Yizhao,Wang Lantian,Peng Jingfeng,Lou Yanbo,Fan Yiqun","Dong X,Zhou YZ,Wang LT,Peng JF,Lou YB,Fan YQ",Dong X,10.1109/ACCESS.2020.3006362,Zhejiang University,"Liver cancer is one of the world's largest causes of death to humans. It is a difficult task and time consuming to identify the cancer tissue manually in the present scenario. The segmentation of liver lesions in CT images can be used to assess the tumor load, plan treatments predict, and monitor the clinical response. In this paper, the Hybridized Fully Convolutional Neural Network (HFCNN) has been proposed for liver tumor segmentation, which has been modeled mathematically to resolve the current issue of liver cancer. For semantic segmentation, HFCNN has been used as a powerful tool for liver cancer analysis. Whereas the CT-based lesion-type definition defines the diagnosis and therapeutic strategy, the distinction between cancer and non-cancer lesions is crucial. It demands highly qualified experience, expertise, and resources. However, a deep end-to-end learning approach to help discrimination in abdominal CT images of the liver between liver metastases of colorectal cancer and benign cysts has been analyzed. Our method includes the successful extraction of features from Inception combined with residual and pre-trained weights. Feature maps have been consistent with the original image voxel features, and The importance of features seemed to represent the most relevant imaging criteria for every class. This deep learning system shows the concept of illumination portions of the decision-making process of a pre-trained deep neural network, through an analysis of inner layers and the description of features that lead to predictions.","Liver cancer detection,deep learning,fully convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"LESION,DETECTION,TUMOR,DETECTION,CLASSIFICATION,SEGMENTATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09130662.pdf,
84,Application of Deep Learning Algorithm in Feature Mining and Rapid Identification of Colorectal Image,8,,128830-128844,"Du Mingchao,Tao Min,Hong Jian,Zhou Dian,Wang Shuihua","Du MC,Tao M,Hong J,Zhou D,Wang SH",Zhou D,10.1109/ACCESS.2020.3008000,Anhui Medical University,"Based on deep learning technology, this paper proposes a two-stage colorectal image feature mining and fast recognition model to achieve fully automatic medical image pathology discrimination. Drawing on the ideas of multi-factor Meta-regression analysis widely used in the medical field and the model aggregation framework based on Bayesian prior probability theory, a prognostic model of colorectal tumors suitable for various situations and scenarios is constructed. And using a combination of public data sets and real data sets, design two sets of experiments to verify these models from different angles. The algorithm was used to select one, four, and five related features from three sequences to construct three sets of prediction models. The application of the six algorithms failed to obtain a better predictive model (AUC value range 0.439 similar to 0.640). The algorithm (AUC value 0.750 +/- 0.137) and the algorithm (AUC value 0.764 +/- 0.128) can be used to obtain models with better predictive performance, and the four models are less effective (AUC value< 0.7). In the joint model, the algorithm (AUC value 0.742 +/- 0.101) and the algorithm (AUC value 0.718 +/- 0.069) can also be used to obtain a model with better prediction performance. Image-based imaging histology tags can be used as a non-invasive auxiliary tool for preoperative evaluation of histological grading of CRAC, and are expected to be applied in clinical practice to assist in the development of individualized treatment plans.","Deep learning,colorectal imaging,feature mining,rapid identification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,HEART-FAILURE,DIAGNOSIS,CLASSIFICATION,INJURY",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09136711.pdf,
85,PROMETEO: A CNN-Based Computer-Aided Diagnosis System for WSI Prostate Cancer Detection,8,,128613-128628,"Duran-Lopez Lourdes,Dominguez-Morales Juan P.,Felix Conde-Martin Antonio,Vicente-Diaz Saturnino,Linares-Barranco Alejandro","Duran-Lopez L,Dominguez-Morales JP,Conde-Martin AF,Vicente-Diaz S,Linares-Barranco A",Duran-Lopez L,10.1109/ACCESS.2020.3008868,University of Sevilla,"Prostate cancer is currently one of the most commonly-diagnosed types of cancer among males. Although its death rate has dropped in the last decades, it is still a major concern and one of the leading causes of cancer death. Prostate biopsy is a test that confirms or excludes the presence of cancer in the tissue. Samples extracted from biopsies are processed and digitized, obtaining gigapixel-resolution images called whole-slide images, which are analyzed by pathologists. Automated intelligent systems could be useful for helping pathologists in this analysis, reducing fatigue and making the routine process faster. In this work, a novel Deep Learning based computer-aided diagnosis system is presented. This system is able to analyze whole-slide histology images that are first patch-sampled and preprocessed using different filters, including a novel patch-scoring algorithm that removes worthless areas from the tissue. Then, patches are used as input to a custom Convolutional Neural Network, which gives a report showing malignant regions on a heatmap. The impact of applying a stain-normalization process to the patches is also analyzed in order to reduce color variability between different scanners. After training the network with a 3-fold cross-validation method, 99.98% accuracy, 99.98% F1 score and 0.999 AUC are achieved on a separate test set. The computation time needed to obtain the heatmap of a whole-slide image is, on average, around 15 s. Our custom network outperforms other state-of-the-art works in terms of computational complexity for a binary classification task between normal and malignant prostate whole-slide images at patch level.","Convolutional neural networks,computer-aided diagnosis,deep learning,medical image analysis,prostate cancer,whole-slide images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,BIOPSIES,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139241.pdf,
86,Safety Monitoring by a Graph-Regularized Semi-Supervised Nonnegative Matrix Factorization With Applications to a Vision-Based Marking Process,8,,112278-112286,"Fan Song,Jia Qilong,Cheng Wan Sheng","Fan S,Jia QL,Cheng WS",Cheng WS,10.1109/ACCESS.2020.3002802,University Science & Technology Liaoning,"This paper proposes a brand-new method to perform safety monitoring using images for steel coil marking industrial processes. The new safety monitoring method is developed with the aid of a new graph-regularized semi-supervised nonnegative matrix factorization (GSNMF) algorithm. Compared with the existing nonnegative matrix factorization (NMF)-like algorithms, GSNMF is developed in an all-new manner so that it not only can take advantage of images with known labels and images with unknown labels to train a model for monitoring purpose, but also can take advantage of graph theory to improve the monitoring performance. Because any two different samples are connected by an edge in a graph, thus graph theory is beneficial for GSNMF to measure the similarity between any two different samples and to assign the same labels for the samples with close connections between them. As a result, GSNMF is more capable of analyzing the samples with a complicated distribution than the existing NMF-like algorithms, theoretically. Finally, an experiment on a steel coil marking process is adopted to evaluate the superiorities of our proposed method over the existing methods.","Fault detection,nonnegative matrix factorization,semi-supervised learning,marking process",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,FAULT-DETECTION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09118902.pdf,
87,Prediction of the Cement Grate Cooler Pressure in the Cooling Process Based on a Multi-Model Fusion Neural Network,8,,115028-115040,"Geng Yusen,Wang Xiaohong,Jiang Ping","Geng YS,Wang XH,Jiang P",Jiang P,10.1109/ACCESS.2020.3002768,University of Jinan,"The reasonable control of the grate cooler is the key factor to ensure the heat exchange and cement clinker quality during the clinker cooling process. In this paper, the cement grate cooler pressure of the grate cooler is taken as the research object and a cement grate cooler pressure prediction model is proposed based on the analysis of the current status of the automatic control of the grate cooler. This model uses a multi-model fusion neural network algorithm that combines a BP neural network, a support vector machine and classification and regression trees with a neural network structure. Furthermore, the multi-model fusion quality characteristics are proposed, and the root mean square error and Pearson linear correlation coefficient of the multi-model fusion quality characteristics are used as the evaluation indicators for the prediction results of the multi-model fusion neural network. After the analysis of the cooling process of the cement clinker, we select seven input variables, and then complete the data preprocessing and model parameter selection. Finally, we predict the cement grate cooler pressure using a multi-model fusion neural network, a BP neural network, a support vector machine and classification and regression trees with three training sets to test sets ratios. Through the comparison of the root mean square error and the Pearson linear correlation coefficient evaluation indicators and their change trends, as well as the display and analysis of the final modelling results, it is found that the multi-model fusion neural network algorithm can greatly improve the accuracy of the prediction of the grate pressure, and at the same time it has good practicality for the accurate prediction of the cement grate cooler pressure in the industry.","Cooling,Kilns,Heating systems,Predictive models,Neural networks,Prediction algorithms,Production,The grate cooler pressure,multi-model fusion neural network,multi-model fusion quality characteristics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CASTING,PROCESS,MACHINE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09118923.pdf,
88,An Evolutionary Perspective on the Design of Neuromorphic Shape Filters,8,,114228-114238,Greene Ernest,Greene E,Greene E,10.1109/ACCESS.2020.3004412,University of Southern California,"A substantial amount of time and energy has been invested to develop machine vision using connectionist (neural network) principles. Most of that work has been inspired by theories advanced by neuroscientists and behaviorists for how cortical systems store stimulus information. Those theories call for information flow through connections among several neuron populations, with the initial connections being random (or at least non-functional). Then the strength or location of connections are modified through training trials to achieve an effective output, such as the ability to identify an object. Those theories ignored the fact that animals that have no cortex, e.g., fish, can demonstrate visual skills that outpace the best neural network models. Neural circuits that allow for immediate effective vision and quick learning have been preprogrammed by hundreds of millions of years of evolution and the visual skills are available shortly after hatching. Cortical systems may be providing advanced image processing, but most likely are using design principles that had been proven effective in simpler systems. The present article provides a brief overview of retinal and cortical mechanisms for registering shape information, with the hope that it might contribute to the design of shape-encoding circuits that more closely match the mechanisms of biological vision.","Visual mechanisms,global shape filters,neuromorphic circuits",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECEPTIVE-FIELDS,VISUAL-DISCRIMINATION,SYNAPTIC,PLASTICITY,GANGLION-CELLS,BIPOLAR,CELLS,RECOGNITION,OBJECTS,ORGANIZATION,MECHANISMS,CONSTANCY",IEEE ACCESS,http://arxiv.org/pdf/2008.13229,
89,Resting State fMRI and Improved Deep Learning Algorithm for Earlier Detection of Alzheimer's Disease,8,,115383-115392,"Guo Haibing,Zhang Yongjin","Guo HB,Zhang YJ",Guo HB,10.1109/ACCESS.2020.3003424,Jiangsu Ocean University,"The development of computerized healthcare has been powered by diagnostic imaging and machine learning techniques. In particular, recent advances in deep learning have opened a new era in support of multimedia healthcare distribution. For earlier detection of Alzheimer's disease, the study suggested the Improved Deep Learning Algorithm (IDLA) and statistically significant text information. The specific information in clinical text includes the age, sex and genes of the person and apolipoprotein E; the brain function is established using resting-state functional data (MRI) for the measurement of connectivity in the brain regions. A specialized network of autoencoders is used in earlier diagnosis to distinguish between natural aging and disorder progression. The suggested approach incorporates effectively biased neural network functionality and allows a reliable Alzheimer's disease recognition. In comparison with conventional classifiers depends on time series R-fMRI results, the proposed deep learning algorithm has improved significantly and, in the best cases, the standard deviation reduced by 45%, indicating the forecast model is more reliable and efficient in relation to conventional methodologies. The work examines the benefits of improved deep learning algorithms from recognizing high-dimensional information in healthcare and can lead to the early diagnosis and prevention of Alzheimer's disease.","Functional magnetic resonance imaging,Alzheimer's disease,Deep learning,Data models,Brain modeling,Alzheimer's disease,autoencoder network,improved deep learning algorithm (IDLA),R-fMRI data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,BETA,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09119997.pdf,
90,Deep Learning Assisted Image Interactive Framework for Brain Image Segmentation,8,,117028-117035,"Han Yibo,Zhang Zheng","Han YB,Zhang Z",Han YB,10.1109/ACCESS.2020.3003624,Nanyang Institute of Technology,"Exacting medical imaging, surgical planning, and many others are very important to handle brain image segmentation. The Convolutional Neural Networks (CNN) has been developed by the efficient auto segmentation technology. In fact, the clinical outcomes are not appropriately specific and detailed. Nevertheless, the lack of sensitivity to images and lack of generality is reduced in traditionally invisible object classes. In this paper, Deep Learning Assisted Image Interactive Medical Image Segmentation (DL-IIMIS) is proposed to tackle these difficulties by including CNNs in the bounding box and scribble-based pipeline. To adapt a CNN model to one test frame, it is proposed that image fine tuning and geodesic transformations can be either unsupervised or supervised. In this frame, two applications are involved: 2-D multi-organ magnetic resonance (MR) segmentation, with only two types of training and 3-D segmentation within brain tumor center and in entire brain tumors with different MR sequences where only one MR sequence is reported. Compared with other algorithms, the proposed framework can output a better performance in brain image segmentation.","Convolutional neural networks (CNN),image-specific fine tuning,geodesic transforms,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ANALYTICS,NETWORK",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09121239.pdf,
91,Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images,8,,118869-118883,"Hu Shaoping,Gao Yuan,Niu Zhangming,Jiang Yinghui,Li Lao,Xiao Xianglu,Wang Minhao,Fang Evandro Fei,Menpes-Smith Wade,Xia Jun","Hu SP,Gao Y,Niu ZM,Jiang YH,Li L,Xiao XL,Wang MH,Fang EF,Menpes-Smith W,Xia J",Ye H,10.1109/ACCESS.2020.3005510,"Hunan Canc Hosp, PET CT Ctr, Changsha 410013, Peoples R China.","An outbreak of a novel coronavirus disease (i.e., COVID-19) has been recorded in Wuhan, China since late December 2019, which subsequently became pandemic around the world. Although COVID-19 is an acutely treated disease, it can also be fatal with a risk of fatality of 4.03% in China and the highest of 13.04% in Algeria and 12.67% Italy (as of 8th April 2020). The onset of serious illness may result in death as a consequence of substantial alveolar damage and progressive respiratory failure. Although laboratory testing, e.g., using reverse transcription polymerase chain reaction (RT-PCR), is the golden standard for clinical diagnosis, the tests may produce false negatives. Moreover, under the pandemic situation, shortage of RT-PCR testing resources may also delay the following clinical decision and treatment. Under such circumstances, chest CT imaging has become a valuable tool for both diagnosis and prognosis of COVID-19 patients. In this study, we propose a weakly supervised deep learning strategy for detecting and classifying COVID-19 infection from CT images. The proposed method can minimise the requirements of manual labelling of CT images but still be able to obtain accurate infection detection and distinguish COVID-19 from non-COVID-19 cases. Based on the promising results obtained qualitatively and quantitatively, we can envisage a wide deployment of our developed technique in large-scale clinical studies.","COVID-19,deep learning,weakly supervision,CT~images,classification,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,PNEUMONIA,IEEE ACCESS,http://spiral.imperial.ac.uk/bitstream/10044/1/80217/9/09127422.pdf,
92,Channel-Attention U-Net: Channel Attention Mechanism for Semantic Segmentation of Esophagus and Esophageal Cancer,8,,122798-122810,"Huang Guoheng,Zhu Junwen,Li Jiajian,Wang Zhuowei,Cheng Lianglun,Liu Lizhi,Li Haojiang,Zhou Jian","Huang GH,Zhu JW,Li JJ,Wang ZW,Cheng LL,Liu LZ,Li HJ,Zhou J",Li HJ; Zhou J,10.1109/ACCESS.2020.3007719,State Key Lab Oncology South China,"The effective segmentation of esophagus and esophageal cancer from Computed Tomography (CT) images can meaningfully assist doctors in the diagnosis and treatment of esophageal cancer patients. However, problems such as the small proportion of the esophageal region in CT images and the irregular shape of the esophagus will make the diagnosis difficult. In practical applications, not all esophagus and esophageal cancer morphology can be included in the training set, so the generalization ability of the model is very important. These are the difficulties in segmenting the esophagus and esophageal cancer. Since some adjacent tissues and organs of the esophagus are visually close to the esophagus and esophageal cancer, how to ensure that the network can extract effective distinguishing features has become the focus of research. In this paper, a novel U-Net structure - Channel-attention U-Net is proposed to segment esophagus and esophageal cancer from CT slices. This novel network combines a Channel Attention Module (CAM) that can distinguish the esophagus and surrounding tissues by emphasizing and inhibiting channel feature and Cross-level Feature Fusion Module (CFFM) which is utilized to strengthen the generalization ability of the network by using high-level features to weight low-level features. Because the high-level features represent specific organizational information, and the low-level features represent the characteristics of detailed information such as edges and contours, the network can learn specific detailed features of a definite organization. In addition, to locate the esophageal region better, a 3D semi-automatic method for segmenting esophagus and esophageal cancer is proposed. The proposed network is trained using 46,400 CT pictures as the training set and divides 11,600 CT images from the dataset at a ratio of 0.2 as the validation set. Finally, 7,250 CT images were used as the test set to test the performance of the network. The experimental results show that the IoU value of our network can reach 0.625, the dice value is 0.732 and the Hausdorff distance is 3.193.","Esophageal cancer,channel attention mechanism,deep learning,computed tomography (CT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CT,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09134858.pdf,
93,Noise Adaptive Optimization Scheme for Robust Radio Tomographic Imaging Based on Sparse Bayesian Learning,8,,118174-118182,"Huang Kaide,Yang Zhiyong","Huang KD,Yang ZY",Huang KD,10.1109/ACCESS.2020.3005048,Foshan University,"This paper addresses the robust signal reconstruction problem caused by different types of noise in radio tomographic imaging (RTI). Most of the existing reconstruction algorithms are built on the assumption of Gaussian noise, which is not the case for practical RTI systems, especially in indoor multipath environments. To weaken the effect of different types of noise on RTI performance, we propose a noise adaptive optimization scheme with sparse Bayesian learning (SBL). Specifically, we model the noise as a mixture of Gaussians (MoG) distribution, which provides the flexibility for describing the unknown and time-varying RTI noise. We further automatically estimate the MoG model parameters as well as the signal under a SBL framework, which makes the signal reconstruction more robust to the complex noise and even outliers. Experimental results in the context of device-free localization show that the proposed scheme can effectively reduce mislocalization and improve localization accuracy in the rich multipath environments, as compared with state-of-the-art reconstruction methods.","Device-free localization,radio tomographic imaging,robust signal reconstruction,sparse Bayesian learning,mixture of Gaussians",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DEVICE-FREE,LOCALIZATION,SIGNAL,STRENGTH,MODEL,SENSOR,NETWORKS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09125871.pdf,
94,S-EEGNet: Electroencephalogram Signal Classification Based on a Separable Convolution Neural Network With Bilinear Interpolation,8,,131636-131646,"Huang Wenkai,Xue Yihao,Hu Lingkai,Liuli Hantang","Huang WK,Xue YH,Hu LK,Liuli HT",Huang WK,10.1109/ACCESS.2020.3009665,Guangzhou University,"As one of the most important research fields in the brain-computer interface (BCI) field, electroencephalogram (EEG) classification has a wide range of application values. However, for the EEG signal, it is difficult for the traditional neural networks to capture the characteristics of the EEG signal more comprehensively from the time and space dimensions, which has a certain effect on the accuracy of EEG classification. To solve this problem, we can improve the accuracy of classification via end-to-end learning of the time and space dimensions of EEG. In this paper, a new type of EEG classification network, the separable EEGNet (S-EEGNet), is proposed based on Hilbert-Huang transform (HHT) and a separable convolutional neural network (CNN) with bilinear interpolation. The EEG signal is transformed into time-frequency representation by HHT, which allows the EEG signal to be better described in the frequency domain. Then, the depthwise and pointwise elements of the network are combined to extract the feature map. The displacement variable is added by the bilinear interpolation method to the convolution layer of the separable CNN, allowing the free deformation of the sampling grid. The deformation depends on the local, dense, and adaptive input characteristics of the EEG data. The network can learn from the time and space dimensions of EEG signals end to end to extract features to improve the accuracy of EEG classification. To show the effectiveness of S-EEGNet, the team used this method to test two different types of EEG public datasets (motor imagery classification and emotion classification). The accuracy of motor imagery classification is 77.9%, and the accuracy of emotion classification is 89.91%, and 88.31%, respectively. The experimental results showed that the classification accuracy of S-EEGNet improved by 3.6%, 1.15%, and 1.33%, respectively.","Electroencephalography,Convolution,Brain modeling,Feature extraction,Interpolation,Neural networks,Machine learning,Hilbert--Huang transform~(HHT),electroencephalogram~(EEG) classification,convolutional neural network~(CNN),bilinear interpolation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EMOTION,RECOGNITION,SELECTION,TIME",IEEE ACCESS,https://doi.org/10.1109/access.2020.3009665,
95,Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes,8,,120537-120547,"Islam Md. Shafiqul,Qaraqe Marwa K.,Belhaouari Samir Brahim,Abdul-Ghani Muhammad A.","Islam MS,Qaraqe MK,Belhaouari SB,Abdul-Ghani MA",Islam MS,10.1109/ACCESS.2020.3005540,Hamad Bin Khalifa University-Qatar,"Diabetes is a costly and burdensome metabolic disorder that occurs due to the elevation of glucose levels in the bloodstream. If it goes unchecked for an extended period, it can lead to the damage of different body organs and develop life-threatening health complications. Studies show that the progression of diabetes can be stopped or delayed, provided a person follows a healthy lifestyle and takes proper medication. Prevention of diabetes or the delayed onset of diabetes is crucial, and it can be achieved if there exists a screening process that identifies individuals who are at risk of developing diabetes in the future. Although machine learning techniques have been applied for disease diagnosis, there is little work done on long term prediction of disease, type 2 diabetes in particular. Moreover, finding discriminative features or risk-factors responsible for the future development of diabetes plays a significant role. In this study, we propose two novel feature extraction approaches for finding the best risk-factors, followed by applying a machine learning pipeline for the long term prediction of type 2 diabetes. The proposed methods have been evaluated using data from a longitudinal clinical study, known as the San Antonio Heart Study. Our proposed model managed to achieve 95.94% accuracy in predicting whether a person will develop type 2 diabetes within the next 7-8 years or not.","Feature extraction,fractional derivative,wavelet transform,machine learning,diabetes prediction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RISK,PREVALENCE,TRANSFORM,MELLITUS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09127427.pdf,
96,Deep Facial Diagnosis: Deep Transfer Learning From Face Recognition to Facial Diagnosis,8,,123649-123661,"Jin Bo,Cruz Leandro,Goncalves Nuno","Jin B,Cruz L,Goncalves N",Jin B; Cruz L; Goncalves N,10.1109/ACCESS.2020.3005687,Universidade de Coimbra,"The relationship between face and disease has been discussed from thousands years ago, which leads to the occurrence of facial diagnosis. The objective here is to explore the possibility of identifying diseases from uncontrolled 2D face images by deep learning techniques. In this paper, we propose using deep transfer learning from face recognition to perform the computer-aided facial diagnosis on various diseases. In the experiments, we perform the computer-aided facial diagnosis on single (beta-thalassemia) and multiple diseases (beta-thalassemia, hyperthyroidism, Down syndrome, and leprosy) with a relatively small dataset. The overall top-1 accuracy by deep transfer learning from face recognition can reach over 90% which outperforms the performance of both traditional machine learning methods and clinicians in the experiments. In practical, collecting disease-specific face images is complex, expensive and time consuming, and imposes ethical limitations due to personal data treatment. Therefore, the datasets of facial diagnosis related researches are private and generally small comparing with the ones of other machine learning application areas. The success of deep transfer learning applications in the facial diagnosis with a small dataset could provide a low-cost and noninvasive way for disease screening and detection.","Facial diagnosis,deep transfer learning (DTL),face recognition,beta-thalassemia,hyperthyroidism,down syndrome,leprosy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09127907.pdf,
97,Skin Lesions Classification Into Eight Classes for ISIC 2019 Using Deep Convolutional Neural Network and Transfer Learning,8,,114822-114832,"Kassem Mohamed A.,Hosny Khalid M.,Fouad Mohamed M.","Kassem MA,Hosny KM,Fouad MM",Hosny KM,10.1109/ACCESS.2020.3003890,Egyptian Knowledge Bank (EKB),"Melanoma is a type of skin cancer with a high mortality rate. The different types of skin lesions result in an inaccurate diagnosis due to their high similarity. Accurate classification of the skin lesions in their early stages enables dermatologists to treat the patients and save their lives. This paper proposes a model for a highly accurate classification of skin lesions. The proposed model utilized the transfer learning and pre-trained model with GoogleNet. The model parameters are used as initial values, and then these parameters will be modified through training. The latest well-known public challenge dataset, ISIC 2019, is used to test the ability of the proposed model to classify different kinds of skin lesions. The proposed model successfully classified the eight different classes of skin lesions, namely, melanoma, melanocytic nevus, basal cell carcinoma, actinic keratosis, benign keratosis, dermatofibroma, vascular lesion, and Squamous cell carcinoma. The achieved classification accuracy, sensitivity, specificity, and precision percentages are 94.92%, 79.8%, 97%, and 80.36%, respectively. The proposed model can detect images that do not belong to any one of the eight classes where these images are classified as unknown images.","Melanoma classification,skin lesions,convolution neural network,GoogleNet,ISIC 2019,bootstrap multiclass SVM,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMPUTER-AIDED,DIAGNOSIS,MELANOMA,CANCER,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09121248.pdf,
98,Residual Connection-Based Encoder Decoder Network (RCED-Net) for Retinal Vessel Segmentation,8,,131257-131272,"Khan Tariq Mahmood,Alhussein Musaed,Aurangzeb Khursheed,Arsalan Muhammad,Naqvi Syed Saud,Nawaz Syed Junaid","Khan TM,Alhussein M,Aurangzeb K,Arsalan M,Naqvi SS,Nawaz SJ",Aurangzeb K,10.1109/ACCESS.2020.3008899,King Saud University,"Devising automated procedures for accurate vessel segmentation (retinal) is crucial for timely prognosis of vision-threatening eye diseases. In this paper, a novel supervised deep learning-based approach is proposed which extends a variant of the fully convolutional neural network. The existing fully convolutional neural network-based counterparts have associated critical drawbacks of involving a large number of tunable hyper-parameters and an increased end-to-end training time furnished by their decoder structure. The proposed approach addresses these intricate challenges by using a skip-connections strategy by sharing indices obtained through max-pooling to the decoder from the encoder stage (respective stages) for enhancing the resolution of the feature map. This significantly reduces the number of required tunable hyper-parameters and the computational overhead of the training as well as testing stages. Furthermore, the proposed approach particularly helps in eradicating the requirement for employing both post-processing and pre-processing steps. In the proposed approach, the retinal vessel segmentation problem is formulated as a semantic pixel-wise segmentation task which helps in spanning the gap between semantic segmentation and medical image segmentation. A prime contribution of the proposed approach is the introduction of external skip-connection for passing the preserved low-level semantic edge information in order to reliably detect tiny vessels in the retinal fundus images. The performance of the proposed scheme is analyzed based on the three publicly available notable fundus image datasets, while the widely recognized evaluation metrics of specificity, sensitivity, accuracy, and the Receiver Operating Characteristics curves are used. Based on the assessment of the images in {DRIVE, CHASE_DB1, and STARE}; datasets, the proposed approach achieves a sensitivity, specificity, accuracy, and ROC performance of {0.8252, 0.8440, and 0.8397};, {0.9787, 0.9810, and 0.9792};, {0.9649, 0.9722, and 0.9659};, and {0.9780, 0.9830, and 0.9810};, respectively. The reduced computational complexity and memory overhead along with improved segmentation performance advocates employing the proposed approach in the automated diagnostic systems for eye diseases.","Retinal vessel segmentation,convolutional neural network,pixel-wise semantic segmentation,skip connection,low-level semantic information,residual edge information",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BLOOD-VESSELS,MATCHED-FILTER,IMAGES,EXTRACTION,LEVEL,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.3008899,
99,An Effective Predictive Maintenance Framework for Conveyor Motors Using Dual Time-Series Imaging and Convolutional Neural Network in an Industry 4.0 Environment,8,,121033-121049,"Kiangala Kahiomba Sonia,Wang Zenghui","Kiangala KS,Wang ZH",Wang ZH,10.1109/ACCESS.2020.3006788,University of South Africa,"The ascent of Industry 4.0 and smart manufacturing has emphasized the use of intelligent manufacturing techniques, tools, and methods such as predictive maintenance. The predictive maintenance function facilitates the early detection of faults and errors in machinery before they reach critical stages. This study suggests the design of an experimental predictive maintenance framework, for conveyor motors, that efficiently detects a conveyor system's impairments and considerably reduces the risk of incorrect faults diagnosis in the plant; We achieve this remarkable task by developing a machine learning model that classifies whether the abnormalities observed are production-threatening or not. We build a classification model using a combination of time-series imaging and convolutional neural network (CNN) for better accuracy. In this research, time-series represent different observations recorded from the machine over time. Our framework is designed to accommodate both univariate and multivariate time-series as inputs of the model, offering more flexibility to prepare for an Industry 4.0 environment. Because multivariate time-series are challenging to manipulate and visualize, we apply a feature extraction approach called principal component analysis (PCA) to reduce their dimensions to a maximum of two channels. The time-series are encoded into images via the Gramian Angular Field (GAF) method and used as inputs to a CNN model. We added a parameterized rectifier linear unit (PReLU) activation function option to the CNN model to improve the performance of more extensive networks. All the features listed added together contribute to the creation of a robust future proof predictive maintenance framework. The experimental results achieved in this study show the advantages of our predictive maintenance framework over traditional classification approaches.","Convolutional neural network (CNN),Gramian angular field (GAF),industry 40 (I40),predictive maintenance,principal component analysis (PCA),smart manufacturing,time-series imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CLASSIFICATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09131796.pdf,
100,Automatic Sleep Staging Based on a Hybrid Stacked LSTM Neural Network: Verification Using Large-Scale Dataset,8,,111837-111849,"Kuo Chih-En,Chen Guan-Ting","Kuo CE,Chen GT",Kuo CE,10.1109/ACCESS.2020.3002548,Feng Chia University,"Previously reported automatic sleep staging methods have usually been developed using healthy groups of fewer than 100 subjects. In this study, an automatic sleep staging method based on hybrid stacked long short-term memory (LSTM) was proposed and evaluated using a large-scale dataset of subjects with sleep disorders. Twenty-four features, including temporal and spectrum factors, were extracted from physiological signals and normalized after extracting the features. A variety of hybrid stacked LSTM structures and hidden units were used to determine the most suitable structure and parameters for the automatic sleep staging method. Finally, the proposed method was validated using a large-scale sleep disorder dataset from the PhysioNet Challenge 2018. To validate the robustness of the proposed system, half of the 994 subjects were randomly assigned to the training set, and the other half were assigned to the testing set. The best accuracy and kappa coefficient of the proposed method are 83.07% and 0.78, respectively. The best hybrid stacked structure was LSTM combined with bidirectional LSTM, which has 125 hidden units. In addition, four common sleep indices, including sleep efficiency, sleep onset time, wake after sleep onset, and total sleep time, were evaluated. The results, according to the intraclass correlation coefficient, indicated a moderate agreement with the results of the expert. The performance of the proposed method was compared with that of conventional machine learning, and it was noted that the hybrid stacked LSTM is a promising solution for automatic sleep staging. In future work, this method may assist clinical staff in reducing the time required for sleep staging.","Sleep,Feature extraction,Electroencephalography,Training,Brain modeling,Electrooculography,Electromyography,Automatic sleep staging system,deep learning,hybrid stacked long short-term memory,large-scale sleep disorder dataset",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EEG,SIGNALS,RELIABILITY",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09117091.pdf,
