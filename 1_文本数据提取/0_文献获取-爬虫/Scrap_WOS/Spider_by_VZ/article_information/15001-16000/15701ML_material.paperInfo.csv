,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Automated Pavement Crack Segmentation Using U-Net-Based Convolutional Neural Network,8,,114892-114899,"Lau Stephen L. H.,Chong Edwin K. P.,Yang Xu,Wang Xin","Lau SLH,Chong EKP,Yang X,Wang X",Yang X,10.1109/ACCESS.2020.3003638,Chang'an University,"Automated pavement crack image segmentation is challenging because of inherent irregular patterns, lighting conditions, and noise in images. Conventional approaches require a substantial amount of feature engineering to differentiate crack regions from non-affected regions. In this paper, we propose a deep learning technique based on a convolutional neural network to perform segmentation tasks on pavement crack images. Our approach requires minimal feature engineering compared to other machine learning techniques. We propose a U-Net-based network architecture in which we replace the encoder with a pretrained ResNet-34 neural network. We use a ""one-cycle"" training schedule based on cyclical learning rates to speed up the convergence. Our method achieves an F1 score of 96% on the CFD dataset and 73% on the Crack500 dataset, outperforming other algorithms tested on these datasets. We perform ablation studies on various techniques that helped us get marginal performance boosts, i.e., the addition of spatial and channel squeeze and excitation (SCSE) modules, training with gradually increasing image sizes, and training various neural network layers with different learning rates.","Convolutional neural network,deep learning,fully convolutional network,pavement crack segmentation,U-Net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"3D,ASPHALT,SURFACES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09121269.pdf,
2,Multi-Phases and Various Feature Extraction and Selection Methodology for Ensemble Gradient Boosting in Estimating Respiratory Rate,8,,125648-125658,"Lee Soojeong,Son Chang-Hwan,Albertini Marcelo K.,Fernandes Henrique C.","Lee S,Son CH,Albertini MK,Fernandes HC",Lee S,10.1109/ACCESS.2020.3007524,Sejong University,"Estimating the correct respiratory rate (RR) is an essential technique for intensive care units, hospitals, geriatric hospital facilities, and home care services. Capnography is a standard methodology used to monitor carbon dioxide concentrations or partial pressures of respiratory gases to provide the most accurate RR measurements. However, it is inconvenient to use and has been primarily used while administering anesthesia and during intensive care. Many researchers now use electrocardiogram signals to estimate RR. Despite the recent developments, the current hospital environments suffer from inaccurate respiratory monitoring. While various machine learning techniques, including deep learning, have recently been applied to the medical processing sector, only a few studies have been conducted in the field of RR estimation. Therefore, using photoplethysmography, machine-learning techniques such as the ensemble gradient boosting algorithm are being employed in RR estimation. Multi-phases are used based on various feature extraction and selection methodology to improve the performance for RR estimation. In this study, the number of ensembles is increased, and the proposed ensemble methodology is effectively learned to estimate the RR. The proposed ensemble-based gradient boosting algorithm are compared with those of ensemble-based long-short memory network, and ensemble-based supported vector regression techniques, 3.30 breaths per min (bpm), 4.82 bpm and 5.83 bpm based on mean absolute errors. The proposed method shows a more accurate estimate of the respiration rate.","Respiration rate estimation,gradient boosting algorithm,ensemble methodology,photolethysmography signals",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,ECG,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09133563.pdf,
3,Automated Gleason Grading and Gleason Pattern Region Segmentation Based on Deep Learning for Pathological Images of Prostate Cancer,8,,117714-117725,"Li Yuchun,Huang Mengxing,Zhang Yu,Chen Jing,Xu Haixia,Wang Gang,Feng Wenlong","Li YC,Huang MX,Zhang Y,Chen J,Xu HX,Wang G,Feng WL",Huang MX; Zhang Y,10.1109/ACCESS.2020.3005180,Hainan University,"Prostate cancer is the second-deadliest cancer in men in the United States, seriously affecting people's life and health. The Gleason grading system is one of the most reliable methods to quantify the invasiveness of prostate cancer, which is of great significance for risk assessment and treatment planning for patients. However, the task of automating Gleason grading is difficult because of the complexity of pathological images of prostate cancer. This paper presents an automated Gleason grading and Gleason pattern region segmentation method based on deep learning for pathological images of prostate cancer. An architecture combining the atrous spatial pyramid pooling and the multiscale standard convolution is proposed for the segmentation of the Gleason pattern region to get accurate Gleason grading. In addition, the postprocessing procedure based on conditional random fields is applied to the prediction. The quantitative experiments on 1211 prostate cancer tissue microarrays demonstrate that our results have a high correlation with the manual segmentations. The mean intersection over union and the overall pixel accuracy for the Gleason pattern region are 77.29% and 89.51%, respectively. Furthermore, the results of the automatic Gleason grading were comparable to the results of experienced pathologists. The inter-annotator agreements between the model and the pathologists, quantified via Cohen's quadratic kappa statistic, was 0.77 on average. Our study shows that the method of combining different deep neural network architectures is suitable for more objective and reproducible Gleason grading of prostate cancer.","Prostate cancer,gleason grading,image segmentation,deep learning,atrous spatial pyramid pooling,computer-aided diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"TUMOR,NUCLEI,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09126781.pdf,
4,Using EEG and Deep Learning to Predict Motion Sickness Under Wearing a Virtual Reality Device,8,,126784-126796,"Liao Chung-Yen,Tai Shao-Kuo,Chen Rung-Ching,Hendry Hendry","Liao CY,Tai SK,Chen RC,Hendry H",Chen RC,10.1109/ACCESS.2020.3008165,Chaoyang University of Technology,"Virtual Reality (VR) research has been widely applied in many fields. VR promises to deliver the experience that is beyond the user's imagination. One of the advantages of VR is the feeling it gives of being there. VR can provide experiences impossible in the real world, such as flying, diving in deep water, exploring outer space, or living with dinosaurs. Despite the improvements in the software and hardware, the problem of motion sickness remains. We implement a deep learning model to train and predict motion sickness. A questionnaire is a well-known method to measure motion sickness. The weakness of the questionnaire is the measurement carried out after the user experiences motion sickness symptoms. By using the deep learning and EEG, the system will learn and classify motion sickness. The system learns the user's EEG pattern when they begin to feel the sickness symptoms. The system will be trained using deep learning to identify the sickness patterns in the future. By the EEG patterns, the system can predict the sickness symptoms before it occurs. Our model outperforms traditional models in loss values, accuracy, and F-measure metrics in Roller Coaster. With other datasets, our model also performs well. Our model can achieve 82.83% accuracy from the dataset. We also found that the time steps to predict motion sickness during 5 minute periods is a suitable configuration.","Brainwaves EEG,cybersickness,deep learning,motion dizziness detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"QUESTIONNAIRE,CYBERSICKNESS,PERFORMANCE,DISPLAYS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09137130.pdf,
5,Prediction Optimization of Cervical Hyperextension Injury: Kernel Extreme Learning Machines With Orthogonal Learning Butterfly Optimizer and Broyden- Fletcher-Goldfarb-Shanno Algorithms,8,,119911-119930,"Liu Guomin,Jia Wenyuan,Luo Yungang,Wang Mingjing,Heidari Ali Asghar,Ouyang Jinsheng,Chen Huiling,Chen Mayun","Liu GM,Jia WY,Luo YG,Wang MJ,Heidari AA,Ouyang JS,Chen HL,Chen MY",Luo YG,10.1109/ACCESS.2020.3003366,Jilin University,"In this research, X-ray and MRI images of patients suffering from cervical hyperextension injury are investigated. Also, radiographic images are collected from patients who suffered from trauma but without cervical hyperextension injury. The core engine algorithm of the optimized prediction model is kernel extreme learning machine (KELM), and the input data is 17 factors that may cause cervical hyperextension injury. As the optimization core, we utilized the Butterfly optimization algorithm (BOA). Up to now, few improved variants of BOA have been reported. The original BOA converges slowly and quickly falls into a locally optimal solution. An enhanced BOA based on orthogonal learning, Levy flight, and an exploitation engine is proposed in this paper to relieve these two shortcomings, which is called LBOLBOA. Orthogonal learning is utilized to construct guidance vectors for guiding agents toward the global optimum solution aiming to increase the accuracy of the solutions. Also, Levy flight and Broyden-Fletcher-Goldfarb-Shanno mechanisms are utilized to enrich the intensification propensities of BOA and stagnation avoidance. The proposed LBOLBOA is used to deal with continuous function optimization and machine learning problems, including parameter optimization of KELM. We rigorously verified this variant using a comprehensive set of the benchmark test suite and real-world dataset on cervical hyperextension injury. The results indicate that LBOLBOA can achieve improved performance in dealing with the function optimization and machine learning problems, especially the capability for prediction of cervical hyperextension injury.","Optimization,Prediction algorithms,Predictive models,Injuries,Kernel,Support vector machines,Benchmark testing,Butterfly optimization algorithm,medical diagnosis,kernel extreme learning machine,parameter optimization,global optimization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MODEL,EVOLUTIONARY,RECOGNITION,PERFORMANCE,FRAMEWORK,STRATEGY,PRICE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09120017.pdf,
6,Integrating Haze Density Features for Fast Nighttime Image Dehazing,8,,113318-113330,"Lou Wenhua,Li Yijun,Yang Guowei,Chen Chenglizhao,Yang Huan,Yu Teng","Lou WH,Li YJ,Yang GW,Chen CLZ,Yang H,Yu T",Yu T,10.1109/ACCESS.2020.3003444,Qingdao University,"To date, much progress has been achieved on daytime image dehazing, yet the nighttime dehazing problem is still not well addressed. Different from the imaging conditions in the daytime, the ambient illumination in the nighttime hazy scene is usually not globally isotropic due to the non-uniform incident lights from multiple artificial light sources. Currently, almost all the existing nighttime dehazing methods use a certain kind of image priors, whereby these spatial filtering based priors are not widely applicable in nighttime hazy scenes. For example, the maximum reflectance prior (MRP) cannot handle the dark regions well and the dark channel prior (DCP) is not valid in the light source regions. In this paper, we propose an efficient and fast method for nighttime image dehazing. By exploring the visual properties of hazy images, we construct an effective linear model to build the connection between the transmission and multiple haze-relevant features. Towards solving this model, a data-driven approach is adopted to learn the unknown coefficients. Operating on the pixel level, this novel approach requires no further refinement of transmission map as used in those prior-based methods. In addition, aiming at solving the problem of halo effect around the light sources caused by MRP, we introduce a color-dependant MRP method for color correction. We demonstrate the effectiveness of our method on a number of experiments compared to the state-of-the-art nighttime dehazing methods.","Image color analysis,Atmospheric modeling,Lighting,Light sources,Materials requirements planning,Scattering,Imaging,Image dehazing,image restoration,color correction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,ALGORITHM,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09120007.pdf,
7,A Novel Adaptive Weighted Loss Design in Adversarial Learning for Retinal Nerve Fiber Layer Defect Segmentation,8,,132348-132359,"Lu Shuai,Hu Man,Li Ruirui,Xu Yongli","Lu S,Hu M,Li RR,Xu YL",Xu YL,10.1109/ACCESS.2020.3009442,Beijing University of Chemical Technology,"Glaucoma is a chronic eye disease that can cause permanent visual loss and is difficult to detect early. Retinal nerve fiber layer defect (RNFLD) is clinical evidence for the diagnosis of glaucoma. Classical deep learning based methods can be used to segment RNFLD from fundus images. However, the segmentation results of these methods do not have the specific geometry of RNFLD, and the segmentation errors of fundus images with special styles are large. In this paper, we present a novel conditional adversarial shuffle U-shaped network (CASU-Net) to segment RNFLD, which consists of a generator and a discriminator. For the generator, a mixed loss is designed, which consists of an adaptive weighted segmentation loss and an adversarial loss. This adaptive weighted segmentation loss can balance the segmentation accuracy of the target and background region, and assign more attention to the hard samples, thus ensuring the consistent improvement of the segmentation accuracy of all fundus images. The adversarial loss not only helps to improve the pixel-wise segmentation accuracy but also makes the geometry of the RNFLD segmentation closer to the ground truth. In addition, in the generator, a shuffle module was designed to fully mine the information of all channels to improve the feature extraction capability of the model. The proposed CASU-Net is verified on a RNFLD dataset from Beijing Tongren Hospital. The experiments show that the CASU-Net achieves state-of-the-art results on this dataset.","Image segmentation,Generators,Image color analysis,Feature extraction,Retina,Machine learning,Training,Glaucoma,retinal nerve fiber layer defect segmentation,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"OPTIC,DISC,GLAUCOMA,QUANTIFICATION,DIAGNOSIS,NETWORK,IMAGES,CNN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09141229.pdf,
8,Automatic Tumor Segmentation by Means of Deep Convolutional U-Net With Pre-Trained Encoder in PET Images,8,,113636-113648,"Lu Yongzhou,Lin Jinqiu,Chen Sheng,He Hui,Cai Yuantao","Lu YZ,Lin JQ,Chen S,He H,Cai YT",Lin JQ; Chen S,10.1109/ACCESS.2020.3003138,University of Shanghai for Science & Technology,"To assist physicists in developing radiation therapy treatment plans and in evaluating the effects of radiotherapy, an accurate and automatic tumor segmentation approach in positron emission tomography (PET) images is highly demanded in the clinical practice. In the present paper we investigate and construct a neural network architecture for auto-segmenting tumors by leveraging a 14-layer U-Net model with two blocks of a VGG19 encoder pre-trained with ImageNet. For pursuing efficient learning, a series of training strategies are proposed with limited training data. First, we apply a loss function based on Jaccard distance to re-balance the weights of training samples without re-weighting. Because of highly unbalanced data, re-weighting is an essential step but brings additional computation when cross-entropy loss function is used for medical image segmentation. Second, we import the DropBlock technique to replace the normal regularization dropout method as the former can help the U-Net efficiently avoid overfitting. We use a database containing 1309 PET images to train and test the proposed model. The mask, contour, and smoothed contour of a tumor are used as truths for teaching the proposed model. These are provided by expert radiologists. The segmentation accuracy compared to the truths is evaluated by calculating the Dice coefficient, Hausdorff distance, Jaccard index, sensitivity, and precision metrics. Extensive experimental results show that our method has achieved a relatively competitive performance in PET images on tumor segmentation. The volumes of the segmented tumors provided by our model would enable accurate automated identification and serial measurement of tumor volumes in PET images.","Image segmentation,Tumors,Positron emission tomography,Biomedical imaging,Thresholding (Imaging),Computer architecture,Training,Deep learning,positron emission tomography (PET),segmentation,tumor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"C-MEANS,ALGORITHM,NEURAL-NETWORK,VOLUME,DELINEATION,CHEST,RADIOGRAPHS,QUANTIFICATION,CLASSIFICATION,SEPARATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09119426.pdf,
9,Supervised Fractional-Order Embedding Geometrical Multi-View CCA (SFGMCCA) for Multiple Feature Integration,8,,114340-114353,"Maeda Keisuke,Ito Yoshiki,Ogawa Takahiro,Haseyama Miki","Maeda K,Ito Y,Ogawa T,Haseyama M",Maeda K,10.1109/ACCESS.2020.3003619,Hokkaido University,"Techniques for integrating different types of multiple features effectively have been actively studied in recent years. Multiset canonical correlation analysis (MCCA), which maximizes the sum of pairwise correlations of inter-view (i.e., between different features), is one of the powerful methods for integrating different types of multiple features, and various MCCA-based methods have been proposed. This work focuses on a supervised MCCA variant in order to construct a novel effective feature integration framework. In this paper, we newly propose supervised fractional-order embedding geometrical multi-view CCA (SFGMCCA). This method constructs not only the correlation structure but also two types of geometrical structures of intra-view (i.e., within each feature) and inter-view simultaneously, thereby realizing more precise feature integration. This method also supports the integration of small sample and high-dimensional data by using the fractional-order technique. We conducted experiments using four types of image datasets, i.e., MNIST, COIL-20, ETH-80 and CIFAR-10. Furthermore, we also performed an fMRI dataset containing brain signals to verify the robustness. As a result, it was confirmed that accuracy improvements using SFGMCCA were statistically significant at the significance level of 0.05 compared to those using conventional representative MCCA-based methods.","Feature integration,multi-view,canonical correlation analysis,fractional-order technique,geometrical structure",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CANONICAL,CORRELATION-ANALYSIS,REDUCTION,REPRESENTATION,APPEARANCE,DIMENSION,FUSION,SETS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09121214.pdf,
10,"Malignant Melanoma Classification Using Deep Learning: Datasets, Performance Measurements, Challenges and Opportunities",8,,110575-110597,"Naeem Ahmad,Farooq Muhammad Shoaib,Khelifi Adel,Abid Adnan","Naeem A,Farooq MS,Khelifi A,Abid A",Farooq MS,10.1109/ACCESS.2020.3001507,"Univ Management & Technol, Dept Comp Sci, Lahore 54000, Pakistan.","Melanoma remains the most harmful form of skin cancer. Convolutional neural network (CNN) based classifiers have become the best choice for melanoma detection in the recent era. The research has indicated that classifiers based on CNN classify skin cancer images equivalent to dermatologists, which has allowed a quick and life-saving diagnosis. This study provides a systematic literature review of the latest research on melanoma classification using CNN. We restrict our study to the binary classification of melanoma. In particular, this research discusses the CNN classifiers and compares the accuracies of these classifiers when tested on non-published datasets. We conducted a systematic review of existing literature, identifying the literature through a systematic search of the IEEE, Medline, ACM, Springer, Elsevier, and Wiley databases. A total of 5112 studies were identified out of which 55 well-reputed studies were selected. The main objective of this study is to collect state of the art research which identify the recent research trends, challenges and opportunities for melanoma diagnosis and investigate the existing solutions for the diagnosis of melanoma detection using deep learning. Moreover, proposed taxonomy for melanoma detection has been presented that summarizes the broad variety of existing melanoma detection solutions. Lastly, proposed model, challenges and opportunities have been presented which helps the researchers in the domain of melanoma detection.","Melanoma,Deep learning,Systematics,Skin,Lesions,Deep learning,CNN,skin cancer,melanoma,detection,diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORK,SKIN-CANCER,SEGMENTATION,DIAGNOSIS,FEATURES,ALGORITHMS,REVIEWS,FUSION,IMAGES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09113301.pdf,
11,Deep-Learning-Based Predictive Architectures for Self-Piercing Riveting Process,8,,116254-116267,"Oh Sehyeok,Kim Hyun Kyung,Jeong Taek-Eon,Kam Dong-Hyuck,Ki Hyungson","Oh S,Kim HK,Jeong TE,Kam DH,Ki H",Ki H,10.1109/ACCESS.2020.3004337,Ulsan National Institute of Science & Technology (UNIST),"Deep-learning architectures were developed for the self-piercing riveting (SPR) process to predict the cross-sectional shape from the scalar input of the punch force. Traditionally, the SPR process is studied using a physic-based approach, including finite element modeling, but in this study, a data-driven approach consisting of two supervised deep-learning models was proposed. The first model was used for data transformation from an optical microscopic image to a material segmentation map, which characterizes the shape and location of the two sheets and the rivet by applying a convolutional neural network (CNN)-based deep-learning structure. To validate the developed models, two types of sheet combinations were tested, namely, carbon-fiber-reinforced plastic (CFRP) and galvanized dual-phase steel (GA590DP) sheets, and steel alloy (SPFC590DP) and aluminum alloy (Al5052-H32) sheets. The transformation was performed with a mean intersection-over-union of 98.50% and a mean pixel accuracy of 99.78%. The next model, which was a novel generative model based on a CNN and conditional generative adversarial network with residual blocks, was then trained to predict the cross-sectional shape from the input punch force. The predicted cross-sectional shapes were compared with the experimental results of SPR. The overall accuracy was 94.20% for CFRP-GA590DP and 96.31% for SPFC590DP-Al5052, with respect to three key geometrical indexes, namely, rivet head height, interlock length, and bottom thickness.","Cross-sectional shape prediction,deep learning,segmentation prediction,scalar-to-segmentation generator,self-piercing riveting",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SPR,JOINTS,SIMULATION,ALUMINUM",IEEE ACCESS,https://doi.org/10.1109/access.2020.3004337,
12,CephaNN: A Multi-Head Attention Network for Cephalometric Landmark Detection,8,,112633-112641,"Qian Jiahong,Luo Weizhi,Cheng Ming,Tao Yubo,Lin Jun,Lin Hai","Qian JH,Luo WZ,Cheng M,Tao YB,Lin J,Lin H",Lin H,10.1109/ACCESS.2020.3002939,Zhejiang University,"Cephalometric landmark detection is a crucial step in orthodontic and orthognathic treatments. To detect cephalometric landmarks accurately, we propose a novel multi-head attention neural network (CephaNN). CephaNN is an end-to-end network based on the heatmaps of annotated landmarks, and it consists of two parts, the multi-head part and the attention part. In the multi-head part, we adopt multi-head subnets to gain comprehensive knowledge of various subspaces of a cephalogram. The intermediate supervision is applied to accelerate the convergence. Based on the feature maps learned from the multi-head Part, the attention part applies the multi-attention mechanism to obtain a refined detection. For solving the class imbalance problem, we propose a region enhancing (RE) loss, to enhance the efficient regions on the regressed heatmaps. Experiments in the benchmark dataset demonstrate that CephaNN is state-of-the-art with the detection accuracy of 87.61% in the clinically accepted 2.0-mm range. Furthermore, CephaNN is efficient in classifying the anatomical types and robust in a real application on a 75-landmark dataset.","Heating systems,Neural networks,Kernel,Feature extraction,Annotations,Two dimensional displays,Deep learning,Cephalometric landmark detection,multi-head attention,neural network,intermediate supervision,region enhance",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09119128.pdf,
13,Iteratively Pruned Deep Learning Ensembles for COVID-19 Detection in Chest X-Rays,8,,115041-115050,"Rajaraman Sivaramakrishnan,Siegelman Jenifer,Alderson Philip O.,Folio Lucas S.,Folio Les R.,Antani Sameer K.","Rajaraman S,Siegelman J,Alderson PO,Folio LS,Folio LR,Antani SK",Rajaraman S,10.1109/ACCESS.2020.3003810,National Institutes of Health (NIH) - USA,"We demonstrate use of iteratively pruned deep learning model ensembles for detecting pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus (2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific feature representations. The learned knowledge is transferred and fine-tuned to improve performance and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and improve memory efficiency. The predictions of the best-performing pruned models are combined through different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that the weighted average of the best-performing pruned models significantly improves performance resulting in an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening using chest radiographs.","COVID-19,convolutional neural network,deep learning,ensemble,iterative pruning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7394290,
14,A Genotype-Based Ensemble Classifier System for Non-Small-Cell Lung Cancer,8,,128509-128518,"Ren Yanqiong,Yang Zi-Yi,Zhang Hui,Liang Yong,Huang Hai-Hui,Chai Hua","Ren YQ,Yang ZY,Zhang H,Liang Y,Huang HH,Chai H",Liang Y,10.1109/ACCESS.2020.3008750,Macau University of Science & Technology,"The heterogeneity of cancer reflects the complexity of genetic mutations. Dissecting the heterogeneity plays an important role in the field of biomarker discovery, targeted therapy and drug designing. As it is time-consuming to identify new biomarkers in biological experiments, various machine learning methods have been developed. However, the current methods are limited because they ignore that patients may correspond to different disease-causing genotypes. In this article, a genotype-based ensemble classifier system (GECS) is proposed which aims to explain pathologies of NSCLC from the view of genotypes and identify the genetic subtypes of tumors. The core strategy of GECS is to construct multiple independent classifiers following the principle that one classifier is constructed based on one genotype of NSCLC. The analysis of synthetic data and three microarray datasets indicated that the proposed method outperforms existing approaches in the identification of genetic subtypes of tumors. The GECS method provides a useful tool for molecular pathology researches for dissecting the heterogeneity of cancer.","Biomarker,genotype,ensemble classifier system,prior information",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MUTATIONS,BIOMARKER,SURVIVAL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139244.pdf,
15,A Review on Recent Progress in Thermal Imaging and Deep Learning Approaches for Breast Cancer Detection,8,,116176-116194,"Roslidar Roslidar,Rahman Aulia,Muharar Rusdha,Syahputra Muhammad Rizky,Arnia Fitri,Syukri Maimun,Pradhan Biswajeet,Munadi Khairul","Roslidar R,Rahman A,Muharar R,Syahputra MR,Arnia F,Syukri M,Pradhan B,Munadi K",Munadi K,10.1109/ACCESS.2020.3004056,Universitas Syiah Kuala,"Developing a breast cancer screening method is very important to facilitate early breast cancer detection and treatment. Building a screening method using medical imaging modality that does not cause body tissue damage (non-invasive) and does not involve physical touch is challenging. Thermography, a non-invasive and non-contact cancer screening method, can detect tumors at an early stage even under precancerous conditions by observing temperature distribution in both breasts. The thermograms obtained on thermography can be interpreted using deep learning models such as convolutional neural networks (CNNs). CNNs can automatically classify breast thermograms into categories such as normal and abnormal. Despite their demostrated utility, CNNs have not been widely used in breast thermogram classification. In this study, we aimed to summarize the current work and progress in breast cancer detection based on thermography and CNNs. We first discuss of breast thermography potential in early breast cancer detection, providing an overview of the availability of breast thermal datasets together with publicly accessible. We also discuss characteristics of breast thermograms and the differences between healthy and cancerous thermographic patterns. Breast thermogram classification using a CNN model is described step by step including a simulation example illustrating feature learning. We cover most research related to the implementation of deep neural networks for breast thermogram classification and propose future research directions for developing representative datasets, feeding the segmented image, assigning a good kernel, and building a lightweight CNN model to improve CNN performance.","Breast cancer,convolutional neural network,deep learning,early detection,thermogram",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMPUTER-AIDED,DETECTION,TEXTURE,FEATURES,NEURAL-NETWORK,TUMOR,SIZE,CLASSIFICATION,SEGMENTATION,THERMOGRAPHY,IMAGES,RISK,MAMMOGRAPHY",IEEE ACCESS,https://opus.lib.uts.edu.au/bitstream/10453/143382/2/09121984.pdf,
16,A Granular Level Feature Extraction Approach to Construct HR Image for Forensic Biometrics Using Small Training DataSet,8,,123556-123570,"Saeed Khalid,Datta Soma,Chaki Nabendu","Saeed K,Datta S,Chaki N",Chaki N,10.1109/ACCESS.2020.3006100,University of Calcutta,"In forensic biometrics old x-ray images are often used for identification and verification. The number of homicide cases has increased manyfold along with population growth. Forensic odontology is a less expensive method to solve these cases. In forensic odontology, the old dental x-ray images of a victim are used as ante mortem data to compare the pattern for identification. The success of this post mortem biometrics process totally depends on the brain perception of forensic odontologist. Low resolution (LR) image may create human brain perception error at the time of making decision both in case of disease diagnosis and forensic biometrics. In such context, a software solution could help to reconstruct high resolution (HR) image from LR medical x-ray image. However, methods like convolution neural network (CNN) require high volume of training images to reconstruct HR images. Unfortunately, the available medical x-ray image repository does not offer a large volume of training dataset. This work aims to overcome this data related issue and presents a granular level feature based HR grayscale medical x-ray image reconstruction mechanism from LR image. This method uses machine learning for HR image reconstruction. The proposed granular level feature extraction method generates adequate amount of training set from limited amount of training image sets. These granular level features contain the influence of neighboring points separately and its direction. These features are highly immune to noises and preserve important properties like edges. Polynomial regression model is used for HR value reconstruction. This image reconstruction provides satisfactory results for image database like dental radiographs datasets and the average structural similarity index (SSIM) metric reaches 0.9326.","Forensic odontology,dental biometrics,granular level features,polynomial neural network,superresolution,image reconstruction,data sequencing,training data shuffling",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FACE,RECOGNITION,SUPERRESOLUTION,INTERPOLATION,RESTORATION,RESOLUTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09129655.pdf,
17,Marker-Less Monitoring Protocol to Analyze Biomechanical Joint Metrics During Pedaling,8,,122782-122790,"Serrancoli Gil,Bogatikov Peter,Huix Joana Pales,Barbera Ainoa Forcada,Egea Antonio J. Sanchez,Ribe Jordi Torner,Kanaan-Izquierdo Samir,Susin Antoni","Serrancoli G,Bogatikov P,Huix JP,Barbera AF,Egea AJS,Ribe JT,Kanaan-Izquierdo S,Susin A",Serrancoli G,10.1109/ACCESS.2020.3006423,Polytechnic University of Catalonia,"Marker-less systems are becoming popular to detect a human skeleton in an image automatically. However, these systems have difficulties in tracking points when part of the body is hidden, or there is an artifact that does not belong to the subject (e.g., a bicycle). We present a low-cost tracking system combined with economic force-measurement sensors that allows the calculation of individual joint moments and powers affordable for anybody. The system integrates OpenPose (deep-learning based C++ library to detect human skeletons in an image) in a system of two webcams, to record videos of a cyclist, and seven resistive sensors to measure forces at the pedals and the saddle. OpenPose identifies the skeleton candidate using a convolution neural network. A corrective algorithm was written to automatically detect the hip, knee, ankle, metatarsal and heel points from webcam-recorded motions, which overcomes the limitations of the marker-less system. Then, with the information of external forces, an inverse dynamics analysis is applied in OpenSim to calculate the joint moments and powers at the hip, knee, and ankle joints. The results show that the obtained moments have similar shapes and trends compared to the literature values. Therefore, this represents a low-cost method that could be used to estimate relevant joint kinematics and dynamics, and consequently follow up or improve cycling training plans.","Marker-less,motion capture,cycling joint moments,cycling joint power",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DYNAMICS,MOMENTS,BICYCLE,VISION,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09131774.pdf,
18,Hyperparameter Tuning Deep Learning for Diabetic Retinopathy Fundus Image Classification,8,,118164-118173,"Shankar K.,Zhang Yizhuo,Liu Yiwei,Wu Ling,Chen Chi-Hua","Shankar K,Zhang YZ,Liu YW,Wu L,Chen CH",Wu L; Chen CH,10.1109/ACCESS.2020.3005152,Fuzhou University,"Diabetic retinopathy (DR) is a major reason for the increased visual loss globally, and it became an important cause of visual impairment among people in 25-74 years of age. The DR significantly affects the economic status in society, particularly in healthcare systems. When timely treatment is provided to the DR patients, approximately 90% of patients can be saved from visual loss. Therefore, it becomes highly essential to classify the stages and severity of DR for the recommendation of required treatments. In this view, this paper introduces a new automated Hyperparameter Tuning Inception-v4 (HPTI-v4) model for the detection and classification of DR from color fundus images. At the preprocessing stage, the contrast level of the fundus image will be improved by the use of contrast limited adaptive histogram equalization (CLAHE) model. Then, the segmentation of the preprocessed image takes place utilizing a histogram-based segmentation model. Afterward, the HPTI-v4 model is applied to extract the required features from the segmented image and it subsequently undergoes classification by the use of a multilayer perceptron (MLP). A series of experiments take place on MESSIDOR (Methods to Evaluate Segmentation and Indexing Techniques in the field of Retinal Ophthalmology) DR dataset to guarantee the goodness of the HPTI-v4 approach and the obtained results clearly exhibited the supremacy of the HPTI-v4 model over the compared methods in a significant way.","Diabetic retinopathy,image classification,hyperparameter,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09126771.pdf,
19,IDS-DLA: Sheet Metal Part Identification System for Process Automation Using Deep Learning Algorithms,8,,127329-127342,"Sheu Ruey-Kai,Lin Yuan-Cheng,Huang Chin-Yin,Chen Lun-Chi,Pardeshi Mayuresh Sunil,Tseng Hsi-Hsien","Sheu RK,Lin YC,Huang CY,Chen LC,Pardeshi MS,Tseng HH",Lin YC,10.1109/ACCESS.2020.3007257,Tunghai University,"Sheet metal-based manufacturing industries operate on several varieties of sheet metal parts. Previously QR codes stickers were put on sheet metal parts for identification by manual workers as per their respective shape and size features, thus ensuring synchronized raw material flow for the manufacturing process. However, identifying a particular type of sheet metal part based on its different features is still a challenge for a trained manual operator. Currently, in the market, there exist some automation solutions for solving such kind of problem but are incapable of achieving better performance and possess accuracy issues. So our goal is to provide process automation by overcoming manual work-based dependency and limitations. Therefore, a system is required that can take input a high definition camera captured sheet metal part image and provide an accurately identified type as output by utilizing a deep learning classification model in computer vision. The automation of sheet metal part identification by using ERP, CAD files and scheduling among them would make a smooth workflow by IDS-DLA. This paper aims to solve the identification problem by using the design and implementation of a sheet metal part identification, given as sheet metal part IDentification System for process automation using Deep Learning Algorithms (IDS-DLA). Considering the sheet metal parts there exists a large volume of types but fewer quantities. IDS-DLA performs high accuracy sheet metal part identification from the CAD model database by using the Geometric and CNN triplet filter. The IDS-DLA also evaluates the Hu moment ranking to choose the top 5 rank predictions as final ranking results. The applications can be given as manufacturing process automation for industry, 2D CAD search, 2D measuring solution, closet formation, etc. Ultimately, from the experiments, it can be observed that better accuracy is obtained as compared with the previous benchmarks. This multi-filtering approach using a deep feature extraction algorithm concludes to be the better approach and achieves higher performance.","Feature identification,large type and small volume,deep learning,sheet metal,CNN",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FEATURE-EXTRACTION,RECOGNITION,FEATURES,CLASSIFICATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09133380.pdf,
20,Prediction of the Electrical Strength and Boiling Temperature of the Substitutes for Greenhouse Gas SF6 Using Neural Network and Random Forest,8,,124204-124216,"Sun Hao,Liang Luqi,Wang Chunlin,Wu Yi,Yang Fei,Rong Mingzhe","Sun H,Liang LQ,Wang CL,Wu Y,Yang F,Rong MZ",Wu Y,10.1109/ACCESS.2020.3004519,Xi'an Jiaotong University,"Finding substitutes for sulfur hexafluoride (SF6), a gas with extremely high global warming potential, has been a persistent effort for years in the field of high voltage power equipment, which focuses on the evaluation of the electrical strength and boiling temperature for the practical purpose. Following up the previous proposed linear regression models, this work introduces machine learning algorithms including artificial neural network (ANN) and random forest (RF) as the potential approaches to predict the electrical strength and boiling temperature. Based on a series of descriptors derived from the molecular structure of 74 molecules, the performance of three different methods: multiple linear regression, artificial neural network and random forest are compared and assessed in terms of the sensitivity to the sample size, prediction accuracy and stability, and the interpretability of predictors. Considering the available data are limited, random forest shows superior performance with higher robustness and efficiency. The same approaches were applied to the boiling temperature and random forest produced better results as well. Besides, the variable importance ranked by RF improves understanding of the correlation between the molecular properties and electrical strength. It provides important insights to analyze the properties of the SF6 substitutes during the design and synthesis of the new eco-friendly gases in power equipment.","SF6 substitutes,artificial neural network,random forest,electrical strength,boiling temperature",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DIELECTRIC,STRENGTH,PARTIAL,DISCHARGE,INSULATION,REGRESSION,MOLECULES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09123755.pdf,
21,"Hybrid Segmentation Algorithm for Medical Image Segmentation Based on Generating Adversarial Networks, Mutual Information and Multi-Scale Information",8,,118957-118968,"Sun Yi,Yuan Peisen,Sun Yuming,Zhai Zhaoyu","Sun Y,Yuan PS,Sun YM,Zhai ZY",Yuan PS,10.1109/ACCESS.2020.3005384,Nanjing Agricultural University,"This paper proposes 3D-MedGAN, MLU-Net and Info-Max-Net models for overcoming the lack of labeled data and extracting the multi-level feature of images in medical image segmentation. 3D-MedGAN is aimed at dealing with the lack of labeled data in medical images. It uses a generative adversarial network to simulate data and then draws newly generated samples from the distribution learned by the model. Training the segmentation model by mixing generated samples with real samples can effectively improve the effect of the segmentation model. MLU-Net uses multiple layers of different levels of convolutional angles to extract feature information from multiple angles in medical images. By adopting the attention mechanism to fuse the multi-level feature information, MLU-Net is able to improve the feature expressions and segmentation effect. Info-Max-Net is aimed at handling the noise problem in medical images. When the information in the images is complex, it is difficult to extract features. Using mutual information to measure the dependency between the image and the extracted features can effectively reduce noise in the image and improve the effect of segmentation. At the same time, for solving the problem that the high dimension of the image makes it difficult to measure mutual information, this paper uses a lower bound BL-estimator to measure the mutual information between the optimized image and the extracted features. Therefore, the model can maintain a high convergence speed as it approaches the true value of mutual information. Considering that the quality of images generated by 3D-MedGAN are not as good as the original images, we combine the 3D-MedGAN, MLU-Net, and Info-Max-Net to improve the sensitivity and the power of feature extraction of the hybird model. The effectiveness of our model is verified through experiments of the 3D-MedGAN, MLU-Net, Info-Max-Net, and the hybrid model over the LIVER100 dataset.","Medical image segmentation,generative adversarial network,mutual information maximization,multi-scale information",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09127418.pdf,
22,A Novelty Approach to Retina Diagnosing Using Biometric Techniques With SVM and Clustering Algorithms,8,,125849-125862,"Szymkowski Maciej,Saeed Emil,Omieljanowicz Miroslaw,Omieljanowicz Andrzej,Saeed Khalid,Mariak Zofia","Szymkowski M,Saeed E,Omieljanowicz M,Omieljanowicz A,Saeed K,Mariak Z",Szymkowski M,10.1109/ACCESS.2020.3007656,Bialystok University of Technology,"A method to extract the retina characteristic points for the purpose of medical diagnosis of the human eye is presented in this research. The proposed method helps to make the primary decision about the illness faster and can be used on mobile devices. The algorithm is mostly based on the characteristic points (the so-called minutiae). These structures are commonly used in the biometric applications for fingerprint-based people recognition. In the case of the conducted research, this trait was used to differentiate healthy eyes from unhealthy ones. The methods were evaluated by appropriately implemented algorithms, showing promising results. Each solution was created with object-oriented programming language. The accuracy of the classification (healthy versus samples with pathological changes) was evaluated using four algorithms: k-Nearest Neighbors, k-Means and Support Vector Machines (SVM) with linear and third-degree polynomial as well as our own approach based on counting the minutiae number. Performance requirements were also checked, and it was verified that the computing power of modern mobile devices is sufficient to implement the proposed solution. The highest accuracy result was equal to 96,45% and was obtained with the third-degree polynomial SVM. This was a novel approach. For comparative purposes, we also implemented currently used solutions for image analysis - deep learning (DL) and Convolution Neural Networks (CNNs). Both medical and computer science backgrounds are presented in the work with the main methodology components to include image segmentation using the Gaussian Matched Filter, binarization by Local Entropy Thresholding and classification with the previously mentioned approaches.","Biometrics,clustering algorithms,retina disease diagnosis,security,support vector machines (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BLOOD-VESSELS,FILTER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09134747.pdf,
23,Quantized Deep Residual Convolutional Neural Network for Image-Based Dietary Assessment,8,,111875-111888,"Tan Ren Zhang,Chew Xinying,Khaw Khai Wah","Tan RZ,Chew XY,Khaw KW",Chew XY,10.1109/ACCESS.2020.3003518,Universiti Sains Malaysia,"Vegetable intake is an essential element to maintain a healthy body of a human. However, research shows most people do not consume an adequate intake of vegetables per day. An ameliorate dietary assessment for vegetable intake is needed to increase awareness and assist users to improve their vegetable consumption. In this paper, we proposed a novel Quantized Deep Residual Convolutional Neural Network (DRCNN) model to ameliorate the fundamental task of dietary assessment. The proposed deep learning strategy integrating a deep residual architecture and a deep learning model, i.e. convolutional neural network, to apply for image-based dietary assessment. The proposed DRCNN model is then deeply fused with post-training quantization techniques to quantize the network weights of the proposed DRCNN model into low-bit fixed-point representations. Extensive experiments have been done to evaluate the proposed model. Results show that the proposed Quantized DRCNN model outperformed the state-of-the-arts, which include the conventional CNN models and also the machine learning models. Those experiments also indicate the effectiveness of the proposed Quantized DRCNN model. Finally, we further evaluate our model with cross-dataset validation to verify the generalization of the proposed model. The experimental result proves that the proposed Quantized DRCNN model is general enough to predict unseen cases and it works well on a wide range of food images.","Convolutional neural network,deep learning,deep residual network,image-based dietary assessment,machine learning,quantized model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FOOD,RECOGNITION,FEATURES,CLASSIFICATION,DESIGN,SYSTEM,NOISE,CNN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09119989.pdf,
24,Application of Deep Learning Algorithm in Clinical Analysis of Patients With Serum Electrolyte Disturbance,8,,124646-124660,"Wang Jian,Wang Yan Ping,Chen Yao,Huang Peiji","Wang J,Wang YP,Chen Y,Huang PJ",Wang J,10.1109/ACCESS.2020.3001212,Fujian Medical University,"This article analyzes the serum electrolyte disturbances of patients through deep learning algorithms. Among the 104 patients with electrolyte disturbances, 6 cases of serum potassium, sodium, chloride, calcium, phosphorus, and magnesium electrolyte disturbances have occurred, the proportion of occurrence The order is sodium > chlorine > calcium > potassium > phosphorus > magnesium. This paper proposes a deep learning algorithm for serum electrolyte disorder, and analyzes and implements the functions at various levels according to the characteristics of the Hadoop framework. The system includes electronic medical records shared storage, distributed realization of definite learning algorithms, classification and recognition of myocardial ischemia by deep learning, and Web system assisting doctor diagnosis, which lays the foundation for the construction of serum electrolyte disorder scientific research data center. In order to explore this relationship, without artificially extracting features, a deep learning model of convolution and long-term and short-term memory circulation neural network cascade was proposed to determine the positive or negative myocardial ischemia by classifying serum disorders. Conduct clinical experiments, including patients with suspected coronary heart disease and coronary angiography as the research object, taking coronary angiography results as the detection standard. Experimental results show that the model has an accuracy of 89.0% for detecting myocardial ischemia, a sensitivity of 91.7%, and a specificity of 81.5%. A linear combination model of CNN and LSTM is proposed to classify and recognize serum electrolyte disorders. Determine the learning theory to dynamically model the ST-T segment in the ECG to obtain serum electrolyte disturbance, which more vividly shows the changes in electrical information under myocardial ischemia. In order to reveal the relationship between serum electrolyte disturbance and myocardial ischemia, this paper builds a neural network model to learn and train serum electrolyte disturbance data to realize the classification of positive or negative myocardial ischemia. Tests on serum electrolyte disturbance data collected in clinical experiments show that this model can better achieve early detection of myocardial ischemia.","Electrolytes,Sodium,Heart,Classification algorithms,Myocardium,Peptides,Deep learning,Deep learning,serum,electrolyte disturbance,clinical analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HEART-FAILURE,DIAGNOSIS,GUIDELINES,CARE,IDENTIFICATION,ASSOCIATION,MANAGEMENT,MEDICINE,NETWORKS,SOCIETY",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09113261.pdf,
25,Pathological Image Classification Based on Hard Example Guided CNN,8,,114249-114258,"Wang Ying,Peng Ting,Duan Jiajia,Zhu Chuang,Liu Jun,Ye Jiandong,Jin Mulan","Wang Y,Peng T,Duan JJ,Zhu C,Liu J,Ye JD,Jin ML",Jin ML,10.1109/ACCESS.2020.3003070,Capital Medical University,"The diagnosis of biopsy tissue with hematoxylin and eosin (H&E) stained images has been widely used by pathologists to detect the lesions and assess the malignancy. Nevertheless, the diagnostic result relies on the visual observation of pathologists which may vary from person to person under different circumstances. With the advantage of automatically and adaptively learning features at multiple levels of abstraction, Convolutional Neural Networks (CNNs) have rapidly become promising alternatives for pathological image analysis. Therefore, in this paper, we propose an effective method for tumor classification called Hard Example Guided CNN. Our contribution is twofold: firstly, to optimize image representation, we design the CNN architecture as dual-branch, used for extracting global features and local features simultaneously. Secondly, we propose a re-weight training algorithm, which improves learning accuracy and accelerates the convergence by increasing the weight of hard examples. Extensive experiments on multiple datasets demonstrate the superiority of our proposed classification method.","Feature extraction,Training,Cancer,Pathology,Lesions,Task analysis,Pathological image classification,feature fusion,re-weight training,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09119412.pdf,
26,An Innovative Scoring System for Predicting Major Adverse Cardiac Events in Patients With Chest Pain Based on Machine Learning,8,,124076-124083,"Wu Chieh-Chen,Hsu Wen-Ding,Wang Yao-Chin,Kung Woon-Man,Tzeng I-Shiang,Huang Chih-Wei,Huang Chu-Ya,Li Yu-Chuan","Wu CC,Hsu WD,Wang YC,Kung WM,Tzeng IS,Huang CW,Huang CY,Li YC",Li YC,10.1109/ACCESS.2020.3004405,Taipei Medical University,"Chest pain is a common complaint in the emergency department, but this may prevent a diagnosis of major adverse cardiac events, a composite of all-cause mortality associated with cardiovascular-related illnesses. To determine potential predictors of major adverse cardiac events in Taiwan, a pilot study was performed, involving the data from 268 patients with major adverse cardiac events, which was by an artificial neural network method. Nine biomarkers were selected for identifying non-ST-elevation myocardial infarction from common chest pain patients. By using a machine learning-based feature selection technique, five biomarkers were chosen from a set of 37 candidate variables. A full and a reduced risk stratification model were built. The full model was based on the characteristics of both invasive (i.e., creatinine and troponin I) and non-invasive (i.e., age, coronary artery disease risk factors, and corrected QT interval) variables, and the reduced model was based only on non-invasive variable characteristics. The full model showed a sensitivity of 0.948 and a specificity of 0.546 when the cutoff was set at 2 points, with a missed major adverse cardiac events rate of 1.32%, a positive predictive value of 0.228, and a negative predictive value of 0.987. High performance was also obtained with the five major biomarkers in the predictor built by the machine learning algorithm. The full model had the highest performance, but the reduced model can be applied as a quick and reasonably performing diagnostic tool.","Chest pain,emergency department,scoring system,major adverse cardiac events,ST-elevation myocardial infarction,non-ST-elevation myocardial infarction,risk stratification,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EMERGENCY-DEPARTMENT,RISK,SCORES,PROSPECTIVE,VALIDATION,QT,INTERVAL,HEART,SCORE,STRATIFICATION,PROLONGATION,MORTALITY,GRACE",IEEE ACCESS,https://doi.org/10.1109/access.2020.3004405,
27,Deep Learning-Based Earlier Detection of Esophageal Cancer Using Improved Empirical Wavelet Transform From Endoscopic Image,8,,123765-123772,"Xue Yuan,Li Na,Wei Xiaojie,Wan Ren'An,Wang Chunyan","Xue Y,Li N,Wei XJ,Wan RA,Wang CY",Wang CY,10.1109/ACCESS.2020.3006106,"Rizhao Peoples Hosp, Rizhao 276800, Peoples R China.","In the current scenario, the research perspective on esophageal cancer becomes severe, high-prognosis malignancy; poor prognosis is primarily attributed to the fact that most tumors remain asymptomatic and unrelated before it grows through the esophagus. Significant decreases in mortality from esophageal cancer may require effective approaches to detect and nurse more patients at early, curable stages. A new Improved Empirical Wavelet Transform (IEWT) dependent on feature extraction approach and a consistent homology for the diagnosis of early esophageal endoscopic cancer have been proposed in this article. The approach is to convert an input endoscope image into CIE colored spaces L * x * y, and the x* and y* components to create a fusion image for analysis. Further, the two kinds of wavelets are obtained by adding the two forms to the fusion signal. Another is the lower-frequency component provided by the improved empirical wavelet transformation of the wave, and the other is the high- components generated from the Deep Learning-based Complex Empirical Wavelet Transformation (DL-CEWT). The fractal sizes are determined using the box interpolation method for each small block, and the abnormal regions are defined for the basis of their fractal sizes. Binary pictures are obtained by the complex threshold in each frequency variable and then divided into small blocks in every binary image. Using the homology of every block to obtain the new features in the entry image. The extraction strategies for this application are comprehensive and preliminary findings indicate that the method is effective for the early detection of esophageal cancer in an image.","Esophageal cancer,empirical wavelet transformation,binary images,endoscopic image,detection and nursing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09129721.pdf,
28,ECG Signal Reconstruction via Doppler Sensor by Hybrid Deep Learning Model With CNN and LSTM,8,,130551-130560,"Yamamoto Kohei,Hiromatsu Ryosuke,Ohtsuki Tomoaki","Yamamoto K,Hiromatsu R,Ohtsuki T",Yamamoto K,10.1109/ACCESS.2020.3009266,"Grad Sch Sci & Technol, Grad Sch Sci & Technol, Yokohama, Kanagawa 2238522, Japan.","An Electrocardiogram (ECG) is a typical method used to detect heartbeat, and an ECG signal analysis enables the detection of some heart diseases. However, the ECG-based heartbeat detection requires device attachment, which is not preferred for daily use. A Doppler sensor could be a device used to enable the non-contact heartbeat detection. In this paper, we propose a Doppler sensor-based ECG signal reconstruction method by a hybrid deep learning model with Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM). An ECG signal can be reconstructed by relating features of a heartbeat signal obtained by a Doppler sensor to those of the ECG signal. Thus, we construct the deep learning model that extracts the spatial and temporal features from the heartbeat signal by CNN and LSTM. Based on the extracted features, the ECG signal is reconstructed. We conducted experiments to observe heartbeat against 9 healthy subjects without heart disease. The experimental results showed that our method performed ECG signal reconstruction with a correlation coefficient of 0.86 between the reconstructed and actual ECG signals, even without attaching devices. The results indicate that it is possible to remotely reconstruct an ECG signal from a heartbeat signal via a Doppler sensor.","Heart beat,Electrocardiography,Doppler effect,Feature extraction,Signal reconstruction,Machine learning,Heartbeat,microwaves,Doppler sensor,ECG,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HEART-RATE-VARIABILITY,RECOGNITION,TRANSFORM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139941.pdf,
29,Non-Contact Heartbeat Detection by Heartbeat Signal Reconstruction Based on Spectrogram Analysis With Convolutional LSTM,8,,123603-123613,"Yamamoto Kohei,Ohtsuki Tomoaki","Yamamoto K,Ohtsuki T",Yamamoto K,10.1109/ACCESS.2020.3006107,Keio University,"Heartbeat detection is one of key techniques to monitor our health condition in daily life, and demands for this technique have increased year and year. Thanks to the non-contact and non-invasive features, various Doppler sensor-based detection methods have been investigated so far. However, the heartbeat detection accuracy of the conventional methods could get degraded due to the low SNR (Signal-to-Noise Ratio) of heartbeat components. Thus, even after some signal processing, non-heartbeat components still remain over such processed signal, which could degrade the heartbeat detection accuracy. In particular for the subjects with low HR (Heart Rate), the estimated HR tends to be higher than the ground truth HR due to such non-heartbeat components, though the conventional methods have mainly focused on the heartbeat detection against the subjects with the normal HR higher than 50 bpm (Beats Per Minute). In this paper, to accurately detect heartbeat even with low HR via a Doppler sensor, we propose a heartbeat detection method based on heartbeat signal reconstruction with convolutional LSTM (Bidirectional-Long Short-Term Memory). In the proposed method, to reconstruct a heartbeat signal based on the periodicity of heartbeat and the spectrum distribution peculiar to heartbeat, successive spectrograms that might be due to heartbeat is used as an input to convolutional LSTM. In addition, for better reconstruction of a heartbeat signal, the previously estimated RRI (R-R Interval) is also used as a feature in the proposed deep learning model with convolutional LSTM. Through the experiments, we confirmed that our proposed method accurately detected heartbeat against 17 subjects including the ones with the HR lower than 50 bpm.","Doppler sensor,heartbeat,spectrogram,deep learning,convolutional LSTM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECOGNITION,TRANSFORM,DISEASE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09129737.pdf,
30,Using a Patch-Wise M-Net Convolutional Neural Network for Tissue Segmentation in Brain MRI Images,8,,120946-120958,"Yamanakkanavar Nagaraj,Lee Bumshik","Yamanakkanavar N,Lee B",Lee B,10.1109/ACCESS.2020.3006317,Chosun University,"Accurate segmentation of brain tissues, such as gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF), in magnetic resonance imaging (MRI) images, is helpful for the diagnosis of neurological disorders, such as schizophrenia, Alzheimer's disease, and dementia. Studies on MRI-based brain segmentation have received significant attention in recent years based on the non-invasive imaging and good soft-tissue contrast provided by MRI. A number of studies have used conventional machine learning strategies, as well as convolutional neural network approaches. In this paper, we propose a patch-wise M-net architecture for the automatic segmentation of brain MRI images. In the proposed brain segmentation method, slices from a brain MRI scan are divided into non-overlapping patches, which are then fed into an M-net model with corresponding ground-truth patches to train the network, which is composed of two encoder-decoder processes. Dilated convolutional kernels with different sizes are used in the encoder and decoder modules to derive abundant semantic features from brain MRI scans. The proposed patch-wise M-net overcomes the drawbacks of conventional methods and provides greater retention of fine details. The proposed M-net model was trained and tested on the open-access series of imaging studies dataset. The performance was measured quantitatively using the Dice similarity coefficient. Experimental results demonstrate that the proposed method achieves average segmentation accuracies of 94.81% for CSF, 95.44% for GM, and 96.33% for WM, meaning it outperforms state-of-the-art methods.","Brain MRI,convolutional neural network,M-net,tissue segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AUTOMATIC,SEGMENTATION,CEREBRAL-CORTEX,EXTRACTION,CLASSIFICATION,CNN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09130719.pdf,
31,Diverse Region-Based CNN for Tongue Squamous Cell Carcinoma Classification With Raman Spectroscopy,8,,127313-127328,"Yan Hao,Yu Mingxin,Xia Jiabin,Zhu Lianqing,Zhang Tao,Zhu Zhihui,Sun Guangkai","Yan H,Yu MX,Xia JB,Zhu LQ,Zhang T,Zhu ZH,Sun GK",Zhu LQ,10.1109/ACCESS.2020.3006567,Beijing Information Science & Technology University,"Border discrimination is very important in the treatment of tongue squamous cell carcinoma (TSCC). This study proposes an ensemble convolutional neural network (CNN) framework based on fiber optic Raman spectroscopy and deep learning techniques to distinguish between TSCC and non-tumor tissue frameworks. First, the data used in the experiments was collected by a fiber optic Raman system. A total of 44 tissues of 22 patients were collected for Raman spectroscopy, with TSCC and adjacent normal tissues each accounting for half. The spectral data range used in the model from a full spectrum of 600-4000 cm(-1). Then, the ensemble CNN model was used in the experiment. By using two convolution kernels, the model is able to extract nonlinear feature representations from different spectral regions. It has two advantages, on the one hand, it reduces the generation of noise, on the other hand, it obtains a stronger distinguishing ability. Finally, a feature vector is formed by the fusion layer, and is sent to the fully connected layer for the TSCC classification task. The results showed that the sensitivity and specificity of the model were 99.2% and 99.2%, respectively. In addition, comparison with existing methods shows that our method achieves the highest accuracy of TSCC classification. By comparing the different channels, the results show that the spectral range of 1380-2250cm(-1) data has the greatest impact on the results. Therefore, Raman spectroscopy combined with the ensemble CNN model has great potential and can provide a useful technique for intraoperative evaluation of the margins of oral tongue squamous cell carcinoma.","Ensemble convolutional neural networks,fiber optic Raman system,Raman spectroscopy,tongue squamous cell carcinoma",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"OPTICAL,PATHOLOGY,SURGICAL,MARGINS,FROZEN-SECTIONS,CANCER,RESECTION,TISSUE,GUIDANCE,SURGERY,WATER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09131705.pdf,
32,Enhanced Automated Diagnosis of Coronary Artery Disease Using Features Extracted From QT Interval Time Series and ST-T Waveform,8,,129510-129524,"Yao Lianke,Liu Changchun,Li Peng,Wang Jikuo,Liu Yuanyuan,Li Wang,Wang Xinpei,Li Han,Zhang Huan","Yao LK,Liu CC,Li P,Wang JK,Liu YY,Li W,Wang XP,Li H,Zhang H",Liu CC,10.1109/ACCESS.2020.3008965,Shandong University,"There is a growing interest in automated diagnosis of coronary artery disease (CAD) with the application of machine learning (ML) methods to the body surface electrocardiograph (ECG). Although prior studies have documented associations of CAD with increased QT variability and ST-T segment abnormalities such as T-wave inversion and ST-segment elevation or depression, their efficacy in automated CAD detection has not been fully investigated. To validate their usefulness, a dataset containing related clinical characteristics and 5-min single-lead ECGs of 107 healthy controls and 93 CAD patients was first constructed. Based on this dataset, simultaneous analyses were then conducted in five scenarios, in which different ML algorithms were applied to classify the two groups with various features derived from the RR and QT interval time-series and ST-T segment waveforms. Compared with utilizing features obtained from the RR interval time-series, better classification results were achieved utilizing that obtained from the QT interval time-series. The classification results were elevated with combining utilization of features derived from both the RR and QT interval time-series. By further fusing features extracted from ST-T segment waveforms, the best performance was achieved with 96.16% accuracy, 95.75% sensitivity, and 96.40% specificity. Based the best performance, an automated CAD detection system was developed with extreme gradient boosting, an ensemble ML algorithm, and the residual neural network, namely, a deep learning method. The results of this study support the potential of information derived from the QT interval time-series and ST-T segment waveforms in ECG-based automated CAD detection.","Coronary artery disease (CAD),QT interval variability (QTV),heart rate variability (HRV),ST-T waveform,signal decomposition",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SUDDEN,CARDIAC,DEATH,MYOCARDIAL-INFARCTION,SEGMENT,DEPRESSION,CARDIOVASCULAR-DISEASE,NONLINEAR,FEATURES,PROGNOSTIC,VALUE,CLINICAL-VALUE,HEART-DISEASE,VARIABILITY,ECG",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139514.pdf,
33,3D Reconstruction for Super-Resolution CT Images in the Internet of Health Things Using Deep Learning,8,,121513-121525,"Zhang Jing,Gong Ling-Rui,Yu Keping,Qi Xin,Wen Zheng,Hua Qiaozhi,Myint San Hlaing","Zhang J,Gong LR,Yu KP,Qi X,Wen Z,Hua QZ,Myint S",Yu KP,10.1109/ACCESS.2020.3007024,Waseda University,"The Internet of Health Things (IoHT) enables health devices to connect to the Internet and communicate with each other, which provides the high-accuracy and high-security diagnosis result in the medical area. As essential parts of the IoHT, computed tomography (CT) images help doctors diagnose disease. In the traditional disease diagnosing process, low-resolution medical CT images produce low-accuracy diagnosis results for microlesions. Moreover, CT images can only provide 2D information about organs, and doctors should estimate the 3D shape of a lesion based on experience. To solve these problems, we propose a 3D reconstruction method for secure super-resolution computed tomography (SRCT) images in the IoHT using deep learning. First, we use deep learning to obtain secure SRCT images from low-resolution images in the IoHT. To this end, we adopt a conditional generative adversarial network (CGAN) based on the edge detection loss function (EDLF) in the deep learning process, namely EDLF-CGAN algorithm. In this algorithm, the CGAN is employed to generate SRCT images with luminance and contrast as the input auxiliary conditions, which can improve the accuracy of super-resolution (SR) images. An EDLF is proposed to consider the edge features in the generated SRCT images, which reduces the deformation of generated image. Second, we apply the secure SR images generated from the deep learning method to perform 3D reconstruction. An advanced ray casting 3D reconstruction algorithm that can reduce the number of rays by selecting the appropriate bounding box is proposed. Compared with the traditional algorithm, the proposed ray casting 3D reconstruction algorithm can reduce the time and memory cost. The experimental results show that our EDLF-CGAN has a better SR reconstruction effect than other algorithms via the indicators of the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). In addition, our advanced ray casting 3D reconstruction algorithm greatly improves the efficiency compared with the traditional ray casting algorithm.","Conditional generative adversarial network,Internet of Health Things,3D reconstruction,super-resolution image,edge detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,FEATURES,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09133099.pdf,
34,Deep Learning Based Analysis of Breast Cancer Using Advanced Ensemble Classifier and Linear Discriminant Analysis,8,,120208-120217,"Zhang Xinfeng,He Dianning,Zheng Yue,Huo Huaibi,Li Simiao,Chai Ruimei,Liu Ting","Zhang XF,He DN,Zheng Y,Huo HB,Li SM,Chai RM,Liu T",Liu T,10.1109/ACCESS.2020.3005228,China Medical University,"In the recent past, the Classifiers are based on genetic signatures in which many microarray studies are analyzed to predict medical results for cancer patients. However, the Signatures from different studies have been benefitted with low-intensity ratio during the classification of individual datasets has been considered as a significant point of research in the present scenario. Hence to overcome the above-discussed issue, this paper provides a Deep Learning Framework that combines an algorithm of necessary processing of Linear Discriminant Analysis (LDA) and Auto Encoder (AE) Neural Network to classify different features within the profile of gene expression. Hence, an advanced ensemble classification has been developed based on the Deep Learning (DL) algorithm to assess the clinical outcome of breast cancer. Furthermore, numerous independent breast cancer datasets and representations of the signature gene, including the primary method, have been evaluated for the optimization parameters. Finally, the experiment results show that the suggested deep learning frameworks achieve 98.27% accuracy than many other techniques such as genomic data and pathological images with multiple kernel learning (GPMKL), Multi-Layer Perception (MLP), Deep Learning Diagnosis (DLD), and Spatiotemporal Wavelet Kinetics (SWK).","Deep learning framework,breast cancer,advanced ensemble classifier,linear discriminant analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,MAMMOGRAPHY,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09126791.pdf,
35,Image Restoration for Low-Dose CT via Transfer Learning and Residual Network,8,,112078-112091,"Zhong Anni,Li Bin,Luo Ning,Xu Yuan,Zhou Linghong,Zhen Xin","Zhong AN,Li B,Luo N,Xu Y,Zhou LH,Zhen X",Zhou LH; Zhen X,10.1109/ACCESS.2020.3002534,Southern Medical University - China,"Deep learning has recently been extensively investigated to remove artifacts in low-dose computed tomography (LDCT). However, the power of transfer learning for medical image denoising tasks has not been fully explored. In this work, we proposed a transfer learning residual convolutional neural network (TLR-CNN) to restore LDCT images at single and blind noise levels. A residual network was implemented to effectively estimate the difference between denoised image and its original map, and a noise-free image was obtained by subtracting the residual map from the LDCT image. The results were compared to competing baseline denoising methods in terms of quantitative metrics including the PSNR, RMSE, SSIM and FSIM. For the single noise level, the proposed method demonstrated better denoising performance than the other algorithms for both simulation data and clinical data. As for the blind denoising, the image qualities were improved for all noise levels for all the quantitative metrics, but such improvements were decreasing as the noise level decrease (higher mAs). Comparative experiments suggested that the proposed network could effectively suppress artifacts and preserve image details with faster converge rate and reduced computational time.","Noise reduction,Computed tomography,Residual neural networks,Training,Biomedical imaging,Image denoising,Task analysis,LDCT,image denoising,CNN,transfer learning,residual network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,BEAM,COMPUTED-TOMOGRAPHY,WEIGHTED,LEAST-SQUARES,NOISE-REDUCTION,RECONSTRUCTION,SPARSE,CNN,CLASSIFICATION,ALGORITHM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09117103.pdf,
36,Domain Uncertainty Quantification in Computational Electromagnetics,8,1,301-341,"Aylwin Ruben,Jerez-Hanckes Carlos,Schwab Christoph,Zech Jakob","Aylwin R,Jerez-Hanckes C,Schwab C,Zech J",Aylwin R,10.1137/19M1239374,Pontificia Universidad Catolica de Chile,"We study the numerical approximation of time-harmonic, electromagnetic fields inside a lossy cavity of uncertain geometry. Key assumptions are a possibly high-dimensional parametrization of the uncertain geometry along with a suitable transformation to a fixed, nominal domain. This uncertainty parametrization results in families of countably parametric, Maxwell-like cavity problems that are posed in a single domain, with inhomogeneous coefficients that possess finite, possibly low spatial regularity, but exhibit holomorphic parametric dependence in the differential operator. Our computational scheme is composed of a sparse grid interpolation in the high-dimensional parameter domain and an Hcurl -conforming edge element discretization of the parametric problem in the nominal domain. As a stepping-stone in the analysis, we derive a novel Strang-type lemma for Maxwell-like problems in the nominal domain, which is of independent interest. Moreover, we accommodate arbitrary small Sobolev regularity of the electric field and also cover uncertain isotropic constitutive or material laws. The shape holomorphy and edge-element consistency error analysis for the nominal problem are shown to imply convergence rates for multilevel Monte Carlo and for quasi-Monte Carlo integration, as well as sparse grid approximations, in uncertainty quantification for computational electromagnetics. They also imply expression rate estimates for deep ReLU networks of shape-to-solution maps in this setting. Finally, our computational experiments confirm the presented theoretical results.","computational electromagnetics,uncertainty quantification,finite elements,shape holomorphy,sparse grid quadrature,Bayesian inverse problems",Article,"SIAM PUBLICATIONS, 3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA","Mathematics,Physics",,,"SPARSE,POLYNOMIAL-APPROXIMATION,MONTE,CARLO,INTEGRATION,MAXWELL,EQUATIONS,INTERPOLATION,CONVERGENCE,COLLOCATION,REGULARITY",SIAM-ASA JOURNAL ON UNCERTAINTY QUANTIFICATION,,
37,Two-Dimensional Electromagnetic Solver Based on Deep Learning Technique,5,,83-88,"Qi Shutong,Wang Yinpeng,Li Yongzhong,Wu Xuan,Ren Qiang,Ren Yi","Qi ST,Wang YP,Li YZ,Wu X,Ren Q,Ren Y",Ren Q,10.1109/JMMCT.2020.2995811,Beihang University,"Although the deep learning technique has been introduced into computational physics in recent years, the feasibility of applying it to solve electromagnetic (EM) scattering field from arbitrary scatters remains open. In this article, the convolutional neural network (CNN) has been employed to predict the EM field scattered by complex geometries under plane-wave illumination. The 2-D finite-difference frequency-domain (FDFD) algorithm, wrapped by a module to randomly generate complex scatters from basic geometries, is employed to produce training data for the network. The multichannel end-to-endCNNis modified and combined with residual architecture and skip connection, which can speed up convergence and optimize network performance, to form the EM-net. The well-trained EM-net has good performance in this problem since it is compatible with different shapes, multiple kinds of materials, and different propagation directions of the incident waves. The effectiveness of the proposed EM-net has been validated by numerical experiments, and the average numerical error can be as small as 1.23%. Meanwhile, its speedup ratio over the FDFD method is as large as 2000.","Convolutional neural network (CNN),deep learning,finite-difference frequency-domain (FDFD) method,2-D Maxwell's equation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,,,IEEE JOURNAL ON MULTISCALE AND MULTIPHYSICS COMPUTATIONAL TECHNIQUES,,
38,Evaluating Solid Lung Adenocarcinoma Anaplastic Lymphoma Kinase Gene Rearrangement Using Noninvasive Radiomics Biomarkers,13,,6927-6935,"Ma De-Ning,Gao Xin-Yi,Dan Yi-Bo,Zhang An-Ni,Wang Wei-Jun,Yang Guang,Zhu Hong-Zhou","Ma DN,Gao XY,Dan YB,Zhang AN,Wang WJ,Yang G,Zhu HZ",Yang G,10.2147/OTT.S257798,"Shanghai Key Lab Magnet Resonance, Dept Phys, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.","Purpose: To develop a radiogenomics classifier to assess anaplastic lymphoma kinase (ALK) gene rearrangement status in pretreated solid lung adenocarcinoma noninvasively.
Materials and Methods: This study consisted of 140 consecutive pretreated solid lung adenocarcinoma patients with complete enhanced CT scans who were tested for both EGFR mutations and ALK status. Pre-contrast CT and standard post-contrast CT radiogenomics machine learning classifiers were designed as two separate classifiers. In each classifier, dataset was randomly split into training and independent testing group on a 7:3 ratio, accordingly subjected to a 5-fold cross-validation. After normalization, best feature subsets were selected by Pearson correlation coefficient (PCC) and analysis of variance (ANOVA) or recursive feature elimination (RFE), whereupon a radiomics classifier was built with support vector machine (SVM). The discriminating performance was assessed with the area under receiver-operating characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV).
Results: In classifier one, 98 cases were selected as training data set, 42 cases as independent testing data set. In classifier two, 87 cases were selected as training data set, 37 cases as independent testing data set. Both classifiers extracted 851 radiomics features. The top 25 pre-contrast features and top 19 post-contrast features were selected to build optimal ALK+ radiogenomics classifiers accordingly. The accuracies, AUCs, sensitivity, specificity, PPV, and NPV of pre-contrast CT classifier were 78.57%, 80.10% (CI: 0.6538-0.9222), 71.43%, 82.14%, 66.67%, and 85.19%, respectively. Those results of standard post-contrast CT classifier were 81.08%, 82.85% (CI: 0.6630-0.9567), 76.92%, 83.33%, 71.43%, and 86.96%.
Conclusion: Solid lung adenocarcinoma ALK+ radiogenomics classifier of standard post-contrast CT radiomics biomarkers produced superior performance compared with that of pre-contrast one, suggesting that post-contrast CT radiomics should be recommended in the context of solid lung adenocarcinoma radiogenomics AI. Standard post-contrast CT machine learning radiogenomics classifier could help precisely identify solid adenocarcinoma ALK rearrangement status, which may act as a pragmatic and cost-efficient substitute for traditional invasive ALK status test.","radiogenomics,SVM,non-small cell lung cancer,anaplastic lymphoma kinase,epidermal growth factor receptor",Article,"DOVE MEDICAL PRESS LTD, PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND","Biotechnology & Applied Microbiology,Oncology",,3.763,"CANCER,PATIENTS,CLINICORADIOLOGIC,CHARACTERISTICS,ALK,REARRANGEMENT,EGFR,FEATURES,CRIZOTINIB,INHIBITORS,MUTATIONS,SIGNATURE,NOMOGRAM",ONCOTARGETS AND THERAPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7371989,
39,Reducing False Alarm Rates in Neonatal Intensive Care: A New Machine Learning Approach,1232,,285-290,"Ostojic D.,Guglielmini S.,Moser V.,Fauchere J. C.,Bucher H. U.,Bassler D.,Wolf M.,Kleiser S.,Scholkmann F.,Karen T.","Ostojic D,Guglielmini S,Moser V,Fauchere JC,Bucher HU,Bassler D,Wolf M,Kleiser S,Scholkmann F,Karen T",Ostojic D,10.1007/978-3-030-34461-0_36,University of Zurich,"In neonatal intensive care units (NICUs), 87.5% of alarms by the monitoring system are false alarms, often caused by the movements of the neonates. Such false alarms are not only stressful for the neonates as well as for their parents and caregivers, but may also lead to longer response times in real critical situations. The aim of this project was to reduce the rates of false alarms by employing machine learning algorithms (MLA), which intelligently analyze data stemming from standard physiological monitoring in combination with cerebral oximetry data (in-house built, OxyPrem). Materials & Methods: Four popular MLAs were selected to categorize the alarms as false or real: (i) decision tree (DT), (ii) 5-nearest neighbors (5-NN), (iii) naive Bayes (NB) and (iv) support vector machine (SVM). We acquired and processed monitoring data (median duration (SD): 54.6 (+/- 6.9) min) of 14 preterm infants (gestational age: 26 6/7 (+/- 2 5/7) weeks). A hybrid method of filter and wrapper feature selection generated the candidate subset for training these four MLAs. Results: A high specificity of >99% was achieved by all four approaches. DT showed the highest sensitivity (87%). The cerebral oximetry data improved the classification accuracy. Discussion & Conclusion: Despite a (as yet) low amount of data for training, the four MLAs achieved an excellent specificity and a promising sensitivity. Presently, the current sensitivity is insufficient since, in the NICU, it is crucial that no real alarms are missed. This will most likely be improved by including more subjects and data in the training of the MLAs, which makes pursuing this approach worthwhile.","False alarms,Oxygen saturation,Neonatal intensive care,Machine learning,NICU",Article; Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Research & Experimental Medicine,,,"SELECTION,SAFETY",,,
40,The Use of Augmented Reality-Based Learning Media to Develop the Technology Literacy of Chemistry Teachers in the 21st Century,2215,,,"Astuti Andari Puji,Mawarsari Venissa Dian,Purnomo Hindriyanto,Sediyono Eko","Astuti AP,Mawarsari VD,Purnomo H,Sediyono E",Astuti AP,10.1063/5.0000745,"Univ Muhammadiyah Semarang, Semarang Cent Java, Indonesia.","The 21st century chemistry learning process requires teachers to implement creative learning methods that are supported by technology. However, the teachers' ability to use technology in chemistry learning is still low. The purpose of this study was to develop the teachers' technology literacy using augmented reality-based learning media. This research used mix-method with sequential strategies of mixed methods. The first stage of this research was conducted by surveying the use of technology in chemistry learning. The instrument used was closed and open questionnaire. The second stage was carried out by collecting qualitative data through interview techniques. The data taken from this stage were to obtain the data of teachers' technology literacy after they received a training treatment using Augmented Reality based learning media. The research subjects consisted of 25 Chemistry teachers spread in Central Java. The results of the study show that teachers' literacy in chemistry learning is still low. The training of augmented reality-based learning increases the teachers' technology literacy. In addition, augmented reality-based learning media also assist teachers to introduce abstract concepts to students. In addition, this learning media also help teachers who have limited tools and materials in the laboratory to introduce the laboratory work virtually to the students.",,Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",Education & Educational Research,,,,,,
41,Improving Students' Science Learning Outcomes through Joyful-Inquiry Interactive Demonstration Assisted by Game Android,2215,,,"Mustikasari Vita Ria,Suwono Hadi,Farhania Kholida","Mustikasari VR,Suwono H,Farhania K",Suwono H,10.1063/5.0000566,Universitas Negeri Malang,"This study aimed to analyze the improvement of students' cognitive learning outcomes after the application of joyful-inquiry interactive demonstration (J-IID) learning assisted by android games on the material of human respiratory system. This research used mixed methods research with embedded experimental. The design of this study used Pretest-Posttest Control Design. The study was conducted at SMPN 5 Malang class VIII B in the academic year of 2018/2019. The sample selection technique used was purposive sampling. The quantitative data were in the form of pretest and posttest scores. The qualitative data were interview results at the end of the learning process and students' responses to the test. The quantitative data were analyzed with Kolmogorov Smirnov, paired t-test, N-Gain, and d-effect size. The qualitative data was analyzed with data reduction and scatter plot. The improved learning outcomes were revealed in an increase in the value of pretest to posttest, from 68.74 to 81.42. The t-test results showed that there was a difference between the pretest and posttest scores. The N-Gain test results, namely 0.40, showed an increase in students' learning outcomes in the medium category. The d-effect size test results indicated the effect of J-IID learning has a high impact on improving students' learning outcomes with score of 1.03. The data analysis showed that the learning used the joyful-inquiry interactive demonstration model assisted by Android games can improve students' cognitive learning outcomes on the material of human respiratory system.",,Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",Education & Educational Research,,,,,,
42,Proposed Intelligent System Using Hybrid Material Techniques: A Review,2235,,,"Kadhim Mohammed Khudhur,Hassan Alia KaremAbdull","Kadhim MK,Hassan AK",Kadhim MK,10.1063/5.0007485,"University of Technology, Iraq","Hybrid Techniques have been used widely to construct a predictive model for intelligent e learning system, a decision tree techniques is one that have been implemented a large area of Intelligent e learning systems. In this paper, we review the recent literature on various solutions to address different techniques to build intelligent e-learning system to serve the academic institutions and enhancing the students learning path. This paper we provide a general overview of methodologies and the machine learning techniques in area of education and learning purposes and gives main citations for the comprehensive understanding and further explorations of this area of research. To be specific, previous attempts to enable to construct intelligent model for e learning system are examined, (1) over view of design intelligent model for e learning system: Various techniques have been used to build predictive and intelligent model for e learning such decision tree techniques, Naive Bays, Neural Network and K-nearest neighbor.(2) the techniques that are used for building intelligent e learning system (3) the issues that have been faced through implementation of the proposed system (4) Problem and system analysis of the predictive model of intelligent e learning system.","SUCCESS,TREES",Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",Materials Science,,,"SUCCESS,TREES",,,
43,Improving temporal resolution of fNIRS-DOT by the guidance of data-reduced pre-OT,11234,,,"Liu Dongyuan,Wang Bingyuan,Zhang Yao,Pan Tiantian,Liu Yang,Gao Feng","Liu DY,Wang BY,Zhang Y,Pan TT,Liu Y,Gao F",Gao F,10.1117/12.2542977,Tianjin University,"Functional near-infrared spectroscopy techniques, in the form of either optical topography (OT) or diffuse optical tomography (DOT), can non-invasively recover the hemodynamic changes occurring in the activated cerebral cortex. In comparison with the traditional OT that provides a less quantitative absorption perturbation map along the subject domain surface, a successful DOT has ability to quantify depth-resolved information that relies on abundant boundary overlapping measurements using a high-density (HD) source-detector array. To achieve a trade-off between the temporal resolution and sensitivity by channel cross-talk suppression, a hybrid frequency- and time-division-multiplexing strategy have to be normally adopted to the HD-DOT implementation, where the temporal resolution degradation due to the multi-field illuminations might still prevent from capturing the high frequency information. In this work, a deep-learning based pre-OT method has been proposed to improve the temporal resolution of HD-DOT. The pre-OT could provide prior information on activation regions to exclude measurements of non-sensitive data. We have performed simulation and phantom experiments to evaluate the performances of the proposed method, and demonstrated its superiority over the stand-alone HD-DOT in improving both the temporal resolution and localization accuracy.","functional near-infrared spectroscopy,optical topography,diffuse optical tomography,deep-learning,temporal resolution",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Physics,Radiology, Nuclear Medicine & Medical Imaging",,,"NEAR-INFRARED,SPECTROSCOPY,DIFFUSE,OPTICAL,TOMOGRAPHY,BRAIN,INSTRUMENTATION,ACTIVATION,FIELDS",,,
44,The Value of Patient and Tumor Factors in Predicting Preoperative Breast MRI Outcomes.,2,4,e190099,",,,,,,","Rahbar Habib,Hippe Daniel S,Alaa Ahmed,Cheeney Safia H,van der Schaar Mihaela,Partridge Savannah C,Lee Christoph I",,10.1148/rycan.2020190099,,"Purpose: To identify patient and tumor features that predict true-positive, false-positive, and negative breast preoperative MRI outcomes. 2020 by the Radiological Society of North America, Inc.",,"Journal Article; Research Support, N.I.H., Extramural",,,,,,,,
45,Evaluating the Implementation of Deep Learning in LibreHealth Radiology on Chest X-Rays,943,,648-657,"Purkayastha Saptarshi,Buddi Surendra Babu,Nuthakki Siddhartha,Yadav Bhawana,Gichoya Judy W.","Purkayastha S,Buddi SB,Nuthakki S,Yadav B,Gichoya JW",Purkayastha S,10.1007/978-3-030-17795-9_47,Indiana University System,"Respiratory diseases are the dominant cause of deaths worldwide. In the US, the number of deaths due to chronic lung infections (mostly pneumonia and tuberculosis), lung cancer and chronic obstructive pulmonary disease has increased. Timely and accurate diagnosis of the disease is highly imperative to diminish the deaths. Chest X-ray is a vital diagnostic tool used for diagnosing lung diseases. Delay in X-Ray diagnosis is run-of-the-mill milieu and the reasons for the impediment are mostly because the X-ray reports are arduous to interpret, due to the complex visual contents of radiographs containing superimposed anatomical structures. A shortage of trained radiologists is another cause of increased workload and thus delay. We integrated CheXNet, a neural network algorithm into the LibreHealth Radiology Information System, which allows physicians to upload Chest X-rays and identify diagnosis probabilities. The uploaded images are evaluated from labels for 14 thoracic diseases. The turnaround time for each evaluation is about 30 s, which does not affect clinical workflow. A Python Flask application hosted web service is used to upload radiographs into a GPU server containing the algorithm. Thus, the use of this system is not limited to clients having their GPU server, but instead, we provide a web service. To evaluate the model, we randomly split the dataset into training (70%), validation (10%) and test (20%) sets. With over 86% accuracy and turnaround time under 30 s, the application demonstrates the feasibility of a web service for machine learning based diagnosis of 14-lung pathologies from Chest X-rays.","Deep learning,Radiology,LibreHealth,Chest X-ray,CheXNet",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,,,https://scholarworks.iupui.edu/bitstream/1805/18297/1/paper_258.pdf,
46,The Effectiveness of Distinctive Information for Cancer Cell Analysis Through Big Data,944,,57-68,"Baniya Babu Kaji,Gnimpieba Etienne Z.","Baniya BK,Gnimpieba EZ",Baniya BK,10.1007/978-3-030-17798-0_7,University of Louisiana System,"In the healthcare system, a huge volume of multi-structured patient data is generated from in-hospital clinical examinations, wearable body sensors, and doctor memos. These data play a deterministic role in finding the patient's cause of disease and corresponding cure. However, there are many challenges underlying healthcare system such as integration of different data format, appropriate selection of healthcare parameters and disease prediction. Besides these, concern whether this data is equally significant for decision making or not exists. To address these problems, we introduced the infinite latent feature selection (ILFS) to find highly informative gene from a gene pool and feed it to the classifier. We adopted a hybrid approach for gene classification. The hybrid scheme integrated two (sophisticated) algorithms: speed advantage of extreme learning machine (ELM) and accuracy advantage of sparse representation classifier (SRC). We validated our proposed model with 198 tumor samples of global cancer map (GCM) dataset and divided them into 14 common tumor categories having 11,370 expression level of genes. The performance of this system was measured using five different matrices (i.e., accuracy, sensitivity, specificity, precision, and F-score). This achieved a notable improvement of accuracies in both scenarios in selective (considering only highly expressive genes) and original genes (74.75% and 81.82% respectively).","Precision,Recall,Sensitivity,Predication,Multi-structure",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,HEALTH-CARE,,,
47,Gait Monitoring System for Stroke Prediction of Aging Adults,973,,93-97,"Park Hongkyu,Hong Seunghee,Hussain Iqram,Kim Damee,Seo Young,Park Se Jin","Park H,Hong S,Hussain I,Kim D,Seo Y,Park SJ",Park SJ,10.1007/978-3-030-20476-1_11,Korea Research Institute of Standards & Science (KRISS),"Health has become a major concern nowadays. People pass significant amount of time of daily life on walking, moving here and there and so on. Some health complexity happens during walking like heart problem, stroke etc. Stroke patient has unbalanced gait pattern compared to normal person. The Internet of Things (IoT) plays an important role in the development of connected people, which offers cloud connectivity, smartphone integration, safety, security, and healthcare services. Insole Foot Pressure sensor and accelerometer will be attached to the foot for gait speed, foot pressure and other gait pattern. Gait parameters of 68 Stroke patients and 208 Elderly healthy persons have been gathered in Chungnam National University Hospital Rehabilitation Center, Daejeon, South Korea. Gait parameters are foot pressure, gait acceleration etc. Dynafoot2 Insole sensor used for data acquisition. Subjects walked and perform activities like walking, sitting, standing, doing some regular activities during gait data acquisition. Area under curve (AUC) of performance curve for C4.5, SVM, Random Tree, Logistic Regression, LSVM, CART algorithms are 0.98, 0.976, 0.935, 0.909 and 0.906, 0.87 respectively. A gait monitoring system has been proposed for stroke onset prediction for stroke patient. IoT sensors are used to gather gait data and machine learning algorithms are used to classify gait pattern of stroke patient group and normal healthy group. In future, sensors such as EEG, EMG will be used to improve system reliability.","Stroke,Gait,Health monitoring,Classification algorithms",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
48,Data-driven Computational Mechanics:a Review,41,1,1-14,",,,,,","Jie Yang,Rui Xu,Qun Huang,Qian Shao,Wei Huang,Heng Hu",,,Jie Yang,"The concept of big data with digital twin and artificial intelligence is profoundly influencing the fourth industrial revolution.At the same time,facing severe challenges in advanced manufacturing and safety assessment of high-performance materials and structures,classical computational mechanics has more and more limitations in achieving the goal ofhalf-time and half-costof R&D cycle.Data-driven computational mechanics emerged in this context and showed great vitality.This paper aims to discuss and analyze the trend of data-driven computational mechanics by reviewing recent research achievements.In this paper,the algorithms in the framework of data-driven computational mechanics are summarized into two categories:the first one is based on energy functional,the key point of which is to construct the constitutive relationship by using material data;while the second category is based on distance functional,the specificity of which lies in directly embedding the material data into mechanical simulations.Several related data-driven algorithms of each category are briefly recalled,and the challenges and prospects of data-driven computational mechanics are discussed.","data-driven; computational mechanics; database; ,machine learning,material, genome; structural genome",Review,,,,,,,,
49,Real-Time Quality Assessment of Pediatric MRI via Semi-Supervised Deep Nonlocal Residual Neural Networks,29,,7697-7706,"Liu Siyuan,Thung Kim-Han,Lin Weili,Yap Pew-Thian,Shen Dinggang","Liu SY,Thung KH,Lin WL,Yap PT,Shen DG",Yap PT; Shen DG,10.1109/TIP.2020.2992079,University of North Carolina,"In this paper, we introduce an image quality assessment (IQA) method for pediatric T1- and T2-weighted MR images. IQA is first performed slice-wise using a nonlocal residual neural network (NR-Net) and then volume-wise by agglomerating the slice QA results using random forest. Our method requires only a small amount of quality-annotated images for training and is designed to be robust to annotation noise that might occur due to rater errors and the inevitable mix of good and bad slices in an image volume. Using a small set of quality-assessed images, we pre-train NR-Net to annotate each image slice with an initial quality rating (i.e., pass, questionable, fail), which we then refine by semi-supervised learning and iterative self-training. Experimental results demonstrate that our method, trained using only samples of modest size, exhibit great generalizability, capable of real-time (milliseconds per volume) large-scale IQA with near-perfect accuracy.","Training,Semisupervised learning,Standards,Quality assessment,Annotations,Deep learning,Kernel,Image quality assessment,nonlocal residual networks,semi-supervised learning,self-training",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"CLASSIFICATION,ARTIFACTS,NOISE",IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1904.03639,
50,Stability of the Deep Neural Networks Learning Process in the Recognition Problems of the Material Microstructure,78,,307-313,"Klyuev A. V,Stolbov V. Yu,Gitman M. B.,Klestov R. A.","Klyuev AV,Stolbov VY,Gitman MB,Klestov RA",Klestov RA,10.1007/978-3-030-22493-6_27,Perm National Research Polytechnic University,"The paper investigates the algorithmic stability of learning a deep neural network in problems of recognition of the materials microstructure. It is shown that at 8% of quantitative deviation in the basic test set the algorithm trained network loses stability. This means that with such a quantitative or qualitative deviation in the training or test sets, the results obtained with such trained network can hardly be trusted.
Although the results of this study are applicable to the particular case, i.e. problems of recognition of the microstructure using ResNet-152, the authors propose a cheaper method for studying stability based on the analysis of the test, rather than the training set.","Deep neural networks,Image recognition,Deep learning,Algorithmic stability",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,"STRENGTH,PROPERTIES",,,
51,Skin Cancer Segmentation and Classification with Improved Deep Convolutional Neural Network,11318,,,"Alom Md Zahangir,Aspiras Theus,Taha Tarek M.,Asari Vijayan K.","Alom MZ,Aspiras T,Taha TM,Asari VK",Alom MZ,10.1117/12.2550146,University of Dayton,"In the last few years, Deep Learning (DL) has been showing superior performance in different modalities of bio-medical image analysis. Several DL architectures have been proposed for classification, segmentation, and detection tasks in medical imaging and computational pathology. In this paper, we propose a new DL architecture, the NABLA-N network (del(N)-Net), with better feature fusion techniques in decoding units for dermoscopic image segmentation tasks. The del(N)-Net has several advances for segmentation tasks. First, this model ensures better feature representation for semantic segmentation with a combination of low to high-level feature maps. Second, this network shows better quantitative and qualitative results with the same or fewer network parameters compared to other methods. In addition, the Inception Recurrent Residual Convolutional Neural Network (IRRCNN) model is used for skin cancer classification. The proposed del(N)-Net network and IRRCNN models are evaluated for skin cancer segmentation and classification on the benchmark datasets from the International Skin Imaging Collaboration 2018 (ISIC-2018). The experimental results show superior performance on segmentation tasks compared to the Recurrent Residual U-Net (R2U-Net). The classification model shows around 87% testing accuracy for dermoscopic skin cancer classification on ISIC2018 dataset.","Skin Cancer Segmentation,Deep Learning,R2U-Net,NABLA-N Net,IRRCNN,Medical Imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
52,Imaging Epigenetics Study of Schizophrenia with Structure-enforced Collaborative Regression,11318,,,"Bai Yuntong,Lian Isabelle,Zhang Xiao,Liu Anqi,Calhoun Vince D.,Wang Yu-Ping","Bai YT,Lian I,Zhang X,Liu AQ,Calhoun C,Wang YP",Wang YP,10.1117/12.2549651,Tulane University,"In the study of complex mental disorders like schizophrenia (SZ), while imaging genetics has achieved great success, imaging epigenetics is attracting increasing attention as it considers the impact of environmental factors on gene expression and resulting phenotypic changes. In this study, we aimed to fill the gap by jointly analyzing imaging and epigenetics data to study SZ. More specifically, we proposed a novel structure-enforced collaborative regression model (SCoRe) to extract co-expressed discriminative features related to SZ from fMRI and DNA methylation data. SCoRe can utilize phenotypical information while enforce an agreement between multiple data views. Moreover, it also considers the group structure within each view of data. The brain network based on fMRI data can be divided into 116 regions of interests (ROIs) based on anatomical structures of the brain and the DNA methylation data can be grouped based on pathway information, which are used as prior knowledge to be incorporated into the learning model. After validation through simulation test, we applied the model to SZ study with data collected by MIND Clinical Imaging Consortium (MCIC). Through integrating fMRI and DNA methylation data of 184 participants (104 SZ and 80 healthy subjects), we succeeded in identifying 8 important brain regions and 3 genes associated with SZ. This study can shed light on the understanding of SZ from both brain imaging and epigenomics, complementary to imaging genomics.","Multi-view learning,imaging epigenetics,fMRI,DNA methylation,schizophrenia,correlative analysis",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"DOPAMINE,RECEPTOR,EXPRESSION,SELECTION,GENES,GYRUS",,,
53,Preprocessing of clinical neuro-oncology MRI studies for big data applications,11318,,,"Chakrabarty Satrajit,LaMontagne Pamela,Marcus Daniel S.,Milchenko Mikhail","Chakrabarty S,LaMontagne P,Marcus DS,Milchenko M",Chakrabarty S,10.1117/12.2548371,Washington University (WUSTL),"Clinically acquired, multimodal and multi-site MRI datasets are widely used for neuro-oncology research. However, manual preprocessing of such data is extremely tedious and error prone due to high intrinsic heterogeneity. Automatic standardization of such datasets is therefore important for data-hungry applications like deep learning. Despite rapid advances in MRI data acquisition and processing algorithms, only limited effort was dedicated to automatic methodologies for standardization of such data.
To address this challenge, we augment our previously developed Multimodal Glioma Analysis (MGA) pipeline with automation tools to achieve processing scale suitable for big data applications. This new pipeline implements a natural language processing (NLP) based scan-type classifier, with features constructed from DICOM metadata based on bag-of-words model. The classifier automatically assigns one of 18 pre-defined scan types to all scans in MRI study.
Using the described data model, we trained three types of classifiers: logistic regression, linear SVM, and multi-layer artificial neural network (ANN) on the same dataset Their performance was validated on four datasets from multiple sources. ANN implementation achieved the highest performance, yielding an average classification accuracy of over 99%. We also built a Jupyter notebook based graphical user interface (GUI) which is used to run MGA in semi-automatic mode for progress tracking purposes and quality control to ensure reproducibility of the analyses based thereof. MGA has been implemented as a Docker container image to ensure portability and easy deployment. The application can run in a single or batch study mode, using either local DICOM data or XNAT cloud storage.","Clinical MRI,Neuro-oncology imaging,Translational research,Natural Language Processing,MRI scan classifier,Docker,Jupyter Notebook",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
54,Exploiting biomedical literature to mine out a large multimodal dataset of rare cancer studies,11318,,,"Dhrangadhariya Anjani,Jimenez-del-Toro Oscar,Andrearczyk Vincent,Atzori Manfredo,Mueller Henning","Dhrangadhariya A,Jimenez-del-Toro O,Andrearczyk V,Atzori M,Muller H",Dhrangadhariya A,10.1117/12.2549565,University of Applied Sciences & Arts Western Switzerland,"The overall lower survival rate of patients with rare cancers can be explained, among other factors, by the limitations resulting from the scarce available information about them. Large biomedical data repositories, such as PubMed Central Open Access (PMC-OA), have been made freely available to the scientific community and could be exploited to advance the clinical assessment of these diseases. A multimodal approach using visual deep learning and natural language processing methods was developed to mine out 15,028 light microscopy human rare cancer images. The resulting data set is expected to foster the development of novel clinical research in this field and help researchers to build resources for machine learning.","PubMed Central,rare cancer,multimodal classification,natural language processing",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
55,Breast Cancer Classification from Digital Breast Tomosynthesis Using a 3D Multi-Subvolume Approach,11318,,,"Doganay Emine,Li Puchen,Luo Yahong,Chai Ruimei,Guo Yuan,Wu Shandong","Doganay E,Li PC,Luo YH,Chai RM,Guo Y,Wu SD",Wu SD,10.1117/12.2551376,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Digital mammography (DM) was the most common image guided diagnostic tool in breast cancer detection up till recent years. However, digital breast tomosynthesis (DBT) imaging, which presents more accurate results than DM, is going to replace DM in clinical practice. As in many medical image processing applications, Artificial Intelligence (AI) has been shown promising in reducing radiologists reading time with enhanced cancer diagnostic accuracy. In this paper, we implemented a 3D network using deep learning algorithms to detect breast cancer malignancy using DBT craniocaudal (CC) view images. We created a multi-sub-volume approach, in which the most representative slice (MRS) for malignancy scans is manually selected/defined by expert radiologists. We specifically compared the effects on different selections of the MRS by two radiologists and the resulting model performance variations. The results indicate that our scheme is relatively robust for all three experiments.","breast cancer,digital breast tomosynthesis,3D deep learning,weakly supervised classification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
56,Impact of data augmentation techniques on a deep learning based medical imaging task,11318,,,"Dutta Sandeep,Prakash Prakhar,Matthews Christopher G.","Dutta S,Prakash P,Matthews CG",Dutta S,10.1117/12.2549806,General Electric,"For any deep learning (DL) based task, model generalization and prediction performance improve as a function of training data set size and variety. However, its application to medical imaging is still challenging because of the limited availability of high-quality and sufficiently diverse annotated data. Data augmentation techniques can improve the model performance when the available dataset size is limited. Anatomy region localization from medical images can be automated with deep learning and is important for tasks such as organ segmentation and lesion detection. Different data augmentation methods were compared for DL based anatomy region localization with computed tomography images. The impact of different neural network architectures was also explored. The prediction accuracy on an independent test set improved from 88% to 97% with optimal selection of data augmentation and architecture while using the same training dataset Data augmentation steps such as zoom, translation and flips had incremental effect on classifier performance whereas sample-wise mean shift appeared to degrade the classifier performance. Global average pooling improved classifier accuracy compared to fully-connected layer when limited data augmentation was used. All model architectures converged to an optimal performance with the right combination of augmentation steps. Prediction inaccuracies were mostly observed in the boundary regions between anatomies. The networks also successfully localized anatomy for Positron Emission Tomography studies reaching an accuracy of up to 97%. Similar impact of data augmentation and pooling layer was also observed.","medical imaging,convolutional neural networks,data augmentation,global average pooling,batch normalization,dropout,deep learning,classification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,ARTIFICIAL-INTELLIGENCE,,,
57,SNIPR: Stroke Neuroimaging Phenotype Repository,11318,,,"Foroushani Hossein Mohammadian,Dhar Rajat,Chen Yasheng,Gurney Jenny,Hamzehloo Ali,Lee Jin-Moo,Marcus Daniel S.","Foroushani HM,Dhar R,Chen YS,Gurney J,Hamzehloo A,Lee JM,Marcus DS",Foroushani HM,10.1117/12.2549622,Washington University (WUSTL),"Gaining a deeper understanding of stroke pathophysiology is critical for discovery and evaluation of emerging stroke treatments. However, such discovery requires deeper phenotyping of stroke and its complications, a Big Data model for integration of demographic, clinical, genetic and imaging phenotypes with sophisticated processing pipelines at massive scale. The Stroke Neuroimaging Phenotype Repository (SNIPR) is a large multi-center centralized imaging repository of clinical CT and MRI scans from stroke patients worldwide, based on open source Extensible Neuroimaging Archive Toolkit (XNAT) imaging informatics platform. The aims of this repository are to: (i) Create a central repository to host and provide secure access to data from anonymized acute stroke patients with serial imaging; (ii) Facilitate extraction and analysis of multiple stroke phenotypes via image processing and data aggregation techniques; and (iii) Expedite the development of containerized pipelines to perform large-scale analysis of complications after stroke. Currently, SNIPR hosts 8 projects, 2245 subjects, and 6148 imaging exams from Washington University Medical Center's clinical image archive as well as contributions from collaborators in different countries, including US, Finland, Poland, and Spain. Moreover, we have used XNAT's standard XML Schema extension mechanism to create data type extensions to support stroke studies, including clinical phenotypes such as NIHSS and imaging phenotypes such as infarct and cerebrospinal fluid (CSF) volume and extent of midline shift or hemorrhagic transformation. We have developed containerized pipelines to facilitate image processing and analysis and deployed these pipelines through XNAT's container service. The container service enables these pipelines to execute at large scale with Docker Swarm on an attached compute cluster. Our pipelines include a scan-type classifier which uses a convolutional neural network (CNN) approach and natural language processing to automatically categorize uploaded CT sequences into defined classes to facilitate selection of appropriate sequences for further analyses. This containerized classifier was deployed within a broader pipeline to facilitate big data analysis of cerebral edema after stroke and produced 99.4 % test accuracy on 10000 scans. SNIPR enables automated pipelines to use this automatic scan selection to derive imaging phenotypes and couple them with clinical and genetic data with the overarching aim of enabling a broad understanding of stroke progression and pathophysiology.","Containerized pipeline,convolutional neural network (CNN),big data,informatics,phenotype repository,stroke neuroimaging,XNAT",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,PREVENT,,,
58,One-Class Classification for Highly Imbalanced Medical Image Data,11318,,,"Gao Long,Yang Lu,Arefan Dooman,Wu Shandong","Gao L,Yang L,Arefan D,Wu SD",Wu SD,10.1117/12.2551389,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Computer-aided diagnosis plays an important role in clinical image diagnosis. Current clinical image classification tasks usually focus on binary classification, which need to collect samples for both the positive and negative classes in order to train a binary classifier. However, in many clinical scenarios, there may have many more samples in one class than in the other class, which results in the problem of data imbalance. Data imbalance is a severe problem that can substantially influence the performance of binary-class machine learning models. To address this issue, one-class classification, which focuses on learning features from the samples of one given class, has been proposed. In this work, we assess the one-class support vector machine (OCSVM) to solve the classification tasks on two highly imbalanced datasets, namely, space-occupying kidney lesions (including renal cell carcinoma and benign) data and breast cancer distant metastasis/non-metastasis imaging data. Experimental results show that the OCSVM exhibits promising performance compared to binary-class and other one-class classification methods.","space-occupying lesions of kidney,breast cancer,One-Class Support Vector Machine",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"CT,TEXTURE,ANALYSIS",,,
59,Anatomical Landmark Segmentation in Uterine Cervix Images Using Deep Learning,11318,,,"Guo Peng,Xue Zhiyun,Long L. Rodney,Antani Sameer K.","Guo P,Xue ZY,Long LR,Antani SK",Guo P,10.1117/12.2549267,National Institutes of Health (NIH) - USA,"For automated evaluation of changes on uterine cervix, the external os (here simply os) is a primary anatomical landmark in locating the transformation zone (T-zone). Any abnormal tissue changes typically occur at or within the T-zone. This makes localizing the os on cervical images of great interest for detecting and classifying changes. However, there has been very limited work reported on segmentation of the os region in digitized cervix images, and to our knowledge no work has been done on sets of cervix images acquired from independent data collections exhibiting variabilities due to collection devices, environments, and procedures. In this paper, we present a process pipeline which consists of deep learning os region segmentation over such multiple datasets, followed by comprehensive evaluation of the performance. First, we evaluate of two state-of-the-art deep learning based localization and classification algorithms, viz., Mask R-CNN and Mask(X) R-CNN, on multiple datasets. Second, in consideration of the os being small and irregularly-shaped, and of the variabilities in image quality, we use performance measurements beyond the commonly used DICE/IoU scores. We obtain higher performance, on a larger dataset, as compared with the work reported in the literature, and achieve a highest detection rate of 99.1% and an average minimal distance of 1.02 pixels. Furthermore, the network models we obtained in this study show potential use of quality control for data acquisition.","Deep learning,uterine cervical cancer,external os segmentation,automated visual evaluation,Mask-RCNN,Mask(X) R-CNN",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"DESIGN,TRIAL",,,
60,A new case-based CAD scheme using a hierarchical SSIM feature extraction method to classify between malignant and benign cases,11318,,,"Heidari Morteza,Mirniaharikandehei Seyedehnafiseh,Danala Gopichandh,Qiu Yuchen,Zheng Bin","Heidari M,Mirniaharikandehei S,Danala G,Qiu YC,Zheng B",Heidari M,10.1117/12.2549130,University of Oklahoma System,"The purpose of this study is to assess feasibility of developing a new case based computer-aided diagnosis (CAD) scheme of mammograms based on a tree-based analysis of SSIM characteristics of the matched bilateral local areas of left and right breasts to predict likelihood of cases being malignant. We assembled a dataset involving screening mammograms acquired from 1000 patients. Among them, 500 cases were positive with cancer detected and verified, while other 500 cases had benign masses. Both CC and MLO view of the mammograms were used for feature extraction in this study. A CAD scheme was applied to preprocess the bilateral mammograms of the left and right breasts, generate image maps in the special domain, compute SSIM-based image features between the matched bilateral mammograms, and apply a support vector machine model to classify between malignant and benign cases. For performance evaluation, CAD scheme was trained and tested using a 10-fold cross-validation method. The area under a receiving operating characteristic curve (AUC) was computed as an index of performance evaluation. Using the poll of 12 extracted SSIM features, the CAD scheme yielded a performance level of AUC = 0.84 +/- 0.016, which is significantly higher than using each individual SSIM feature for the classification purpose (p < 0.05), and an odds ratio of 19.0 with 95% confidence interval of [15.3, 29.8]. Thus, this study supports the feasibility of applying an innovative method to develop a new case-based CAD scheme without lesion segmentation and demonstrates higher performance of new CAD scheme to classify between malignant and benign mammographic cases.","Computer-aided diagnosis,case-based CAD scheme of mammography,Cancer detection,Machine learning,Bilateral SSIM feature analysis",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DIAGNOSIS,BREAST-CANCER",,,
61,A Comparative Study of 2D Image Segmentation Algorithms for Traumatic Brain Lesions Using CT Data from the ProTECTIII Multicenter Clinical Trial,11318,,,"Jadon Shruti,Leary Owen P.,Pan Ian,Harder Tyler J.,Wright David W.,Merck Lisa H.,Merck Derek","Jadon S,Leary OP,Pan I,Harder TJ,Wright DW,Merck LH,Merck D",Jadon S,10.1117/12.2566332,Brown University,"Automated segmentation of medical imaging is of broad interest to clinicians and machine learning researchers alike. The goal of segmentation is to increase efficiency and simplicity of visualization and quantification of regions of interest within a medical image. Image segmentation is a difficult task because of multiparametric heterogeneity within the images, an obstacle that has proven especially challenging in efforts to automate the segmentation of brain lesions from non-contrast head computed tomography (CT). In this research, we have experimented with multiple available deep learning architectures to segment different phenotypes of hemorrhagic lesions found after moderate to severe traumatic brain injury (TBI). These include: intraparenchymal hemorrhage (IPH), subdural hematoma (SDH), epidural hematoma (EDH), and traumatic contusions. We were able to achieve an optimal Dice Coefficient score of 0.94 using UNet++ 2D Architecture with Focal Tversky Loss Function, an increase from 0.85 using UNet 2D with Binary Cross-Entropy Loss Function in intraparenchymal hemorrhage (IPH) cases. Furthermore, using the same setting, we were able to achieve the Dice Coefficient score of 0.90 and 0.86 in cases of Extra-Axial bleeds and Traumatic contusions, respectively.","Automated segmentation,traumatic brain injury,non-contrast head computed tomography,ProTECTIII,methods comparison",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,http://arxiv.org/pdf/2006.01263,
62,MR-radiomic biopsy for estimation of malignancy grade in parotid gland cancer,11318,,,"Kamezawa H.,Arimura H.,Yasumatsu R.,Ninomiya K.","Kamezawa H,Arimura H,Yasumatsu R,Ninomiya K",Kamezawa H,10.1117/12.2549462,Teikyo University,"We have developed a magnetic resonance (MR) image-based radiomic biopsy approach for estimation of malignancy grade in parotid gland cancer (PGC). Preoperative T1- and T2-weighted MR images of 39 PGC patients with 20 high-and 19 intermediate-/low-malignancy grades were employed. High- versus intermediate-/low-malignancy grades were estimated using MR-radiomic biopsy approaches, i.e. 972 hand-crafted feature and transfer learning of five pre-trained deep learning (DL) architectures (AlexNet, GoogLeNet, VGG-16, ResNet-101, DenseNet-201). The 39 patients were divided into 70% for training datasets and 30% for test datasets. The hand-crafted features were extracted from cancer regions in T1- and T2-weighted MR images. Three features were selected as a radiomic signature by using a least absolute shrinkage and selection operator (LASSO), whose coefficients of three features were used for constructing the radiomic score (Rad-score). The two grade malignancy was estimated by using an optimal cut-off value of Rad-score. On the other hand, last three layers of the DL architectures were replaced with new three layers for the estimation task. The DL architectures were fine-tuned with training datasets and were evaluated with test datasets. The performances of the MR-radiomic biopsy approaches were assessed by using the accuracy and the area under the receiver operating characteristic curve (AUC). The VGG-16 demonstrated the best performance (accuracy=85.4%, AUC=0.906), but the other approaches showed worse performances (Rad-score: 83.3%, 0.830, AlexNet: 84.4%, 0.915, GoogLeNet: 84.9%, 0.884, ResNet-101: 84.9%, 0.918, DenseNet-201: 84.4%, 0.869) than the VGG-16. The VGG-16-based MR-radiomic biopsy could be feasible for the malignancy grade estimation of PGC.","radiomics,malignancy grade,parotid gland cancer,deep learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"PROGNOSTIC-FACTORS,TEXTURAL,FEATURES,CARCINOMA",,,
63,Automated Coronary Artery Segmentation in Coronary Computed Tomography Angiography (CCTA) using Deep Learning Neural Networks,11318,,,"Lei Yang,Guo Bangjun,Fu Yabo,Wang Tonghe,Liu Tian,Curran Walter,Zhang Longjiang,Yang Xiaofeng","Lei Y,Guo BJ,Fu YB,Wang TH,Liu T,Curran W,Zhang LJ,Yang XF",Yang XF,10.1117/12.2550368,Emory University,"Automatic segmentation of the coronary artery in coronary computed tomographic angiography (CCTA) is important for clinicians in evaluating patients with coronary artery disease (CAD). Tradition visual interpretation of coronary artery stenosis is observer-dependent and time-consuming. In this work, we proposed to use a 3D attention fully convolution network (FCN) method to automatically segment the coronary artery for CCTA. FCN was used to perform end-to-end mapping from CCTA image to the binary segmentation of coronary artery. Deep attention strategy was integrated into the FCN model to highlight the informative semantic features extracted from CCTA image and thus to enhance the accuracy of segmentation. The proposed method was tested on 30 patients' CCTA data. Dice similarity coefficient (DSC), precision and recall indices between manually delineated coronary artery contour and segmented contour were used to quantify the segmentation accuracy of the proposed method. The DSC, precision, and recall were 83%+/- 4%, 84%+/- 4% and 87%+/- 3%, which demonstrated the segmentation accuracy of the proposed method.","coronary computed tomographic angiography,coronary artery disease,segmentation,fully convolution network,deep attention",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,QUANTIFICATION,,,
64,Cloud platform for deep learning-based CAD via collaboration between Japanese medical societies and institutes of informatics,11318,,,"Murao Kohei,Ninomiya Youichirou,Han Changhee,Aida Kento,Satoh Shin'ichi","Murao K,Ninomiya Y,Han CH,Aida K,Satoh S",Murao K,10.1117/12.2543521,Research Organization of Information & Systems (ROIS),"Deep Learning-based medical imaging research has been actively conducted thanks to its high diagnostic accuracy comparable to that of expert physicians. However, to apply developed Computer Aided Diagnosis (CAD) systems to various data collected from different hospitals, we should prepare sufficient training data in terms of quality/quantity; unfortunately, especially in Japan, we need to overcome each hospital's different ethical codes to obtain such multi-institutional data. Therefore, we built a cloud platform for (i) collecting multi-modal large-scale medical images from hospitals through medical societies and (ii) conducting various Deep Learning-based CAD research via collaboration between Japanese medical societies and institutes of informatics. Each hospital first provides the data to the corresponding medical society among 6 societies (e.g., Japan Radiological Society and Japanese Society of Pathology) based on their modality among 8 modalities (e.g., Computed Tomography and Whole Slide Imaging (WSI)); then, each society uploads them, possibly with annotation, to our cloud platform established in November 2017. We have collected over 80 million medical images by December 2019, and over 60 registered researchers have conducted CAD research on the platform. We presented the achieved results at major international conferences/in medical journals; their ongoing clinical applications include remote WSI diagnosis. We plan to further increase the number of images/modalities and apply our research results to a clinical environment.","cloud platform,medical big data,Deep Learning-based CAD,Japanese medical societies",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
65,Two-Stage Deep Learning Architecture for Pneumonia Detection and its Diagnosis in Chest Radiographs,11318,,,"Narayanan Barath Narayanan,Davuluru Venkata Salini Priyamvada,Hardie Russell C.","Narayanan BN,Davuluru VSP,Hardie RC",Narayanan BN,10.1117/12.2547635,University of Dayton,"Approximately two million pediatric deaths occur every year due to Pneumonia. Detection and diagnosis of Pneumonia plays an important role in reducing these deaths. Chest radiography is one of the most commonly used modalities to detect pneumonia. In this paper, we propose a novel two-stage deep learning architecture to detect pneumonia and classify its type in chest radiographs. This architecture contains one network to classify images as either normal or pneumonic, and another deep learning network to classify the type as either bacterial or viral. In this paper, we study and compare the performance of various stage one networks such as AlexNet, ResNet, VGG16 and Inception-v3 for detection of pneumonia. For these networks, we employ transfer learning to exploit the wealth of information available from prior training. For the second stage, we find that transfer learning with these same networks tends to overfit the data. For this reason we propose a simpler CNN architecture for classification of pneumonic chest radiographs and show that it overcomes the overfitting problem. We further enhance the performance of our system in a novel way by incorporating lung segmentation using a U-Net architecture. We make use of a publicly available dataset comprising 5856 images (1583 - Normal, 4273 - Pneumonic). Among the pneumonia patients, 2780 patients are identified as bacteria type and the rest belongs to virus category. We test our proposed algorithm(s) on a set of 624 images and we achieve an area under the receiver operating characteristic curve of 0.996 for pneumonia detection. We also achieve an accuracy of 97.8% for classification of pneumonic chest radiographs thereby setting a new benchmark for both detection and diagnosis. We believe the proposed two-stage classification of chest radiographs for pneumonia detection and its diagnosis would enhance the workflow of radiologists.","Pneumonia Detection,Computer Aided Detection,Computer Aided Diagnosis,Convolutional Neural Networks,Lung Segmentation",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DIAGNOSIS,LUNG,NODULES",,,
66,Radiomics for predicting response to neoadjuvant chemotherapy treatment in breast cancer,11318,,,"Rabinovici-Cohen Simona,Tlusty Tal,Abutbul Ami,Antila Kari,Fernandez Xose,Rejo Beatriz Grandal,Hexter Efrat,Cubelos Oliver Hijano,Khateeb Abed,Pajula Juha","Rabinovici-Cohen S,Tlusty T,Abutbul A,Antila K,Fernandez X,Rejo BG,Hexter E,Cubelos OH,Khateeb A,Pajula J",Rabinovici-Cohen S,10.1117/12.2551374,"IBM Res Haifa, IL-3498825 Haifa, Israel.","Women who are diagnosed with breast cancer are referred to Neoadjuvant Chemotherapy Treatment (NACT) before surgery when treatment guidelines indicate that. Achieving complete response in this treatment is correlated with improved overall survival compared with those experiencing a partial or no response at all. In this paper, we explore multi modal clinical and radiomics metrics including quantitative features from medical imaging, to assess in advance complete response to NACT. Our dataset consists of a cohort from Institut Curie with 1383 patients; from which 528 patients have mammogram imaging. We analyze the data via image processing, machine learning and deep learning algorithms to increase the set of discriminating features and create effective models. Our results show ability to classify the data in this problem settings, using the clinical data. We then show the possible improvement we may achieve in combining clinical and mammogram data measured by the AUC, sensitivity and specificity. We show that for our cohort the overall model achieves sensitivity 0.954 while keeping good specificity of 0.222. This means that almost all patients that achieved pathologic complete response will also be correctly classified by our model. At the same time, for 22% of the patients, the model could correctly predict in advance that they won't achieve pathologic complete response, enabling them to reassess in advance this treatment. We also describe our system architecture that includes the Biomedical Framework, a platform to create configurable reusable pipelines and expose them as micro-services on-premise or in-the-cloud.","Neoadjuvant Chemotherapy Treatment,Neoadjuvant Treatment,Breast Cancer,Radiomics,Big Data,Artificial Intelligence,Deep Learning,Machine Learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
67,Machine Learning for Automatic Construction of Pediatric Abdominal Phantoms for Radiation Dose Reconstruction,11318,,,"Virgolin Marco,Wang Ziyuan,Alderliesten Tanja,Bosman Peter A. N.","Virgolin M,Wang ZY,Alderliesten T,Bosman PAN",Virgolin M,10.1117/12.2548969,"Ctr Wiskunde & Informat, Life Sci & Hlth Grp, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.","The advent of Machine Learning (ML) is proving extremely beneficial in many healthcare applications. In pediatric oncology, retrospective studies that investigate the relationship between treatment and late adverse effects still rely on simple heuristics. To capture the effects of radiation treatment, treatment plans are typically simulated on virtual surrogates of patient anatomy called phantoms. Currently, phantoms are built to represent categories of patients based on reasonable yet simple criteria. This often results in phantoms that are too generic to accurately represent individual anatomies. We present a novel approach that combines imaging data and ML to build individualized phantoms automatically. We design a pipeline that, given features of patients treated in the pre-3D planning era when only 2D radiographs were available, as well as a database of 3D Computed Tomography (CT) imaging with organ segmentations, uses ML to predict how to assemble a patient-specific phantom. Using 60 abdominal CTs of pediatric patients between 2 to 6 years of age, we find that our approach delivers significantly more representative phantoms compared to using current phantom building criteria, in terms of shape and location of two considered organs (liver and spleen), and shape of the abdomen. Furthermore, as interpretability is often central to trust ML models in medical contexts, among other ML algorithms we consider the Gene-pool Optimal Mixing Evolutionary Algorithm for Genetic Programming (GP-GOMEA), that learns readable mathematical expression models. We find that the readability of its output does not compromise prediction performance as GP-GOMEA delivered the best performing models.","machine learning,pediatric cancer,radiation treatment,dose reconstruction,phantom",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"CHILDHOOD-CANCER,RADIOTHERAPY,ADULTS",,https://repository.tudelft.nl/islandora/object/uuid%3A1fb01798-c514-4dc9-82c8-5cf038b2136e/datastream/OBJ/download,
68,Feasibility of predicting pancreatic neuroendocrine tumor grade using deep features from unsupervised learning,11318,,,"Wan Yidong,Xu Lei,Yang Pengfei,Cao Zuozhen,Luo Chen,Shen Xiaoyong,Wu Yan,Ruan Dan,Niu Tianye","Wan YD,Xu L,Yang PF,Cao ZZ,Luo C,Shen XY,Wu Y,Ruan D,Niu TY",Niu TY,10.1117/12.2548723,Zhejiang University,"This paper aimed to investigate if deep image features extracted via sparse autoencoder (SAE) could be used to preoperatively predict histologic grade in pancreatic neuroendocrine tumors (pNETs). In this study, a total of 114 patients from two institutions were involved. The deep image features were extracted based on the sparse autoencoder network via a 2000-time iteration. Considering the possible prediction error due to the small patient data size, we performed 10-fold cross-validation. To find the optimal hidden size, we set the size as a range of 6-16. The maximum relevance minimum redundancy (mRMR) features selection algorithm was used to select the most histologic grade-related image features. Then the radiomics signature was generated by using the selected features with Support Vector Machine (SVM), Multivariable Logistic Regression (MLR) and Artificial Neural Networks (ANN) methods. The prediction performance was evaluated using AUC value.","unsupervised learning,pancreatic neuroendocrine tumors,tumor quantification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"CT,FINDINGS,MR",,,
69,A tracking-based semi-automatic software for focal liver lesion extraction in contrast-enhanced ultrasound (CEUS) cine-loops,11318,,,"Wang Yuqi,Wang Kung,Tian Jie","Wang YQ,Wang K,Tian J",Wang YQ,10.1117/12.2542984,Chinese Academy of Sciences,"The tracking-based semi-automatic software is a user-friendly tool to draw bounding box around focal liver lesions (FLLs) in Contrast-enhanced Ultrasound (CEUS) cine-loop based on MATLAB 2019b. The software development based on the consideration that deep learning has a broad prospect in processing FLLs CEUS cine-loops while extracting enormous ground-truth for detecting, tracking as well as further data analysis is necessary. Until now, there is no public software committing to successive extracting region of interests (ROIs) in CEUS cine-loops. The tracking algorithm build on point-based registration techniques (PBRTs) which are widely used for motion compensation in 2-D FLL CEUS imaging. The software need user draw a bounding box firstly for every tracking sequence and allows user to fine-tune or delete some bad tracking results in time. The software can show the dual bounding box when the cine-loop is in double display mode, all the functions for examples bounding box drawing and tracking can work directly in ultrasound in case that CEUS is unrecognizable. We also add some interactive items and sequence analysis algorithms to make the processing more efficient and you can download the software in https://github.com/Yuqi-Zest/CEUS-tracking-software.","Contrast-enhanced ultrasound,data preprocess software,focal liver lesion,tracking,image process",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,HEPATOCELLULAR-CARCINOMA,,,
70,A Method of Dividing Clinical Data Set for Medical Image AI Training,11318,,,"Zheng Dezhong,Yang Yuanyuan,Li Wentao","Zheng DZ,Yang YY,Li WT",Yang YY,10.1117/12.2549552,Chinese Academy of Sciences,"In the AI training, the data set is always divided into training set and test set at random, but the clinical image data from hospitals is different from the public data set. The division of public data set is reasonably divided and evenly distributed after many experiments. Accurate understanding of the data distribution directly affects the training model quality. So we proposed a new method of dividing clinical data set based on distance metric learning of the Gaussian mixture model to obtain more reasonable data set divisions. The distance metric learning based on deep neural network, first embeds data into a new metric space, then in the metric space uses in-depth mining based on data characteristics, calculates the distance between samples, finally compares the differences. The method can accurately know the data distribution characteristics to a certain extent. Under the condition of understanding the data distribution characteristics, more reasonable divisions can be obtained. That can greatly affect the accuracy and generalization performance of the models we trained.","AI training,data set division,deep neural network,distance metric learning of the Gaussian mixture model",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
71,Identification of early cancerous lesion of esophagus with endoscopic images by Convolutional Neural Network,11214,,,"Yang Tsung-Yu,Syu Hao-Yi,Wu I-Chen,Wang Hsiang-Chen","Yang TY,Syu HY,Wu IC,Wang HC",Yang TY,10.1117/12.2544889,National Chung Cheng University,"Esophageal cancer is less predictive than other diseases, and patients are usually diagnosed at an advanced stage, so effective treatment is usually too late. Therefore, this experiment proves that AI detects esophageal cancer. The diagnostic ability of the number of phases is expected to assist doctors in using endoscopy plus artificial intelligence to increase the accuracy of diagnosis of esophageal cancer.
This study provided 936 images of esophageal cancer endoscopy as a training image, including 498 white light endoscopes (WLI) and 438 narrow-band imaging endoscopes (NBI) images. According to the esophageal cancerization process, it is divided into four types: metaplasia (Dysplasia), metaplasia and esophageal cancer (Dysplasia-ECA), and esophageal cancer (ECA). A Single Shot Multibox Detector (SSD) was constructed by Convolutional Neural Network (CNN), and 264 test images were prepared to evaluate the accuracy of the model diagnosis.
We developed a system called DNN-CAD to identify neoplastic or hyperplastic colorectal polyps less than 5 mm. The system classified polyps with a PPV of 89.6%, and a NPV of 91.5%, and in a shorter time than endoscopists. This deep-learning model has potential for not only endoscopic image recognition but for other forms of medical image analysis, including sonography, computed tomography, and magnetic resonance images.
The construction of an SSD system for detecting esophageal cancer can analyze stored endoscopic images with high sensitivity in a short time, but more training can improve the accuracy of diagnosis. The system can facilitate early detection in practice and thus have a better diagnosis in the future.","Esophageal cancer,Narrow-band imaging (NBI),Convolutional Neural Network (CNN),Single Shot Multibox Detector (SSD),DNN-CAD",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Microscopy,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
72,Machine Learning Applications in Polymer Composites,2205,,,"Hamidi Youssef K.,Berrado Abdelaziz,Altan M. Cengiz","Hamidi YK,Berrado A,Altan MC",Hamidi YK,10.1063/1.5142946,University of Houston System,"The primary interest in numerous research problems in both polymer composites and Machine Learning (ML) is to develop predictive models for one or more variables of interest using relevant independent variables, or inputs. However, these two fields have often adopted different approaches, where modeling of composite behavior is often based on physics-based models and phenomenological theories. These physical models are more precise and robust, but often suffer from restricted predictive capability since they are confined to a specific set of conditions. ML models, on the other hand, can be more efficient during the design phase as they allow managing massive and high dimensional data sets to extract the best lit or a predictive behavior for the application at hand.
In this context, material scientists would benefit from understanding and implementing some of the powerful ML methods, in order to predict or characterize a behavior of interest of a polymer composite. In this paper, we present a general methodology aimed at employing supervised machine learning models for predicting the properties of polymer composites, including thermo-mechanical properties, environmental effects such as moisture saturation level, durability, or other important behavior, based on the composite constituents, manufacturing processes, relevant process parameters, and expected life-span of the composite product.","Polymer Composites,Behavior Prediction,machine learning",Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",,,,"MECHANICAL-PROPERTIES,MOISTURE,ABSORPTION,ADHESION",,https://aip.scitation.org/doi/pdf/10.1063/1.5142946,
73,Utilizing a transfer model to classify epithelium and stroma on digital histopathological images for ovarian cancer patients,11241,,,"Chen Xuxin,Zhang Roy,Fung Kar-Ming,Liu Hong,Zheng Bin,Qiu Yuchen","Chen XX,Zhang R,Fung KM,Liu H,Zheng B,Qiu YC",Qiu YC,10.1117/12.2547512,University of Oklahoma System,"Automatic classification of epithelium and stroma regions on histopathological images is critically important in digital pathology. Although many studies have been conducted in this research area, few investigations have been focused on model generalizability between different types of tissue samples. The objective of this study is to initially verify the classification effectiveness of a sufficiently optimized transfer model. Accordingly, two datasets were assembled, which contain 157 breast cancer images (Dataset I) and 11 ovarian cancer images (Dataset II), respectively. A computer aided detection (CAD) scheme was developed for this classification task. The scheme first divided each image into small regions of interest (ROI) containing only epithelium or stroma tissues, using multi-resolution super-pixel algorithm. Then, a total of 26 quantitative features were computed for each ROI, which were used as the input of five different machine learning classifiers, namely, linear support vector machine (SVM), linear discriminant analysis (LDA), logistic regression, decision tree and k-nearest neighbors (KNN). The scheme was trained and optimized on Dataset I, and five-fold cross validation strategy was utilized for performance evaluation. After the scheme was sufficiently optimized on Dataset I, it was applied ""as is"" on dataset II. The results of the breast cancer dataset show that linear SVM achieved the highest classification accuracy of 0.910. When applied on the 11 ovarian cancer cases (Dataset II), the SVM model achieved an average classification accuracy of 0.744. This preliminary study initially demonstrates the model transfer performance for epithelium-stroma classification task.","Epithelium-stroma classification,transfer model,ovarian cancer,machine learning,digital pathology",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Plant Sciences,Oncology,Immunology,Medical Laboratory Technology,Optics",,,"CLASSIFICATION,RATIO",,,
74,A Perspective on Using Machine Learning in 3D Bioprinting,6,1,,"Yu Chunling,Jiang Jingchao","Yu CL,Jiang JC",Jiang JC,10.18063/ijb.v6i1.253,University of Auckland,"Recently, three-dimensional (3D) printing technologies have been widely applied in industry and our daily lives. The term 3D bioprinting has been coined to describe 3D printing at the biomedical level. Machine learning is currently becoming increasingly active and has been used to improve 3D printing processes, such as process optimization, dimensional accuracy analysis, manufacturing defect detection, and material property prediction. However, few studies have been found to use machine learning in 3D bioprinting processes. In this paper, related machine learning methods used in 3D printing are briefly reviewed and a perspective on how machine learning can also benefit 3D bioprinting is discussed. We believe that machine learning can significantly affect the future development of 3D bioprinting and hope this paper can inspire some ideas on how machine learning can be used to improve 3D bioprinting.","3D printing,Bioprinting,Machine learning",Article,"WHIOCE PUBLISHING PTE LTD, SINGAPORE, 7030 ANG MO KIO AVE 5, 04-15 NORTHSTAR AMK, SINGAPORE, 569880, SINGAPORE","Engineering,Materials Science",,6.633,"SUPPORT,STRUCTURES,OPTIMIZATION,TRENDS",INTERNATIONAL JOURNAL OF BIOPRINTING,https://doi.org/10.18063/ijb.v6i1.253,
75,Task Decomposition and Synchronization for Semantic Biomedical Image Segmentation,29,,7497-7510,"Ren Xuhua,Ahmad Sahar,Zhang Lichi,Xiang Lei,Nie Dong,Yang Fan,Wang Qian,Shen Dinggang","Ren XH,Ahmad S,Zhang LC,Xiang L,Nie D,Yang F,Wang Q,Shen DG",Wang Q,10.1109/TIP.2020.3003735,Shanghai Jiao Tong University,"Semantic segmentation is essentially important to biomedical image analysis. Many recent works mainly focus on integrating the Fully Convolutional Network (FCN) architecture with sophisticated convolution implementation and deep supervision. Such complex networks need large training datasets, a requirement which is challenging for medical image analysis. In this paper, we propose to decompose the single segmentation task into three subsequent sub-tasks, including (1) pixel-wise image semantic segmentation, (2) prediction of the instance class labels of the objects within the image, and (3) classification of the scene the image belonging to. While these three sub-tasks are trained to optimize their individual loss functions at different perceptual levels, we propose to allow their interaction within the task-task context ensemble. Moreover, we propose a novel sync-regularization to penalize the deviation between the outputs of the pixel-wise semantic segmentation and the instance class prediction tasks. These effective regularizations help FCN utilize context information comprehensively and attain accurate segmentation, even though the number of images for training may be limited in many biomedical applications. We have successfully applied our framework to three diverse 2D/3D medical image datasets, including Robotic Scene Segmentation Challenge 18 (ROBOT18), Brain Tumor Segmentation Challenge 18 (BRATS18), and Retinal Fundus Glaucoma Challenge (REFUGE18). We have achieved outperformed or comparable performance in all the three challenges. Our code, typical data and trained models are available at https://github.com/xuhuaren/TDSNet.","Semantic segmentation,fully convolutional network,task decomposition,sync-regularization,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,,IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1905.08720,
76,Triaxial Accelerometer-Based Falls and Activities of Daily Life Detection Using Machine Learning,20,13,,"Althobaiti Turke,Katsigiannis Stamos,Ramzan Naeem","Althobaiti T,Katsigiannis S,Ramzan N",Katsigiannis S,10.3390/s20133777,University of West Scotland,"The detection of activities of daily living (ADL) and the detection of falls is of utmost importance for addressing the issue of serious injuries and death as a consequence of elderly people falling. Wearable sensors can provide a viable solution for monitoring people in danger of falls with minimal external involvement from health or care home workers. In this work, we recorded accelerometer data from 35 healthy individuals performing various ADLs, as well as falls. Spatial and frequency domain features were extracted and used for the training of machine learning models with the aim of distinguishing between fall and no fall events, as well as between falls and other ADLs. Supervised classification experiments demonstrated the efficiency of the proposed approach, achieving an F1-score of 98.41% for distinguishing between fall and no fall events, and an F1-score of 88.11% for distinguishing between various ADLs, including falls. Furthermore, the created dataset, named ""ShimFall&ADL"" will be publicly released to facilitate further research on the field.","activities of daily living,fall detection,accelerometer,wearable sensors,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ACTIVITY,RECOGNITION,PLATFORM,SYSTEM",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7378757,
77,Received Power Prediction for Suburban Environment based on Neural Network,,,35-39,"Wu Lina,He Danping,Guan Ke,Ai Bo,Briso-Rodriguez Cesar,Shui Tianyun,Liu Chenji,Zhu Liju,Shen Xiaopeng","Wu LN,He DP,Guan K,Ai B,Briso-Rodriguez C,Shui TY,Liu CJ,Zhu LJ,Shen XP",Ai B,,Beijing Jiaotong University,"Accurate received power prediction is important to wireless network planning and optimization, and appropriate channel modeling approach is highly demanded. The existing channel modeling approaches mainly include deterministic models and stochastic models. The deterministic models usually require detailed three-dimensional (3D) environment model including geometry and material information. The stochastic models are based on mathematical expressions which are difficult in describing complex environments. For mountaineous and suburban scenarios, where the environment is complex and difficult to reconstructed, both channel modeling approaches are limited. In this work, back propagation (BP) neural network which is the most widely used artificial neural network (ANN), is employed to accurately predict received power in the suburban scenario. An environmental feature is defined, which can describe the propagation environment only by using limited environmental types instead of complex 3D environment reconstruction. Furthermore, the low-dimensional environmental feature is generated by principal component analysis (PCA). From the measurements, the information of base station (BS) and the receiver (Rx), including 3D locations, frequency, transmitted power, angle information of antenna, and the received power of all the locations are obtained. The information of BS and Rx is combined with environmental features to form datasets for ANN training and testing. The training samples are randomly selected with different percentage from the formed datasets. The mean error, standard deviation and the prediction accuracy of BP networks are explored in the work, which will help researchers to carry out network planning and communication system design.","artificial neural network,environmental feature,principal component analysis,received power prediction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020),,
78,Cost-Sensitive Feature Selection using Particle Swarm Optimization: A Post-Processing Approach,,,97-101,"Ali Syed Imran,Khan Wajahat Ali,Lee Sungyoung,Lee Sang-Ho","Ali SI,Khan WA,Lee S,Lee SH",Ali SI,,Kyung Hee University,"Feature selection is one of the important tasks in machine learning. Feature selection task deals with selecting a subset of feature from an original feature set. An important consideration in feature selection is the usefulness of a feature i.e. a set of feature which is selected is neither irrelevant nor redundant. Most of the existing algorithms in the domain of feature selection are designed to optimize the aforementioned objective. In our research we have addressed a third dimension of usefulness i.e. cost of the feature. Cost-effectives of a solution is most apt in cases where there is an asymmetric cost of data acquisition such as medical diagnosis applications. In this regard, our research deals with enhancing the existing feature selection techniques with a post-processing stage in which cost consideration is also accounted for. The resultant solution is optimized for both important as well as cost-effective features. We have used particle swarm optimization with post processing over chronic kidney disease dataset for generating a feature subset set which is both salient and cost-effective.","Cost-sensitive Feature Selection,Particle Swarm Optimization,Post Processing,Data Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020),,
79,Evaluation of Feature Engineering on Wearable Sensor-based Fall Detection,,,110-114,"Ramachandran Anita,Ramesh Adarsh,Karuppiah Anupama","Ramachandran A,Ramesh A,Karuppiah A",Ramachandran A,,Birla Institute of Technology & Science Pilani (BITS Pilani),"Internet of Things (IoT) enabled geriatric healthcare systems have gained importance in the recent years due to an increase in the number of elderly people living alone. The application of machine learning (ML) in areas of geriatric healthcare such as fall detection, has, consequently been an area of active research. Wearable systems for fall detection has the advantage of being light-weight and low power-consuming, yet reasonably accurate without being overly intrusive. However, the accuracy of fall detection using wearable systems depends, among other factors, on the types of sensors embedded in them. The use of inertial motion unit (IMU) sensors for fall detection, combined with machine learning classifiers applied on datasets collected from IMU sensors is an area of active research. In this paper, we analyze the impact of using IMU sensor parameters in combination with vital signs parameters, on the performance of ML algorithms for fall detection. We compare the performance of various ML algorithms on the dataset we collected for this purpose. We also perform statistical analysis to examine the relative importance of the various features on the behavior of ML classifiers.","Fall detection,machine learning,wearable systems",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020),,
80,Fundamental band gap and alignment of two-dimensional semiconductors explored by machine learning,29,4,,",,,,","朱震,董宝娟,郭怀红,杨腾,张志东",,,Zhu Zhen,"Two-dimensional (2D) semiconductors isoelectronic to phosphorene have been drawing much attention recently due to their promising applications for next-generation (opt)electronics. This family of 2D materials contains more than 400 members, including (a) elemental group-V materials, (b) binary III-VII and IV-VI compounds, (c) ternary III-VI-VII and IV-V-VII compounds, making materials design with targeted functionality unprecedentedly rich and extremely challenging. To shed light on rational functionality design with this family of materials, we systemically explore their fundamental band gaps and alignments using hybrid density functional theory (DFT) in combination with machine learning. First, calculations are performed using both the Perdew-Burke-Ernzerhof exchange-correlation functional within the generalgradient- density approximation (GGA-PBE) and Heyd-Scuseria-Ernzerhof hybrid functional (HSE) as a reference. We find this family of materials share similar crystalline structures, but possess largely distributed band-gap values ranging approximately from 0 eV to 8 eV. Then, we apply machine learning methods, including linear regression (LR), random forest regression (RFR), and support vector machine regression (SVR), to build models for the prediction of electronic properties. Among these models, SVR is found to have the best performance, yielding the root mean square error (RMSE) less than 0.15 eV for the predicted band gaps, valence-band maximums (VBMs), and conduction-band minimums (CBMs) when both PBE results and elemental information are used as features. Thus, we demonstrate that the machine learning models are universally suitable for screening 2D isoelectronic systems with targeted functionality, and especially valuable for the design of alloys and heterogeneous systems.","two-dimensional semiconductors; ,machine learning",Article,,,,,,,,
81,OFF-eNET: An Optimally Fused Fully End-to-End Network for Automatic Dense Volumetric 3D Intracranial Blood Vessels Segmentation,29,,7192-7202,"Nazir Anam,Cheema Muhammad Nadeem,Sheng Bin,Li Huating,Li Ping,Yang Po,Jung Younhyun,Qin Jing,Kim Jinman,Feng David Dagan","Nazir A,Cheema MN,Sheng B,Li HT,Li P,Yang P,Jung YY,Qin J,Kim JM,Feng DD",Sheng B,10.1109/TIP.2020.2999854,Shanghai Jiao Tong University,"Intracranial blood vessels segmentation from computed tomography angiography (CTA) volumes is a promising biomarker for diagnosis and therapeutic treatment in cerebrovascular diseases. These segmentation outputs are a fundamental requirement in the development of automated decision support systems for preoperative assessment or intraoperative guidance in neuropathology. The state-of-the-art in medical image segmentation methods are reliant on deep learning architectures based on convolutional neural networks. However, despite their popularity, there is a research gap in the current deep learning architectures optimized to address the technical challenges in blood vessel segmentation. These challenges include: (i) the extraction of concrete brain vessels close to the skull; and (ii) the precise marking of the vessel locations. We propose an Optimally Fused Fully end-to-end Network (OFF-eNET) for automatic segmentation of the volumetric 3D intracranial vascular structures. OFF-eNET comprises of three modules. In the first module, we exploit the up-skip connections to enhance information flow, and dilated convolution for detailed preservation of spatial feature map that are designed for thin blood vessels. In the second module, we employ residual mapping along with inception module for speedy network convergence and richer visual representation. For the third module, we make use of the transferred knowledge in the form of cascaded training strategy to gradually optimize the three segmentation stages (basic, complete, and enhanced) to segment thin vessels located close to the skull. All these modules are designed to be computationally efficient. Our OFF-eNET, evaluated using 70 CTA image volumes, resulted in 90.75% performance in the segmentation of intracranial blood vessels and outperformed the state-of-the-art counterparts.","Image segmentation,Three-dimensional displays,Biomedical imaging,Convolution,Blood vessels,Computer architecture,Feature extraction,Convolution neural network,computed tomography angiography,dilated convolution,inception module,up-skip connection,intracranial vessels segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,,IEEE TRANSACTIONS ON IMAGE PROCESSING,https://eprints.whiterose.ac.uk/161477/1/FINAL%20%281%29.pdf,
82,Automated Gleason grading of prostate cancers via deep learning in label-free multiphoton microscopic images,11244,,,"Cai Jianyong,Yang Qinqin,Xu Zhexin,Chen Hong,Zhu Xiaoqin","Cai JY,Yang QQ,Xu ZX,Chen H,Zhu XQ",Zhu XQ,10.1117/12.2545881,Fujian Normal University,"In the current clinical care, Gleason grading system based on the architectural pattern of cancerous epithelium in histological images is the most powerful prognostic predictor for prostate cancers (PCa). However, the standard procedure of histological examination often includes complicated tissue fixation and staining, which are time-consuming and may delay the diagnosis and surgery. In this study, the unstained prostate tissues were investigated with multi-photon microscopy (MPM) to produce subcellular-resolution images. And then, a deep learning network (AlexNet) was introduced for automated Gleason grading. We achieved an average accuracy of Gleason grading of 78.1%+/- 3.4% for classification. And the area under the curve (AUC) in test set achieves 0.943 which indicates that the proposed model is effective in Gleason grading. At the end, the heat map was performed to visualize the Gleason score of tumour. Our results suggested that MPM, combined with deep learning method, holds the potential to be used as a real-time clinical diagnostic tool for PCa diagnosis.","Multiphoton microscopy,prostate cancer,Gleason grading,Gleason score,deep learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Microscopy,Optics",,,"CONVOLUTIONAL,NEURAL-NETWORKS,HISTOPATHOLOGY,INTEROBSERVER,STAIN",,,
83,Instance segmentation of immune cells in human lupus nephritis using deep learning: Comparing performance on sample preparation and staining panels,11243,,,"Durkee Madeleine S.,Abraham Rebecca,Sibley Adam,Cifu Benjamin,Ai Junting,Liarski Vladimir M.,Clark Marcus R.,Giger Maryellen L.","Durkee MS,Abraham R,Sibley A,Cifu B,Ai JT,Liarski VM,Clark MR,Giger ML",Durkee MS,10.1117/12.2545110,University of Chicago,"Computer vision and deep learning are integral tools in the improvement of high-throughput analysis of cellular images. Specifically, optimization of algorithms for object detection and instance segmentation tasks are important in cellular image analysis to segment and classify multi-object, multi-class images. In this work, we employ an instance segmentation pipeline with Mask RCNN, using a ResNet-101 and Feature Pyramid Network convolutional backbone to segment and classify T cells and antigen presenting cells (APCs) in multi-channel fluorescence confocal images of lupus nephritis biopsies. This task was first performed on a dataset of fresh frozen biopsies stained for T cells (CD3 and CD4) and two APC populations: 1) myeloid dendritic cells (BDCA1 and CD11c), and 2) plasmacytoid dendritic cells (BDCA2 and CD123). The network achieved an average sensitivity of 0.82, specificity of 0.91, and Jaccard index of 0.79 across all cell types. However, relative to fresh frozen tissue, samples prepared through formalin fixation and paraffin embedding (FFPE) provide larger potential datasets for investigating immune activity. Training this same network architecture on an FFPE database of lupus nephritis tissue stained with the same antibody panel, the network achieved an average sensitivity of 0.82, specificity of 0.92, and Jaccard index of 0.77 across all cell types. In addition to working with FFPE tissue, it would also be beneficial to identify APCs with a single stain and image more cell types with a single staining panel. We have trained this network on a single-stained APC panel FFPE dataset to achieve an average sensitivity of 0.79, specificity of 0.86, and Jaccard index of 0.63 across all cell types. These three trained networks were used to assess differences in cell shape features between fixation and staining protocols.","Instance segmentation,high-throughput image analysis,deep learning,immunology",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Cell Biology,Microscopy,Optics",,,,,,
84,AN OVERVIEW OF HEAT TRANSFER ENHANCEMENT LITERATURE IN 2019,51,9,807-824,"Guo Zhixiong,Tao Yong X.,Nan Yi,Zhang Hang,Huang Xu,Cao Hongxiang,Min Jue,Cai Yaomin,Hao Yihua,Tang Nai-Jei","Guo ZX,Tao YX,Nan Y,Zhang H,Huang X,Cao HX,Min J,Cai YM,Hao YH,Tang NJ",Guo ZX,10.1615/HeatTransRes.2020033880,Rutgers State University New Brunswick,"Advances in modern technology with increasing power density call for new technologies of heat transfer enhancement. This article briefly reviews archival journal literature on enhanced heat transfer research and development published in 2019 in the English language. Since a large number of articles were published, the selected studies are focused and grouped into conduction, convection, radiation, phase-change materials energy storage, and high-performance heat exchange devices. The methodologies for enhancing convective heat transfer are further categorized into passive, active, and compound techniques. The review on heat conduction focuses on the micro/nanoscale aspects, interfaces and high-conductivity carbon materials. The emphasis of thermal radiation is on near-field radiation, solar energy, and metamaterial. Recent progress in applying machine learning to enhanced heat transfer research in nanofluids, solar energy, and heat exchangers is also discussed.","enhanced heat transfer,conduction,convection,radiation,energy,nanoscale,nanofluid,interface,machine learning",Article,"BEGELL HOUSE INC, 50 NORTH ST, DANBURY, CT 06810 USA",Thermodynamics,,1.49,"PHASE-CHANGE,MATERIALS,THERMAL-ENERGY-STORAGE,FORCED-CONVECTION,FLOW,TRANSFER,PERFORMANCE,NUMERICAL-ANALYSIS,THERMOHYDRAULIC,PERFORMANCE,CARBON,NANOTUBES,PRESSURE-DROP,CONDUCTIVITY,ENHANCEMENT,ENTROPY,GENERATION",HEAT TRANSFER RESEARCH,,
85,Unclonable photonic keys hardened against machine learning attacks,5,1,,"Bosworth Bryan T.,Atakhodjaev Iskandar A.,Kossey Michael R.,Grubel Brian C.,Vresilovic Daniel S.,Stroud Jasper R.,MacFarlane Neil,Villalba Jesus,Dehak Najim,Cooper A. Brinton","Bosworth BT,Atakhodjaev IA,Kossey MR,Grubel BC,Vresilovic DS,Stroud JR,MacFarlane N,Villalba J,Dehak N,Cooper AB",Bosworth BT,10.1063/1.5100178,Johns Hopkins University,"The hallmark of the information age is the ease with which information is stored, accessed, and shared throughout the globe. This is enabled, in large part, by the simplicity of duplicating digital information without error. Unfortunately, an ever-growing consequence is the global threat to security and privacy enabled by our digital reliance. Specifically, modern secure communications and authentication suffer from formidable threats arising from the potential for copying of secret keys stored in digital media. With relatively little transfer of information, an attacker can impersonate a legitimate user, publish malicious software that is automatically accepted as safe by millions of computers, or eavesdrop on countless digital exchanges. To address this vulnerability, a new class of cryptographic devices known as physical unclonable functions (PUFs) are being developed. PUFs are modern realizations of an ancient concept, the physical key, and offer an attractive alternative for digital key storage. A user derives a digital key from the PUF's physical behavior, which is sensitive to physical idiosyncrasies that are beyond fabrication tolerances. Thus, unlike conventional physical keys, a PUF cannot be duplicated and only the holder can extract the digital key. However, emerging machine learning (ML) methods are remarkably adept at learning behavior via training, and if such algorithms can learn to emulate a PUF, then the security is compromised. Unfortunately, such attacks are highly successful against conventional electronic PUFs. Here, we investigate ML attacks against a nonlinear silicon photonic PUF, a novel design that leverages nonlinear optical interactions in chaotic silicon microcavities. First, we investigate these devices' resistance to cloning during fabrication and demonstrate their use as a source of large volumes of cryptographic key material. Next, we demonstrate that silicon photonic PUFs exhibit resistance to state-of-the-art ML attacks due to their nonlinearity and finally validate this resistance in an encryption scenario. (C) 2020 Author(s).",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Optics,Physics",,5.27,,APL PHOTONICS,https://aip.scitation.org/doi/pdf/10.1063/1.5100178,
86,Modeling of CCT diagrams for tool steels using different machine learning techniques,171,,,"Geng Xiaoxiao,Wang Hao,Xue Weihua,Xiang Song,Huang Hailiang,Meng Li,Ma Guang","Geng XX,Wang H,Xue WH,Xiang S,Huang HL,Meng L,Ma G",Wang H,10.1016/j.commatsci.2019.109235,University of Science & Technology Beijing,"Continuous cooling transformation (CCT) diagram is an important basis to make an optimal heat treatment process of steels with a desired microstructure and properties. Therefore, it is of great practical importance to predict the CCT diagram rapidly and accurately, especially for costly and time-consuming material design by trial and error. In this study, machine learning approaches are provided to predict CCT diagrams of tool steels using relevant material descriptors including the chemical compositions, austenitizing temperature and cooling rate. Different machine learning techniques including the Multilayer Perceptron Regressor, k-Nearest Neighbours, Bagging and Random Forest are performed on experimental dataset for appropriate model selecting. Random forest is proved to be the best model to predict pearlite transition temperature and martensite transformation start temperature accurately. K-Nearest Neighbours and Bagging are suitable for predicting the start and end temperatures of bainite formation respectively. These optimal models are then used to predict the CCT diagrams of T8, 6CrW2Si, 4CrMoV, CrMn and Cr12W. Comparing with the calculation results by the commercial software JMatPro, these optimal models work much better for their distinguished prediction performance with high correlation coefficient and low error values, which is thus of great engineering significance.","Continuous cooling transformation,Tool steel,JMatPro",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"TRANSFORMATION,PREDICTION",COMPUTATIONAL MATERIALS SCIENCE,,
87,Structure prediction of multi-principal element alloys using ensemble learning,37,3,1003-1022,"Choudhury Amitava,Konnur Tanmay,Chattopadhyay P. P.,Pal Snehanshu","Choudhury A,Konnur T,Chattopadhyay PP,Pal S",Pal S,10.1108/EC-04-2019-0151,National Institute of Technology (NIT System),"Purpose
The purpose of this paper, is to predict the various phases and crystal structure from multi-component alloys. Nowadays, the concept and strategies of the development of multi-principal element alloys (MPEAs) significantly increase the count of the potential candidate of alloy systems, which demand proper screening of large number of alloy systems based on the nature of their phase and structure. Experimentally obtained data linking elemental properties and their resulting phases for MPEAs is profused; hence, there is a strong scope for categorization/classification of MPEAs based on structural features of the resultant phase along with distinctive connections between elemental properties and phases.
Design/methodology/approach
In this paper, several machine-learning algorithms have been used to recognize the underlying data pattern using data sets to design MPEAs and classify them based on structural features of their resultant phase such as single-phase solid solution, amorphous and intermetallic compounds. Further classification of MPEAs having single-phase solid solution is performed based on crystal structure using an ensemble-based machine-learning algorithm known as random-forest algorithm.
Findings
The model developed by implementing random-forest algorithm has resulted in an accuracy of 91 per cent for phase prediction and 93 per cent for crystal structure prediction for single-phase solid solution class of MPEAs. Five input parameters are used in the prediction model namely, valence electron concentration, difference in the pauling negativeness, atomic size difference, mixing enthalpy and mixing entropy. It has been found that the valence electron concentration is the most important feature with respect to prediction of phases. To avoid overfitting problem, fivefold cross-validation has been performed. To understand the comparative performance, different algorithms such as K-nearest Neighbor, support vector machine, logistic regression, naive-based approach, decision tree and neural network have been used in the data set.
Originality/value
In this paper, the authors described the phase selection and crystal structure prediction mechanism in MPEA data set and have achieved better accuracy using machine learning.","Machine learning,Random forest,Multi-principal element alloys,High entropy alloy,Phase prediction,Structure prediction",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND","Computer Science,Engineering,Mathematics,Mechanics",,1.442,"HIGH-ENTROPY,ALLOYS,SUPPORT,VECTOR,MACHINE,BULK,METALLIC,GLASSES,SOLID-SOLUTION,PHASE,CRYSTALLIZATION,BEHAVIOR,RECENT,PROGRESS,RANDOM,FOREST,MICROSTRUCTURE,CO,CLASSIFICATION",ENGINEERING COMPUTATIONS,,
88,Automatic Pancreas Segmentation via Coarse Location and Ensemble Learning,8,,2906-2914,"Liu Shangqing,Yuan Xinrui,Hu Runyue,Liang Shujun,Feng Shaohua,Ai Yuhua,Zhang Yu","Liu SQ,Yuan XR,Hu RY,Liang SJ,Feng SH,Ai YH,Zhang Y",Ai YH; Zhang Y,10.1109/ACCESS.2019.2961125,Southern Medical University - China,"Automatic and reliable segmentation of the pancreas is an important but difficult task for various clinical applications, such as pancreatic cancer radiotherapy and computer-aided diagnosis (CAD). The main challenges for accurate CT pancreas segmentation lie in two aspects: (1) large shape variation across different patients, and (2) low contrast and blurring around the pancreas boundary. In this paper, we propose a two-stage, ensemble-based fully convolutional neural network (FCN) to solve the challenging pancreas segmentation problem in CT images. First, candidate region generation is performed by classifying patches generated by superpixels. Second, five FCNs based on the U-Net architecture are trained with different objective functions. For each network, 2.5D slices are used as the input to provide 3D image information complementarily without the need for computationally expensive 3D convolutions. Then, an ensemble model is utilized to combine the five output segmentation maps and achieve the final segmentation. The proposed method is extensively evaluated on a publicly available dataset of 82 manually segmented CT volumes via 4-fold cross-validation. Experimental results show its superior performance compared with several state-ofthe-art methods with a Dice coefficient of 84.10 +/- 4.91% and Jaccard coefficient of 72.86 +/- 6.89%.","Superpixel,ResNet,fully convolutional neural networks,ensemble learning,pancreas segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ABDOMINAL,MULTIORGAN,SEGMENTATION,NEURAL-NETWORK,LOCALIZATION",IEEE ACCESS,https://doi.org/10.1109/access.2019.2961125,
89,A Novel Deep Learning Pipeline for Retinal Vessel Detection In Fluorescein Angiography,29,,6561-6573,"Ding Li,Bawany Mohammad H.,Kuriyan Ajay E.,Ramchandran Rajeev S.,Wykoff Charles C.,Sharma Gaurav","Ding L,Bawany MH,Kuriyan AE,Ramchandran RS,Wykoff CC,Sharma G",Sharma G,10.1109/TIP.2020.2991530,University of Rochester,"While recent advances in deep learning have significantly advanced the state of the art for vessel detection in color fundus (CF) images, the success for detecting vessels in fluorescein angiography (FA) has been stymied due to the lack of labeled ground truth datasets. We propose a novel pipeline to detect retinal vessels in FA images using deep neural networks (DNNs) that reduces the effort required for generating labeled ground truth data by combining two key components: cross-modality transfer and human-in-the-loop learning. The cross-modality transfer exploits concurrently captured CF and fundus FA images. Binary vessels maps are first detected from CF images with a pre-trained neural network and then are geometrically registered with and transferred to FA images via robust parametric chamfer alignment to a preliminary FA vessel detection obtained with an unsupervised technique. Using the transferred vessels as initial ground truth labels for deep learning, the human-in-the-loop approach progressively improves the quality of the ground truth labeling by iterating between deep-learning and labeling. The approach significantly reduces manual labeling effort while increasing engagement. We highlight several important considerations for the proposed methodology and validate the performance on three datasets. Experimental results demonstrate that the proposed pipeline significantly reduces the annotation effort and the resulting deep learning methods outperform prior existing FA vessel detection methods by a significant margin. A new public dataset, RECOVERY-FA19, is introduced that includes high-resolution ultra-widefield images and accurately labeled ground truth binary vessel maps.","Pipelines,Deep learning,Retinal vessels,Angiography,Training,Annotations,Fluorescein angiography,generative adversarial networks,vessel detection,retinal image analysis,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"BLOOD-VESSELS,SEGMENTATION,MORPHOLOGY,IMAGES",IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1907.02946,
90,Three Dimensional Root CT Segmentation Using Multi-Resolution Encoder-Decoder Networks,29,,6667-6679,"Soltaninejad Mohammadreza,Sturrock Craig J.,Griffiths Marcus,Pridmore Tony P.,Pound Michael P.","Soltaninejad M,Sturrock CJ,Griffiths M,Pridmore TP,Pound MP",Pound MP,10.1109/TIP.2020.2992893,"Univ Nottingham Jubilee Campus, Sch Comp Sci, Nottingham NG8 1BB, England.","We address the complex problem of reliably segmenting root structure from soil in X-ray Computed Tomography (CT) images. We utilise a deep learning approach, and propose a state-of-the-art multi-resolution architecture based on encoder-decoders. While previous work in encoder-decoders implies the use of multiple resolutions simply by downsampling and upsampling images, we make this process explicit, with branches of the network tasked separately with obtaining local high-resolution segmentation, and wider low-resolution contextual information. The complete network is a memory efficient implementation that is still able to resolve small root detail in large volumetric images. We compare against a number of different encoder-decoder based architectures from the literature, as well as a popular existing image analysis tool designed for root CT segmentation. We show qualitatively and quantitatively that a multi-resolution approach offers substantial accuracy improvements over a both a small receptive field size in a deep network, or a larger receptive field in a shallower network. We then further improve performance using an incremental learning approach, in which failures in the original network are used to generate harder negative training examples. Our proposed method requires no user interaction, is fully automatic, and identifies large and fine root material throughout the whole volume.","Image segmentation,Computed tomography,Soil,Image resolution,Decoding,Three-dimensional displays,Biomedical imaging,X-ray computed tomography,image segmentation,deep learning,root system analysis,plant phenotyping",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"ARCHITECTURE,SOFTWARE",IEEE TRANSACTIONS ON IMAGE PROCESSING,https://nottingham-repository.worktribe.com/4625445/1/Three Dimensional Root CT Segmentation using Multi-Resolution Encoder-Decoder Networks,
91,Multi-Atlas Brain Parcellation Using Squeeze-and-Excitation Fully Convolutional Networks,29,,6864-6872,"Tang Zhenyu,Liu Xianli,Li Yang,Yap Pew-Thian,Shen Dinggang","Tang ZY,Liu XL,Li Y,Yap PT,Shen DG",Shen DG,10.1109/TIP.2020.2994445,University of North Carolina,"Multi-atlas parcellation (MAP) is carried out on a brain image by propagating and fusing labelled regions from brain atlases. Typical nonlinear registration-based label propagation is time-consuming and sensitive to inter-subject differences. Recently, deep learning parcellation (DLP) has been proposed to avoid nonlinear registration for better efficiency and robustness than MAP. However, most existing DLP methods neglect using brain atlases, which contain high-level information (e.g., manually labelled brain regions), to provide auxiliary features for improving the parcellation accuracy. In this paper, we propose a novel multi-atlas DLP method for brain parcellation. Our method is based on fully convolutional networks (FCN) and squeeze-and-excitation (SE) modules. It can automatically and adaptively select features from the most relevant brain atlases to guide parcellation. Moreover, our method is trained via a generative adversarial network (GAN), where a convolutional neural network (CNN) with multi-scale l(1) loss is used as the discriminator. Benefiting from brain atlases, our method outperforms MAP and state-of-the-art DLP methods on two public image datasets (LPBA40 and NIREP-NAO).","Brain parcellation,fully convolutional networks,squeeze-and-excitation module,brain atlas selection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"DIFFEOMORPHIC,IMAGE,REGISTRATION,LABEL,FUSION,SEGMENTATION",IEEE TRANSACTIONS ON IMAGE PROCESSING,,
92,A Statistical Learning-Based Algorithm for Topology Verification in Natural Gas Networks Based on Noisy Sensor Measurements,15,,3653-3666,"Wang Zisheng,Blum Rick S.","Wang ZS,Blum RS",Blum RS,10.1109/TIFS.2020.2998943,Lehigh University,"Accurate knowledge of natural gas network topology is critical for the proper operation of natural gas networks. Failures, physical attacks, and cyber attacks can cause the actual natural gas network topology to differ from what the operator believes to be present. Incorrect topology information misleads the operator to apply inappropriate control causing damage and lack of gas supply. Several methods for verifying the topology have been suggested in the literature for electrical power distribution networks, but we are not aware of any publications for natural gas networks. In this paper, we develop a useful topology verification algorithm for natural gas networks based on modifying a general known statistics-based approach to eliminate serious limitations for this application while maintaining good performance. We prove that the new algorithm is equivalent to the original statistics-based approach for a sufficiently large number of sensor observations. We provide new closed-form expressions for the asymptotic performance that are shown to be accurate for the typical number of sensor observations required to achieve reliable performance.","Topology,Network topology,Pipelines,Natural gas,Electric variables measurement,Noise measurement,Mathematical model,Natural gas networks,generalized likelihood ratio test,semidefinite relaxation programming,asymptotic performance",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,7.273,"SEMIDEFINITE,RELAXATION,BOUNDS",IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY,http://arxiv.org/pdf/2004.01087,
93,Deep Model-Based Semi-Supervised Learning Way for Outlier Detection in Wireless Capsule Endoscopy Images,8,,81621-81632,"Gao Yan,Lu Weining,Si Xiaobei,Lan Yu","Gao Y,Lu WN,Si XB,Lan Y",Lan Y,10.1109/ACCESS.2020.2991115,"Beijing Jishuitan Hosp, Dept Gastroenterol, Beijing 100035, Peoples R China.","Wireless capsule endoscopy (WCE) has become an irreplaceable tool for diagnosing small intestinal diseases, and detecting the outliers in WCE images automatically remains as a hot research topic. Considering the difficulties in obtaining sufficient labeled WCE data, it is necessary to develop the diagnosis model which works well with only little labeled or even unlabeled training samples. In this paper, a novel semi-supervised deep-structured framework is introduced to solve the problem of outlier detection in WCE images. The key idea of our model is to mine the anomalous graphical patterns existed in the image by analyzing the spatial-scale trends of sequential image regions. Three main contributions are concluded: 1) we integrate a convolutional neural network into long short term memory network, so that the intrinsic differences between outliers and normal instances could be captured. Besides, 2) a assessment model is built by using various signs of anomaly occurrence and fake outliers knowledge learned during the training stage, which enhances the outlier alarm accuracy significantly. Furthermore, 3) a nest-structured training method is proposed, which helps our model achieving efficient training process. Experimental results on the real WCE images demonstrate the effectiveness of our model.","Convolutional neural network,long short term memory network,outlier detection,semi-supervised,wireless capsule endoscopy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,FAULT-DETECTION,IEEE ACCESS,https://doi.org/10.1109/access.2020.2991115,
94,Forecasting of Wood Moisture Content Based on Modified Ant Colony Algorithm to Optimize LSSVM Parameters,8,,85116-85127,"Li Jicheng,Sun Liping","Li JC,Sun LP",Sun LP,10.1109/ACCESS.2020.2991889,Northeast Forestry University - China,"Wood moisture content (WMC) is an important technical index used in the wood drying process, and assessing its change accurately and reliably is the key to improving wood drying quality. In order to improve the accuracy and reliability of WMC forecasting, a modeling method is proposed that uses a modified ant colony algorithm (MACA) to optimize the least square support vector machine (LSSVM). The MACA combines the large-step size global search with the small-step size local fine search to obtain the optimal parameter combination automatically and are tested by five standard functions. Then the MACA-LSSVM model is proposed to predict the WMC and compared with back propagation neural network (BP-NN), LSSVM model, and ant colony optimization LSSVM (ACO-LSSVM). The drying data from a small-sized wood drying kiln independently developed by Northeast Forestry University are taken as the samples for analyzing. The results indicate that the root mean square relative error (RMSRE) obtained by the proposed method (MACA-LSSVM) is only 1.82%, which is 0.77%, 0.50%, and 0.20% less than those of the BP-NN, LSSVM, and ACO-LSSVM models. The forecasting time are 0.0070 s, 0.0030 s, and 0.0010 s shorter, respectively. The relative error (RE) and the mean absolute error (MAE) are also lower than those of the latter three models. The MACA-LSSVM shows the characteristics of low computational complexity, fast convergence speed, high prediction accuracy and strong generalization ability, and the prediction effect is ideal. This model can provide the theoretical support for intelligent control of the wood drying process.","Ant colony algorithm,least square support vector machine,parameter optimization,wood moisture content",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SUPPORT,VECTOR,MACHINE,GENETIC,ALGORITHMS,SIMULATION,SELECTION,SEARCH",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09085362.pdf,
95,SCCNN: A Diagnosis Method for Hepatocellular Carcinoma and Intrahepatic Cholangiocarcinoma Based on Siamese Cross Contrast Neural Network,8,,85271-85283,"Wang Qiyuan,Wang Zhongmin,Sun Yu,Zhang Xin,Li Weifeng,Ge Yun,Huang Xiaolin,Liu Yun,Chen Ying","Wang QY,Wang ZM,Sun Y,Zhang X,Li WF,Ge Y,Huang XL,Liu Y,Chen Y",Ge Y; Chen Y,10.1109/ACCESS.2020.2992627,Nanjing University,"This paper proposes a novel siamese cross contrast neural network (SCCNN) to classify the hepatocellular carcinoma (HCC) and the intrahepatic cholangiocarcinoma (ICC) on computed tomography (CT) images. This method is inspired from cross contrast neural networks (CCNN) which is based on tailored CNN and information based similarity(IBS) theory. A new IBS-based measurement named as discriminative IBS(DisIBS) is designed for SCCNN. SCCNN is composed of two main parts including siamese feature extractors with DisIBS operator and MLP classifiers. Siamese networks extract features with DisIBS calculated by DisIBS operator as metric at the top. MLP classifiers are connected with but gradient-stop to feature extractors deriving classification results. We assign different loss functions with different parts to make better practice, specially DisIBS-based loss for feature extractors and softmax-based for MLP classifiers. SCCNN preserves the advantages of CCNN that can fit the insufficient medical images and small lesions. Furthermore, it extends CCNN with the siamese mechanism and gradient-stop MLP classifiers to accept the random inputs and predict like traditional CNN. To present the effectiveness of SCCNN empirically, we apply this method on a 234-person (157/77 for train/test) dataset and achieve better results than other classic CNN and CCNN methods. We try different base models of siamese structures and display prediction accuracy in two levels (slice/patient). The highest slice/patient accuracy which we have achieved on three-categories classification (HCC/ICC/Normal) is 90.22%/94.92% and the accuracy rises to 94.17%/97.44% on binary classification(HCC/ICC).","Siamese networks,multiple loss,cross contrast neural networks,hepatocellular carcinoma,intrahepatic cholangiocarcinoma",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CANCER,STATISTICS,CLASSIFICATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09086453.pdf,
96,Cuffless Blood Pressure Estimation Using Single Channel Photoplethysmography: A Two-Step Method,8,,58146-58154,"Khalid Syed Ghufran,Liu Haipeng,Zia Tahir,Zhang Jufen,Chen Fei,Zheng Dingchang","Khalid SG,Liu HP,Zia T,Zhang JF,Chen F,Zheng DC",Khalid SG; Zheng DC,10.1109/ACCESS.2020.2981903,Coventry University,"Traditional cuff-based blood pressure (BP) monitoring procedure causes inconvenience and discomfort to the users. To overcome these limitations, cuffless BP estimation based on pulse transit time (PTT) and single-channel photoplethysmography (PPG) has been proposed. However, existing studies based on PTT and PPG for BP estimation did not achieve AAMI/ISO standard criteria for BP measurement (mean difference within +/- 5mmHg and SD of difference within +/- 8mmHg) under each BP category (Hypotensive, Normotensive and Hypertensive). This study aims to validate an innovative two-step method for PPG-based cuffless BP estimation. A combined database was derived from two online databases (Queensland and MIMIC II) to cover a wide range of corresponding BPs. In total, there were 18010 raw PPG signal segments (5 seconds for each) with corresponding BPs, separated into two halves for training and testing of algorithms (independent datasets). Each PPG signal segment was pre-processed to extract 16 signal features. Later, three significant features have been selected using multicollinearity test. The traditional generic (trained with uncategorized BP) algorithm and two-step algorithm (specifically optimized for each BP category) were developed using machine learning. Generally, the two-step algorithm achieved the AAMI/ISO standard in estimating systolic BP (mean +/- SD: 0.07 +/- 7.1 mmHg, p<0.001) and diastolic BP (-0.08 +/- 6.0 mmHg, p<0.001). Categorically, the two-step method also achieved standard accuracy in all BP categories except Hypotensive systolic BP whereas generic algorithm did not conform to standard accuracy in any BP category except Hypotensive diastolic BP and Normotensive categories. Compared to the traditional generic algorithm, the two-step algorithm specifically designed for three different BP category patients and achieved standard accuracy for cuffless BP estimation.","Cuffless BP,pulse transit time,Photoplethysmography & categorical BP estimation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://arro.anglia.ac.uk/id/eprint/705377/6/Khalid_et_al_2020.pdf,
97,Cascade U-ResNets for Simultaneous Liver and Lesion Segmentation,8,,68944-68952,"Xi Xue-Feng,Wang Lei,Sheng Victor S.,Cui Zhiming,Fu Baochuan,Hu Fuyuan","Xi XF,Wang L,Sheng VS,Cui ZM,Fu BC,Hu FY",Sheng VS,10.1109/ACCESS.2020.2985671,Texas Tech University System,"In recent years, several deep learning networks are proposed to segment 2D or 3D bio-medical images. However, in liver and lesion segmentation, the proportion of interested tissues and lesions are tiny when contrasting to the image background. That is, the objects to be segmented are highly imbalanced in terms of the frequency of occurrences. This makes existing deep learning networks prone to predict pixels of livers and lesions as background. To address this imbalance issue, several loss functions are proposed. Since no researches are having made a comparison among those proposed loss functions, we are curious about that which loss function is the best among them? At the same time, we also want to investigate whether the combination of several different loss functions is effective for liver and lesion segmentation. Firstly, we propose a novel deep learning network (cascade U-ResNets) to produce liver and lesion segmentation simultaneously. Then, we investigate the performance of 5 selected loss functions, WCE (Weighted Cross Entropy), DL (Dice Loss), WDL (Weighted Dice Loss), TL (Teverskry Loss), WTL (Weighted Teversky Loss), with our cascade U-ResNets. We further assemble all cascade U-ResNets trained with different loss functions together to segment livers and lesions jointly on the liver CT (Computed Tomography) volume. Experimental results on the LiTS dataset(1) showed our ensemble model can achieve much better results than every individual model for liver segmentation.","Data imbalance,deep learning,ensemble learning,lesion segmentation,liver segmentation,medical image segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,NETWORK,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09057545.pdf,
98,Deep Learning Cross-Phase Style Transfer for Motion Artifact Correction in Coronary Computed Tomography Angiography,8,,81849-81863,"Jung Sunghee,Lee Soochahn,Jeon Byunghwan,Jang Yeonggul,Chang Hyuk-Jae","Jung S,Lee S,Jeon B,Jang Y,Chang HJ",Jung S,10.1109/ACCESS.2020.2991445,Yonsei University,"Motion artifacts may occur in coronary computed tomography angiography (CCTA) due to the heartbeat and impede the clinician & x2019;s diagnosis of coronary arterial diseases. Thus, motion artifact correction of the coronary artery is required to quantify the risk of disease more accurately. We present a novel method based on deep learning for motion artifact correction in CCTA. Because the image of the coronary artery without motion (the ground-truth data required in supervised deep learning) is medically unattainable, we apply a style transfer method to 2D image patches cropped from full-phase 4D computed tomography (CT) to synthesize these images. We then train a convolutional neural network (CNN) for motion artifact correction using this synthetic ground-truth (SynGT). During testing, the output motion-corrected 2D image patches of the trained network are reinserted into the 3D CT volume with volumetric interpolation. The proposed method is evaluated using both phantom and clinical data. A phantom study demonstrates comparable results to other methods in quantitative performance and outperforms those methods in computation time. For clinical data, a quantitative analysis based on metric measurements is presented that confirms the correction of motion artifacts. Moreover, an observer study finds that by applying the proposed method, motion artifacts are markedly reduced, and boundaries of the coronary artery are much sharper, with a strong inter-observer agreement ($\kappa = 0.78$ ). Finally, evaluations using commercial software on the original and resulting CT volumes of the proposed method reveal a considerable increase in tracked coronary artery length.","Computed tomography,deep learning,image restoration,motion correction and analysis,coronary angiography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE,QUALITY,HEART-RATE,COMPENSATION",IEEE ACCESS,https://ir.ymlib.yonsei.ac.kr/bitstream/22282913/183814/1/T202007100.pdf,
99,Robust Multimodal Heartbeat Detection Using Hybrid Neural Networks,8,,82201-82214,"Schwob Michael R.,Dempsey Aeren,Zhan Felix,Zhan Justin,Mehmood Asif","Schwob MR,Dempsey A,Zhan F,Zhan J,Mehmood A",Zhan J,10.1109/ACCESS.2020.2990607,University of Arkansas System,"Many arrhythmia datasets are multimodal due to the simultaneous collection of physiological signals of a subject. These datasets frequently have missing modalities or missing block-wise data, a characteristic that various recent applications of neural networks fail to consider. Most arrhythmic detection models only use electrocardiogram and blood pressure recordings. Unconsidered physiological signals may be strongly correlated with other modalities despite having missing data. To improve robustness and accuracy of heartbeat detection, all available modalities should be considered in multimodal arrhythmia datasets. Several hybrid neural networks are proposed to robustly analyze heartbeats by considering every available physiological signal. These networks combine elements from convolutional neural networks, recurrent neural networks, and a deep learning architecture. This enables researchers to analyze every signal of subjects while the set of signals collected among subjects may differ. The proposed hybrid neural networks provide more robust results in heartbeat detection when utilizing missing data modalities.","Multimodal,heartbeat detection,deep learning,neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,FUSION,FEATURES,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.2990607,
100,Automating the ABCD Rule for Melanoma Detection: A Survey,8,,83333-83346,"Ali Abder-Rahman H.,Li Jingpeng,Yang Guang","Ali ARH,Li JP,Yang G",Li JP,10.1109/ACCESS.2020.2991034,University of Stirling,"The ABCD rule is a simple framework that physicians, novice dermatologists and non-physicians can use to learn about the features of melanoma in its early curable stage, enhancing thereby the early detection of melanoma. Since the interpretation of the ABCD rule traits is subjective, different solutions have been proposed in literature to tackle such subjectivity and provide objective evaluations to the different traits. This paper reviews the main contributions in literature towards automating asymmetry, border irregularity, color variegation and diameter, where the different methods involved have been highlighted. This survey could serve as an essential reference for researchers interested in automating the ABCD rule.","Image processing,machine learning,melanoma detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"COMPUTER-AIDED,DIAGNOSIS,SKIN-LESION,SEGMENTATION,MALIGNANT-MELANOMA,BORDER,IRREGULARITY,DERMOSCOPIC,IMAGES,BOUNDARY,DETECTION,PIGMENTED,LESIONS,CLASSIFICATION,FEATURES,NEVI",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09079806.pdf,
