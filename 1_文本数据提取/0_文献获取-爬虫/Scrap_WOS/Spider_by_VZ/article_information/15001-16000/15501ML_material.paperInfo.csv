,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Early Detection of Parkinson's Disease Using Deep Learning and Machine Learning,8,,147635-147646,"Wang Wu,Lee Junho,Harrou Fouzi,Sun Ying","Wang W,Lee J,Harrou F,Sun Y",Harrou F,10.1109/ACCESS.2020.3016062,King Abdullah University of Science & Technology,"Accurately detecting Parkinson's disease (PD) at an early stage is certainly indispensable for slowing down its progress and providing patients the possibility of accessing to disease-modifying therapy. Towards this end, the premotor stage in PD should be carefully monitored. An innovative deep-learning technique is introduced to early uncover whether an individual is affected with PD or not based on premotor features. Specifically, to uncover PD at an early stage, several indicators have been considered in this study, including Rapid Eye Movement and olfactory loss, Cerebrospinal fluid data, and dopaminergic imaging markers. A comparison between the proposed deep learning model and twelve machine learning and ensemble learning methods based on relatively small data including 183 healthy individuals and 401 early PD patients shows the superior detection performance of the designed model, which achieves the highest accuracy, 96.45% on average. Besides detecting the PD, we also provide the feature importance on the PD detection process based on the Boosting method.","Machine learning,Parkinson's disease,Feature extraction,Biomarkers,Single photon emission computed tomography,Parkinson's disease,deep learning,ensemble learning,early detection,premotor features,features importance",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORKS,REGULARIZATION,QUESTIONNAIRE,PROGRESSION,PREDICTION,DIAGNOSIS,MODEL",IEEE ACCESS,https://repository.kaust.edu.sa/bitstream/10754/664603/1/Early%20detection.pdf,
2,Automated Detection and Classification of Oral Lesions Using Deep Learning for Early Detection of Oral Cancer,8,,132677-132693,"Welikala Roshan Alex,Remagnino Paolo,Lim Jian Han,Chan Chee Seng,Rajendran Senthilmani,Kallarakkal Thomas George,Zain Rosnah Binti,Jayasinghe Ruwan Duminda,Rimal Jyotsna,Kerr Alexander Ross","Welikala RA,Remagnino P,Lim JH,Chan CS,Rajendran S,Kallarakkal TG,Zain RB,Jayasinghe RD,Rimal J,Kerr AR",Welikala RA,10.1109/ACCESS.2020.3010180,Kingston University,"Oral cancer is a major global health issue accounting for 177,384 deaths in 2018 and it is most prevalent in low- and middle-income countries. Enabling automation in the identification of potentially malignant and malignant lesions in the oral cavity would potentially lead to low-cost and early diagnosis of the disease. Building a large library of well-annotated oral lesions is key. As part of the MeMoSA(R)(Mobile Mouth Screening Anywhere) project, images are currently in the process of being gathered from clinical experts from across the world, who have been provided with an annotation tool to produce rich labels. A novel strategy to combine bounding box annotations from multiple clinicians is provided in this paper. Further to this, deep neural networks were used to build automated systems, in which complex patterns were derived for tackling this difficult task. Using the initial data gathered in this study, two deep learning based computer vision approaches were assessed for the automated detection and classification of oral lesions for the early detection of oral cancer, these were image classification with ResNet-101 and object detection with the Faster R-CNN. Image classification achieved an F-1 score of 87.07% for identification of images that contained lesions and 78.30% for the identification of images that required referral. Object detection achieved an F-1 score of 41.18% for the detection of lesions that required referral. Further performances are reported with respect to classifying according to the type of referral decision. Our initial results demonstrate deep learning has the potential to tackle this challenging task.","Cancer,Lesions,Image classification,Machine learning,Cavity resonators,Image segmentation,Composite annotation,deep learning,image classification,object detection,oral cancer,oral potentially malignant disorders",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,IMAGES,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144177.pdf,
3,Multimodal Fused Emotion Recognition About Expression-EEG Interaction and Collaboration Using Deep Learning,8,,133180-133189,"Wu Di,Zhang Jianpei,Zhao Qingchao","Wu D,Zhang JP,Zhao QC",Zhang JP,10.1109/ACCESS.2020.3010311,Harbin Engineering University,"The proposed emotion recognition model is based on the hierarchical long-short term memory neural network (LSTM) for video-electroencephalogram (Video-EEG) signal interaction. The inputs are facial-video and EEG signals from the subjects when they are watching the emotion-stimulated video. The outputs are the corresponding emotion recognition results. Facial-video features and corresponding EEG features are extracted based on a fully connected neural network (FC) at each time point. These features are fused through hierarchical LSTM to predict the key emotional signal frames at the next time point until the emotion recognition result is calculated at the last time point. Specially, a self-attention mechanism is applied to show the correlation of the stacked LSTM at different hierarchies. In this process, the ""selective focus"" is used to analyze the human-emotional temporal sequences in each model, which improves the utilization of the key spatial EEG signals. Moreover, the process includes the temporal attention mechanism to predict the key signal frame at next time point, which utilizes the key emotion data in temporal domain. The experimental results prove that the classification rate (CR) and F1-score of the proposed emotion recognition model are significantly increased by at least 2% and 0.015, respectively, compared to other methods.","Emotion recognition,Electroencephalography,Feature extraction,Physiology,Brain modeling,Human computer interaction,Face,Emotion recognition,long-short term memory neural network,attention mechanism,multimodal signal fusion,electroencephalogram,time sequence",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,MACHINE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144198.pdf,
4,Elevating Prediction Performance for Mechanical Properties of Hot-Rolled Strips by Using Semi-Supervised Regression and Deep Learning,8,,134124-134136,"Wu Siwei,Yang Jian,Cao Guangming,Qiu Yunlong,Cheng Guoguang,Yao Meiyi,Dong Jianxin","Wu SW,Yang J,Cao GM,Qiu YL,Cheng GG,Yao MY,Dong JX",Yang J,10.1109/ACCESS.2020.3010506,Shanghai University,"In the present work, to solve the problem of the lacking enough labeled training data for deep learning, a safe semi-supervised regression supporting Bayesian optimization deep neural network (SAFER-BODNN) model was proposed to establish mechanical property prediction model of hot-rolled strips. The Pearson correlation coefficient was applied to reduce the data dimension. The safe semi-supervised regression was implemented to add the pseudo labels to the unlabeled data for training dataset expansion. The deep neural network was trained with Bayesian optimization to determine the optimal hyper-parameters of the network. The results show that the SAFER-BODNN model achieves good performance for mechanical property prediction of hot-rolled strips with correlation coefficient of 0.9610 for yield strength, 0.9682 for tensile strength, and 0.8619 for elongation, respectively. Compared with the deep neural network trained on the labeled dataset, the SAFER-BODNN model obtains stable smaller predicted errors. Among all the variables, C content and Mn content have large influence on the yield strength and tensile strength, coiling temperature has the largest influence on the elongation. The investigation makes full use of unlabeled data to elevate the prediction performance of the deep neural network, and also provides a way for deep learning modeling when the data are insufficient.","Mechanical factors,Data models,Predictive models,Training,Biological neural networks,Linear programming,Strips,Mechanical property,deep neural network,safe semi-supervised regression,Bayesian optimization,hot-rolled strips",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ARTIFICIAL,NEURAL-NETWORKS,MICROSTRUCTURE,EVOLUTION,STEEL,STRENGTH,SYSTEMS,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144570.pdf,
5,Heart Coronary Artery Segmentation and Disease Risk Warning Based on a Deep Learning Algorithm,8,,140108-140121,"Xiao Can,Li Yi,Jiang Yimin","Xiao C,Li Y,Jiang YM",Jiang YM,10.1109/ACCESS.2020.3010800,Shanghai Jiao Tong University,"This paper is based on an improved three-dimensional U-net convolutional neural network deep learning algorithm for heart coronary artery segmentation for disease risk prediction, and it is practical with multiple data sets under two backgrounds without centerline and with the centerline. By using a new local feature to extract the ventricular information, and using the deep belief network to extract the features to regress the contour coordinates of the biventricular. Combining features and deep belief networks and training regression networks can not only extract high-level information but also accurately divide the left and right ventricles at a small computational cost. The performance of segmentation based on the dice coefficient compared between the two datasets. The results show that the model training effect of the centerline preprocessing is superior to the original data. The experimental results show that the best effect reaches the dice coefficient of 0.8291. In the experiment, it found that simple data expansion may be detrimental to the test data. From the training curve, it is believed that with the improvement of the quality of training data, the performance of coronary artery segmentation can be further improved, and it is of great significance to provide doctors and patients with more accurate and efficient opinions and suggestions in clinical practice to improve the quality of diagnosis and treatment. The purpose of assisting experts in real-time diagnosis and analysis achieved.","Image segmentation,Diseases,Arteries,Biomedical imaging,Feature extraction,Machine learning,Heart,Deep learning,heart coronary artery,graph segmentation,disease risk warning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,FRAMELETS,NEURAL-NETWORK,VALIDATION,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09145586.pdf,
6,A Study on Wireless Capsule Endoscopy for Small Intestinal Lesions Detection Based on Deep Learning Target Detection,8,,159017-159026,"Xiao Zhiguo,Feng Li Nian","Xiao ZG,Feng LN",Feng LN,10.1109/ACCESS.2020.3019888,Changchun University,"Wireless capsule endoscope (WCE) has been verified in clinical medicine for many years. However, the detection process needs experienced doctors to read the film manually for a long time. In addition, the cost of the endoscope itself leads to a high cost of WCE detection and overall cycle is long. New research method based on deep learning technology with robustness and high accuracy can reduce the detection cost and benefit the public. According to the characteristics of small intestine lesion, a method focuses on labeling and feature detection which can optimize the process by analyzing small intestine WCE image and experimental comparison. Based on the YOLOv3 detection network, retaining the original basic feature of detection network, an improved one is further optimized and effectively verified. Finally, the redundant images are filtered out by comparing the Hash value of images, presenting the final concise detection results for doctors. Starting from image labeling, the design of deep learning network structure for the image of small intestine digestive tract endoscope is studied, which can effectively improve intelligent detection computer-aided clinical application of WCE, with higher accuracy and lower missing detection rate than manual detection.","Feature extraction,Lesions,Object detection,Intestines,Machine learning,Endoscopes,Detection network,wireless capsule endoscope,small intestine lesions,YOLOv3",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,TEXTURE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09178775.pdf,
7,A Novel Acoustic Emission Sources Localization and Identification Method in Metallic Plates Based on Stacked Denoising Autoencoders,8,,141123-141142,"Yang Li,Xu Feiyun","Yang L,Xu FY",Xu FY,10.1109/ACCESS.2020.3012521,Southeast University - China,"Nowadays, deep learning could be an alternative approach to crack characterization. However, to the best of the authors' knowledge, little research exists on a deep learning-based characterization of fatigue-related AE sources occurring in plate-like structures. Consequently, this paper introduces a stacked denoising autoencoders (SDAE)-based framework to localize acoustic emission (AE) sources in common and complex metallic panels. The experimental specimen are respectively a Q235B steel plate and a 316L stainless steel containing a laser cladding layer. Specifically, SDAE is pre-trained and utilized to localize AE sources that are simulated by using the classical pencil lead break (PLB) approach. Meanwhile, the number of layers and hidden nodes of SDAE used for coordinate-based location is optimized according to a Bayesian Information Criteria (BIC) approach. To validate the proposed network and simplify the analysis, experiments are carried out on the surface of plate-like structures, which only one sensor is applied. After identifying AE sources that occur near laser cladding layers, the proposed approach classifies them into four source-to-laser cladding layer distance categories. Particularly, a ten-fold cross-validation method is utilized to improve the accuracy of localization in this paper. Moreover, the effectiveness analysis to the number of sensors and comparison with conventional machine learning methods, including support vector machine (SVM) and artificial neural network (ANN), are also evaluated. In order to validate the performance of the proposed approach in terms of coordinate-based source localization. Ultimately, the results demonstrate that 100% accuracy for zonal localization, and the root mean squared (RMS) localization errors of two metallic panels are 38 mm (1.5"") and 48 mm (1.9""), respectively. Additionally, in comparison with conventional machine learning approaches (i.e. SVM and ANN) which the RMS errors were 78 mm (2.5"") and 67 mm (2.1""), respectively, the coordinates-based localization accuracy is significantly improved using the proposed approach. The results demonstrate the proposed approach is effective in AE-based structural health monitoring of plate-like structures with single-sensor.","Machine learning,Steel,Feature extraction,Signal processing algorithms,Lasers,Neural networks,Support vector machines,Acoustic emission (AE),sources localization and identification,stacked denoising autoencoders (SDAE),metallic steel plates,structural health monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DEEP,LEARNING,FRAMEWORK,HEALTH-ASSESSMENT,FAULT-DIAGNOSIS,DAMAGE,CLASSIFICATION,LUBRICATION,COMPOSITES,EVOLUTION,WEAR,TOOL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151142.pdf,
8,PGMM-Pre-Trained Gaussian Mixture Model Based Convolution Neural Network for Electroencephalography Imagery Analysis,8,,157418-157426,"Yu Ming,Zhang Guang,Li Qinwei,Chen Feng","Yu M,Zhang G,Li QW,Chen F",Chen F,10.1109/ACCESS.2020.3016481,"Inst Med Support Technol, Tianjin 300161, Peoples R China.","Electroencephalography (EEG) signal processing through imagery inputs using intelligent computation methods are practiced in the recent years for improving the accuracy of detecting neural disorders. Classification and analysis of the input imagery requires prior training and assisted error detection to improve the accuracy. In this article, pre-trained Gaussian mixture model (PGMM) is introduced for improving the accuracy of EEG signal imagery analysis. The proposed model relies on deep learning classifiers for analyzing the imagery using pixel based segmentation through pre-training models. The errors in classification are identified through recurrent convolution neural network training process as aided by the extracted features. Based on the pre-trained feature assessment, the false positive errors are mitigated to achieve a better accuracy (92%) under controlled classification time and high true positives.","Electroencephalography,Feature extraction,Brain modeling,Training,Machine learning,Image segmentation,Gaussian mixture model,Convolutional neural network,EEG,feature extraction,imagery analysis,learning classifier",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EEG,SIGNALS,CLASSIFICATION,DECOMPOSITION",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016481,
9,Detecting Noisy ECG QRS Complexes Using WaveletCNN Autoencoder and ConvLSTM,8,,143802-143817,"Yuen Brosnan,Dong Xiaodai,Lu Tao","Yuen B,Dong XD,Lu T",Dong XD; Lu T,10.1109/ACCESS.2020.3012904,University of Victoria,"In this paper, we propose a novel machine learning pipeline to detect QRS complexes in very noisy wearable electrocardiogram (ECG) devices. The machine learning pipeline consists of a Butterworth filter, two wavelet convolutional neural networks (WaveletCNNs) autoencoders, an optional QRS complex inverter, a Monte Carlo k-nearest neighbours (k-NN), and a convolutional long short-term memory (ConvLSTM). WaveletCNN autoencoders filter out electrode contact noise, instrumentation noise, and motion artifact noise by using the advantages of wavelet filters and convolutional neural networks. The QRS complex inverter flips inverted QRS complexes. Monte Carlo k-NN performs automatic gain control on the ECG signals in order to normalize it. The ConvLSTM executes the final QRS complex detection by using the power of a convolutional neural network and a long short-term memory. The MIT-BIH, the European ST-T, and the Long Term ST database Noise Stress Test databases provide the training and testing ECG recordings. The proposed machine learning pipeline performs 3 standard deviations better than the state of the art QRS complex detection algorithms in terms of F-1 score for very noisy environments.","Electrocardiography,Detection algorithms,Noise measurement,Machine learning,Pipelines,Testing,Databases,Artificial neural networks,electrocardiogram (ECG),QRS complex,feedforward neural networks,multi-layer neural network,convolutional neural networks,recurrent neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"TRANSFORM,ALGORITHM,STANDARD,DATABASE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151983.pdf,
10,Breast Lesion Classification in Ultrasound Images Using Deep Convolutional Neural Network,8,,133349-133359,"Zeimarani Bashir,Fernandes Costa Marly Guimaraes,Nurani Nilufar Zeimarani,Bianco Sabrina Ramos,De Albuquerque Pereira Wagner Coelho,Costa Filho Cicero Ferreira Fernandes","Zeimarani B,Costa MGF,Nurani NZ,Bianco SR,Pereira WCD,Costa CFF",Costa CFF,10.1109/ACCESS.2020.3010863,Universidade Federal de Amazonas,"In recent years, convolutional neural networks (CNNs) have found many applications in medical image analysis. Having enough labeled data, CNNs could be trained to learn image features and used for object localization, classification, and segmentation. Although there are many interests in building and improving automated systems for medical image analysis, lack of reliable and publicly available biomedical datasets makes such a task difficult. In this work, the effectiveness of CNNs for the classification of breast lesions in ultrasound (US) images will be studied. First, due to a limited number of training data, we use a custom-built CNN with a few hidden layers and apply regularization techniques to improve the performance. Second, we use transfer learning and adapt some pre-trained models for our dataset. The dataset used in this work consists of a limited number of cases, 641 in total, histopathologically categorized (413 benign and 228 malignant lesions). To assess how the results of our classifier generalize on our data set, a 5-fold cross-validation were employed, where in each fold 80% of data were used for training and the 20% for testing. Accuracy and the area under the ROC curve (AUC) were used as the main performance metrics. Before applying any regularizations techniques, we achieved an overall accuracy of 85.98% for tumor classification, and the AUC equal to 0.94. After applying image augmentation and regularization, the accuracy and the AUC increased to 92.05% and 0.97, respectively. Using a pre-trained model, we achieved an overall accuracy of 87.07% and an AUC equal to 0.96. The obtained results demonstrated the effectiveness of our custom architecture for classification of tumors in this small US imaging dataset, surpassing some traditional learning algorithm based on manual feature selection.","Lesions,Training,Ultrasonic imaging,Breast tumors,Feature extraction,Breast tumor,ultrasound images,convolutional neural network,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,AREA,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09145538.pdf,
11,Research on Human-Computer Interaction Intention Recognition Based on EEG and Eye Movement,8,,145824-145832,"Zhao Minrui,Gao Hongni,Wang Wei,Qu Jue","Zhao MR,Gao HN,Wang W,Qu J",Zhao MR; Qu J,10.1109/ACCESS.2020.3011740,Air Force Engineering University,"In this work, we present a novel method to intention recognition, based on electroencephalogram (EEG) and eye movement in human-computer interaction(HCI). The fusion of EEG and eye movement will allow the utmost of the advantages of the two physiological signals. Signals of EEG and eye movement were collected for feature extraction, recognition network of machine learning pattern was input for intent recognition, final recognition result was attained by decision-level fusion. We compare the results of the Intention Recognition Algorithms to those of an experiment involving the intention recognition of the operator in a simulated flight mission. In most every case, results show that the intention recognition algorithms performed better than solely rely on single signal.","Electroencephalography,Classification algorithms,Feature extraction,Physiology,Visualization,Eigenvalues and eigenfunctions,Human computer interaction,Intention recognition,physiological signals,EEG,eye movement,simulated flight,decision-level fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"INTERFACES,TRACKING",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146850.pdf,
12,A CRNN System for Sound Event Detection Based on Gastrointestinal Sound Dataset Collected by Wearable Auscultation Devices,8,,157892-157905,"Zheng Xue,Zhang Chun,Chen Ping,Zhao Kang,Jiang Hanjun,Jiang Zhiwei,Pan Huafeng,Wang Zhihua,Jia Wen","Zheng X,Zhang C,Chen P,Zhao K,Jiang HJ,Jiang ZW,Pan HF,Wang ZH,Jia W",Jiang HJ,10.1109/ACCESS.2020.3020099,Tsinghua University,"In this article, we set up a novel audio dataset named Gastrointestinal (GI) Sound Set which includes 6 kinds of body sounds Bowel sound, Speech, Snore, Cough, Groan, and Rub. We do sound event detection (SED) based on it, and can accurately detect 6 types of sound events. First, the GI Sound Set is collected by wearable auscultation devices. To ensure generalization, patients from five different hospital departments are recruited for data collection, along with a group of healthy subjects. GI Sound Set refers to Google AudioSet in data format but varies in audio length and sampling rate. Second, we extract Mel-filter features from the recordings and investigate the performance of different activation functions and neural network architectures for detecting sound events. We use data augmentation, class balance to deal with the problem of quantitative imbalance between classes on the dataset. We apply multiple instances learning(MIL) to give out not only bag-level results but also frame-level results. In this work, GI Sound Set is the largest body sound dataset to date, and our approach shows state-of-the-art performance with an average score of F1=81.06% evaluated on the test set. Due to its simple network and conventional processing method, our CRNN system has high universality, which can be used in other audio datasets, such as respiratory sound and heart sound.","Gastrointestinal (GI) sound set,sound event detection(SED),convolutional recurrent neural network (CRNN),multiple instance learning(MIL)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,NEURAL-NETWORKS,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09179762.pdf,
13,Eso-Net: A Novel 2.5D Segmentation Network With the Multi-Structure Response Filter for the Cancerous Esophagus,8,,155548-155562,"Zhou Donghao,Huang Guoheng,Li Jiajian,Zhu Siyu,Wang Zhuowei,Ling Bingo Wing-Kuen,Pun Chi-Man,Cheng Lianglun,Cai Xiuyu,Zhou Jian","Zhou DH,Huang GH,Li JJ,Zhu SY,Wang ZW,Ling BWK,Pun CM,Cheng LL,Cai XY,Zhou J",Huang GH,10.1109/ACCESS.2020.3019518,Guangdong University of Technology,"Automatic segmentation of the cancerous esophagus in computed tomography (CT) images is a computer-assisted method that can improve the efficiency of the diagnosis and treatment. Due to the diversity of the cancer stage and location, the anatomical structure of the cancerous esophagus is various. Moreover, the low contrast against surrounding tissues leads to a blurry boundary of the cancerous esophagus. Therefore, existing segmentation networks cannot achieve satisfactory results in automatic segmentation of the cancerous esophagus. In this article, we propose a novel 2.5D segmentation network named Eso-Net for the cancerous esophagus based on an encoder-decoder architecture. A 3D enhancement filter called Multi-Structure Response Filter (MSRF) is designed to extract 3D structural information as prior knowledge. Furthermore, dilated convolutions and residual connections are employed in the convolutional blocks of Eso-Net for multi-scale feature learning. With 3D structural priors, Prior Attention Modules (PAM) are incorporated into the network to facilitate the transmission of relevant spatial information. The experiments are conducted on the dataset from 30 esophageal cancer patients, and we report an 84.839% dice similarity coefficient, an 85.955% precision, an 83.752% sensitivity, and a 2.583mm Hausdorff distance. The experimental results demonstrate that the proposed method outperforms other existing segmentation networks in this task and can effectively assist doctors in the diagnosis and treatment of esophageal cancer.","Esophagus,Image segmentation,Feature extraction,Three-dimensional displays,Cancer,Computed tomography,Biomedical imaging,Esophageal cancer,medical image segmentation,deep learning,attention mechanism,enhancement filter",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AUTOMATIC,SEGMENTATION,CT,VESSELS,SCALE,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09178277.pdf,
14,An Efficient High-Quality Medical Lesion Image Data Labeling Method Based on Active Learning,8,,144331-144342,"Zhou Jiancun,Cao Rui,Kang Jian,Guo Kehua,Xu Yangting","Zhou JC,Cao R,Kang J,Guo KH,Xu YT",Kang J,10.1109/ACCESS.2020.3014355,Central South University,"The rapid development of artificial intelligence has allowed deep learning technology to change our lives and has brought considerable convenience, but deep learning cannot succeed without a sufficient quantity and quality of data. In medical systems, due to the special nature of medical data resources, labeling and screening require professional input from doctors at considerable cost. However, if these data cannot be used effectively, then resources are wasted. To solve this problem, this paper proposes an effective high-quality medical lesion image data labeling method based on active learning, which labels the most representative and high-quality medical image data with artificial assistance. First, we generated subregions for all unlabeled images and predicted their classifications. Second, multifactor calculations were performed on all images. Finally, the values of multiple factors were used to sort all images, and the top-ranked images were selected and labeled with artificial assistance. The above steps were repeated until a suitable number of datasets had been labeled. The experimental results showed that a model trained on the labeled high-quality dataset could achieve the same quality as the model trained on all the data and save a considerable amount of time on manual labeling, which demonstrates the effectiveness of the method. The method ensures that the labeled data are valuable, high quality and rich in information to reduce the labeling workload and avoid wasting data resources.","Biomedical imaging,Machine learning,Labeling,Semisupervised learning,Data models,Manuals,Diseases,High-quality data,biomedical engineering,active learning,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CLASSIFICATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09159118.pdf,
15,A Level Set Based Unified Framework for Pulmonary Nodule Segmentation,27,,1465-1469,"Roy Rukhmini,Banerjee Pranavesh,Chowdhury Ananda S.","Roy R,Banerjee P,Chowdhury AS",Chowdhury AS,10.1109/LSP.2020.3016563,Jadavpur University,"This letter introduces a unified framework for accurate segmentation of five different types of pulmonary nodules, namely, solid, juxtapleural, juxtavascular, part solid and ground glass by designing a contrast-adaptive shape-driven level set algorithm. Most of the existing methods have targeted segmenting few specific types of nodules. Variability of shapes along with poor contrast make pulmonary nodule segmentation an extremely challenging problem. To deal with low contrast, a contrast-adaptive term, based on intensities, is incorporated to guide the evolution of level set. A shape term is further introduced for accurate segmentation of different pulmonary nodules having varying shapes. Experiments on the publicly available LIDC/IDRI dataset clearly reveal that our method achieves promising results as compared to several state-of-the-art competitors.","Level set,Shape,Lung,Solids,Image segmentation,Glass,Machine learning,Pulmonary nodule segmentation,level sets,shape information,contrast adaptation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,"IMAGE,DATABASE,CONSORTIUM,AUTOMATIC,DETECTION,DETECTION,SYSTEM,LUNG,NODULES,EVOLUTION,RESOURCE,FEATURES,NETWORK,MODEL",IEEE SIGNAL PROCESSING LETTERS,,
16,Exploring Task Structure for Brain Tumor Segmentation From Multi-Modality MR Images,29,,9032-9043,"Zhang Dingwen,Huang Guohai,Zhang Qiang,Han Jungong,Han Junwei,Wang Yizhou,Yu Yizhou","Zhang DW,Huang GH,Zhang Q,Han JG,Han JW,Wang YZ,Yu YZ",Zhang Q,10.1109/TIP.2020.3023609,Xidian University,"Brain tumor segmentation, which aims at segmenting the whole tumor area, enhancing tumor core area, and tumor core area from each input multi-modality bio-imaging data, has received considerable attention from both academia and industry. However, the existing approaches usually treat this problem as a common semantic segmentation task without taking into account the underlying rules in clinical practice. In reality, physicians tend to discover different tumor areas by weighing different modality volume data. Also, they initially segment the most distinct tumor area, and then gradually search around to find the other two. We refer to the first property as the task-modality structure while the second property as the task-task structure, based on which we propose a novel task-structured brain tumor segmentation network (TSBTS net). Specifically, to explore the task-modality structure, we design a modality-aware feature embedding mechanism to infer the important weights of the modality data during network learning. To explore the task-task structure, we formulate the prediction of the different tumor areas as conditional dependency sub-tasks and encode such dependency in the network stream. Experiments on BraTS benchmarks show that the proposed method achieves superior performance in segmenting the desired brain tumor areas while requiring relatively lower computational costs, compared to other state-of-the-art methods and baseline models.","Tumors,Task analysis,Image segmentation,Three-dimensional displays,Brain modeling,Two dimensional displays,Semantics,Machine vision,object segmentation,image analysis,supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"OBJECT,DETECTION",IEEE TRANSACTIONS ON IMAGE PROCESSING,https://pure.aber.ac.uk/portal/files/39139562/manuscript_TIP.pdf,
17,Low-Complexity On-Demand Reconstruction for Compressively Sensed Problematic Signals,68,,4094-4107,"Chou Ching-Yao,Hsu Kai-Chieh,Cho Bo-Hong,Chen Kuan-Chun,Wu An-Yeu Andy","Chou CY,Hsu KC,Cho BH,Chen KC,Wu AYA",Wu AYA,10.1109/TSP.2020.3006766,National Taiwan University,"Compressed Sensing (CS) is a revolutionary technology for realizing low-power sensor nodes through sub-Nyquist sampling, and the CS reconstruction engines have been widely studied to fulfill the energy efficiency for real-time processing. However, in most cases, we only want to analyze the problematic signals which account for a very low percentage. Therefore, large efforts will be wasted if we recover uninterested signals. On the other hand, in order to identify the high-risk signals, additional hardware and computation overhead are required for classification other than CS reconstruction. In this paper, to achieve low-complexity on-demand CS reconstruction, we propose a two-stage classification-aided reconstruction (TS-CAR) framework. The compressed signals can be classified with a sparse coding based classifier, which provides the hardware sharing potential with reconstruction. Furthermore, to accelerate the reconstruction speed, a cross-domain sparse transform is applied from classification to reconstruction. TS-CAR is implemented in electrocardiography based atrial fibrillation (AF) detection. The average computational cost of TS-CAR is 2.25x fewer compared to traditional frameworks when AF percentage is among 10% to 50%. Finally, we implement TS-CAR in TSMC 40 nm technology. The post-layout results show that the proposed intelligent CS reconstruction engine can provide a competitive area- and energy-efficiency compared to state-of-the-art CS and machine learning engines.","Compressed sensing,on-demand reconstruction,compressed learning,sparse transform,hardware sharing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.239,"COUPLED,DICTIONARY,ECG,ALGORITHM,RECOVERY",IEEE TRANSACTIONS ON SIGNAL PROCESSING,,
18,The Autoregressive Linear Mixture Model: A Time-Series Model for an Instantaneous Mixture of Network Processes,68,,4481-4496,"Bohannon Addison W.,Lawhern Vernon J.,Waytowich Nicholas R.,Balan Radu V.","Bohannon AW,Lawhern VJ,Waytowich NR,Balan RV",Bohannon AW,10.1109/TSP.2020.3012946,United States Department of Defense,"Vector autoregressive models provide a simple generative model for multivariate, time-series data. The autoregressive coefficients of the vector autoregressive model describe a network process. However, in real-world applications such as macroeconomics or neuroimaging, time-series data arise not from isolated network processes but instead from the simultaneous occurrence of multiple network processes. Standard vector autoregressive models cannot provide insights about the underlying structure of such time-series data. In this work, we present the autoregressive linear mixture (ALM) model. The ALM proposes a decomposition of time-series data into co-occurring network processes that we call autoregressive components. We also present a non-convex likelihood-based estimator for fitting the ALM model and show that it can be solved using the proximal alternating linearized minimization (PALM) algorithm. We validate the ALM on both synthetic and real-world electroencephalography data, showing that we can disambiguate task-relevant autoregressive components that correspond with distinct network processes.","Brain modeling,Machine learning,Data models,Computational modeling,Mathematical model,Signal processing algorithms,Mixture models,Time series analysis,autoregressive processes,mixture models,unsupervised learning,electroencephalography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.239,"MATRIX-FACTORIZATION,ALGORITHMS,NONCONVEX",IEEE TRANSACTIONS ON SIGNAL PROCESSING,,
19,Fast volumetric mapping of human brain slices,11360,,,"Pesce Luca,Laurino Annunziatina,Gavryusev Vladislav,Mazzamuto Giacomo,Sancataldo Giuseppe,Scardigli Marina,Roffilli Matteo,Silvestri Ludovico,Costantini Irene,Pavone Francesco Saverio","Pesce L,Laurino A,Gavryusev V,Mazzamuto G,Sancataldo G,Scardigli M,Roffilli M,Silvestri L,Costantini I,Pavone FS",Pavone FS,10.1117/12.2555644,University of Florence,"We still lack a detailed map of the anatomical disposition of neurons in the human brain. A complete map would be an important step for deeply understanding the brain function, providing anatomical information useful to decipher the neuronal pattern in healthy and diseased conditions. Here, we present several important advances towards this goal, obtained by combining a new clearing method, advanced Light Sheet Microscopy and automated machine-learning based image analysis. We perform volumetric imaging of large sequentially stained human brain slices, labelled for two different neuronal markers NeuN and GAD67, discriminating the inhibitory population and reconstructing the brain connectivity.","Light sheet microscopy,whole brain imaging,quantitative imaging,tissue clearing,human brain",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Neurosciences & Neurology,Optics",,,,,https://doi.org/10.1117/12.2555644,
20,A system approach for closed-loop assessment of neuro-visual function based on convolutional neural network analysis of EEG signals,11360,,,"Stock Simon C.,Armengol-Urpi Alexandre,Kovacs Balint,Maier Heiko,Gerdes Marius,Stork Wilhelm,Sarma Sanjay E.","Stock SC,Armengol-Urpi A,Kovacs B,Maier H,Gerdes M,Stork W,Sarma SE",Stock SC,10.1117/12.2554417,Helmholtz Association,"We propose a generalized, modular, closed-loop system for objective assessment of human visual parameters. Our system presents periodical visual stimuli to the patient's field of view and analyses the consequent evoked brain potentials elicited in the occipital lobe and recorded through EEG. The analysis of the monitored EEG data is performed in an end-to-end fashion by a convolutional neural network (CNN). We propose a novel CNN architecture for EEG signal analysis that can be trained utilizing the benefits of multi-task learning. The closedloop attribute of our system allows for a real-time adaptation of the subsequent stimuli to further examine a potentially damaged area or increase the granularity of the exploration. Interchangeability is provided in terms of software modules, stimulus type, visual hardware, EEG acquisition device and EEG electrodes. Initially, the system is designed to monitor visual field loss originating from glaucoma or damage to the optic nerve using a virtual reality (VR) headset for the stimuli presentation. The modular architecture of our system paves the way for the assessment and monitoring of other neuro-visual functions.","Neuroscience,Brain-Computer-Interface,EEG,Ophthalmology,Deep Learning,Convolutional Neural Networks,System Design",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Neurosciences & Neurology,Optics",,,"EVOKED-POTENTIALS,MULTIFOCAL,VEP,GLAUCOMA,BRAIN,PERIMETRY,LOCATION,ACUITY,DAMAGE",,https://dspace.mit.edu/bitstream/1721.1/136990/2/1136008.pdf,
21,A New Smart-Fabric based Body Area Sensor Network for Work Risk Assessment,,,187-190,"Lanata Antonio,Greco Alberto,Di Modica Stefano,Niccolini Francesco,Vivaldi Federico,Di Francesco Fabio,Tamantini Christian,Cordella Francesca,Zollo Loredana,Di Rienzo Marco","Lanata A,Greco A,Di Modica S,Niccolini F,Vivaldi F,Di Francesco F,Tamantini C,Cordella F,Zollo L,Di Rienzo M",Lanata A,,University of Florence,"This study reports on a novel Smart-Fabric based wireless Body Area Sensor Network for assessing psychological and physiological work risk levels. The combination of smart-sensing fabrics advantages, high electronic miniaturization, and the latest machine learning enables the system to assess the risk level of the worker. The body area sensor network includes a smartphone, an artificial intelligence algorithm for risk assessment, and a set of sensor-nodes integrated into a textile substrate (i.e., activity detection, electrocardiogram (ECG), sweat rate, body temperature, and textile integrated respiration sensors). Preliminary and encouraging results are shown in terms of physiological signals and physical activity detection.","Biomedical Signal Processing,Wireless Body Area Sensor Network,Smart Textile,Work Risk Assessment,Machine Learning,Mobile Platform",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Instruments & Instrumentation",,,,2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (METROIND4.0&IOT),https://flore.unifi.it/bitstream/2158/1208713/1/09138273.pdf,
22,VITAL-ECG : a de-bias algorithm embedded in a gender-immune device,,,314-317,"Paviglianiti Annunziata,Pasero Eros","Paviglianiti A,Pasero E",Paviglianiti A,,Polytechnic University of Turin,"Artificial intelligence, sensors technology and sensors networks influence people behavior in everyday life. The diffusion of mobile devices, based on Internet of Things (IoT) paradigms, has created specific solutions for applications, in which physical objects are connected to Internet system. Wearable IoT (WIoT) represents a new IoT area, concerning detection, processing and communication capabilities in the field of healthcare. Vital-ECG is a smart device, related to health monitoring, which complies with gender equality. The wearable device takes the form of a smartwatch, which monitors heart activity and the most important vital parameters: blood oxygen saturation, skin temperature and fatigue level. Electrocardiogram and plethysmogram signals are acquired from Vital-ECG, which is able to track the blood pressure values, through a deep learning implementation. The neural algorithm has been implemented avoiding the ""Gender Bias"". The gender balance in machine learning, especially in biomedical application, is a crucial point to prevent algorithms from making a distorted prediction, disadvantaging women.","arterial bloodpressure,ECG,electrocardiogram,fairness,gender bias,machine learning,plethysmogram,photo-plethysmogram,PPG,VITAL-ECG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Instruments & Instrumentation",,,"HEART-DISEASE,RISK",2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (METROIND4.0&IOT),,
23,A Body Hydration Analysis System to improve running performance,,,507-510,"Lapadula Valerio,Sabatini Anna,Zompanti Alessandro,Buscaglione Silvia,Lanaro Davide,Merone Mario","Lapadula V,Sabatini A,Zompanti A,Buscaglione S,Lanaro D,Merone M",Lapadula V,,University Campus Bio-Medico - Rome Italy,"During an intense activity, such as marathon or bicycle training, body is subjected to a high physical stress. This brings the performance decreasing, given by several factors such as reduction of body hydration. Low hydration gives a loss of body cooling's efficiency on which athlete's performance capabilities depend. Body hydration monitoring devices have poor accuracy and moreover it's very difficult to find them on the market. In this work we do not aspire to the production of a hydration sensor, but rather we want to analyse and identify possible measures related to body hydration, acquired during a running and not yet observed in literature. For these reasons,we present an acquisition system to collect data from whether, subject performance and saliva, an experimentation protocol and features relevance analysis. The preliminary results shown in this work are obtained using the Bio-electric Impedance Analysis as benchmark measure of body hydration.","Monitoring sport,Body Hydration",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Instruments & Instrumentation",,,SENSOR,2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (METROIND4.0&IOT),,
24,Infrared Thermography applied on Fresh Food Monitoring in Automated Alerting Systems,,,554-558,"Massaro Alessandro,Panarese Antonio,Galiano Angelo","Massaro A,Panarese A,Galiano A",Massaro A,,"Dyrecta Lab Srl, MIUR Res Inst, Conversano, BA, Italy.","The infrared thermography approach is applied for the monitoring of fresh foods located into a refrigerator by controlling the temperature and automatizing the deterioration risk alert. Specifically, the paper discusses the results about infrared thermography methodology combined with image processing technique. The study is performed to check during the time the evolution of the meat temperature when placed out of the refrigerator at room temperature. The experimentation is performed by analyzing the meat oxidation time evolution and checking the minimum temperature behavior defining food quality. A K-Means algorithm is applied in order to locally process the radiometric image highlighting the oxidation effect. Finally are discussed different aspects about radiometric approaches.","Infrared Termography,Automated alerting food deterioration system,K-Means image post processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Instruments & Instrumentation",,,,2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (METROIND4.0&IOT),,
25,,,7,28-36,,,,10.18565/aig.2020.7.28-36,,"Проведен систематический анализ литературных данных о возможностях использования новейших методов в области искусственного интеллекта (ИИ) в сфере вспомогательных репродуктивных технологий (ВРТ). Обзор освещает ряд иностранных и отечественных публикаций, посвященных данной теме. На основе анализа литературы был сделан вывод, что научные коллаборации в области ВРТ и ИИ открывают новые возможности работы с биологическим материалом пациентов, страдающих бесплодием, и повышают их шансы стать родителями. Более точный и стандартизированный анализ структуры и морфологии позволит клиническим эмбриологам отбирать наиболее жизнеспособные эмбрионы для переноса и использовать лучшие сперматозоиды для оплодотворения в программах ВРТ. Несмотря на то что многие методы в этой области все еще остаются экспериментальными и требуют дальнейших исследований и доработки, на их основе уже можно создавать вспомогательные системы, реализующие поддержку принятия решений. Однако репродуктивные центры нуждаются в системах. Актуальность подобных систем в современной медицине не оставляет сомнений: инструментальных средств зачастую недостаточно, границы норма-патология достаточно широкие и могут перекрываться, итоговый прогноз носит субъективный характер.",вспомогательные репродуктивные технологии; искусственный интеллект; эмбрионы; сперматозоиды; беременность; экстракорпоральное оплодотворение; машинное обучение,Review,,,,,,,,
26,,16,2,26-38,,,,10.22337/2587-9618-2020-16-2-26-38,,"The work is devoted to the development of a high-performance deep learning algorithm related to the diagnosis and classification of defects of water-repellent membranes. The mechanism of constructing visual models of the membrane surface is discussed. This allows to get the representative training data set. The proposed methodology consists in the sequent transformations of pixel-image intensities to find defected fragments on the membrane's surface. The computational algorithm is based on the architecture of convolution neural networks. To assess its effectiveness, the ""confidence of confidence"" criterion is proposed. The presented computations show that the methodology can be successfully applied in material sciences, for example, to study the properties of building materials, or in forensic science when examining the causes of construction catastrophes.",гидроизоляционные мембраны; глубокое обучение; машинное обучение; классификация патологий,Article,,,,,,,https://ijccse.iasv.ru/index.php/ijccse/article/download/289/194,
27,,,3,91-96,,,,10.24937/2542-2324-2020-3-393-91-96,,"Объект и цель научной работы. Объектом исследования является проблема классификации кораблей по их изображениям в видимом, инфракрасном и радиолокационном диапазонах. Цель статьи - оценка возможности использования для классификации основных современных алгоритмов и подходов, применяемых для решения задач компьютерного зрения. Материалы и методы. Проанализирована эволюция компьютеров и программного обеспечения, позволяющая использовать машинное зрение и самообучающиеся компьютерные сети для распознавания кораблей по их изображениям. Изложены основные подходы развития корабельных радиолокационных систем в различных странах. Отражены два подхода при создании моделей классификаторов с использованием «готовых» сетей, обученных для классификации изображений. Основные результаты. На основе анализа развития сверточных нейронных сетей выявлены основные тенденции развития машинного зрения. Отмечены наиболее перспективные методы их использования для классификации изображений кораблей. Разработаны две модели классификаторов оптических портретов кораблей и судов. Для них получены количественные оценки достигнутых точностей распознавания. Заключение. Представленные материалы позволяют определить тенденции развития классификаторов портретов кораблей. Полученные результаты могут быть использованы при распознавании тепловых и радиолокационных портретов кораблей.",нейронная сеть; машинное зрение; обработка изображений; распознавание объектов; датасет; компьютерное зрение,Article,,,,,,,https://doi.org/10.24937/2542-2324-2020-3-393-91-96,
28,Computational Notebooks in Public Repositories,16,1,38-44,"Speicher Daniel,Cremers Armin B.","Speicher D,Cremers AB",Speicher D,,University of Bonn,"A computational notebook - most prominently a Jupyter notebook - is a special kind of a document that encompasses data, text, calculations, visualizations. Public repositories - most prominently GitHub - make them available. The number of notebooks is growing almost exponentially as more and more software developers, data scientists and machine learning students, teachers and engineers share their notebooks publicly. They use these repositories not only to store own notebooks but to find solutions to their specific problems at hand. The open exchange of computational narratives in Jupyter notebooks is an overwhelming success story. In this paper we ask the question of how the use and spread of publicly available notebooks affect the quality of code and its embedding in a computational narrative. Drawing on empirical studies and our own experiences in the creation of digital material to support machine learning education and our observation of students' use of notebooks, we comment on the quality. Our findings include that we cannot just reuse the concrete quality criteria that are in use for software in general. Much rather, we must integrate the competing demands in creating a linear computational narrative, thus adapting programming style and design patterns to the data science context.","Code quality,Computational notebook,Education,Explanation,Exploration,Machine Learning,Project Jupyter,Public repository,Reproducibility",Article,"IPSI BELGRADE LTD, DALMATINSKA 55, BELGRADE, 00000, SERBIA",Computer Science,,,,IPSI BGD TRANSACTIONS ON INTERNET RESEARCH,,
29,Abnormal Detection and Classification in i-Ceramic Images,,,17-18,"Min Borin,Tin Hok,Nasridinov Aziz,Yoo Kwan-Hee","Min B,Tin H,Nasridinov A,Yoo KH",Min B,10.1109/BigComp48618.2020.0-106,Chungbuk National University,"Nowadays, smart factory has evolved as a big aspect of the research field. i-ceramic paradigm plays an important role in innovative ceramic material development by applying big data and machine learning techniques. One of the issues in i-ceramic paradigm is to detect and classify several types of defects in images sensed in manufacturing process. Generally, the defects are detected by using computer vision techniques. In this paper, we propose using the convolutional neural network (CNN) to detect defects, such as crack, bubble, scratch, and burr in ceramic-made products. The initial experiment results indicate that the proposed model achieves high defect detection accuracy.","classification,i-ceramic image,defects,ceramic materials",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
30,Trainable Multi-Contrast Windowing for Liver CT Segmentation,,,169-172,"Kwon Jangho,Choi Kihwan","Kwon J,Choi K",Choi K,10.1109/BigComp48618.2020.00-80,Korea Institute of Science & Technology (KIST),"This study proposes a trainable multi-contrast windowing method in order to optimally choose contrast windows for deep learning-based CT segmentation. Existing contrast windowing methods use parameters predefined by radiologists or manufacturers. These predefined contrast windows, however, have not been proven to be optimal set for machine learning based approaches. We therefore propose a trainable multi-contrast windowing module which can be easily integrated into deep convolutional neural networks. For performance evaluation, we investigate the effects of the trainable multi-contrast windows by applying the proposed windowing modules to a deep learning based segmentation network measuring liver tumors. The results show significant performance improvement when the windowing parameters are trainable. The proposed method enhances the performance for medical image analyses compared to rule-based windowing methods.","computer-aided diagnosis,machine learning,deep learning,computational tomography,semantic segmentation,medical application",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
31,Recursive undersampling-based decision boundary alignment for imbalanced radiology image,,,425-428,"Kang Jaewoong,Sohn Mye","Kang J,Sohn M",Kang J,10.1109/BigComp48618.2020.00-36,Sungkyunkwan University (SKKU),"The data imbalance problem is a huge obstacle in radiology field. Although the accuracy of the classifier is very high due to the number of data in the majority class, the classifier is not sufficiently reflected the information of the minority class. In this paper, we proposed a recursive undersampling method that can classify minority class well by shifting decision boundaries from near minority class to near majority class. In this method, iterative sampling is performed on the majority class with the same size as the minority class, but the decision boundary was shifted by reducing the influence of the sampled data near the decision boundary. Through this, the problem of imbalance in the radiology field was partially solved, and the learning of the classifier using all the high-cost medical image data was made possible.","Imbalanced data,Decision boundary,Radiology",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
32,Drill-Core Hyperspectral and Geochemical Data Integration in a Superpixel-Based Machine Learning Framework,13,,4214-4228,"Acosta Isabel Cecilia Contreras,Khodadadzadeh Mahdi,Tolosana-Delgado Raimon,Gloaguen Richard","Acosta ICC,Khodadadzadeh M,Tolosana-Delgado R,Gloaguen R",Acosta ICC,10.1109/JSTARS.2020.3011221,Helmholtz Association,"The analysis of drill-core samples is one of the most important steps in the mining industry for the exploration and discovery of mineral resources. Geochemical assays are a common approach to represent the abundance of different chemical elements and aid at quantifying the concentrations of the important ore accumulations. However, their acquisition is time-consuming and usually averages of long core portions. Hyperspectral data are increasingly being used in the mining industry to complement the analysis of drill-cores due to their efficiency and fast turn-around time. Moreover, hyperspectral imaging is a technique able to provide data with high spatial resolution. In this article, we propose to integrate the complementary information derived from hyperspectral and geochemical data via a superpixel-based machine learning framework. This framework considers the difference in spatial resolution through segmentation. We extract labels from the geochemical assays and select, from the hyperspectral data, representative samples for each measurement. A supervised machine learning classification (composite kernel support vector machine) is then used to extrapolate the elements relative abundance to the entire core length. We propose an innovative integration of hyperspectral data covering different regions of the electromagnetic spectrum in a kernel-based framework to facilitate the identification of a larger amount of elements. A qualitative and quantitative evaluation of the results demonstrates the capabilities of the proposed method, which provides approximately 20% more accurate results than the pixel-based approach. Results also imply that the method could be beneficial for the reduction of geochemical assays needed for the detailed analysis of the cores.","Hyperspectral imaging,Minerals,Chemical elements,Electromagnetic spectrum,Absorption,Machine learning,Data integration,drill-cores,geochemical data,hyperspectral data,superpixel segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physical Geography,Remote Sensing,Imaging Science & Photographic Technology",,,"IMAGING,SPECTROMETER,DATA,MAPPING,ALTERATION,SLIC,SUPERPIXELS,EXPLORATION,MINERALOGY,EXTRACTION,DEPOSIT,GOLD",IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,https://ieeexplore.ieee.org/ielx7/4609443/8994817/09146200.pdf,
33,Machine learning analyses of bacterial oligonucleotide frequencies to assess the benthic impact of aquaculture,12,,131-137,"Armstrong Ethan G.,Verhoeven Joost T. P.","Armstrong EG,Verhoeven JTP",Verhoeven JTP,10.3354/aei00353,Memorial University Newfoundland,"Aquaculture is a rapidly expanding industry and is now one of the primary sources of all consumed seafood. Intensive aquaculture production is associated with organic enrichment, which occurs as organic material settles onto the seafloor, creating anoxic conditions which disrupt ecological processes. Bacteria are sensitive bioindicators of organic enrichment, and supervised classifiers using features derived from 16s rRNA gene sequences have shown potential to become useful in aquaculture environmental monitoring. Current taxonomy-based approaches, however, are time intensive and built upon emergent features which cannot easily be condensed into a monitoring pipeline. Here, we used a taxonomy-free approach to examine 16s rRNA gene sequences derived from flocculent matter underneath and in proximity to hard-bottom salmon aquaculture sites in Newfoundland, Canada. Tetranucleotide frequencies (k = 4) were tabulated from sample sequences and included as features in a machine learning pipeline using the random forest algorithm to predict 4 levels of benthic disturbance; resulting classifications were compared to those obtained using a published taxonomy-based approach. Our results show that k-mer count features can effectively be used to create highly accurate predictions of benthic disturbance and can resolve intermediate changes in seafloor condition. In addition, we present a robust assessment of model performance which accounts for the effect of randomness in model creation. This work outlines a flexible framework for environmental assessments at aquaculture sites that is highly reproducible and free of taxonomy-assignment bias.","Aquaculture,Machine learning,Environmental monitoring,Organic enrichment,Bacterial eDNA,Random forest,Supervised classification",Article,"INTER-RESEARCH, NORDBUNTE 23, D-21385 OLDENDORF LUHE, GERMANY","Fisheries,Marine & Freshwater Biology",,3.475,"QUALITY,STATUS,COMMUNITIES",AQUACULTURE ENVIRONMENT INTERACTIONS,https://www.int-res.com/articles/aei2020/12/q012p131.pdf,
34,Building Cognitive Profiles of Learners Using EEG,,,027-032,"Elkerdawy Mohamed,Elhalaby Mohamed,Hassan Afnan,Maher Mohamed,Shawky Doaa,Badawi Ashraf","Elkerdawy M,Elhalaby M,Hassan A,Maher M,Shawky D,Badawi A",Elkerdawy M,10.1109/ICICS49469.2020.239535,Egyptian Knowledge Bank (EKB),"Cognitive load refers to the used amount of working memory. It is very hard to be detected, especially in on-line and computer-supported learning. Thus, it is one of the most important challenges for educational technologists and instructional designers to address. Electroencephalogram (EEG) is a methodology that monitors the electric activity in the brain. EEG has been effective in detecting subjects' emotional and cognitive states. In this paper, an approach for detecting the basic cognitive states that affect learning outcomes using EEG signals is proposed. Detected states include engagement, instantaneous attention, focused attention, working memory, planning, shifting and visual perception. The proposed approach consists of the following. First, 127 students in their undergraduate university-level studies undergo scientifically-validated cognitive assessment tests that evoke and measure their full cognitive profiles while putting on a 14-channel wearable EEG headset. Then, the collected data are used to train deep models as well as shallow classifiers to automatically predict the analyzed cognitive states. Although the main advantage of the deep learning models is avoiding the hand-crafted features needed for the shallow classifiers, the shallow classifiers outperformed the deep learning-based ones with a minimum accuracy of 92% as compared to the deep models with a maximum obtained accuracy of 78%.","EEG,Cognition,Classification,Adaptive Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,CLASSIFICATION,,,
35,A review of recent progress in deep learning-based methods for MRI brain tumor segmentation,,,149-154,"Chihati Sarah,Gaceb Djamel","Chihati S,Gaceb D",Chihati S,10.1109/ICICS49469.2020.239550,Universite de M'hammed Bougara Boumerdes,"Brain tumor segmentation is a challenging task that involves delimiting cancerous tissues with heterogeneous and diffuse forms in brain medical images. This process is undoubtedly an important step in computer-aided diagnosis systems, in which tumor regions must be isolated for visualization and subsequent analysis. Recently, great progress has been made in brain tumor segmentation with the emergence of deep learning-based methods, which automatically learn hierarchical, and discriminative features from raw data. These methods outperformed the classical machine learning approaches where handcrafted features are used to describe the differences between pathological and healthy tissues. In this paper, we present a comprehensive overview of recent progress in deep learning-based methods for brain tumor segmentation from magnetic resonance images. Moreover, we discuss the most common challenges and suggest possible solutions.","Brain tumor segmentation,deep learning,medical image segmentation,MRI,image processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"CONVOLUTIONAL,NEURAL-NETWORKS,CNN",,,
36,A Deep Learning Approach for Classifying Emotions from Physiological Data,,,214-219,"AlZoubi Omar,ALMakhadmeh Buthina,Tawalbeh Saja Khaled,Yassien Muneer Bani,Hmeidi Ismail","AlZoubi O,ALMakhadmeh B,Tawalbeh SK,Yassien MB,Hmeidi I",AlZoubi O,10.1109/ICICS49469.2020.239534,Jordan University of Science & Technology,"Affect detection form physiological signals has been an active research field recently. It has many applications in education, computer games, car driver monitoring, and health. Electrocardiography, electromyography, respiration, and skin conductivity have all been considered as potential physiological channels for recognizing affective states. There is a large amount of literature on physiology-based affect detection that reports on high detection rates of affective states (either discrete emotions, or dimensional valence/arousal) under laboratory conditions. However, one challenge is that physiological measures exhibit considerable variations over time, non-stationary, making classification of future data difficult. In this study, we aim to investigate the changing physiological features over multiple sessions. In our experiments, we use a dataset collected from four participants who viewed a set of images from the International Affective Picture System (IAPS) over multiple days. This study also provides a comparison between self-reported and IAPS ratings for both valence and arousal dimensional affective model. In addition, the study provides an analysis of the performance of individual physiological channels for affect detection. Results indicate that a Deep Neural Network achieved accuracy with 61.12%, 67.14% of detecting self-report compared with IAPS rating for valence and arousal. Results also show that EMG zygomatic features and a fusion of features from all physiological channels have the highest affect detection accuracy for both valence and arousal.","Affect,Emotion,Physiological Signals,Deep Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"ADAPTIVE,CLASSIFICATION,RECOGNITION",,,
37,Overview of Positron Emission Tomography (PET) for Brain Functions Degeneration Classification,,,277-282,"Abu Alasal Sanaa,Bashabsheh Emran A. L.,Najadat Hassan","Abu Alasal S,Bashabsheh EAL,Najadat H",Abu Alasal S,10.1109/ICICS49469.2020.239500,Jordan University of Science & Technology,"Positron Emission Tomography scans show metabolic changes that occur in an organ or tissue at the cellular level. This is important because at the cellular level the disease always starts. Computed Tomography scans and Magnetic Resonance Images are not able to reveal cell-level problems. So, Positron Emission Tomography scans can detect changes in the cells very early, but the others detect changes as a disease affects the organs or tissue structure. Since it rises, Positron Emission Tomography gained a serious role in the diagnosis and treatment of brain disorders such as Alzheimer's disease, Parkinson's and Dementia, in addition to tumors. Because of the high level of chemical activity that exists in abnormal tissues such as cancer cells, these cells will show up as bright spots on these scans. This can play a major role in the diagnostic process if modern image processing methods are used to identify bright areas, as it will assist specialists in the diagnostic process and monitor the pathological condition during the treatment period. In this paper we summarize the most prominent methods used in processing positron images, starting from the traditional stages through to machine learning techniques and then to deep learning that occupies a large area in recent days.","PET-scans,Alzheimer's,Parkinson's,MCI,Brain tumor",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"TARGET,DELINEATION,SEGMENTATION,HEAD,CANCER",,,
38,The impact of Deep learning algorithms with MRI Systematic review,,,288-293,"Al-Aiad Ahmad,Mustafa Omara","Al-Aiad A,Mustafa O",Al-Aiad A,10.1109/ICICS49469.2020.239508,Jordan University of Science & Technology,"The current trend in the medical diagnosis world is aiming towards utilizing Artificial Intelligence (AI) in the medical imaging field to highlight what is supposed to be abnormal signs and abnormal structures in the medical image. In our study we construct a systematic review to gather the deep learning algorithms, that have a direct impact with MRI in one single article, to analyze, synthesize and focus on their advantages, and limitations, to ensure that the future researchers will try to get over these limitations, and to take the benefits from the previous. We used Ramey and Rao's that separate the research into two main phases, In the first phase, we are planning to review the published literature on the deep learning algorithms and their impact with MRI, to identify the main algorithms to identify the main limitations and gaps in the current literature. In the second phase conducting the review, this includes how we collect the data, what is the search keywords, the databases where used, and what is inclusion and exclusion criteria. Then we extract the main themes in our researches and build taxonomy connect the whole articles with their themes. And in conclusion we can conclude the deep learning algorithms and their impact with MRI can facilitate the image diagnosis and can also make an improvement on the images whether in resolution or get thinner slice thickness from the thicker one, furthermore, they can enhance the decision-making process that has a direct impact with patient care.","MRI,Magnetic Resonance Imaging,Deep learning algorithms,Medical imaging",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,,,,
39,The Use of Big Data Analytics in Medical Images: a Survey,,,294-298,"Shatnawi Mohammed,Yassein Muneer Bani,Jalabneh Ibtihal","Shatnawi M,Yassein MB,Jalabneh I",Shatnawi M,10.1109/ICICS49469.2020.239514,Jordan University of Science & Technology,"as data grows there is a needs for the technology that has the capacity to deal with this growth. As data grows in all fields on a daily basis, the challenge becomes harder in finding the right technological tools that can handle this expansion. This growth poses new challenges in terms of creating the technology or solutions that can deal with this growth or even the challenges arisen on the organizational level. Many sectors have already adopted big data. However, in the area of healthcare sector, it is still in the early stages of adoption. The problem is not in the data itself but the lack of information that can be gained with the help of technologies like Hadoop to generate this information. Hadoop also helps in generating meaningful real time analysis which can predict emergency situations or help in planning, strategizing, and decision making but its uses in the ECG field is still limited. The data generated by healthcare organizations can also have more and higher value if we can elicit more useful information from it using proper data analytics. By adopting big data analytics, organizations can have the chance to manage and analyze volumes of massive data more efficiently. A comparison of the potential between machine learning and big data was discussed and finally the available literature on the use of big data and deep learning in the ECG filed and its possible applications.","Big data analytics,healthcare analytics,analytics,big data,Hadoop",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"DEEP,LEARNING,APPROACH,CLASSIFICATION",,,
40,Automatic ECG-Based Emotion Recognition in Music Listening,11,1,85-99,"Hsu Yu-Liang,Wang Jeen-Shing,Chiang Wei-Chun,Hung Chien-Han","Hsu YL,Wang JS,Chiang WC,Hung CH",Wang JS,10.1109/TAFFC.2017.2781732,National Cheng Kung University,"This paper presents an automatic ECG-based emotion recognition algorithm for human emotion recognition. First, we adopt a musical induction method to induce participants' real emotional states and collect their ECG signals without any deliberate laboratory setting. Afterward, we develop an automatic ECG-based emotion recognition algorithm to recognize human emotions elicited by listening to music. Physiological ECG features extracted from the time-, and frequency-domain, and nonlinear analyses of ECG signals are used to find emotion-relevant features and to correlate them with emotional states. Subsequently, we develop a sequential forward floating selection-kernel-based class separability-based (SFFS-KBCS-based) feature selection algorithm and utilize the generalized discriminant analysis (GDA) to effectively select significant ECG features associated with emotions and to reduce the dimensions of the selected features, respectively. Positive/negative valence, high/low arousal, and four types of emotions (joy, tension, sadness, and peacefulness) are recognized using least squares support vector machine (LS-SVM) recognizers. The results show that the correct classification rates for positive/negative valence, high/low arousal, and four types of emotion classification tasks are 82.78, 72.91, and 61.52 percent, respectively.","Electrocardiography,Music,Emotion recognition,Physiology,Feature extraction,Multiple signal classification,Algorithm design and analysis,Electrocardiogram,emotion recognition,music,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,,"HEART-RATE-VARIABILITY,CIRCUMPLEX,MODEL,ELECTROCARDIOGRAM,CLASSIFICATION,EXTRACTION,ALGORITHM,FREQUENCY,SELECTION,DYNAMICS",IEEE TRANSACTIONS ON AFFECTIVE COMPUTING,,
41,Classification and Diagnosis of Invasive Ductal Carcinoma Using Deep Learning,,,242-247,"Siddiqui Fahad,Gupta Shubham,Dubey Shashwat,Murtuza Shariq,Jain Arti","Siddiqui F,Gupta S,Dubey S,Murtuza S,Jain A",Jain A,,Jaypee Institute of Information Technology (JIIT),"In the past decades, researchers have demonstrated abilities to automate the process of detection and analysis of different kinds of cancers using Whole Slide Images (WSI) datasets. The breast cancer detection in histopathology images (one of the WSI dataset) using deep learning is one of the key research areas among the Computer AiDed (CAD) diagnostic systems. When it is done manually, it is a very tedious and challenging task for a pathologist as it involves thorough scanning of tissues to detect malignancy. This paper presents Convolutional Neural Network (CNN) classifier for breast cancer detection on the Breast Histopathology Images (BHI) dataset. A confusion matrix is computed for the Bill samples to analyze the prediction results of the CNN classifier. The CNN detects carcinoma tissues while labeling 55,505 image test samples as positive or negative; and achieves accuracy of 84.93%, recall of 84.70% and F-measure as 76.07% respectively.","Breast Cancer,Breast Histopathology Images,Convolutional Neural Network,Invasive Ductal Carcinoma,Whole Slide images,Women",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORK,CANCER","PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING",,
42,Chronic Kidney Disease (CKD) Diagnosis using Multi-Layer Perceptron Classifier,,,346-350,"Vashisth Shubham,Dhall Ishika,Saraswat Shipra","Vashisth S,Dhall I,Saraswat S",Vashisth S,,Amity University Noida,"Chronic Kidney Disease or CKD is one of the most widespread Kidney diseases that affect people on a larger scale. It gives rise to other biological problems like weak bones, anemia, nerve damage, high blood pressure and can even lead to complete kidney failure. Millions of deaths are caused each year because of CKD. The diagnosis of CKD is a problematic job as there is no major symptom that serves a classification feature in detecting this disease. This paper proposes a Multi-Layer Perceptron Classifier that uses a fully connected Deep Neural Network to predict whether a patient suffers from the problem of CKD or not. The model is trained on a dataset of around 400 patients and considers various symptoms like blood pressure, age, sugar level, red blood cell count, etc. that assist the model in performing accurate classification. Our experimental results show that the proposed model can perform classification with the testing accuracy of 92.5%, surpassing the scores achieved by SVM and Naive Bayes Classifier.","chronic kidney disease,deep neural network,classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,"PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING",,
43,Evaluation of transfer learning techniques for classifying small surgical dataset,,,744-750,"Bali Shweta,Tyagi S. S.","Bali S,Tyagi SS",Bali S,,"FET Manav Rachna Int Inst Res & Studies MRIIRS, Dept Comp Sci & Engn CSE, Faridabad, India.","Deep learning is the key technology used in a large variety of applications such as self-driving cars, image recognition, automatic machine translation, automatic handwriting generation. The success was fueled due to accessibility of huge datasets, GPUs, max pooling. Earlier machine learning techniques employed two phases: features extraction and classification. The performance of such algorithms was highly dependent on how well the features are extracted and that was the major bottleneck of these techniques. Deep learning techniques employ Convolutional Neural Networks (CNNs) with numerous layers of non-linear processing for extracting the features automatically and classification that solves the previous problem. In the real time applications most of the time, either the dataset is unavailable or has less amount of data which makes it difficult to achieve accurate results for classifying the images. CNNs are hard to be trained using the small datasets. Transfer learning has emerged as a very powerful technique where in the knowledge gained from the larger dataset is transferred to the new dataset. Data augmentation and dropout are also powerful techniques that are useful for dealing with small datasets. In this paper, different techniques using the VGG16 pretrained model are compared on the small dataset.","Classification,Convolutional Neural Networks,Deep Learning,Transfer Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORKS,DEEP,ARCHITECTURES","PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING",,
44,Alzheimer Disease Prediction using Machine Learning Algorithms,,,101-104,"Neelaveni J.,Devasana M. S. Geetha","Neelaveni J,Devasana MSG",Neelaveni J,,Sri Ramakrishna Engineering College,"Alzheimer disease is the one amongst neurodegenerative disorders. Though the symptoms are benign initially, they become more severe over time. Alzheimer's disease is a prevalent sort of dementia. This disease is challenging one because there is no treatment for the disease. Diagnosis of the disease is done but that too at the later stage only. Thus if the disease is predicted earlier, the progression or the symptoms of the disease can be slow down. This paper uses machine learning algorithms to predict the Alzheimer disease using psychological parameters like age, number of visit, MMSE and education.","Aizheimer disease,mild cognitive impairment,psychological parameters",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,DIAGNOSIS,,,
45,Texture and Colour Gradient Features for Grade analysis of Pomegranate and Mango Fruits using kernel-SVM Classifiers,,,122-126,"Gurubelli Yogeswararao,Malmathanraj R.,Palanisamy P.","Gurubelli Y,Malmathanraj R,Palanisamy P",Gurubelli Y,,National Institute of Technology (NIT System),"There is an extended demand for quality fruits and vegetables for processing into juice, wine and syrup in today's competitive market. Traditional fruit and vegetable processing and grading of good and fresh quality is time consuming and requires more skilled labour. Computer vision and Machine learning approaches are the best solutions to the above mentioned problem. The present paper implements a novel approach of grade classification of pomegranate and mango fruits with texture and colour gradient features. Texture of the fruits are modelled using structural features using local binary pattern (LBP) and statistical features using pixel run length matrix (PRLM) and GLCM, while colour gradients (CG) of the fruits are calculated using average colour gradients, variances and colour coordinates of the three primary colours red, green and blue. Kernel support vector machine (KSVM) is used to grade/classify the extracted features from the proposed and existing methods. The statistical performance results show that the proposed approach is effective in grade classification and defect identification of the fruits with varying texture and colour gradients to an acceptable degree.","Local Binary Pattern,statistical features,GLCM,Colour Gradients,Run Length Matrix,kernel Support Vector Machine",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"COMPUTER,VISION",,,
46,Detection and Classification of Brain Tumor in MRI Images using Deep Convolutional Network,,,248-252,"Bhanothu Yakub,Kamalakannan Anandhanarayanan,Rajamanickam Govindaraj","Bhanothu Y,Kamalakannan A,Rajamanickam G",Bhanothu Y,,Council of Scientific & Industrial Research (CSIR) - India,"Brain tumor is a serious disease occurring in human being. Medical treatment process mainly depends on tumor types and its location. The final decision of neurospecialists and radiologist for the tumor diagnosis mainly depend on evaluation of MRI (Magnetic Resonance Imaging) Images. The manual evaluation process is time-consuming and needs domain expertise to avoid human errors. To overcome this issue, Faster R-CNN deep learning algorithm was proposed for detecting the tumor and marking the area of their occurrence with Region Proposal Network (RPN). The selected MR image dataset consists of three primary brain tumors namely glioma, meningioma and pituitary. The proposed algorithm uses VGG-16 architecture as a base layer for both the region proposal network and the classifier network. Detection and classification results of the algorithm demonstrate that it is able to achieve an average precision of 75.18% for glioma, 89.45% for meningioma and 68.18% for pituitary tumor. As a performance measure, the algorithm achieved a mean average precision of 77.60% for all the classes.","Brain tumor detection,glioma,meningioma,pituitary,Faster R-CNN,VGG-16,mean average precision,MRI",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,,,,
47,Dense Residual Convolutional Auto Encoder For Retinal Blood Vessels Segmentation,,,280-284,"Adarsh R.,Amarnageswarao Gadipudi,Pandeeswari R.,Deivalakshmi S.","Adarsh R,Amarnageswarao G,Pandeeswari R,Deivalakshmi S",Adarsh R,,National Institute of Technology (NIT System),"In order to overcome the difficulties in retinal blood vessel segmentation and aid ophthalmologists in diagnosis of diabetic retinopathy and glaucoma, there is a need for effective segmentation techniques. One such efficient technique is to use a model for segmentation using deep learning In this paper, an auto encoder deep learning network model based on residual path and U-net has been implemented to effectively segment the retinal blood vessels. Our network model has been implemented and tested on DRIVE dataset. This proposed model is reporting an increase in efficiency and Area under ROC compared to previous methods.","Residual Network,U-net,Retinal vessels,medical image segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,IMAGES,,,
48,A Comparative Study on Machine Learning and Artificial Neural Networking Algorithms,,,516-517,"Udaiyakumar R.,Vijayalakshmi N.,Prashanthram M.,Jayaprakash S.","Udaiyakumar R,Vijayalakshmi N,Prashanthram M,Jayaprakash S",Vijayalakshmi N,,"Sri Krishna Coll Technol, Dept ECE, Coimbatore, Tamil Nadu, India.","The diagnosis of heart disease by classical medical approach takes huge amount of time Besides blood tests and X-ray this approach includes multiple tests like MM, Echocardiogram and whose results are prone to misdiagnosis. Our proposed model can predict whether a patient with given health parameters and certain test results is affected by a heart disease. The proposed model uses AI approach with several ML algorithms like KNN, SVM, Decision Tree, Random forest classifiers and also with deep neural networks. This prediction is done based on the historical data collected from different medical Institutes in Central Europe.","KNN Classifier,Decision Tree,Support Vector Machine,Random Forest,Artificial Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,,,,
49,Artifact Removal using Elliptic Filter and Classification using 1D-CNN for EEG signals,,,551-556,"Nagabushanam P.,George S. Thomas,Davu Praharsha,Bincy P.,Naidu Meghana,Radha S.","Nagabushanam P,George ST,Davu P,Bincy P,Naidu M,Radha S",Radha S,,Karunya Institute of Technology & Sciences,"Convolution plays major role in deep learning. CNN is the basic architecture and most of the other deep learning architectures ae built based on CNN. However, 1D-CNN is suitable for EEG signals as it is time-series one dimensional characteristic signal. In this paper, we have proposed a 6-layer 1D-CNN to analyze the classification of EEG. Elliptic filter helps to filter Multivariate EEG signal of sleep apnea patient and then classify sleep stages using CNN. Simulations are carried out using Mat Lab.","EEG,1D-CNN,Artifact removal,elliptic filter",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,,,,
50,Skin Disease Classification from Image - A Survey,,,599-605,"Goswami Tanvi,Dabhi Vipul K.,Prajapati Harshadkumar B.","Goswami T,Dabhi VK,Prajapati HB",Goswami T,,Dharmsinh Desai University,"Skin diseases are one of the most common types of health illnesses faced by the people for ages. The identification of skin disease mostly relies on the expertise of the doctors and skin biopsy results, which is a time-consuming process. An automated computer-based system for skin disease identification and classification through images is needed to improve the diagnostic accuracy as well as to handle the scarcity of human experts. Classification of skin disease from an image is a crucial task and highly depends on the features of the diseases considered in order to classify it correctly. Many skin diseases have highly similar visual characteristics, which add more challenges to the selection of useful features from the image. The accurate analysis of such diseases from the image would improve the diagnosis, accelerates the diagnostic time and leads to better and cost-effective treatment for patients. This paper presents the survey of different methods and techniques for skin disease classification namely; traditional or handcrafted feature-based as well as deep learning-based techniques.","Skin diseases,lesions,classification,deep learning,CNN,SVM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,,,,
51,Spine Magnetic Resonance Image Segmentation Using Deep Learning Techniques,,,945-950,"Andrew J.,DivyaVarshini Murathoti,Barjo Prerna,Tigga Irene","Andrew J,DivyaVarshini M,Barjo P,Tigga I",Andrew J,,Karunya Institute of Technology & Sciences,"Spinal Malalignment is a chronic disease that is widespread across the world. It causes different diseases such as Stenosis, Scoliosis, Osteoporotic Fractures, Thoracolumbar fractures, Disc degeneration, etc. The diagnosis of such disease is generally done by analyzing the Magnetic Resonance Imaging (MRI) scan of the lumbar spine region. MRI analysis is done by well experienced medical professionals (radiologists and orthopedists). The flip side to this inspection is that it is time-consuming and may be subjected to a lack of accuracy. The manual segmentation of MRI scans from a large number of scan images is a tedious and time-consuming process. Thus, there is a need for automatic segmentation and analysis of spine MRI scans to improve clinical outputs and the accuracy of spinal measurements. In recent, the rise of deep learning technologies is making a revolution in medical systems. It is capable of analyzing a large amount of data and yield better accuracy. So, deep learning approaches can be efficiently used for the automatic segmentation of MRI scans. In this paper, an overview of spinal MRI segmentation using deep learning techniques is presented. The disease diagnosis from spine MRI is conferred. Then the state-of-art research in the automatic image segmentation using Convolutional Neural Network (CNN) is discussed. A comparative analysis is done on various deep learning techniques based on the performance metrics is presented. Finally, the evaluation metrics for automatic segmentation is provided along with the comparison of the state-of-art results.","CNN,MRI Segmentation,Spine MRI,Deep Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"THORACOLUMBAR,FRACTURES,NEURAL-NETWORKS,VERTEBRAE",,,
52,Pulmonary Nodule Detection Techniques in CT Images: New Strategies and Challenges,,,1279-1283,"Jacob Chinnu,Gopakumar C.","Jacob C,Gopakumar C",Gopakumar C,,"APJ Abdul Kalam Technol Univ, Coll Engn Karunagappally, Dept ECE, Thiruvananthapuram, Kerala, India.","Pulmonary cancer is considered as one among the fatal cancers globally. The only way to reduce its mortality rate is by early detection. Screening of lung cancer by computed tomography (CT) images is considered to be the most effective method for its initial analysis. The variation in the interpretation of nodules by different radiologists can pave a way for misdiagnosis. So, to tackle this problem computer-aided analysis act as a helping hand in its early detection. This paper provides an ample survey of the current techniques adopted in identifying lung nodules from CT scans. A high false-positive rate in shallow learning algorithms deteriorated its performance. This was resolved by the arrival of deep learning approaches in the sphere of image detection and classification. It has been observed that the nodule detection using 3D dense convolutional networks exhibits higher performance than other networks.","Computed Tomography (CT),Lung nodules,Convolutional Neural Networks (CNN),Computer aided detection (CAD)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Telecommunications",,,"AUTOMATIC,DETECTION,LUNG-CANCER,CLASSIFICATION,SYSTEM",,,
53,Bayesian Nonnegative Matrix Factorization With Dirichlet Process Mixtures,68,,3860-3870,"Li Caoyuan,Xie Hong-Bo,Mengersen Kerrie,Fan Xuhui,Da Xu Richard Yi,Sisson Scott A.,Van Huffel Sabine","Li CY,Xie HB,Mengersen K,Fan XH,Da Xu RY,Sisson SA,Van Huffel S",Xie HB,10.1109/TSP.2020.3003120,Queensland University of Technology (QUT),"Nonnegative Matrix Factorization (NMF) is valuable in many applications of blind source separation, signal processing and machine learning. A number of algorithms that can infer nonnegative latent factors have been developed, but most of these assume a specific noise kernel. This is insufficient to deal with complex noise in real scenarios. In this paper, we present a hierarchical Dirichlet process nonnegative matrix factorization (DPNMF) model in which the Gaussian mixture model is used to approximate the complex noise distribution. Moreover, the model is cast in the nonparametric Bayesian framework by using Dirichlet process mixture to infer the necessary number of Gaussian components. We derive a mean-field variational inference algorithm for the proposed nonparametric Bayesian model. We first test the model on synthetic data sets contaminated by Gaussian, sparse and mixed noise. We then apply it to extract muscle synergies from the electromyographic (EMG) signal and to select discriminative features for motor imagery single-trial electroencephalogram (EEG) classification. Experimental results demonstrate that DPNMF performs better in extracting the latent nonnegative factors in comparison with state-of-the-art methods.","Dirichlet process,nonnegative matrix factorization,nonparametric Bayesian methods,Gaussian mixture model,variational Bayes",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.239,"BCI,COMPETITION,2003,EEG",IEEE TRANSACTIONS ON SIGNAL PROCESSING,,
54,IDRiD: Diabetic Retinopathy - Segmentation and Grading Challenge,59,,,"Porwal Prasanna,Pachade Samiksha,Kokare Manesh,Deshmukh Girish,Son Jaemin,Bae Woong,Liu Lihong,Wang Jianzong,Liu Xinhui,Gao Liangxin","Porwal P,Pachade S,Kokare M,Deshmukh G,Son J,Bae W,Liu LH,Wang J,Liu XH,Gao LX",Porwal P,10.1016/j.media.2019.101561,Shri Guru Gobind Singhji Institute of Engineering & Technology,"Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on ""Diabetic Retinopathy - Segmentation and Grading"" was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI-2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal subchallenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular. (C) 2019 Elsevier B.V. All rights reserved.","Diabetic Retinopathy,Retinal image analysis,Deep learning,Challenge",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CONVOLUTIONAL,NEURAL-NETWORKS,RETINAL,IMAGE-ANALYSIS,RED,LESION,DETECTION,HIGHER-ORDER,SPECTRA,COLOR,FUNDUS,IMAGES,OPTIC,DISC,AUTOMATIC,DETECTION,MACULAR,EDEMA,MICROANEURYSM,DETECTION,FEATURE-EXTRACTION",MEDICAL IMAGE ANALYSIS,https://dea.lib.unideb.hu/dea/bitstream/2437/274207/1/FILE_UP_1_MEDIA-D-19-00049R1_rev1.pdf,
55,TRANSIENT EPIDERMAL ELECTRONICS FOR LEARNING THE PHYSIOLOGICAL SIGNATURES,,,76-79,"Zhang Yujia,Tao Tiger H.","Zhang YJ,Tao TH",Tao TH,,Chinese Academy of Sciences,"We report a set of transient epidermal electronics (TEEs) consisting of both physical and biochemical sensors that can monitor multi-dimensional physiological parameters such as electrocardiograms (ECG), electrooculography (EOG), and electromyography (EMG) as well as temperature, strain, humidity and on-skin bacterial infection. Strong adhesion and easy detachment are achieved concurrently through an environmentally benign, plasticized protein platform offering skin-friendly mechanical properties, stable performance during usage and moisture-triggered, on-demand decomposition lifetime (transiency). Moreover, using an artificial neural network (ANN), important physiology signatures can be identified that are nearly unaffected by individual differences. These skin-friendly electronics are essential in many daily physical exercise and clinically-relevant scenarios for skin-sensitive people (including infants and dermatosis patients); this enables their use on sensitive, vulnerable and even wounded skin regions without causing adverse effects.","Epidermal electronics,transient electronics,silk protein,resilin protein,physiological monitoring,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Science & Technology - Other Topics",,,"RATIONAL,DESIGN",,,
56,MULTI-BAND MEMS RESONANT MICROPHONE ARRAY FOR CONTINUOUS LUNG-SOUND MONITORING AND CLASSIFICATION,,,857-860,"Liu Hai,Liu Song,Shkel Anton A.,Tang Yongkui,Kim Eun Sok","Liu H,Liu S,Shkel AA,Tang YK,Kim ES",Liu H,,University of Southern California,"This paper reports a piezoelectric MEMS resonant microphone array for wheezing detection in lung sounds. The microphone array is composed of resonant cantilevers with serpentine support beams, and each of the resonant microphones has an unamplified sensitivity between 34.6 and 131.4 mV/Pa at the resonant frequencies, over a frequency range of 150 - 700 Hz (where wheezing spectral density is most prominent). With the high sensitivity and signal-to-noise ratio, wheezing is distinguished in both frequency domain and time domain, and as high as 97.73% identification accuracy is achieved on automatic classification through deep machine learning, when the resonant microphone array is used to record lung sounds.","MEMS microphone,resonant microphones,microphone array,lung sound monitoring,wheezing detection,deep learning,wearable stethoscope",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Science & Technology - Other Topics",,,,,,
57,"Automated Segmentation of Thyroid Nodule, Gland, and Cystic Components From Ultrasound Images Using Deep Learning",8,,63482-63496,"Kumar Viksit,Webb Jeremy,Gregory Adriana,Meixner Duane D.,Knudsen John M.,Callstrom Matthew,Fatemi Mostafa,Alizad Azra","Kumar V,Webb J,Gregory A,Meixner DD,Knudsen JM,Callstrom M,Fatemi M,Alizad A",Alizad A,10.1109/ACCESS.2020.2982390,Mayo Clinic,"Sonographic features associated with margins, shape, size, and volume of thyroid nodules are used to assess their risk of malignancy. Automatically segmenting nodules from normal thyroid gland would enable an automated estimation of these features. A novel multi-output convolutional neural network algorithm with dilated convolutional layers is presented to segment thyroid nodules, cystic components inside the nodules, and normal thyroid gland from clinical ultrasound B-mode scans. A prospective study was conducted, collecting data from 234 patients undergoing a thyroid ultrasound exam before biopsy. The training and validation sets encompassed 188 patients total; the testing set consisted of 48 patients. The algorithm effectively segmented thyroid anatomy into nodules, normal gland, and cystic components. The algorithm achieved a mean Dice coefficient of 0.76, a mean true positive fraction of 0.90, and a mean false positive fraction of 1.61 x 10(-6). The values are on par with a conventional seeded algorithm. The proposed algorithm eliminates the need for a seed in the segmentation process, thus automatically detecting and segmenting the thyroid nodules and cystic components. The detection rate for thyroid nodules and cystic components was 82% and 44%, respectively. The inference time per image, per fold was 107ms. The mean error in volume estimation of thyroid nodules for five select cases was 7.47%. The algorithm can be used for detection, segmentation, size estimation, volume estimation, and generating thyroid maps for thyroid nodules. The algorithm has applications in point of care, mobile health monitoring, improving workflow, reducing localization time, and assisting sonographers with limited expertise.","Deep learning,segmentation,thyroid nodule,thyroid nodule volume,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"TASK-FORCE,CANCER,MANAGEMENT,US,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09044381.pdf,
58,Future Scaling: Where Systems and Technology Meet,,,25-29,Collaert Nadine,Collaert N,Collaert N,,IMEC,"coming toward us, with numbers going to several hundreds of zettabytes per year by 2025! This data will need to be distributed, stored, computed, and analyzed to glean its most valuable information. At the heart of it will be innovations at the technology level, but also on the system side. With Moore's Law under pressure, a rethinking of what the semiconductor industry calls scaling will be needed.
In this paper, we will show that there is a strong push to technology diversification, blending different technologies together to achieve benefits at the system level. This brings the interaction of technology and design to the next level: system-technology co-optimization (STCO), with 3D technologies taking a central stage. Furthermore, the growing demand for storage will put an increasing pressure on the memory hierarchy where emerging concepts like MRAM, FeFET, so on, have the potential to bring new speed and capacity benefits. Next to that, memories such as RRAM are getting a lot of traction for analog in-memory computing to enable energy efficient machine learning at the IoT edge. Finally, we will also briefly review the status of quantum computing, these days gaining a lot of interest as a path to ultra-powerful computing.
Essentially, in this paper we motivate the following conclusions:
While there is an increasing pressure on CMOS scaling, the trend from pure dimensional 2D scaling to scaling at the cell level (track height reduction) will extend to the (sub-)system level.
In that respect, heterogeneous integration being able to co-integrate different technologies will gain in importance and 3D integration will take an important place as an enabling technology.
There is an increasing demand for storage and the boundaries between logic and memory are fading.
New computing paradigms such as machine learning (ML) and quantum computing needed for big data analytics and intractable computing problems are gaining a lot of traction, and they will benefit from innovations at the material, device, and architecture level to enable powerful and energy-efficient solutions.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
59,Non-contact PPG measurement system incorporating image analyzed photoplethysmogram signals and deep learning algorithms,11361,,,"Hsu Yu-Jie,Wang Chun-Hsiung,Lee Shu-Sheng,Wu Wen-Jong,Lee Chih-Kung","Hsu YJ,Wang CH,Lee SS,Wu WJ,Lee CK",Lee CK,10.1117/12.2555338,National Taiwan University,"We designed a new non-contact photoplethysmographic (PPG) measurement system by adopting an imaging-PPG (iPPG) method which used specific wavelengths detection and signal processing algorithms. PPG signals can be used to obtain information about blood oxygen saturation and provide diagnostic data on cardiovascular condition and atrial fibrillation (AFib). Most traditional PPG detection methods requires contacting sensors to the measuring surface. In our study, we developed a non-contact iPPG system with its high-potential performance to reduce the processing time. The selective narrow-band filter and incorporated an active illumination lighting array are used to designed according to the blood absorption spectrum. After collecting a series of iPPG images of a preset duration, the iPPG signals were remotely analyzed using traditional methods and using our deep learning (DL) algorithms. The DL algorithm based on a long short-term memory (LSTM) model was developed to fulfill waveform improvement. An InGaAs camera and a monochrome Si camera, both set at a 50fps frame rate, were used for field image detection. The measurement data collected at 550nm wavelength are shown in the discussion. Several indicators such as heart rhythm, peak-to-peak interval error, similarity, and root mean squared errors (RMSE) were adopted to compare the DL detection iPPG signal with the ECG and PPG signals. Our newly developed iPPG system has a high potential application for personnel health monitoring.","image photoplethysmogray,LED basal metrology,deep learning,long short-term memory",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
60,Plantar Fascia Ultrasound Images Characterization and Classification Using Support Vector Machine,1058,,102-111,"Boussouar Abdelhafid,Meziane Farid,Walton Lucy Anne","Boussouar A,Meziane F,Walton LA",Meziane F,10.1007/978-3-030-31129-2_10,University of Salford,"The examination of plantar fascia (PF) ultrasound (US) images is subjective and based on the visual perceptions and manual biometric measurements carried out by medical experts. US images feature extraction, characterization and classification have been widely introduced for improving the accuracy of medical assessment, reducing its subjective nature and the time required by medical experts for PF pathology diagnosis. In this paper, we develop an automated supervised classification approach using the Support Vector Machine (Linear and Kernel) to distinguishes between symptomatic and asymptomatic PF cases. Such an approach will facilitate the characterization and the classification of the PF area for the identification of patients with inferior heel pain at risk of plantar fasciitis. Six feature sets were extracted from the segmented PF region. Additionally, features normalization, features ranking and selection analysis using an unsupervised infinity selection method were introduced for the characterization and the classification of symptomatic and asymptomatic PF subjects.
The performance of the classifiers was assessed using confusion matrix attributes and some derived performance measures including recall, specificity, balanced accuracy, precision, F-score and Matthew's correlation coefficient. Using the best selected features sets, Linear SVM and Kernel SVM achieved an F-Score of 97.06 and 98.05 respectively.","Plantar fascia ultrasound images,Features selection and characterization,SVM,K-folded cross validation,Matthew's correlation coefficient",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Automation & Control Systems,Computer Science,Engineering",,,"TEXTURAL,FEATURES,THERAPY",,http://usir.salford.ac.uk/id/eprint/51434/1/AISI%202019.pdf,
61,Heartbeat Classification Using 1D Convolutional Neural Networks,1058,,502-511,"Shaker Abdelrahman M.,Tantawi Manal,Shedeed Howida A.,Tolba Mohamed F.","Shaker AM,Tantawi M,Shedeed HA,Tolba MF",Shaker AM,10.1007/978-3-030-31129-2_46,Egyptian Knowledge Bank (EKB),"Electrocardiogram (ECG) is an essential source of information for heart diseases classification. Hence, it is used by the cardiologist to diagnose heart attacks and detect the abnormalities of the heart. The automatic classification of the ECG signals is playing a vital role in the clinical diagnosis of heart diseases. In this paper, an end-to-end classification method is proposed using 1D Convolution Neural Networks (CNN) to extract the important features from the input signals and classify it automatically. The main advantage of CNN compared to the related work methods is that it gets rid of the hand-crafted features by combining the feature extraction and the classification into a single learning method without any human supervision. The proposed solution consists of data filtering, dynamic heartbeat segmentation, and 1D-CNN consisting of 10 layers without the input and the output layers.
Our experimental results on 14 classes of the public MIT-BIH arrhythmia dataset achieved a promising classification accuracy of 97.8% which outperforms several ECG classification methods.","ECG classification,Heart diseases,Convolution Neural Networks",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Automation & Control Systems,Computer Science,Engineering",,,"COMPONENT,ANALYSIS,ECG,RECOGNITION,FEATURES,MODEL",,,
62,An experimental study on upper limb position invariant EMG signal classification based on deep neural network,55,,,"Mukhopadhyay Anand Kumar,Samui Suman","Mukhopadhyay AK,Samui S",Samui S,10.1016/j.bspc.2019.101669,Indian Institute of Technology System (IIT System),"The classification of surface electromyography (sEMG) signal has an important usage in the man-machine interfaces for proper controlling of prosthetic devices with multiple degrees of freedom. The vital research aspects in this field mainly focus on data acquisition, pre-processing, feature extraction and classification along with their feasibility in practical scenarios regarding implementation and reliability. In this article, we have demonstrated a detailed empirical exploration on Deep Neural Network (DNN) based classification system for the upper limb position invariant myoelectric signal. The classification of eight different hand movements is performed using a fully connected feed-forward DNN model and also compared with the existing machine learning tools. In our analysis, we have used a dataset consisting of the sEMG signals collected from eleven subjects at five different upper limb positions. The time domain power spectral descriptors (TDPSD) is used as the feature set to train the DNN classifier. In contrast to the prior methods, the proposed approach excludes the feature dimensionality reduction step, which in turn significantly reduce the overall complexity. As the EMG signal classification is a subject-specific problem, the DNN model is customized for each subject separately to get the best possible results. Our experimental results in various analysis frameworks demonstrate that DNN based system can outperform the other existing classifiers such as k-Nearest Neighbour (kNN), Random Forest, and Decision Tree. The average accuracy obtained among the five subjects for DNN, SVM, kNN, Random Forest and Decision Tree is 98.88%, 98.66%, 90.64%, 91.78%, and 88.36% respectively. Moreover, it can achieve competitive performance with the state-of-the-art SVM based model, even though the proposed DNN model requires minimal processing in feature engineering. This study provides an insight into the detailed step-by-step empirical procedure to achieve the optimum results regarding classification accuracy using the DNN model. (C) 2019 Elsevier Ltd. All rights reserved.","sEMG signal classification,Deep neural network,Electromyogram,Upper-limb invariant,Hand movement classification,Prosthetic application",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"INDEPENDENT,COMPONENT,ANALYSIS,MYOELECTRIC,PATTERN-RECOGNITION,SURFACE,EMG,PROSTHESES,EXTRACTION,SEPARATION,SCHEME",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
63,Stratified squamous epithelial biopsy image classifier using machine learning and neighborhood feature selection,55,,,"Nawandhar Archana,Kumar Navin,Veena R.,Yamujala Lakshmi","Nawandhar A,Kumar N,Veena R,Yamujala L",Kumar N,10.1016/j.bspc.2019.101671,Amrita Vishwa Vidyapeetham,"Squamous cell carcinoma (SCC) of oral cavity is the most common among oral cancer patients. In this paper, we have developed machine learning based automatic oral squamous cell carcinoma (OSCC) classifier named as Stratified Squamous Epithelial Biopsy Image Classifier (SSE-BIC) to categorize H&E-stained microscopic images of squamous epithelial layer in four different classes: normal, well-differentiated, moderately-differentiated and poorly-differentiated. Five classifiers are used to perform the classification by maximum voting method. Total 305 features are extracted from the images of oral mucosa which include color features, textural features, gradient features, geometrical features and tamura features. Unsupervised data mining is used for segmenting the cellular area to compute geometrical features of the cells retaining color details of the images. Feature selection has been performed by neighborhood component feature selection (NCFS) technique. Total 676 images have been used to design, train and test the classifier. A detailed performance analysis is presented with individual feature sets and hybrid feature sets with feature selection applied using individual classifiers as well as proposed classifier. The proposed classifier achieves overall accuracy of 95.56%. This can account for first level of automatic screening of the biopsy images. (C) 2019 Elsevier Ltd. All rights reserved.","H&E-stained microscopic image,Oral squamous cell carcinoma,SVM,NCFS,Decision tree,RS-LDA",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"TEXTURAL,FEATURES,CANCER,SEGMENTATION,DIAGNOSIS",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
64,RescueNet: An unpaired GAN for brain tumor segmentation,55,,,"Nema Shubhangi,Dudhane Akshay,Murala Subrahmanyam,Naidu Srivatsava","Nema S,Dudhane A,Murala S,Naidu S",Murala S,10.1016/j.bspc.2019.101641,Indian Institute of Technology System (IIT System),"Even with proper acquisition of brain tumor images, the accurate and reliable segmentation of tumors in brain is a complicated job. Automatic segmentation become possible with development of deep learning algorithms that brings plethora of solutions in this research prospect. In this paper, we designed a network architecture named as residual cyclic unpaired encoder-decoder network (RescueNet) using residual and mirroring principles. RescueNet uses unpaired adversarial training to segment the whole tumor followed by core and enhance regions in a brain MRI scan. The problem in automatic brain tumor analysis is preparing large scale labeled data for training of deep networks which is a time consuming and tedious task. To eliminate this need of paired data we used unpaired training approach to train the proposed network. Performance evaluation parameters are taken as DICE and Sensitivity measure. The experimental results are tested on BraTS 2015 and BraTS 2017 [1] dataset and the result outperforms the existing methods for brain tumor segmentation. The combination of domain-specific segmentation methods and general-purpose adversarial learning loomed to leverage huge advantages for medical imaging applications and can improve the ability of automated algorithms to assist radiologists. (C) 2019 Elsevier Ltd. All rights reserved.","Computer aided diagnosis,Brain tumor,BraTS,Deep learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,,MODEL,BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
65,Cervical precancerous lesions classification using pre-trained densely connected convolutional networks with colposcopy images,55,,,"Zhang Tao,Luo Yan-min,Li Ping,Liu Pei-zhong,Du Yong-zhao,Sun Pengming,Dong BinHua,Xue Huifeng","Zhang T,Luo YM,Li P,Liu PZ,Du YZ,Sun PM,Dong BH,Xue HF",Luo YM,10.1016/j.bspc.2019.101566,Huaqiao University,"Colposcopy is currently a common medical technique for preventing cervical cancer. However, with the increase of the workload, screening by artificial vision has the problems of misdiagnosis and low diagnostic efficiency. Based on transfer learning, pre-trained densely connected convolutional networks are used to propose a computer-aided-diagnosis (CAD) method for automatic classification of cervical precancerous. The proposed method is applied to determine CIN2 or higher-level lesions in cervical images. In the present work, image data are initially prepossessing with ROI extraction and data augmentation. Then, parameters of all layers are fine-tuning with pre-trained DenseNet convolutional neural networks from two datasets (ImageNet and Kaggle). The impact of different training strategies on the model performance with limited training data is analyzed, including random initialization (RI) training from scratch, fine-tuning (FT) pre-trained model, different size of training data and K-fold cross-validation. Experimental results show that our method (FT) achieves an accuracy of 73.08% (AUC approximate to 0.75) in 600 test images. Compared with previous related work and clinicians, the performance of our approach can effective diagnosis CIN2+ and comparable with a senior physician, which proves the feasibility and promising of the proposed computer-aided diagnostic method. (C) 2019 Elsevier Ltd. All rights reserved.","Colposcopy,Cervical precancerous,Computer-aided diagnosis,Densely connected convolutional networks,Transfer learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,NEURAL-NETWORK,BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
66,Learning-based vertebra localization and labeling in 3D CT data of possibly incomplete and pathological spines,183,,,"Jakubicek Roman,Chmelik Jiri,Jan Jiri,Ourednicek Petr,Lambert Lukas,Gavelli Giampaolo","Jakubicek R,Chmelik J,Jan J,Ourednicek P,Lambert L,Gavelli G",Jakubicek R,10.1016/j.cmpb.2019.105081,Brno University of Technology,"Background and objective: We present a fully automatic system based on learning approaches, which aims to localization and identification (labeling) of vertebrae in 3D computed tomography (CT) scans of possibly incomplete spines in patients with bone metastases and vertebral compressions.
Methods: The framework combines a set of 3D algorithms for i) spine detection using a convolution neural network (CNN) ii) spinal cord tracking based on combination of a CNN and a novel growing sphere method with a population optimization, iii) intervertebral discs localization using a novel approach of spatially variant filtering of intensity profiles and iv) vertebra labeling using a CNN-based classification combined with global dynamic optimization.
Results: The proposed algorithm has been validated in testing databases, including also a publicly available dataset. The mean error of intervertebral discs localization is 4.4 mm, and for vertebra labeling, the average rate of correctly identified vertebrae is 87.1%, which can be considered a good result with respect to the large share of highly distorted spines and incomplete spine scans.
Conclusions: The proposed framework, which combines several advanced methods including also three CNNs, works fully automatically even with incomplete spine scans and with distorted pathological cases. The achieved results allow including the presented algorithms as the first phase to the fully automated computer-aided diagnosis (CAD) system for automatic spine-bone lesion analysis in oncological patients. (C) 2019 Elsevier B.V. All rights reserved.","Vertebra detection,Learning-based approach,Convolution neural network,Pathological vertebrae",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,SEGMENTATION,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
67,Application of deep canonically correlated sparse autoencoder for the classification of schizophrenia,183,,,"Li Gang,Han Depeng,Wang Chao,Hu Wenxing,Calhoun Vince D.,Wang Yu-Ping","Li G,Han DP,Wang C,Hu WX,Calhoun VD,Wang YP",Li G,10.1016/j.cmpb.2019.105073,Chang'an University,"Background and objective: Imaging genetics has been widely used to help diagnose and treat mental illness, e.g., schizophrenia, by combining magnetic resonance imaging of the brain and genomic information for comprehensive and systematic analysis. As a result, utilizing the correlation between magnetic resonance imaging of the brain and genomic information is becoming an important challenge.
Methods: In this paper, the joint analysis of single nucleotide polymorphisms and functional magnetic resonance imaging is conducted for comprehensive study of schizophrenia. We developed a deep canonically correlated sparse autoencoder to classify schizophrenia patients from healthy controls, which can address the limitation of many existing methods such as canonical correlation analysis, deep canonical correlation analysis and sparse autoencoder.
Results: The proposed deep canonically correlated sparse autoencoder can not only use complex nonlinear transformation and dimension reduction, but also achieve more accurate classifications. Our experiments showed the proposed method achieved an accuracy of 95.65% for SNP data sets and an accuracy of 80.53% for fMRI data sets.
Conclusions: Experiments demonstrated higher accuracy of using the proposed method over other conventional models when classifying schizophrenia patients and healthy controls. (C) 2019 Elsevier B.V. All rights reserved.","Imaging-genetic associations,Canonical correlation analysis,Sparse autoencoder,Deep canonically correlated sparse autoencoder,Schizophrenia classification",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"BIPOLAR,DISORDER,WORKING-MEMORY,SNP,DATA,FMRI,GENETICS,LINKAGE,DISC1,RISK",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
68,"Role of image thermography in early breast cancer detection- Past, present and future",183,,,"Singh Deepika,Singh Ashutosh Kumar","Singh D,Singh AK",Singh D,10.1016/j.cmpb.2019.105074,Indian Institute of Information Technology Allahabad,"One of the most prevalent cancers among women is the breast cancer. Accurate diagnosis of breast cancer at an early stage can reduce the mortality associated with this disease. Infrared Breast Thermography, which is a screening tool used to measure the temperature distribution of breast tissue, is a suitable adjunct tool to mammography. Breast thermography has many advantages as it is non-invasive, safe and painless. Thermographic image and usage of artificial neural networks have improved the accuracy of thermography in early diagnosis of breast abnormality. This paper presents survey based on the main steps of computer aided detection systems: image acquisition protocols, segmentation techniques, feature extraction and classification methods, used in the field of breast thermography over the past few decades. The detailed survey emphasizes on the improved reliability of breast thermography. This has become possible with the utilization of machine learning techniques for correct classification of breast thermograms. Numerical Simulation can be used as a supporting method to overcome high false positive rates in thermographic diagnosis. The paper also presents future recommendations to utilize recent machine learning advances in real time. (C) 2019 Elsevier B.V. All rights reserved.","Infrared breast thermography,Region of interest,Segmentation,Feature extraction,Classification,Numerical simulation",Review,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"TEXTURE,FEATURES,SEGMENTATION,DENSITY",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
69,Machine learning in cardiovascular flows modeling: Predicting arterial blood pressure from non-invasive 4D flow MRI data using physics-informed neural networks,358,,,"Kissas Georgios,Yang Yibo,Hwuang Eileen,Witschey Walter R.,Detre John A.,Perdikaris Paris","Kissas G,Yang YB,Hwuang E,Witschey WR,Detre JA,Perdikaris P",Perdikaris P,10.1016/j.cma.2019.112623,University of Pennsylvania,"Advances in computational science offer a principled pipeline for predictive modeling of cardiovascular flows and aspire to provide a valuable tool for monitoring, diagnostics and surgical planning. Such models can be nowadays deployed on large patient-specific topologies of systemic arterial networks and return detailed predictions on flow patterns, wall shear stresses, and pulse wave propagation. However, their success heavily relies on tedious pre-processing and calibration procedures that typically induce a significant computational cost, thus hampering their clinical applicability. In this work we put forth a machine learning framework that enables the seamless synthesis of non-invasive in-vivo measurement techniques and computational flow dynamics models derived from first physical principles. We illustrate this new paradigm by showing how one-dimensional models of pulsatile flow can be used to constrain the output of deep neural networks such that their predictions satisfy the conservation of mass and momentum principles. Once trained on noisy and scattered clinical data of flow and wall displacement, these networks can return physically consistent predictions for velocity, pressure and wall displacement pulse wave propagation, all without the need to employ conventional simulators. A simple post-processing of these outputs can also provide a relatively cheap and effective way for estimating Windkessel model parameters that are required for the calibration of traditional computational models. The effectiveness of the proposed techniques is demonstrated through a series of prototype benchmarks, as well as a realistic clinical case involving in-vivo measurements near the aorta/carotid bifurcation of a healthy human subject. (C) 2019 Elsevier B.V. All rights reserved.","Deep neural networks,Blood flow modeling,Pulse wave propagation,Data-driven modeling,Non-invasive diagnostics",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"ONE-DIMENSIONAL,MODEL,UNCERTAINTY,QUANTIFICATION,BOUNDARY-CONDITIONS,WAVE-PROPAGATION,SIMULATIONS,VALIDATION,1-D,CIRCULATION,PARAMETERS,FRAMEWORK",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,http://arxiv.org/pdf/1905.04817,
70,Semi-supervised mp-MRI data synthesis with StitchLayer and auxiliary distance maximization,59,,,"Wang Zhiwei,Lin Yi,Cheng Kwang-Ting (Tim),Yang Xin","Wang ZW,Lin Y,Cheng KT,Yang X",Yang X,10.1016/j.media.2019.101565,Huazhong University of Science & Technology,"The availability of a large amount of annotated data is critical for many medical image analysis applications, in particular for those relying on deep learning methods which are known to be data-hungry. However, annotated medical data, especially multimodal data, is often scarce and costly to obtain. In this paper, we address the problem of synthesizing multi-parameter magnetic resonance imaging data (i.e. mp-MRI), which typically consists of Apparent Diffusion Coefficient (ADC) and T2-weighted (T2w) images, containing clinically significant (CS) prostate cancer (PCa) via semi-supervised learning and adversarial learning. Specifically, our synthesizer generates mp-MRI data in a sequential manner: first utilizing a decoder to generate an ADC map from a 128-d latent vector, followed by translating the ADC to the T2w image via U-Net. The synthesizer is trained in a semi-supervised manner. In the supervised training process, a limited amount of paired ADC-T2w images and the corresponding ADC encodings are provided and the synthesizer learns the paired relationship by explicitly minimizing the reconstruction losses between synthetic and real images. To avoid overfitting limited ADC encodings, an unlimited amount of random latent vectors and unpaired ADC-T2w Images are utilized in the unsupervised training process for learning the marginal image distributions of real images. To improve the robustness for training the synthesizer, we decompose the difficult task of generating full-size images into several simpler tasks which generate sub-images only. A StitchLayer is then employed to seamlessly fuse sub-images together in an interlaced manner into a full-size image. In addition, to enforce the synthetic images to indeed contain distinguishable CS PCa lesions, we propose to also maximize an auxiliary distance of Jensen-Shannon divergence (JSD) between CS and nonCS images. Experimental results show that our method can effectively synthesize a large variety of mp-MRI images which contain meaningful CS PCa lesions, display a good visual quality and have the correct paired relationship between the two modalities of a pair. Compared to the state-of-the-art methods based on adversarial learning (Liu and Tuzel, 2016; Costa et al., 2017), our method achieves a significant improvement in terms of both visual quality and several popular quantitative evaluation metrics. (C) 2019 Elsevier B.V. All rights reserved.","Generative models,GAN,Multimodal image synthesis,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,PROSTATE-CANCER,MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/1812.06625,
71,Segmentation and quantification of infarction without contrast agents via spatiotemporal generative adversarial learning,59,,,"Xu Chenchu,Howey Joanne,Ohorodnyk Pavlo,Roth Mike,Zhang Heye,Li Shuo","Xu CC,Howey J,Ohorodnyk P,Roth M,Zhang HY,Li S",Li S,10.1016/j.media.2019.101568,Western University (University of Western Ontario),"Accurate and simultaneous segmentation and full quantification (all indices are required in a clinical assessment) of the myocardial infarction (MI) area are crucial for early diagnosis and surgical planning. Current clinical methods remain subject to potential high-risk, nonreproducibility and time-consumption issues. In this study, a deep spatiotemporal adversarial network (DSTGAN) is proposed as a contrast-free, stable and automatic clinical tool to simultaneously segment and quantify MIs directly from the cine MR image. The DSTGAN is implemented using a conditional generative model, which conditions the distributions of the objective cine MR image to directly optimize the generalized error of the mapping between the input and the output. The method consists of the following: (1) A multi-level and multi-scale spatiotemporal variation encoder learns a coarse to fine hierarchical feature to effectively encode the MI specific morphological and kinematic abnormality structures, which vary for different spatial locations and time periods. (2) The top-down and cross-task generators learn the shared representations between segmentation and quantification to use the commonalities and differences between the two related tasks and enhance the generator preference. (3) Three inter-/intra-tasks to label the relatedness discriminators are iteratively imposed on the encoder and generator to detect and correct the inconsistencies in the label relatedness between and within tasks via adversarial learning. Our proposed method yields a pixel classification accuracy of 96.98%, and the mean absolute error of the MI centroid is 0.96 mm from 165 clinical subjects. These results indicate the potential of our proposed method in aiding standardized MI assessments. (C) 2019 Elsevier B.V. All rights reserved.","Myocardial infarction,Segmentation,Full quantification,Sequential images,Generative adversarial networks",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"MYOCARDIAL-INFARCTION,MR-IMAGES,REGRESSION,TRANSMURALITY,ENHANCEMENT,MOTION,SIZE,SCAR",MEDICAL IMAGE ANALYSIS,,
72,Evaluation and Prediction of Early Alzheimer's Disease Using a Machine Learning-based Optimized Combination-Feature Set on Gray Matter Volume and Quantitative Susceptibility Mapping,17,5,428-437,"Kim Hyug-Gi,Park Soonchan,Rhee Hak Y.,Lee Kyung M.,Ryu Chang-Woo,Lee Soo Y.,Kim Eui J.,Wang Yi,Jahng Geon-Ho","Kim HG,Park S,Rhee HY,Lee KM,Ryu CW,Lee SY,Kim EJ,Wang Y,Jahng GH",Jahng GH,10.2174/1567205017666200624204427,Kyung Hee University,"Background: Because Alzheimer's Disease (AD) has very complicated pattern changes, it is difficult to evaluate it with a specific factor. Recently, novel machine learning methods have been applied to solve limitations.
Objective: The objective of this study was to investigate the approach of classification and prediction methods using the Machine Learning (ML)-based Optimized Combination-Feature (OCF) set on Gray Matter Volume (GMV) and Quantitative Susceptibility Mapping (QSM) in the subjects of Cognitive Normal (CN) elderly, Amnestic Mild Cognitive Impairment (aMCI), and mild and moderate AD.
Materials and Methods: 57 subjects were included: 19 CN, 19 aMCI, and 19 AD with GMV and QSM. Regions-of-Interest (ROIs) were defined at the well-known regions for rich iron contents and amyloid accumulation areas in the AI) brain. To differentiate the three subject groups, the Support Vector Machine (SVM) with the three different kernels and with the OCF set was conducted with GMV and QSM values. To predict the aMCI stage, regression-based ML models were performed with the OCF set. The result of prediction was compared with the accuracy of clinical data.
Results: In the group classification between CN and aMCI, the highest accuracy was shown using the combination of GMVs (hippocampus and entorhinal cortex) and QSMs (hippocampus and pulvinar) data using the r d SVM classifier (AUC = 0.94). In the group classification between aMCI and AD, the highest accuracy was shown using the combination of GMVs (amygdala, entorhinal cortex, and posterior cingulate cortex) and QSMs (hippocampus and pulvinar) data using the 2nd SVM classifier (AUC = 0.93). In the group classification between CN and AD, the highest accuracy was shown using the combination of GMVs (amygdala, entorhinal cortex, and posterior cingulate cortex) and QSMs (hippocampus and pulvinar) data using the 2nd SVM classifier (AUC = 0.99). To predict aMCI from CN, the exponential Gaussian process regression model with the OCF set using GMV and QSM data was shown the most similar result (RMSE = 0.371) to clinical data (RMSE = 0.319).
Conclusion: The proposed OCF based ML approach with GMV and QSM was shown the effective performance of the subject group classification and prediction for aMCI stage. Therefore, it can be used as personalized analysis or diagnostic aid program for diagnosis.","Alzheimer's disease (AD),mild cognitive impairment (MCI),quantitative susceptibility mapping (QSM),gray matter volume (GMV),neurodegenerative disorder,memory loss",Article,"BENTHAM SCIENCE PUBL LTD, EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES",Neurosciences & Neurology,,4.083,"MILD,COGNITIVE,IMPAIRMENT,BRAIN,IRON",CURRENT ALZHEIMER RESEARCH,,
73,Performance comparison between model-based and machine learning approaches for the automated active alignment of FAC-lenses,11262,,,"Hoeren Maximilian,Zontar Daniel,Tavakolian Armin,Berger Marvin,Ehret Susanne,Mussagaliyev Temirlan,Brecher Christian","Hoeren M,Zontar D,Tavakolian A,Berger M,Ehret S,Mussagaliyev T,Brecher C",Hoeren M,10.1117/12.2546607,Fraunhofer Gesellschaft,"Due to their short focal lengths, FAC lenses significantly influence the performance of high-power diode laser systems. In addition to the shape, coating and surface quality, high demands are placed on the assembly accuracy for these microoptical components. In order to optimally align and position the lenses despite varying properties (e.g. focal length), active alignment strategies are used. The automation of the active alignment process for production offers enormous potential. Compared to manual processes, the reproducibility and accuracy of the alignment is increased. For the automation of the active alignment process, a deep understanding of the system behaviour is necessary. To control a diversity of variants cost-effectively and robust, new approaches must be taken into account. Concepts of AI or machine learning are great for this kind of generalization and adoption and they have many advantages for the active alignment of systems like DOEs or free-form-optics, with a complex system behaviour. In this publication, we want to compare the performance of a classically model-based algorithm and a machine learning approach for the automated active alignment of FAC-lenses. The model-based algorithm uses a physical model of the metrology system ( including the FAC to be aligned) to estimate a misalignment in 4-DOF. The machine learning algorithm consist of a deep neuronal network which was trained with image data.","Automated Active Alignment,Fast-Axis-Collimator,Precision Optics Assembly,Machine Learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Physics",,,,,,
74,A Novel MKL Method for GBM Prognosis Prediction by Integrating Histopathological Image and Multi-Omics Data,24,1,171-179,"Zhang Ya,Li Ao,He Jie,Wang Minghui","Zhang Y,Li A,He J,Wang MH",Li A,10.1109/JBHI.2019.2898471,Chinese Academy of Sciences,"Glioblastoma multiforme (GBM) is one of the most malignant brain tumors with very short prognosis expectation. To improve patients' clinical treatment and their life quality after surgery, researches have developed tremendous in silico models and tools for predicting GBM prognosis based on molecular datasets and have earned great success. However, pathology still plays the most critical role in cancer diagnosis and prognosis in the clinic at present. Recent advancement of storing and processing histopathological images has drawn attention of researchers. Models based on histopathological images are developed, which show great potential for computer-aided pathological diagnoses. But models based on both molecular and histopathological images that could predict GBM prognosis with high accuracy are not present yet. In our previous research, we used the simple MKL method to integrate multi-omics data to improve GBM prognosis prediction successfully. In this paper, we have developed a novel multiple kernel learning (MKL) method, named histopathological integrating multiple kernel learning (HI-MKL), that could integrate both histopathological images and multi-omics data efficiently. By using datasets from The Cancer Genome Atlas project, we have built a system that could predict the GBM prognosis with high accuracy. Our research shows that HI-MKL is an accurate, robust, and generalized MKL method, which performs well in a GBM prognosis task.","Prognostics and health management,Feature extraction,Cancer,Shape measurement,Size measurement,Area measurement,Kernel,Gliomas,glioblastoma multiforme,GBM,multiple kernel learning,MKL,prognosis prediction,prognosis classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"MRMR,FILTER,CLASSIFICATION,TUMORS,SURVIVAL",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
75,[Creating a Predictive Model of the Contrast Enhancement for Coronary CT Angiography by Using Statistical Analysis and Machine Learning].,76,9,906-910,",","Akiyama Nobuyuki,Nakamura Yukihiro",,10.6009/jjrt.2020_JSRT_76.9.906,,,"contrast media; coronary CT angiography; ,machine learning,; statistical analysis",Journal Article,,,,,,,,
76,A Novel Deep Learning Approach for the Removal of Speckle Noise from Optical Coherence Tomography Images Using Gated Convolution-Deconvolution Structure,1024,,115-126,"Menon Sandeep N.,Reddy V. B. Vineeth,Yeshwanth A.,Anoop B. N.,Rajan Jeny","Menon SN,Reddy VBV,Yeshwanth A,Anoop BN,Rajan J",Anoop BN,10.1007/978-981-32-9291-8_10,National Institute of Technology (NIT System),Optical coherence tomography (OCT) is an imaging technique widely used to image retina. Speckle noise in OCT images generally degrades the quality of the OCT images and makes the clinical diagnosis tedious. This paper proposes a new deep neural network despeckling scheme called gated convolution-deconvolution structure (GCDS). The robustness of the proposed method is evaluated on the publicly available OPTIMA challenge dataset and Duke dataset. The quantitative analysis based on PSNR shows that the results of the proposed method are superior to other state-of-the-art methods. The application of the proposed method for segmenting retinal cyst from OPTIMA challenge dataset was also studied.,"OCT,GCDS,Speckle noise,Denoising",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE","Computer Science,Engineering,Imaging Science & Photographic Technology",,,REDUCTION,,,
77,Image Embedding for Detecting Irregularity,1024,,243-255,"Sharma M. K.,Sheet D.,Biswas Prabir Kumar","Sharma MK,Sheet D,Biswas PK",Sharma MK,10.1007/978-981-32-9291-8_20,Indian Institute of Technology System (IIT System),"Detecting irregularity in an image or video is an important task in quality control or automatic visual inspection. This paper presents an image embedding technique for detecting an irregularity or abnormality in images. This can further be utilized in image screening application. In the proposed architecture, deep adversarial autoencoder is trained to extract the features from images. Using these features and skip-gram model, we develop the image2vec architecture to capture contextual probability in an image. Various score aggregation techniques are explored and its performance is reported. As a case study, we present a scenario of foreign body object detection in clinical-grade X-ray images. The proposed approach is found to correctly detect and localize abnormality in images.","Visual inspection,Image embedding,Contextual abnormality detection,Adversarial autoencoder,Skip-gram,Negative sampling",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE","Computer Science,Engineering,Imaging Science & Photographic Technology",,,,,,
78,Complementarity of Sensors and Weak Supervision for Defect Detection in Concrete Structures,,,1-6,"Kasahara Jun Younes Louhi,Fujii Hiromitsu,Yamashita Atsushi,Asama Hajime","Kasahara JYL,Fujii H,Yamashita A,Asama H",Kasahara JYL,,University of Tokyo,"The automation of concrete structure inspection methods such as the hammering test is highly desirable and critical, especially for social infrastructures such as tunnels and bridges. This is to ensure the safety of their users. Semi supervised approaches have great compatibility with critical inspection methods since they allow to greatly reduce the workload on humans while still not removing them completely from the process, and thus providing some level of reassuring confidence. However, the performance of such semi-supervised approaches is conditioned by the correctness of the provided weak supervision by human and it can easily be imagined that. in practice, weak supervision will rarely be without errors. Therefore, the present paper proposes a method to complement weak supervision using sensor-provided information in order to both increase performance and mitigate the negative impacts of human errors. Experiments conducted in laboratory conditions using concrete test blocks in various configurations showed the effectiveness of the proposed method, returning better performance and higher robustness to errors in weak supervision.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,,,
79,Development of a Needle Deflection Detection System for a CT Guided Robot,,,34-38,"Guinot Lena,Tsumura Ryosuke,Inoue Shun,Iwata Hiroyasu","Guinot L,Tsumura R,Inoue S,Iwata H",Guinot L,,Waseda University,"The uncertainty and unpredictability regarding the occurrence of needle deflection during percutaneous puncture, especially when using very fine needles, can greatly, complexity surgical tasks such as needle insertion in the lower abdomen. To avoid the increased risks induced by prolonged CT scan radiation exposure, this paper offers an alternative to the retrieval of needle tip position from CT scan images. In this method, the deflection of the needle is detected and reported in accordance with insertion force data as the needle is inserted into the bowel. This method relies on the use of a Gated Recurrent Unit based neural network to predict the occurrence and type of deflection met during the procedure depending on the intended path and tissue type to be punctured in order to reach the target (cancer tumor). This system accounts for the original angle of insertion of the needle. Results of final experiments returned a 100% true positive rate, signifying that in the eventuality of needle deflection, it would systematically have been predicted by the neural network.","machine learning,needle deflection,robot assisted needle insertion",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"LIVER-BIOPSY,SOFT-TISSUE,COMPLICATIONS,RISK,INSERTION",,,
80,Structural displacement compensation of a gigantic manipulator via deep learning,,,219-224,"Maruyama T.,Ogawa S.,Noda K.,Edaya M.,Jaklin N.,Tolsma S.,Takeda N.","Maruyama T,Ogawa S,Noda K,Edaya M,Jaklin N,Tolsma S,Takeda N",Maruyama T,,National Institutes for Quantum & Radiological Science & Technology (QST)-Japan,"Structures of robotic systems that handle extremely heavy loads undergo static displacement. The ITER blanket remote handling system, which handles 4-ton objects, has displacements of up to 100 mm at the end effector. We propose a novel method that combines deep learning with a physics-based virtual reality system to compensate for displacement. Our deep learning model was trained by using data obtained from both the virtual reality system and physical measurement data of end effector positions. By using a prototype of the ITER blanket remote handling system, we experimentally show that our method successfully reduces the displacement at the end effector to a maximum error of 5.7 mm and a median error of 1.2 mm. We conclude that our approach provides an effective contribution to ensuring the feasibility and safety of the remote maintenance procedures that are to be performed within the ITER project.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,,,
81,Enhancement of child gross-motor action recognition by motional time-series images conversion,,,225-230,"Suzuki Satoshi,Amemiya Yukie,Sato Maiko","Suzuki S,Amemiya Y,Sato M",Suzuki S,,Tokyo Denki University,"Acquisition of gross motor skills during childhood is quite significant for the physical and psychological developments; hence, early intervention and adequate care are desired if possibility of their developmental disability is discovered. Due to these reasons, several tests were presented and have been used in several countries, but they are not so popular in Japan because of staff shortage and/or time deficit. Therefore, the present authors have been studying a labor-saving AI assessment system based on the gross motor action recognition (GM-AR). In our previous studies, main scheme of the system was proposed, and several IT tools and the GM-ARs were developed. This paper focuses on an improvement of the GM-AR by expanding the previous result, and the following three methods are newly presented: conversion of the skeleton's time-series data into motional time-series images, the data augmentation, and new CNN-based deep learning. As a result, applying these methods to actual GM assessment including thirteen GM skills at kindergarten, total about 0.15 million data sets were obtained and the classification accuracy was extremely improved to 99.5% by cross validation.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,,,
82,Active Learning of the Cutting of Cooking Ingredients using Simulation with Object Splitting,,,1224-1231,"Ikegami Nahomi,Arnold Solvi,Nagahama Kotaro,Yamazaki Kimitoshi","Ikegami N,Arnold S,Nagahama K,Yamazaki K",Ikegami N,,Shinshu University,"Food preparation is hard to automate on general-purpose robot hardware. This work focuses on acquisition of cutting manipulations for food preparation. We construct a physical simulation environment for virtually performing cutting operations on food ingredients, including routines for splitting food object models at arbitrary positions, and design a compact manipulation description format. Using the simulation environment, we generate data for training a neural network architecture (EMD-net) to predict the state transformation induced by a given cutting manipulation and evaluate the network's performance. We also perform automatic generation of cutting manipulations for obtaining a given goal state from a given initial state, and evaluate the obtained manipulations by performing them in the physical simulation environment.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,,,
83,Machine Learning Ranks ECG as an Optimal Wearable Biosignal for Assessing Driving Stress,8,,34362-34374,"Elgendi Mohamed,Menon Carlo","Elgendi M,Menon C",Elgendi M,10.1109/ACCESS.2020.2974933,Simon Fraser University,"The demand for wearable devices that can detect anxiety and stress when driving is increasing. Recent studies have attempted to use multiple biosignals to detect driving stress. However, collecting multiple biosignals can be complex and is associated with numerous challenges. Determining the optimal biosignal for assessing driving stress can save lives. To the best of our knowledge, no study has investigated both longitudinal and transitional stress assessment using supervised and unsupervised ML techniques. Thus, this study hypothesizes that the optimal signal for assessing driving stress will consistently detect stress using supervised and unsupervised machine learning (ML) techniques. Two different approaches were used to assess driving stress: longitudinal (a combined repeated measurement of the same biosignals over three driving states) and transitional (switching from state to state such as city to highway driving). The longitudinal analysis did not involve a feature extraction phase while the transitional analysis involved a feature extraction phase. The longitudinal analysis consists of a novel interaction ensemble (INTENSE) that aggregates three unsupervised ML approaches: interaction principal component analysis, connectivity-based clustering, and K-means clustering. INTENSE was developed to uncover new knowledge by revealing the strongest correlation between the biosignal and driving stress marker. These three MLs each have their well-known and distinctive geometrical basis. Thus, the aggregation of their result would provide a more robust examination of the simultaneous non-causal associations between six biosignals: electrocardiogram (ECG), electromyogram, hand galvanic skin resistance, foot galvanic skin resistance, heart rate, respiration, and the driving stress marker. INTENSE indicates that ECG is highly correlated with the driving stress marker. The supervised ML algorithms confirmed that ECG is the most informative biosignal for detecting driving stress, with an overall accuracy of 75.02%","Stress,Electrocardiography,Urban areas,Road transportation,Skin,Electromyography,Vehicles,Digital health,anxiety monitoring,mental well-being,biosignals,mobile health,wearable devices",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"HEART-RATE,INTERVENTION",IEEE ACCESS,http://summit.sfu.ca/system/files/iritems1/19835/09003418.pdf,
84,Accurate Detection of Non-Proliferative Diabetic Retinopathy in Optical Coherence Tomography Images Using Convolutional Neural Networks,8,,34387-34397,"Ghazal Mohammed,Ali Samr Samir,Mahmoud Ali H.,Shalaby Ahmed M.,El-Baz Ayman","Ghazal M,Ali SS,Mahmoud AH,Shalaby AM,El-Baz A",Ghazal M,10.1109/ACCESS.2020.2974158,Abu Dhabi University,"Diabetic retinopathy (DR) is a disease that forms as a complication of diabetes. It is particularly dangerous since it often goes unnoticed and can lead to blindness if not detected early. Despite the clear importance and urgency of such an illness, there is no precise system for the early detection of DR so far. Fortunately, such system could be achieved using deep learning including convolutional neural networks (CNNs), which gained momentum in the field of medical imaging due to its capability of being effectively integrated into various systems in a manner that significantly improves the performance. This paper proposes a computer aided diagnostic (CAD) system for the early detection of non-proliferative DR (NPDR) using CNNs. The proposed system is developed for the optical coherence tomography (OCT) imaging modality. Throughout this paper, all aspects of deployment of the proposed system are studied starting from the preprocessing stage required to extract input retina patches to train the CNN without resizing the image, to the use of transfer learning principals and how to effectively combine features in order to optimize performance. This is done through investigating several scenarios for the system setup and then selecting the best one, which from the results revealed to be a two pre-trained CNNs based system, in which one of these CNNs is independently fed by nasal retina patches and the other one by temporal retina patches. The proposed transfer learning based CAD system achieves a promising accuracy of 94&%.","Convolutional neural network (CNN),diabetic retinopathy (DR),optical coherence tomography (OCT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BLOOD-VESSEL,SEGMENTATION,AUTOMATED,DETECTION,RETINAL,IMAGES,DEEP,CLASSIFICATION,LESIONS,LEVEL,RISK",IEEE ACCESS,https://doi.org/10.1101/667865,
85,Automatic Detection of Genetic Diseases in Pediatric Age Using Pupillometry,8,,34949-34961,"Iadanza Ernesto,Goretti Francesco,Sorelli Michele,Melillo Paolo,Pecchia Leandro,Simonelli Francesca,Gherardelli Monica","Iadanza E,Goretti F,Sorelli M,Melillo P,Pecchia L,Simonelli F,Gherardelli M",Iadanza E,10.1109/ACCESS.2020.2973747,University of Florence,"Inherited retinal diseases cause severe visual deficits in children. They are classified in outer and inner retina diseases, and often cause blindness in childhood. The diagnosis for this type of illness is challenging, given the wide range of clinical and genetic causes (with over 200 causative genes). It is routinely based on a complex pattern of clinical tests, including invasive ones, not always appropriate for infants or young children. A different approach is thus needed, that exploits Chromatic Pupillometry, a technique increasingly used to assess outer and inner retina functions. This paper presents a novel Clinical Decision Support System (CDSS), based on Machine Learning using Chromatic Pupillometry in order to support diagnosis of Inherited retinal diseases in pediatric subjects. An approach that combines hardware and software is proposed: a dedicated medical equipment (pupillometer) is used with a purposely designed custom machine learning decision support system. Two distinct Support Vector Machines (SVMs), one for each eye, classify the features extracted from the pupillometric data. The designed CDSS has been used for diagnosis of Retinitis Pigmentosa in pediatric subjects. The results, obtained by combining the two SVMs in an ensemble model, show satisfactory performance of the system, that achieved 0.846 accuracy, 0.937 sensitivity and 0.786 specificity. This is the first study that applies machine learning to pupillometric data in order to diagnose a genetic disease in pediatric age.","Diseases,Retina,Pediatrics,Machine learning,Decision support systems,Protocols,Genetics,Artificial intelligence,clinical decision support systems,machine learning,pupillometry,python,rare diseases,retinitis pigmentosa,retinopathy,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CHROMATIC,PUPILLOMETRY,RETINITIS-PIGMENTOSA,PUPIL,RESPONSES,CLASSIFICATION,ROD,DIAGNOSIS,CONE",IEEE ACCESS,https://flore.unifi.it/bitstream/2158/1183830/5/08998205.pdf,
86,Electroencephalography based User Mood Validation using Convolutional Neural Network,,,78-81,"Mehta Darshak B.,Barot Pratik A.,Langhnoja Shaily G.","Mehta DB,Barot PA,Langhnoja SG",Mehta DB,,Gujarat Technological University,"EEG signals are being used for medical diagnosis purposes since centuries. In the last few decades, EEG is also being used for user brainwave reading for various purposes in computer science and other related branches. In the same direction, attempts were made here to validate two classes of what the user is thinking with the help of CNN. The study was conducted and found that accuracy was having the scope of improvement while having the same task being implemented using ANN and other machine learning techniques such as SVM, Decision Tree, Random Forests, etc. After finding these techniques to be less effective in finding sufficient accuracy, CNN comes to help to find better accuracy. The research here surrounds binary classification with exceptional accuracy of 99.82% with a dataset of 14 participants.","brainwaves,EEG,CNN,signal classification,Convolutional Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020),,
87,A Review of Early Detection of Autism Based on Eye-Tracking and Sensing Technology,,,160-166,"Ahmed Zeyad Abdulhameed Taha,Jadhav Mukti E.","Ahmed ZAT,Jadhav ME",Ahmed ZAT,,Dr. Babasaheb Ambedkar Marathwada University (BAMU),"The current paper is a review of eye-tracking and sensing technologies that detect and monitor Autism Spectrum Disorder (ASD). Nowadays, the biggest challenge is the detection of autism before the age of 36 months. The diagnosis of autism in the early stage of life can help autistic children improve their social communication and quality of life. Therefore, the technology can support psychologists to get the right diagnoses of autism and accordingly the autistic children can get appropriate treatment for their condition. In this review, the focus is on eye - tracking and sensing technologies. The autistic children have different attentional biases in social interactions that can be measured by eye-tracking technology. Moreover, the autistic children have some signs that can be easily detected by using the sensing technology such as hand flapping, body rocking and motion trackers.","Autism Spectrum Disorder (ASD),Typical Developing (TD),Eye Tracking,Sensing Technology,Hand Flapping,Motion Trackers,Machine Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"SYSTEM,CHILDREN,NETWORK",PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020),,
88,Convolutional Neural Network based Skin Lesion Classification and Identification,,,264-270,"Aishwarya U.,Daniel I. Jackson,Raghul R.","Aishwarya U,Daniel IJ,Raghul R",Aishwarya U,,National Engineering College - India,"Melanoma disease is the type of skin cancer in melanocytes, which are in the epidermis layer of the skin. The rate of msselanoma is in increasing order and found to be dangerous if not diagnosed at its beginning stage. To overcome this challenge, deep convolutional neural network techniques are used. The patient injured image is processing under different steps such as pre-processing using various filters followed by segmentation using the K-means clustering algorithm and Fuzzy C-means clustering algorithm. Finally, the detection and classification are executed with Convolutional Neural Network. Performance measures are evaluated for the proposed methodology with the accuracy of 98.43%, specificity of 98.77%, the sensitivity of 99.83%. The results drive that the proposed model of learning surpasses the existing algorithm and could be used to help medical practitioners to classify skin lesions.","k-means,FCM,CNN,Melanoma",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020),,
89,A Proficient Evalution with the Pre-Term Birth Classification in ECG Signal using KNN,,,276-282,"Lincy P. Michael Infant,Santhi D.,Geetha A.","Lincy PMI,Santhi D,Geetha A",Lincy PMI,,National Engineering College - India,"The rate of premature births is rising all over the world and there is still no forecast against the births. Recent research is based on ECG record analysis, which contains information on the electrophysiological properties of the mother's and fetal's cardiac signals. The purpose of this work is to classify the fetal ECG heartbeats, using the KNN classifier, and to predict preterm birth. 50 ECG signals were taken in this work, it is preprocessed using the FIR and NLMS filters. Using FFT the function was extracted based on the pre-processed signals. Classification of the signals with the extracted features is unclear. The features were optimized The functions were designed using PSO and chosen. In addition, identify the ECG signals according to the qualified features, selected features and target value. ECG signals were marked as a term or premature with 93.4045 percent accuracy, 99.596 percent sensitivity and 88.3268 percent specificity.","Preterm Births,ECG,FIR,NLMS,FFT,PSO,KNN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"DELIVERY,TERM",PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020),,
90,An Effective Discrete Artificial Bee Colony Algorithm for Scheduling an Automatic-Guided-Vehicle in a Linear Manufacturing Workshop,8,,35063-35076,"Zou Wen-Qiang,Pan Quan-Ke,Tasgetiren M. Fatih","Zou WQ,Pan QK,Tasgetiren MF",Pan QK,10.1109/ACCESS.2020.2973336,Shanghai University,"This paper deals with a new automatic guided vehicle (AGV) scheduling problem from the material handling process in a linear manufacturing workshop. The problem is to determine a sequence of Cells for AGV to travel to minimize the standard deviation of the waiting time of the Cells and the total travel distance of AGV. For this purpose, we first propose an integer linear programming model based on a comprehensive investigation. Then, we present an improved nearest-neighbor-based heuristic so as to fast generate a good solution in view of the problem-specific characteristics. Next, we propose an effective discrete artificial bee colony algorithm with some novel and advanced techniques including a heuristic-based initialization, six neighborhood structures and a new evolution strategy in the onlooker bee phase. Finally, the proposed algorithms are empirically evaluated based on several typical instances from the real-world linear manufacturing workshop. A comprehensive and thorough experiment shows that the presented algorithm produces superior results which are also demonstrated to be statistically significant than the existing algorithms.","Automated guided vehicle,heuristic,discrete artificial bee colony algorithm,scheduling,linear manufacturing workshop",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ROUTING,PROBLEM,OPTIMIZATION,ALGORITHM,LOGISTICS,DESIGN,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08995549.pdf,
91,A Spectrogram-Based Deep Feature Assisted Computer-Aided Diagnostic System for Parkinsons Disease,8,,35482-35495,"Zahid Laiba,Maqsood Muazzam,Durrani Mehr Yahya,Bakhtyar Maheen,Baber Junaid,Jamal Habibullah,Mehmood Irfan,Song Oh-Young","Zahid L,Maqsood M,Durrani MY,Bakhtyar M,Baber J,Jamal H,Mehmood I,Song OY",Maqsood M,10.1109/ACCESS.2020.2974008,COMSATS University Islamabad (CUI),"Parkinsons disease is a neural degenerative disease. It slowly progresses from mild to severe stage, resulting in the degeneration of dopamine cells of neurons. Due to the deficiency of dopamine cells in the brain, it leads to a motor (tremor, slowness, impaired posture) and non-motor (speech, olfactory) defects in the body. Early detection of Parkinson's disease is a difficult chore as the symptoms of disease appear overtime. However, different diagnostic systems have contributed towards disease detection by considering gait, tremor and speech characteristics. Recent work has shown that speech impairments can be considered as a possible predictor for Parkinson's disease classification and remains an open research area. The speech signals show major differences and variations for Parkinson patients as compared to normal human beings. Therefore, variation in speech should be modeled using acoustic features to identify these variations. In this research, we propose three methods- the first method employs a transfer learning-based approach using spectrograms of speech recordings, the second method evaluates deep features extracted from speech spectrograms using machine learning classifiers and the third method evaluates simple acoustic feature of recordings using machine learning classifiers. The proposed frameworks are evaluated on a Spanish dataset pc-Gita. The results show that the second framework shows promising results with deep features. The highest 99.7% accuracy on vowel \o\ and read text is observed using a multilayer perceptron. Whereas 99.1% accuracy observed on vowel \o\ deep features using random forest. The deep feature-based method performs better as compared to simple acoustic features and transfer learning approaches. The proposed methodology outperforms the existing techniques on the pc-Gita dataset for Parkinson's disease detection.","Parkinson disease,classification,deep features,speech signals,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,SPEECH,ARTICULATION,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.2974008,
92,Generalization of Convolutional Neural Networks for ECG Classification Using Generative Adversarial Networks,8,,35592-35605,"Shaker Abdelrahman M.,Tantawi Manal,Shedeed Howida A.,Tolba Mohamed F.","Shaker AM,Tantawi M,Shedeed HA,Tolba MF",Shaker AM,10.1109/ACCESS.2020.2974712,Egyptian Knowledge Bank (EKB),"Electrocardiograms (ECGs) play a vital role in the clinical diagnosis of heart diseases. An ECG record of the heart signal over time can be used to discover numerous arrhythmias. Our work is based on 15 different classes from the MIT-BIH arrhythmia dataset. But the MIT-BIH dataset is strongly imbalanced, which impairs the accuracy of deep learning models. We propose a novel data-augmentation technique using generative adversarial networks (GANs) to restore the balance of the dataset. Two deep learning approaches-an end-to-end approach and a two-stage hierarchical approach-based on deep convolutional neural networks (CNNs) are used to eliminate hand-engineering features by combining feature extraction, feature reduction, and classification into a single learning method. Results show that augmenting the original imbalanced dataset with generated heartbeats by using the proposed techniques more effectively improves the performance of ECG classification than using the same techniques trained only with the original dataset. Furthermore, we demonstrate that augmenting the heartbeats using GANs outperforms other common data augmentation techniques. Our experiments with these techniques achieved overall accuracy above 98.0%, precision above 90.0%, specificity above 97.4%, and sensitivity above 97.7% after the dataset had been balanced using GANs, results that outperform several other ECG classification methods.","Class imbalance,convolution neural networks (CNNs),ECG classification,generative adversarial networks (GANs)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMPONENT,ANALYSIS,TRANSFORM,FEATURES,RECOGNITION,MODEL,PCA",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09000871.pdf,
93,Burden Surface Decision Using MODE With TOPSIS in Blast Furnace Ironmkaing,8,,35712-35725,"Li Yanjiao,Li Huiqi,Zhang Jie,Zhang Sen,Yin Yixin","Li YJ,Li HQ,Zhang J,Zhang S,Yin YX",Li HQ,10.1109/ACCESS.2020.2974882,Beijing Institute of Technology,"Burden surface distribution plays a key role in achieving an energy-efficient status of blast furnace (BF). However, actual adjustment of burden surface usually depends on the operators experience when the production status changes. Meanwhile, due to the characteristics of high dimension, strong coupling, and distributed parameters, it is difficult to establish the accurate mechanism model for BF ironmaking process. Considering the aforementioned issues, this paper proposes an integrated multi-objective optimization framework for optimizing burden surface distribution based on the analysis of BF operation characteristics. Firstly, data-driven models are constructed for two objectives, i.e., gas utilization ratio (GUR) and coke ratio (CR), and two constraints using adaptive particle swarm optimization (APSO) based extreme learning machine (ELM), named APSO-ELM. Multi-objective optimization is subsequently carried out between GUR and CR using the multi-objective differential evolution algorithm (MODE) to generate the Pareto optimal solutions. Finally, TOPSIS is applied to select a best compromise solution among the Pareto optimal solutions for this optimization problem. Comprehensive experiments are presented to illustrate the performance of the proposed integrated multi-objective optimization framework. The experimental results demonstrate that the proposed framework can give a reasonable burden surface profile according to the production status changes to guarantee the BF operation more efficient and stable.","Surface treatment,Production,Mathematical model,Iron,Pareto optimization,Blast furnaces,Blast furnace,burden surface optimization,multi-objective optimization,extreme learning machine,MODE,TOPSIS",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EXTREME,LEARNING-MACHINE,MULTIOBJECTIVE,EVOLUTIONARY,DIFFERENTIAL,EVOLUTION,OPTIMIZATION,ALGORITHM,MULTIPLE,OBJECTIVES,PREDICTION,SYSTEM,REGRESSION,FRAMEWORK",IEEE ACCESS,https://doi.org/10.1109/access.2020.2974882,
94,Thermal conductivity prediction based on machine learning,48,3,"134-137,142",",,,,,","Niu Chengcheng,Li Shaobo,Dan Yabo,Cao Zhuo,Li Xiang,Hu Jianjun",,,Niu Chengcheng,"Traditional theoretical research,experimental research and computational simulation have failed to satisfy scientists'exploration and design of new materials.Data-driven machine learning algorithms have a driving role in material screening and performance prediction.The machine learning was applied to material informatics.Based on the existing material thermal conductivity data set,a machine learning thermal conductivity prediction model was developed and evaluated by crossvalidation. Machine learning was used to establish a mapping model between descriptors and thermal conductivity properties,which can be used for large-scale material screening to guide experimental research.","data driven; ,machine learning,; thermal conductivity",Article,,,,,,,,
95,Identity Authentication of OSA Patients Using Microwave Doppler radar and Machine Learning Classifiers,,,251-254,"Islam Shekh M. M.,Rahman Ashikur,Yavari Ehsan,Baboli Meheran,Boric-Lubecke Olga,Lubecke Victor M.","Islam SMM,Rahman A,Yavari E,Baboli M,Boric-Lubecke O,Lubecke VM",Islam SMM,,University of Hawaii System,"Non-contact home-based sleep monitoring will bring a paradigm shift to diagnosis and treatment of Obstructive Sleep Apnea (OSA) as it can facilitate easier access to specialized care in order to reach a much boarder set of patients. However, current remote unattended sleep studies are mostly contact sensor based and test results are sometimes falsified by sleep-critical job holders (driver, airline pilots) due to fear of potential job loss. In this work, we investigated identity authentication of patients with OSA symptoms based on extracting respiratory features (peak power spectral density, packing density and linear envelop error) from radar captured paradoxical breathing patterns in a small-scale clinical sleep study integrating three different machine learning classifiers (Support Vector Machine (SVM), K-nearest neighbor (KNN), Random forest). The proposed OSA-based authentication method was tested and validated for five OSA patients with 93.75% accuracy using KNN classifier which outperformed other classifiers.","Sleep Apnea,SVM,KNN Classifier,Authentication,Radar",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Telecommunications,,,,,,
96,Learning a Lightweight Representation: First Step Towards Automatic Detection of Multidimensional Relationships between Ideas,,,230-233,Khiat Abderrahmane,Khiat A,Khiat A,10.1109/ICSC.2020.00048,"Fraunhofer IAIS, Enterprise Informat Syst, Bonn, Germany.","Moving ideation from a closed paradigm (companies) to an open one (crowd) yields several benefits: (1) the crowd allows the generation of a large number of ideas and (2) its heterogeneity increases the potential in obtaining creative ideas. In practice, however, the crowd often fails at generating innovative solutions, leading to duplicate or ideas that use each other's description. Thus, it is practically and economically unfeasible to sift through this large number of ideas to select valuable ones. One promising solution to overcome this issue is identifying relationships between idea text descriptions, such as duplicate, generalize, disjoint, alternative solution. Existing approaches rely either on human judgment, which is expensive and requires domain experts or automatic approaches which compute similarity i.e. one dimension and do not consider other relations. To find complex relationships between idea texts, a first logical step is to fully structure ideas into logic-based representation. However, logic-based representations are very expensive to obtain since ideas' texts do not adhere to any specific structure. Our goal is then to come up with a representation that can be learned by the machine, while still being expressive to allow establishing relationships between ideas. This research in progress introduces an approach based on a sequence-to-sequence learning approach, which allows the machine to learn a lightweight structural representation that is used next to establishing multidimensional relationships between ideas (i.e. different kind of relations between ideas). Based on our investigation, we found out that ideas contain the following patterns: what the idea is about (e.g. window with heat-sensitive material), how it works (e.g. it lights up) and when it works (e.g. in case of fire). Those extracted patterns are then compared with the corresponding patterns of other ideas to establish relations. Our preliminary investigation shows promising results to learn such lightweight structural representation and leverages it in identifying complex relationships between ideas.","Lightweight Knowledge Representation,Machine Learning,Patterns Discovery",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
97,A Semantic Segmentation Approach to Recognize Assault Rifles in ISIS Propaganda Images,,,424-429,"Abeysinghe Bhashithe,Veilleux-Lepage Yannick,Bloom Mia M.","Abeysinghe B,Veilleux-Lepage Y,Bloom MM",Abeysinghe B,10.1109/ICSC.2020.00082,University System of Georgia,"Between 2014 and 2018, the Islamic State in Iraq and Syria (ISIS) perfected the use of social media for its propaganda. To understand and counter these efforts by ISIS, it is critical to analyze their propaganda materials. During the past few years, a systematic effort has been made to catalog and annotate these materials which appear in the form of images, video and text. However due to the sheer volume of the material, it is an extremely onerous task to maintain. In this work, we present a deep learning solution to automatically identify and tag images for assault rifles. We present our experiments of a semantic segmentation approach to localization of assault rifles in a self-collected and maintained data set. Our goal is to consume minimal amount of data and cater to an analysis platform. The state of the art for object localization is the Convolutional Neural Network (CNN). A limitation of CNN is that it only handles images of fixed dimensions. One way to deal with this limitation is to re-size the input images, however this is not an ideal solution. A more flexible approach is to use a Fully Convolutional Network (FCN), which provides a robust solution for varied sizes of input images. We show that FCNs can achieve high performance in detecting and localizing objects in a real world setting, with noncurated data. We also show that by using a step wise training pipeline it is possible to learn a representation of the object using a bounding box annotation.","localization,Fully Convolutional Networks,assault rifles,semantic segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
98,Online Adaptive Image Reconstruction (OnAIR) Using Dictionary Models,6,,153-166,"Moore Brian E.,Ravishankar Saiprasad,Nadakuditi Raj Rao,Fessler Jeffrey A.","Moore BE,Ravishankar S,Nadakuditi RR,Fessler JA",Moore BE,10.1109/TCI.2019.2931092,University of Michigan System,"Sparsity and low-rank models have been popular for reconstructing images and videos from limited or corrupted measurements. Dictionary or transform learning methods are useful in applications such as denoising, inpainting, and medical image reconstruction. In this paper, we propose a framework for online (or time-sequential) adaptive reconstruction of dynamic image sequences from linear (typically undersampled) measurements. We model the spatiotemporal patches of the underlying dynamic image sequence as sparse in a dictionary, and we simultaneously estimate the dictionary and the images sequentially from streaming measurements. Multiple constraints on the adapted dictionary are also considered such as a unitary matrix, or low-rank dictionary atoms that provide additional efficiency or robustness. The proposed online algorithms are memory efficient and involve simple updates of the dictionary atoms, sparse coefficients, and images. Numerical experiments demonstrate the usefulness of the proposed methods in inverse problems such as video reconstruction or inpainting from noisy, subsampled pixels, and dynamic magnetic resonance image reconstruction from very limited measurements.","Online methods,sparse representations,dictionary learning,machine learning,inverse problems,video processing,dynamic magnetic resonance imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Imaging Science & Photographic Technology",,5.107,"ACCELERATED,DYNAMIC,MRI,LOW-RANK,MATRIX-FACTORIZATION,SPARSITY,TRANSFORMS,ALGORITHM",IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING,http://arxiv.org/pdf/1809.01817,
99,Fast Enhanced CT Metal Artifact Reduction Using Data Domain Deep Learning,6,,181-193,"Ghani Muhammad Usman,Karl W. Clem","Ghani MU,Karl WC",Ghani MU,10.1109/TCI.2019.2937221,Boston University,"Filtered back projection (FBP) is the most widely used method for image reconstruction in X-ray computed tomography (CT) scanners, and can produce excellent images in many cases. However, the presence of dense materials, such as metals, can strongly attenuate or even completely block X-rays, producing severe streaking artifacts in the FBP reconstruction. These metal artifacts can greatly limit subsequent object delineation and information extraction from the images, restricting their diagnostic value. This problem is particularly acute in the security domain, where there is great heterogeneity in the objects that can appear in a scene, highly accurate decisions must be made quickly, and processing time is highly constrained. The standard practical approaches to reducing metal artifacts in CT imagery are either simplistic nonadaptive interpolation-based projection data completion methods or direct image post-processing methods. These standard approaches have had limited success. Motivated primarily by security applications, we present a new deep-learning-based metal artifact reduction approach that tackles the problem in the projection data domain. We treat the projection data corresponding to dense, metal objects as missing data and train an adversarial deep network to complete the missing data directly in the projection domain. The subsequent complete projection data is then used with conventional FBP to reconstruct an image intended to be free of artifacts. This new approach results in an end-to-end metal artifact reduction algorithm that is computationally efficient textcolorred and therefore practical and fits well into existing CT workflows allowing easy adoption in existing scanners. Training deep networks can be challenging, and another contribution of our work is to demonstrate that training data generated using an accurate X-ray simulation can be used to successfully train the deep network, when combined with transfer learning using limited real data sets. We demonstrate the effectiveness and potential of our algorithm on simulated and real examples.","Computed tomography,metal artifact reduction,sinogram completion,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Imaging Science & Photographic Technology",,5.107,"CONVOLUTIONAL,NEURAL-NETWORK,COMPUTED-TOMOGRAPHY,RECONSTRUCTION",IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING,http://arxiv.org/pdf/1904.04691,
100,Fast Retinomorphic Event-Driven Representations for Video Gameplay and Action Recognition,6,,276-290,"Chen Huaijin,Liu Wanjia,Goel Rishab,Lua Rhonald C.,Mittal Siddharth,Huang Yuzhong,Veeraraghavan Ashok,Patel Ankit B.","Chen HJ,Liu WJ,Goel R,Lua RC,Mittal S,Huang YZ,Veeraraghavan A,Patel AB",Patel AB,10.1109/TCI.2019.2948755,Baylor College of Medicine,"Good temporal representations are crucial for video understanding, and the state-of-the-art video recognition framework is based on two-stream networks. In such framework, besides the regular ConvNets responsible for RGB frame inputs, a second network is introduced to handle the temporal representation, usually the optical flow (OF). However, OF or other task-oriented flow is computationally costly, and is thus typically pre-computed. Critically, this prevents the two-stream approach from being applied to reinforcement learning (RL) applications such as video game playing, where the next state depends on current state and action choices. Inspired by the early vision systems of mammals and insects, we propose a fast event-driven representation (EDR) that models several major properties of early retinal circuits: (1) log-arithmic input response, (2) multi-timescale temporal smoothing to filter noise, and (3) bipolar (ON/OFF) pathways for primitive event detection. Trading off the directional information for fast speed (>9000 fps), EDR enables fast real-time inference/learning in video applications that require interaction between an agent and the world such as game-playing, virtual robotics, and domain adaptation. In this vein, we use EDR to demonstrate performance improvements over state-of-the-art reinforcement learning algorithms for Atari games, something that has not been possible with pre-computed OF. Moreover, with UCF-101 video action recognition experiments, we show that EDR performs near state-of-the-art in accuracy while achieving a 1,500x speedup in input representation processing, as compared to optical flow.","Smart cameras,retina,real-time systems,streaming media,cells (biology),reinforcement learning,video signal processing,video",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Imaging Science & Photographic Technology",,5.107,"ON-CENTER,CELLS,CONTRAST",IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING,,
