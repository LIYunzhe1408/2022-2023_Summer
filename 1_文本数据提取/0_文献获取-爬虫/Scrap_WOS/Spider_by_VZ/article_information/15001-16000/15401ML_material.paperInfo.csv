,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Multiscale and Adversarial Learning-Based Semi-Supervised Semantic Segmentation Approach for Crack Detection in Concrete Structures,8,,170939-170950,"Shim Seungbo,Kim Jin,Cho Gye-Chun,Lee Seong-Won","Shim S,Kim J,Cho GC,Lee SW",Lee SW,10.1109/ACCESS.2020.3022786,Korea Institute of Civil Engineering & Building Technology (KICT),"Typically, the operational lifetime of underground concrete structures is several decades. At present, many such structures are approaching their original life expectancy. In this stage, the essential functionality of the structures may be considerably degraded, leading to various safety hazards such as collapse roof and tunnel flooding. In general, to overcome such problems, the maintenance of underground structures has been conducted through manual subjective inspections so far. However, recently, several objective inspection technologies have been actively developed by fusing artificial intelligence and imaging techniques recently. In particular, deep learning algorithms have been developed to detect concrete cracks, based on a large amount of data for supervised learning, including numerous labeled images. Such data acquisition requires considerable time and effort. To reduce these costs, in this study, multiscale and adversarial learning techniques were applied to realize crack detection. A total of 1,200 labeled data and 3,000 unlabeled data were used to implement and verify the proposed method. The multiscale segmentation neural network, discriminator neural network, and adversarial learning technique were used to realize accurate crack detection, enhance the learning performance, and ensure the efficiency of training data, respectively. The resulting algorithm had a pixel accuracy, mean intersection over union, frequency weighted intersection over union, and F1 score of 98.176%, 88.936%, 96.525%, and 88.789%, respectively. The proposed technique can be used to examine the conditions to ensure the safe maintenance of aging structures.","Neural networks,Machine learning,Image segmentation,Maintenance engineering,Inspection,Training data,Feature extraction,Adversarial learning,multiscale learning,crack detection,semantic segmentation,image processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MACHINE,VISION,INSPECTION,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09193940.pdf,
2,Machine Learning Analysis of Heart Rate Variability for the Detection of Seizures in Comatose Cardiac Arrest Survivors,8,,160515-160525,"Sung Chih-Wei,Shieh Jiann-Shing,Chang Wei-Tien,Lee Yi-Wei,Lyu Ji-Huan,Ong Hooi-Nee,Chen Wei-Ting,Huang Chien-Hua,Chen Wen-Jone,Jaw Fu-Shan","Sung CW,Shieh JS,Chang WT,Lee YW,Lyu JH,Ong HN,Chen WT,Huang CH,Chen WJ,Jaw FS",Jaw FS,10.1109/ACCESS.2020.3020742,National Taiwan University,"Objective: Heart rate variability (HRV) reflects autonomous nervous system disturbance and is used for seizure prediction. The aim of this study was to develop a real-time, continuous physiological medical signal data acquisition system in seizure detection for intensive care unit (ICU). Methods: This prospective study was conducted in National Taiwan University Hospital from August 2018 to October 2019. This study included 20 patients who (a) had a sustained return of spontaneous circulation following out-of-hospital cardiac arrest, (b) were over 18 years old, (c) and were admitted to the emergency ICU for post-cardiac-arrest care. One-lead electrocardiography and bilateral two-channel electroencephalography recorders were synchronically used to conduct measurements for a maximum of 72 hours. The recorded data were wirelessly real-time transmitted by a proxy transmitting module through an access point and a local gateway. A system with a novel algorithm processed the signals and conducted feature extraction and supervised learning for seizure detection. Results: A total of 89 nonseizure and 83 seizure events were detected by the system. Seizure occurred in two-thirds of the patients assessed by intensivists and neurologists. Four HRV parameters, namely standard deviation of normal-to-normal R-wave intervals, high frequency, low frequency-high frequency ratio, and sample entropy, were determined as potential features for identifying seizures. The sensitivity and specificity of the developed system were 0.74 and 0.81, respectively, and the positive predictive value was 0.82. Conclusion: The developed system can be used to identify seizure events through HRV features. Significance: The current study achieved real-time seizure detection and overcame previous limitations on continuity and accessibility.","Heart rate variability,Electroencephalography,Electrocardiography,Cardiac arrest,Resonant frequency,Machine learning,Real-time systems,Heart rate variability,seizure,cardiac arrest,machine learning,electroencephalography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EPILEPTIC-SEIZURES,WAVELET,ANALYSIS,POINCARE,PLOT,ADMISSION,SPECTRUM,MODE,EEG",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09181556.pdf,
3,Intervention of Hepatocellular Carcinoma in Fibrosis Staging Based on Multi-Parameter Magnetic Resonance Image Depth Learning Method,8,,174353-174364,"Tian Zhenhua,Qu Xudong","Tian ZH,Qu XD",Qu XD,10.1109/ACCESS.2020.3021718,Fudan University,"This paper mainly discusses the deep learning solution for non-invasive evaluation of the differentiation degree of hepatocellular carcinoma based on multi-parameter nuclear magnetic resonance images, combined with the clinical diagnosis experience of radiologists and the characteristics of nuclear magnetic resonance images. The method of multimodal data fusion is studied based on multi-parameter nuclear magnetic resonance imaging data. Multi-channel three-dimensional convolution neural network and multi-scale depth residual network are proposed to extract the features of three-dimensional medical image data and two-dimensional fusion medical image data, and to solve the problem of insufficient cases in clinical image data of hepatocellular carcinoma (HCC). We examine the role of transition learning and metric learning in medical image classification. In this study, we use a method of data fusion, transition learning and multi scale feature extraction to construct a deep learning model for medical image aided diagnosis. Multiple modal fusion decisions for finding complementary modal data fusion for the complementarity of multimodal images in diagnostic decisions can effectively improve diagnostic effects. Although there is a clear difference between natural and medical images through experiments, a model trained with a natural image dataset as an initialization of the network can ensure and converge the training. At the same time, improve the performance of the model on the test set. The multi-scale feature extraction model proposed in this paper enhances the robustness of the model and further improves the effect of medical image classification.","Medical diagnostic imaging,Magnetic resonance imaging,Feature extraction,Cancer,Convolution,Computer-aided diagnosis,multi-parameter nuclear magnetic resonance imaging,convolution neural network,liver cancer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"VIRTUAL-REALITY,AUGMENTED,REALITY,TECHNOLOGY,INTERNET",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09186686.pdf,
4,Operational Planning of a Residential Fuel Cell System for Minimizing Expected Operational Costs Based on a Surrogate Model,8,,173983-173998,"Tsuchiya Yuta,Fujimoto Yu,Yoshida Akira,Amano Yoshiharu,Hayashi Yasuhiro","Tsuchiya Y,Fujimoto Y,Yoshida A,Amano Y,Hayashi Y",Tsuchiya Y,10.1109/ACCESS.2020.3023820,Waseda University,"This study proposes a novel operational planning method for polymer electrolyte fuel cell cogeneration systems (PEFC-CGSs). PEFC-CGSs provide hot water by utilizing waste heat produced in the electricity generation process, and hot water is stored in an attached tank. Generating and storing hot water based on an optimal operational plan according to household demand leads to further energy saving; therefore, operational planning methods based on household demand prediction have received significant attention. However, the improvement in the demand prediction accuracy does not necessarily lead to efficient PEFC-CGS operation in terms of operational costs; in other words, the accuracy in the demand prediction does not directly indicate the resulting operational efficiency. In this study, the authors propose a novel approach based on a surrogate model for deriving an appropriate plan that minimizes the expected operational costs among the operational plan candidates. In the proposed scheme, the error between expected and actual operational costs explicitly represents the relevance of the operational plan, so that the optimal operational plan can be selected directly from the perspective of the resulting operational efficiency. The practicality of the proposed approach is evaluated with the existing demand prediction-based approach via numerical simulations using real-world measurements of multiple customers in Japan. The proposed method reveals 30% reduction of the excessive operational costs by avoiding the inefficient operation of the auxiliary gas-heater in the experiments and will further enhance the value of introducing highly efficient residential fuel cell system that contributes to a low-carbon society.","Planning,Fuel cells,Cogeneration,Energy management,Numerical models,Polymers,Electrolytes,Cost minimization,machine learning,operational planning,polymer electrolyte fuel cell cogeneration systems,surrogate model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"ENERGY,MANAGEMENT,OPTIMIZATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09195504.pdf,
5,Prediction of Harvestable Energy for Self-Powered Wearable Healthcare Devices: Filling a Gap,8,,170336-170354,"Wahba Maram A.,Ashour Amira S.,Ghannam Rami","Wahba MA,Ashour AS,Ghannam R",Wahba MA,10.1109/ACCESS.2020.3024167,Egyptian Knowledge Bank (EKB),"Self-powered or autonomously driven wearable devices are touted to revolutionize the personalized healthcare industry, promising sustainable medical care for a large population of healthcare seekers. Current wearable devices rely on batteries for providing the necessary energy to the various electronic components. However, to ensure continuous and uninterrupted operation, these wearable devices need to scavenge energy from their surroundings. Different energy sources have been used to power wearable devices. These include predictable energy sources such as solar energy and radio frequency, as well as unpredictable energy from the human body. Nevertheless, these energy sources are either intermittent or deliver low power densities. Therefore, being able to predict or forecast the amount of harvestable energy over time enables the wearable to intelligently manage and plan its own energy resources more effectively. Several prediction approaches have been proposed in the context of energy harvesting wireless sensor network (EH-WSN) nodes. In their architectural design, these nodes are very similar to self-powered wearable devices. However, additional factors need to be considered to ensure a deeper market penetration of truly autonomous wearables for healthcare applications, which include low-cost, low-power, small-size, high-performance and lightweight. In this paper, we review the energy prediction approaches that were originally proposed for EH-WSN nodes and critique their application in wearable healthcare devices. Our comparison is based on their prediction accuracy, memory requirement, and execution time. We conclude that statistical techniques are better designed to meet the needs of short-term predictions, while long-term predictions require the hybridization of several linear and non-linear machine learning techniques. In addition to the recommendations, we discuss the challenges and future perspectives of these technique in our review.","Energy harvesting,Wireless sensor networks,Biomedical monitoring,Sensors,Medical services,Power system management,Wireless communication,Wearable devices,energy harvesting,healthcare,wireless sensors,energy prediction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SENSOR,NETWORKS,SOLAR,DRIVEN,CHALLENGES,MACHINE,DESIGN,SERIES",IEEE ACCESS,http://eprints.gla.ac.uk/223152/1/223152.pdf,
6,Learning to Recognize Thoracic Disease in Chest X-Rays With Knowledge-Guided Deep Zoom Neural Networks,8,,159790-159805,"Wang Kun,Zhang Xiaohong,Huang Sheng,Chen Feiyu,Zhang Xiangbo,Huangfu Luwen","Wang K,Zhang XH,Huang S,Chen FY,Zhang XB,Huangfu LW",Zhang XH,10.1109/ACCESS.2020.3020579,Chongqing University,"Automatic and accurate thorax disease diagnosis in Chest X-ray (CXR) image plays an essential role in clinical assist analysis. However, due to its imaging noise regions and the similarity of visual features between diseases and their surroundings, the precise analysis of thoracic disease becomes a challenging problem. In this study, we propose a novel knowledge-guided deep zoom neural network (KGZNet) which is a data-driven model. Our approach leverage prior medical knowledge to guide its training process, due to thoracic diseases typically limit within the lung regions. Also, we utilized weakly-supervised learning (WSL) to search for finer regions without using annotated samples. Learning on each scale consists of a classification sub-network. The KGZNet starts from global images, and iteratively generates discriminative part from coarse to fine; while a finer scale sub-network takes as input an amplified attended discriminative region from previous scales in a recurrent way. Specifically, we first train a robust modified U-Net model of lung segmentation and capture the lung area from the original CXR image through the Lung Region Generator. Then, guided by the attention heatmap, we obtain a finer discriminative lesion region from the lung region images by the Lesion Region Generator. Lastly, the most discriminative features knowledge is fused, and the complementary features information is learned for final disease prediction. Extensive experiments demonstrate that our method can effectively leverage discriminative region information, and significantly outperforms the other state-of-the-art methods in the thoracic disease recognition task. Furthermore, the proposed KGZNet can gradually learn the discriminative region from coarse to fine in a mutually reinforced way. The code is will available at: https://github.com/ISSE-AILab/KGZNet.","Diseases,Lung,Feature extraction,Lesions,X-rays,Neural networks,Visualization,Chest X-ray,thoracic disease recognition,weakly-supervised learning,discriminative feature learning,biomedical imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CLASSIFICATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09181568.pdf,
7,Pixel-Wise Fabric Defect Detection by CNNs Without Labeled Training Data,8,,161317-161325,"Wang Zhen,Jing Junfeng","Wang Z,Jing JF",Jing JF,10.1109/ACCESS.2020.3021189,Xi'an Polytechnic University,"Surface inspection is a necessary process of fabric quality control. However, it remains a challenging task owing to diverse types of defects, various patterns of fabric texture, and application requirements for detection speed. In this article, a lightweight deep learning model is therefore proposed to complete the segmentation of fabric defects. The input of the model is a fabric image, and the output is a binary image. Generally known, a deep learning model usually needs much data to update the parameters. Still, as an abnormal phenomenon, fabric defects are unpredictable, which makes it impossible to collect a large number of data. Distinct from other models, the proposed method is a supervised network but does not need manually labeled samples for training. A fake sample generator is designed to simulate the defect image, which only needs the defect-free fabric image. The proposed model is trained with fake samples and verified with real samples. The experimental results show that the model trained with false data is useful and achieves high segmentation accuracy on real fabric samples. Besides, a loss function is proposed to deal with the problem of imbalance between the number of background pixels and the number of defective pixels in the fabric image. Comprehensive experiments were performed on representative fabric samples to verify the segmentation accuracy and detection speed of this method.","Fabrics,Image segmentation,Feature extraction,Machine learning,Data models,Training,Convolution,Fabric defect,deep learning,image segmentation,defect detection,imbalanced dataset",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09184894.pdf,
8,Deep Learning Applied for Histological Diagnosis of Breast Cancer,8,,162432-162448,"Yari Yasin,Nguyen Thuy V.,Nguyen Hieu T.","Yari Y,Nguyen TV,Nguyen HT",Nguyen HT,10.1109/ACCESS.2020.3021557,"Posts & Telecommun Inst Technol, Fac Informat Technol, Hanoi 122, Vietnam.","Deep learning, as one of the currently most popular computer science research trends, improves neural networks, which has more and deeper layers allowing higher abstraction levels and more accurate data analysis. Although deep convolutional neural networks, as a deep learning algorithm, has recently achieved promising results in data analysis, the requirement for a large amount of data prevents its use in medical data analysis since it is challenging to obtain data from the medical field. Breast cancer is a common cancer in women. To diagnose this kind of cancer, breast cell shapes in histopathology images should be examined by senior pathologists. The number of pathologists per population in the world is not enough, especially in Africa, and human mistake may occur in diagnosis procedure. After the evaluation of deep learning methods and algorithms in breast histological data processing, we tried to improve the current systems' accuracy. As a result, this study proposes two effective deep transfer learning-based models, which rely on pre-trained DCNN using a large collection of ImageNet dataset images that improve current state-of-the-art systems in both binary and multiclass classification. We transfer pre-trained weights of the ResNet50 and DesneNet121 on the Imagenet as initial weights and fine-tune these models with a deep classifier with data augmentation to detect various malignant and benign samples tissues in the two categories of binary classification and multiclass classification. The proposed models have been examined with optimized hyperparameters in magnification-dependent and magnification-independent classification modes. In the multiclass classification, the proposed system achieved up to 98% accuracy. As for binary classification, the proposed system provides up to 100% accuracy. The results outperform previous studies accuracies in all defined performance metrics in breast cancer CAD systems from histological images.","Feature extraction,Breast cancer,Solid modeling,Machine learning,Biomedical imaging,Breakhis dataset,breast cancer,CNN,computer-aided diagnosis (CAD),medical image classification,densNet,ResNet",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CLASSIFICATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09186080.pdf,
9,In-Vitro Classification of Saliva Samples of COPD Patients and Healthy Controls Using Machine Learning Tools,8,,168053-168060,"Zarrin Pouya Soltani,Roeckendorf Niels,Wenger Christian","Zarrin PS,Roeckendorf N,Wenger C",Zarrin PS,10.1109/ACCESS.2020.3023971,Leibniz Institut fur Innovative Mikroelektronik (IHP),"Chronic Obstructive Pulmonary Disease (COPD) is a life-threatening lung disease and a major cause of morbidity and mortality worldwide. Although a curative therapy has yet to be found, permanent monitoring of biomarkers that reflect the disease progression plays a pivotal role for the effective management of COPD. The accurate examination of respiratory tract fluids like saliva is a promising approach for staging disease and predicting its upcoming exacerbations in a Point-of-Care (PoC) environment. However, the concurrent consideration of patients' demographic and medical parameters is necessary for achieving accurate outcomes. Therefore, Machine Learning (ML) tools can play an important role for analyzing patient data and providing comprehensive results for the recognition of COPD in a PoC setting. As a result, the objective of this research work was to implement ML tools on data acquired from characterizing saliva samples of COPD patients and healthy controls as well as their demographic information for PoC recognition of the disease. For this purpose, a permittivity biosensor was used to characterize dielectric properties of saliva samples and, subsequently, ML tools were applied on the acquired data for classification. The XGBoost gradient boosting algorithm provided a high classification accuracy and sensitivity of 91.25% and 100%, respectively, making it a promising model for COPD evaluation. Integration of this model on a neuromorphic chip, in the future, will enable the real-time assessment of COPD in PoC, with low cost, low energy consumption, and high patient privacy. In addition, constant monitoring of COPD in a near-patient setup will enable the better management of the disease exacerbations.","Diseases,Dielectrics,Lung,Tools,Biosensors,Permittivity,Machine learning,COPD classification,AI in medicine,personalized healthcare,permittivity spectroscopy,precision diagnostic,saliva characterization,XGBoost",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,DIAGNOSIS,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09195859.pdf,
10,Gathering Effective Information for Real-Time Material Recognition,8,,159511-159529,"Zhang Hongbin,Jiang Ziliang,Xiong Qipeng,Wu Jinpeng,Yuan Tian,Li Guangli,Huang Yiwang,Ji Donghong","Zhang HB,Jiang ZL,Xiong QP,Wu JP,Yuan T,Li GL,Huang YW,Ji DH",Zhang HB; Jiang ZL,10.1109/ACCESS.2020.3020382,East China Jiaotong University,"Material recognition is a fundamental problem in the field of computer vision. Material recognition is still challenging because of varying camera perspectives, light conditions, and illuminations. Feature learning or feature engineering helps build an important foundation for effective material recognition. Most traditional and deep learning-based features usually point to the same or similar material semantics from diverse visual perspectives, indicating the implicit complementary information (or cross-modal semantics) among these heterogeneous features. However, only a few studies focus on mining the cross-modal semantics among heterogeneous image features, which can be used to boost the final recognition performance. To address this issue, we first improve the well-known multiset discriminant correlation analysis model to fully mine the cross-modal semantics among heterogeneous image features. Then, we propose a novel hierarchical multi-feature fusion (HMF2) model to gather effective information and create novel yet more effective and robust features. Finally, a general classifier is employed to train a new material recognition model. Experimental results demonstrate the simplicity, effectiveness, robustness, and efficiency of the HMF2 model on two benchmark datasets. Furthermore, based on the HMF2 model, we design an end-to-end online system for real-time material recognition.","Semantics,Image recognition,Correlation,Robustness,Benchmark testing,Visualization,Analytical models,hierarchical multi-feature fusion,discriminant correlation analysis,cross-modal semantics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE,FEATURES,FRAMEWORK,SCENE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09180292.pdf,
11,Expression-EEG Based Collaborative Multimodal Emotion Recognition Using Deep AutoEncoder,8,,164130-164143,Zhang Hongli,Zhang HL,Zhang HL,10.1109/ACCESS.2020.3021994,Inner Mongolia Normal University,"Emotion recognition has shown many valuable roles in people's lives under the background of artificial intelligence technology. However, most existing emotion recognition methods have poor recognition performance, which prevents their promotion in practical applications. To alleviate this problem, we proposed an expression-EEG interaction multi-modal emotion recognition method using a deep automatic encoder. Firstly, decision tree is applied as objective feature selection method. Then, based on the facial expression features recognized by sparse representation, the solution vector coefficients are analyzed to determine the facial expression category of the test samples. After that, the bimodal deep automatic encoder is adopted to fuse the EEG signals and facial expression signals. The third layer of BDAE extracts features for training of supervised learning. Finally, LIBSVM classifier is used to complete classification task. We carried out experiments on a constructed video library to verify the proposed emotion recognition method. The results show that the proposed method can effectively extract and integrate high-level emotion-related features in EEG and facial expression signals. The recognition rate of discrete emotion state type and the average emotion recognition rate have been improved relatively, in which the average emotion recognition rate is 85.71%. Overall, the emotion recognition ability has been greatly improved.","Emotion recognition,Feature extraction,Electroencephalography,Face recognition,Diseases,Brain modeling,Physiology,EEG signals,facial expression features,multi-modal fusion,deep automatic encoder,emotion recognition,decision tree,sparse representation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FUSION,SELECTION,NETWORKS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09187342.pdf,
12,U-net Based Method for Automatic Hard Exudates Segmentation in Fundus Images Using Inception Module and Residual Connection,8,,167225-167235,"Zong Yongshuo,Chen Jinling,Yang Lvqing,Tao Siyi,Aoma Cieryouzhen,Zhao Jiangsheng,Wang Shuihua","Zong YS,Chen JL,Yang LQ,Tao SY,Aoma C,Zhao JS,Wang SH",Yang LQ,10.1109/ACCESS.2020.3023273,Xiamen University,"Diabetic retinopathy (DR) is an eye abnormality caused by chronic diabetes that affected patients worldwide. Hard exudate is an important and observable sign of DR and can be used for early diagnosis. In this paper, an automatic hard exudates segmentation method is proposed in order to aid ophthalmologists to diagnose DR in the early stage. We utilized the SLIC superpixel algorithm to generate sample patches, thus overcoming the difficulty of the limited and imbalanced dataset. Furthermore, a U-net based network architecture with inception modules and residual connections is proposed to conduct end-to-end hard exudate segmentation, and focal loss is utilized as the loss function. Extensive experiments have been conducted on the IDRiD dataset to evaluate the performance of the proposed method. The reported sensitivity, specificity, and accuracy achieve 96.38%, 97.14%, and 97.95% respectively, which demonstrates the effectiveness and superiority of our method. The achieved segmentation results prove the potential of the method for clinical diagnosis.","Image segmentation,Feature extraction,Machine learning,Diabetes,Biomedical imaging,Classification algorithms,Image color analysis,Deep learning,diabetic retinopathy,exudates segmentation,superpixel,U-net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COLOR,RETINAL,IMAGES,DIABETIC-RETINOPATHY,NEURAL-NETWORKS,PHOTOGRAPHS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09194249.pdf,
13,Metrology of 3D-NAND Structures using Machine Learning Assisted Fast Marching Level-Sets Algorithm,11325,,,"Adiga Umesh,Higgins Derek,Lee Sang Hoon,Biedrzycki Mark,Nelson Dan","Adiga U,Higgins D,Lee SH,Biedrzycki M,Nelson D",Adiga U,10.1117/12.2552080,Thermo Fisher Scientific,"Accurate segmentation of 3D-NAND memory cells and the interfaces of different materials within is the basis of reliable metrology for 3D-NAND memory fabrication. We are proposing a machine learning assisted fast marching level sets method (FMLS) to efficiently delineate material interfaces within 3D-NAND cells. This method works with single or multiple seed initialization that evolves and propagates towards object boundaries independent of topological merger and splitting. Images containing thousands of NAND cells can be processed within a few seconds using this method, making this a very convenient tool for inline metrology during fabrication. With an appropriate preprocessing, FMLS can be used to segment nonconvex structures, such as fins and gates, too.","Memory,3D-NAND,Fast-marching,Level-sets",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
14,Contrasting Conventional and Machine Learning Approaches to Optical Critical Dimension Measurements,11325,,,"Barnes Bryan M.,Henn Mark-Alexander","Barnes BM,Henn MA",Barnes BM,10.1117/12.2551504,National Institute of Standards & Technology (NIST) - USA,"Accurate, optics-based measurement of feature sizes at deep sub-wavelength dimensions has been conventionally challenged by improved manufacturing, including smaller linewidths, denser layouts, and greater materials complexity at near-atomic scales. Electromagnetic modeling is relied upon heavily for forward maps used to solve the inverse problem of optical measurements for parametric estimation. Machine learning (ML) approaches are continually under consideration, either as a means to bypass direct comparison to simulation or as a method to augment nonlinear regression. In this work, ML approaches are investigated using a well-characterized experimental data set and its simulation library that assumes a 2-D geometry. The benefits and limitations of ML for optical critical dimension (OCD) metrology are illustrated by comparing a straightforward library lookup method and two ML approaches, a data-driven surrogate model for nonlinear regression using radial basis functions (RBF) and multiple-output Gaussian process regression (GPR) that indirectly applies the simulated intensity data. Both RBF and GPR generally improve accuracy over the conventional method with as few as 32 training points. However, as measurement noise is decreased the uncertainties from RBF and GPR differ greatly as the GPR posterior estimate of the variance appears to overestimate parametric uncertainties. Both accuracy and uncertainty must be addressed in OCD while balancing simulation versus ML computational requirements.",LIMITS,Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,LIMITS,,,
15,Enabling Accurate and Robust Optical Metrology of In Device Overlay,11325,,,"Kang Min-Seok,Hwang Chan,Lee Seung Yoon,Lee Jeongjin,Park Joon-Soo,Leewis Christian,Yang Eun-Ji,Lee Do-Haeng,Lee James,Huda Sabil","Kang MS,Hwang C,Lee SY,Lee J,Park JS,Leewis C,Yang EJ,Lee DH,Lee J,Huda S",Leewis C,10.1117/12.2553446,ASML Holding,"Utilizing a unique high NA optical system, a new methodology to measure device overlay accurately has been developed with a key differentiation. Historically, optical techniques to measure features below the image resolution require supporting measurement techniques to be used as a reference to anchor the optical measurement. This novel selfreference methodology enables accurate and robust optical metrology for device features after etch eliminating the need for external reference measurements such as Decap, x-sections or high landing energy SEMs.
In this paper, we discuss how a high NA Optical Metrology system enables measurements on small area device replica targets, which enables the ability to create a reference target for device measurements. The methodology utilizes this reference target to enable accurate direct on device overlay measurements without the need for an external reference. Furthermore, the technique is expanded to improve the robustness of the measurement and monitor live in production the health of the recipe, ensuring accuracy overtime. This ultimately leads to a method to extend the recipes in real-time based on the health KPIs.
The improved accurate and robust device overlay measurements have proven to improve the overlay performance compared to other techniques. This, combined with the speed of optical systems, enables unconstrained dense measurements directly on device structures after etch, allowing for improved overlay control.","Machine Learning,Overlay,Optical Metrology,robustness,DRAM,after etch,in device measurements,self-reference",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
16,Machine Learning for Tool Induced Shift (TIS) Reduction,11325,,,"Katz Shlomit,Ophir Boaz,Shusterman Udi,Golotsvan Anna,Yerushalmi Liran,Megged Efi,Grauer Yoav,Zhang Jian,Shih Alimei,Wei Shi-Ming","Katz S,Ophir B,Shusterman U,Golotsvan A,Yerushalmi L,Megged E,Grauer Y,Zhang J,Shih A,Wei SM",Katz S,10.1117/12.2550747,KLA Corporation,"Tool induced shift (TIS) is a measurement error attributed to tool asymmetry issues and is commonly used to measure the accuracy of metrology tools. Overlay (OVL) measurement inaccuracy is commonly caused by lens aberration, lens alignment, illumination alignment and asymmetries on the measured target. TIS impacts total measurement uncertainty (TMU) and tool-to-tool matching, and TIS variation across wafer can account for inaccuracy, if not fully corrected, as it depends on the incoming process condition. In addition, both lot-to-lot and wafer-to-wafer process variation are influenced by TIS in terms of overlay performance, which also includes metrology tool-to- tool efficiency in terms of throughput. In the past, TIS correction was only done using a small sampling, resulting in additional error in the measurement which was not corrected. Hence, a new methodology is explored to improve overlay measurement accuracy by Modeled-TIS (M-TIS). This paper discusses a new approach of harnessing Machine Learning (ML) algorithms to predict TIS correction on imaging-based overlay (IBO) measurements at the after-develop inspection (ADI) step. KLA's ML algorithm is trained to detect TIS error contributors to overlay measurements by training a model to find the required TIS correction for one wafer. This information, along with additional accuracy metrics, is then used to predict the TIS for other wafers, without having to actually measure the wafers. In this paper, we present the results of a case study focusing on DRAM and 3D NAND production lots.","Photolithography Overlay (OVL),Imaging-Based Overlay (IBO),Tool Induced Shift (TIS),Total Measurement Uncertainty (TMU),Modeled-TIS (M-TIS),Data Analytics,Predictive Metrology,3D NAND,DRAM,Foundry,On-Product Overlay (OPO)",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
17,Machine learning and hybrid metrology using HV-SEM and optical methods to monitor channel hole tilting in-line for 3D NAND wafer production,11325,,,"Meng Michael,Tu Leeming,Mi Jian,Zhou Haydn,Zou Xi","Meng M,Tu L,Mi J,Zhou H,Zou X",Mi J,10.1117/12.2551622,"Yangtze Memory Technol Co Ltd, Wuhan, Peoples R China.","Tilted channel holes affect final yield significantly in High Aspect Ratio (HAR) 3D NAND memory wafer processing. An in-line measurement method is developed to use machine learning that utilizes the spectra from optical metrology to map Tilt-X and Tilt-Y. Reliable reference is provided by high voltage SEM. Results show that the correlation of optical and HV e-Beam measurements has R-2 more than 0.92. In addition, measurement throughput is improved tremendously by 40% from e-Beam to optical metrology. Combined with other optical metrology on the same platform (thickness, and Optical CD), this method is much efficient for in-line tilt measurement after channel hole etch process.","Machine learning,Tilt,3D NAND,HAR,HV-SEM,Optical metrology",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
18,Contour extraction algorithm for edge placement error measurement using machine learning,11325,,,"Okamoto Yosuke,Nakazawa Shinichi,Kawamura Akinori,Haga Tsugihiko,Mori Taihei,Maruyama Kotaro,Kang Seul-Ki,Yamazaki Yuichiro","Okamoto Y,Nakazawa S,Kawamura A,Haga T,Mori T,Maruyama K,Kang SK,Yamazaki Y",Okamoto Y,10.1117/12.2553663,"TASMIT Inc, Yokohama, Kanagawa 2220033, Japan.","The accurate and precise contour extraction on SEM image is important to measure overlay, improve OPC model, inspect tiny hot-spot, and so on. In 2019, we reported about the measurement repeatability of edge placement error (EPE) with Die-to-Database (D2DB) algorithm. In this study, we apply machine learning for the contour extraction to improve the measurement throughput with high accuracy and precision of EPE on 2D pattern.
The pattern contour on SEM image can be extracted by processing gray-level profile data across the measurement line. Generally, in order to extract the precise contour, the direction of the profile should be perpendicular to the pattern contour. Although the direction used to be determined by the design pattern, it can't be accurate enough to extract the contour exactly since the shape between the design pattern and the actual pattern are different. We propose the method that determines the direction of the profile acquisition using the contour taken by machine learning, which is more similar to the actual pattern contour than the design pattern contour. The accuracy and the precision of EPE measurement using the contour extracted by our method has been improved in actual SEM images captured repeatedly.","D2DB,Contour Extraction,Machine Learning,Edge Placement Error",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
19,Trainable Die-To-Database for Fast e-Beam Inspection: Learning Normal Images to Detect Defects,11325,,,"Ouchi Masanori,Ishikawa Masayoshi,Shinoda Shinichi,Toyoda Yasutaka,Yumiba Ryo,Shindo Hiroyuki,Izawa Masayuki","Ouchi M,Ishikawa M,Shinoda S,Toyoda Y,Yumiba R,Shindo H,Izawa M",Ouchi M,10.1117/12.2551456,Hitachi Limited,"In the drive toward sub-10-nm semiconductor devices, manufacturers have been developing advanced lithography technologies such as extreme ultraviolet lithography and multiple patterning. However, these technologies can cause unexpected defects, and a high-speed inspection is thus required to cover the entire surface of a wafer. A Die-to-Database (D2DB) inspection is commonly known as a high-speed inspection. The D2DB inspection compares an inspection image with a design layout, so it does not require a reference image for comparing with the inspection image, unlike a die-to-die inspection, thereby achieving a high-speed inspection. However, conventional D2DB inspections suffer from erroneous detection because the manufacturing processes deform the circuit pattern from the design layout, and such deformations will be detected as defects. To resolve this issue, we propose a deep-learning-based D2DB inspection that can distinguish a defect deformation from a normal deformation by learning the luminosity distribution in normal images. Our inspection detects outliers of the learned luminosity distribution as defects. Because our inspection requires only normal images, we can train the model without defect images, which are difficult to obtain with enough variety. In this way, our inspection can detect unseen defects. Through experiments, we show that our inspection can detect only the defect region on an inspection image.","Inspection,Defect detection,Image processing,Machine learning,Lithography,Scanning electron microscope",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
20,Realizing more accurate OPC models by utilizing SEM contours,11325,,,"Wei Chih- I,Sejpal Rajiv,Deng Yunfei,Kusnadi Ir,Fenger Germain,Oya Masahiro,Okamoto Yosuke,Maruyama Kotaro,Yamazaki Yuichiro,Das Sayantan","Wei CI,Sejpal R,Deng YF,Kusnadi I,Fenger G,Oya M,Okamoto Y,Maruyama K,Yamazaki Y,Das S",Wei CI,10.1117/12.2554527,Mentor Graphics Inc,"The method to perform Optical Proximity Correction (OPC) model calibration with contour-based input data from both small field of view (SFoV) and large field of view (LFoV) e-beam inspection is presented. For advanced OPC models - such as Neural Network Assisted Models (NNAM) [1], pattern sampling is a critical topic, where pattern feature vectors utilized in model training, such as image parameter space (IPS) is critical to ensure accurate model prediction [2-5]. In order to improve the design space coverage, thousands of gauges with unique feature vector combinations might be brought into OPC model calibration to improve pattern coverage. The time and cost in conventional Critical Dimension Scanning Electron Microscope (CD-SEM) metrology to measure this large amount of CD gauges is costly. Hence, an OPC modeling solution with contour-based input has been introduced [6]. Built on this methodology, a single inspection image and SEM contour can include a large amount of information along polygon edges in complex logic circuit layouts. Namely, a better feature vector coverage could be expected [7]. Furthermore, much less metrology time is needed to collect the OPC modeling data comparing to conventional CD measurements. It is also shown that by utilizing large field 2D contours, which are difficult to characterize by CD measurements, in model calibration the model prediction of 2D features is improved. Finally, the model error rms of conventional SFoV modeling and LFoV contour modeling between SEM contours and simulation results are compared.","EUV Lithography,SEM Contour,Contour-based OPC Modeling,5nm,Machine Learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
21,Learning-based Material Classification in X-ray Security Images,,,284-291,"Emil Benedykciuk,Marcin Denkowski,Krzysztof Dmitruk","Emil B,Marcin D,Krzysztof D",Emil B,10.5220/0008951702840291,Maria Curie-Sklodowska University,"Although a large number of papers have been published on material classification in the X-ray images, relatively few of them study X-ray security raw images as regards of material classification. This paper takes into consideration the task of materials classification into four main types of organics and metals in images obtained from Dual-Energy X-ray (DEXA) security scanner. We adopt well-known methods of machine learning and conduct experiments to examine the effects of various combinations of data and algorithms for generalization of the material classification problem. The methods giving the best results (Random Forests and Support Vector Machine) were used to predict the materials at every pixel in the testing image. The results motivate a novel segmentation scheme based on the multi-scale patch classification. This paper also introduces a new, open dataset of X-ray images (MDD) of various materials. The database contains over one million samples, labelled and stored in its raw, original 16-bit depth form.",X-ray Imaging,Proceedings Paper,"SCITEPRESS, AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL",Computer Science,,,"MODEL,SELECTION","VISAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4: VISAPP",,
22,Application of Artificial Intelligence in Pharmaceutical and Biomedical Studies,26,29,3569-3578,"Thakur Abhimanyu,Mishra Ambika P.,Panda Bishnupriya,Rodriguez Diana C. S.,Gaurav Isha,Majhi Babita","Thakur A,Mishra AP,Panda B,Rodriguez DCS,Gaurav I,Majhi B",Thakur A,10.2174/1381612826666200515131245,City University of Hong Kong,"Background: Artificial intelligence (AI) is the way to model human intelligence to accomplish certain tasks without much intervention of human beings. The term AI was first used in 1956 with The Logic Theorist program, which was designed to simulate problem-solving ability of human beings. There have been a significant amount of research works using AI in order to determine the advantages and disadvantages of its applicabication and, future perspectives that impact different areas of society. Even the remarkable impact of AI can be transferred to the field of healthcare with its use in pharmaceutical and biomedical studies crucial for the socioeconomic development of the population in general within different studies, we can highlight those that have been conducted with the objective of treating diseases, such as cancer, neurodegenerative diseases, among others. In parallel the long process of drug development also requires the application of AI to accelerate research in medical care.
Methods: This review is based on research material obtained front PubMed up to Jan 2020. The search terms include ""artificial intelligence"", ""machine learning"" in the context of research on pharmaceutical and biomedical applications.
Results: This study aimed to highlight the importance of AI in the biomedical research and also recent studies that support the use of AI to generate tools using patient data to improve outcomes. Other studies have demonstrated the use of AI to create prediction models to determine response to cancer treatment.
Conclusion: The application of AI in the field of pharmaceutical and biomedical studies has been extensive, including cancer research, for diagnosis as well as prognosis of the disease state. It has become a tool for researchers in the management of complex data, ranging from obtaining complementary results to conventional statistical analyses. AI increases the precision in the estimation of treatment effect in cancer patients and determines prediction outcomes.","Artificial intelligence,machine learning,pharmaceutical research,biomedical research,pharmaceutical and biomedical applications,conventional statistical analyses",Review,"BENTHAM SCIENCE PUBL LTD, EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES",Pharmacology & Pharmacy,,3.309,"DEEP-LEARNING,ALGORITHM,TABLET,FORMULATIONS,CANCER,PROGNOSIS,NEURAL-NETWORK,MACHINE,SYSTEM,PREDICTION,MANAGEMENT,FRAMEWORK,SURGERY",CURRENT PHARMACEUTICAL DESIGN,,
23,"Analysis of trade-off relationships between resolution, line edge roughness, and sensitivity in extreme ultraviolet lithography using machine learning",11323,,,"Azumagawa Kazuki,Kozawa Takahiro","Azumagawa K,Kozawa T",Azumagawa K,10.1117/12.2551826,Osaka University,"High-volume production of semiconductor devices by extreme ultraviolet (EUV) lithography has started since 2019. A high numerical aperture tool is planned to extend the use of EUV lithography. The trade-off relationships between resolution, line edge roughness (LER), and sensitivity are a significant concern for the extendability of EUV lithography. In previous study, the dependences of chemical gradient (an indicator of LER) on the half-pitch of line-and-space patterns, the sensitivity, the sensitizer concentration, and the effective reaction radius for deprotection were investigated using a simulation on the basis of the sensitization and reaction mechanisms of chemically amplified EUV resists. Although the relationships between resolution, LER, and sensitivity were formulated in the half-pitch range lager than 10 nm, they were deviated from the equations in the sub-10 nm half-pitch resolution region. Recently, the application of information science to the material engineering has attracted much attention. In this study, the feasibility of the application of machine learning to the analysis of trade-off relationships was investigated. The sub-10 nm region was fitted well using lasso.","EUV lithography,machine learning,materials informatics,LWR,trade-off,mechanism,chemical gradient",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
24,Machine Learning Techniques for OPC Improvement at the Sub-5 nm Node,11323,,,"Kim Changsoo,Lee Seungjong,Park Sangwoo,Chung No-Young,Kim Jungmin,Bang Narae,Lee Sanghwa,Lee SooRyong,Boone Robert,Li Pengcheng","Kim C,Lee S,Park S,Chung NY,Kim J,Bang N,Lee S,Lee S,Boone R,Li PC",Kim C,10.1117/12.2551841,Samsung,"With conventional methods, improvements in optical proximity correction (OPC) runtime and accuracy can be challenging. Often improvements in accuracy have limited impact or require longer runtimes. Conversely, improvements in runtime often come at a sacrifice to overall correction quality. OPC industries have been developing and applying machine-learning (ML) methods to address both issues together, such as the Newron (R) machine learning family of products, which provides for both faster ML-based correction and more accurate resist models. Benchmark testing shows that ML-based correction prediction can yield runtime improvements of 30% or more without sacrificing pattern fidelity. It also shows that a ML resist model can deliver simulation accuracy 15% better than a conventional lithography model. This paper discusses the conversion flow from baseline OPC recipe to ML-accelerated recipe and presents results of a study that applies this technique to a sub-5 nm EUV test case, as well as results of a study that leverages a ML resist model to improve OPC accuracy.","optical proximity correction,pattern classification,machine learning,deep learning (DL),edge placement error (EPE),modeling,runtime optimization",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
25,Mechanical properties modeling of severely plastically deformed biodegradable ZK60 magnesium alloy for bone implants,17,5,,"Zhang Yan,Wang Ning,Li Jingyi,Mesbah Mohsen,Wong Kuan Yew,Fallahpour Alireza,Nasiri-Tabrizi Bahman,Yang Jiangfei","Zhang Y,Wang N,Li JY,Mesbah M,Wong KY,Fallahpour A,Nasiri-Tabrizi B,Yang JF",Yang JF,10.1590/1679-78256151,Shandong First Medical University & Shandong Academy of Medical Sciences,"The effectiveness of magnesium (Mg) alloys to improve the capability of bone tissue generation may be severely diminished if the required mechanical properties are not provided. Here, the effort is directed to model the mechanical performance of severely plastically deformed biodegradable ZK60 Mg alloy in bone regeneration protocols. For this purpose, the effects of parallel tubular channel angular pressing (PTCAP) on yield strength (sigma(YS)), ultimate tensile strength (sigma(UTS)), and elongation to failure (delta) were addressed. Given the multifaceted variables of the PTCAP with nonlinear interactions, a precise determination of the mechanical properties requires a large number of experiments. Therefore, gene expression programming (GEP) and genetic programming (GP) models were proposed to achieve appropriate combinations of mechanical properties for bone implant purposes based on a rational hypothesis that for correlation coefficient (vertical bar R vertical bar) higher than 0.8, a strong correlation is established between the predicted and measured values. The results verified that the highest mechanical performance was achieved at the second pass of PTCAP, thus has a great potential to be the most promising candidate for biodegradable implant material. Besides, the proposed models were capable of precisely predicting the mechanical performance of the SPD-processed biodegradable ZK60 Mg.","severe plastic deformation (SPD),mechanical properties,biodegradable bone implants,prediction",Article,"LATIN AMER J SOLIDS STRUCTURES, UNIV SAO PAULO, GROUP SOLID MECHANICS & STRUCTURAL IMPACT, SAO PAULO, 05508-900, BRAZIL","Engineering,Mechanics",,1.481,"MICROSTRUCTURE,DEFORMATION,NANO,PREDICTION,CORROSION,STRENGTH,BEHAVIOR,OPPORTUNITIES,EVOLUTION,SELECTION",LATIN AMERICAN JOURNAL OF SOLIDS AND STRUCTURES,http://www.scielo.br/pdf/lajss/v17n5/1679-7825-lajss-17-05-e293.pdf,
26,Automated Defect Detection for Non-Destructive Evaluation by Radar Imaging and Machine Learning,,,25-28,"Ullmann Ingrid,Egerer Pascal,Schuer Jan,Vossiek Martin","Ullmann I,Egerer P,Schur J,Vossiek M",Ullmann I,,University of Erlangen Nuremberg,"This work provides a concept for a fully automated, non-invasive evaluation of dielectric objects by use of synthetic aperture radar (SAR) imaging combined with machine learning for application in non-destructive evaluation (NDE).
For demonstration purposes we investigated a set of polyvinylchloride (PVC) test objects. A millimetre-wave imaging system is used to scan the objects. By employing subsurface SAR imaging techniques, high-resolution images from the objects' insides can be obtained. These images are used as a dataset for a convolutional neural network. By training the network on several typical defect structures such as cracks, delaminations or contaminations, the proposed procedure enables an automated decision whether an object under test is intact or defective, independent of the kind of defect.","synthetic aperture radar,radar imaging,machine learning,nondestructive evaluation,nondestructive testing,millimeter wave radar",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
27,Skin microcirculation in patients with a history of cardiovascular events,11457,,,"Glazkova Polina A.,Kulikov Dmitry A.,Rogatkin Dmitry A.,Terpigorev Stanislav A.,Shekhyan Grant G.,Glazkov Aleksey A.,Kulikov Aleksandr V,Makmatov-Rys Mikhail B.,Charaeva Tatiana G.,Kozlova Ksenia A.","Glazkova PA,Kulikov DA,Rogatkin DA,Terpigorev SA,Shekhyan GG,Glazkov AA,Kulikov AV,Makmatov-Rys MB,Charaeva TG,Kozlova KA",Glazkova PA,10.1117/12.2564182,"Moscow Reg Res & Clin Inst MONIKI, 61-2 Schepkina, Moscow 129110, Russia.","The reactivity of skin microcirculation was compared in 3 groups of patients. Group 1 included healthy volunteers without cardiovascular diseases (n = 19), Group 2 included patients with diseases that increase the risk of cardiovascular events (arterial hypertension and / or angina pectoris and / or diabetes mellitus) (n = 40), Group 3 included patients with a history of cardiovascular events (myocardial infarction and / or stroke and / or coronary revascularization) (n = 20). Microcirculation measurement was performed by Laser Doppler flowmetry using LAKK 02 device during the heating test. Patients from Group 2 had a decrease in the reactivity of skin microcirculation compared with the control group, while the reactivity of skin microcirculation in these patients was better than in patients from Group 3. The highest difference was observed for the Slope_180 parameter (slope of the regression line of the microcirculation curve for the first 180 seconds of heating). Using the machine learning we developed a method for classifying patients into Group 1, Group 2, Group 3 according to the Slope_180 parameter. The sensitivity and specificity of Slope_180 parameter in identifying patients with cardiovascular diseases, diabetes (groups 2 and 3 together) was 82% and 68%, respectively. Such methods may be a promising for health screening. Thus, the relationship between the severity of skin microcirculation disorders and the ""severity"" of cardiovascular disease demonstrates the prospect of studying microcirculatory disorders as a cardiovascular risk factor.","microcirculation,laser Doppler flowmetry,diabetes mellitus,arterial hypertension,myocardial infarction,microcirculation reactivity,cardiovascular diseases,cardiovascular risk factor",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics",,,"MICROVASCULAR,FUNCTION,REACTIVE,HYPEREMIA,DISEASE,DYSFUNCTION,INDEXES,RISK",,,
28,Application of machine learning approach in disordered materials,50,6,,",,,","Wu Jiaqi,Sun Yitao,Wang Weihua,Li Maozhi",,,Wu Jiaqi,"As a new amorphous material,metallic glass has been widely studied because of its excellent mechanical,physical and chemical properties.Glass-forming ability has always been an important problem restricting the development of amorphous materials.In order to design amorphous materials with good glass-forming ability,a lot of research has been done on the glass-forming ability of amorphous materials.It has been shown that a single factor cannot describe glassforming ability of amorphous materials.Because of the complex and disordered structure of amorphous materials,it is difficult to understand the structure and nature of amorphous materials comprehensively and clearly by traditional methods.Machine learning method,as a new research paradigm,provides new opportunities for exploring these bottleneck scientific issues in disordered materials.In this paper,some machine learning algorithms,such as support vector machine,artificial neural network and K-means clustering,are briefly introduced.Moreover,we briefly review the application of machine learning approach in amorphous materials,including the classification of amorphous structure,the correlation between amorphous structure and properties,and the prediction of macroscopic properties of amorphous materials.We also discuss the future application of machine learning approach to disordered materials,including the development of comprehensive database,high throughput calculation method and the development of machine learning potential function.","machine learning,; disordered materials; glass-forming ability; structure-property relationships",Review,,,,,,,,
29,AA Comparison of Dynamic Modeling Approaches for Epileptic EEG Detection and Classification.,2020,,523-527,",,","Song Xiaomu,Aguilar Luis,Yoon Suk-Chung",,10.1109/EMBC44109.2020.9175979,,,,Journal Article,,,,,,,,
30,FCN-Based DenseNet Framework for Automated Detection and Classification of Skin Lesions in Dermoscopy Images,8,,150377-150396,"Adegun Adekanmi A.,Viriri Serestina","Adegun AA,Viriri S",Viriri S,10.1109/ACCESS.2020.3016651,University of Kwazulu Natal,"Skin Lesion detection and classification are very critical in diagnosing skin malignancy. Existing Deep learning-based Computer-aided diagnosis (CAD) methods still perform poorly on challenging skin lesions with complex features such as fuzzy boundaries, artifacts presence, low contrast with the background and, limited training datasets. They also rely heavily on a suitable turning of millions of parameters which often leads to over-fitting, poor generalization, and heavy consumption of computing resources. This study proposes a new framework that performs both segmentation and classification of skin lesions for automated detection of skin cancer. The proposed framework consists of two stages: the first stage leverages on an encoder-decoder Fully Convolutional Network (FCN) to learn the complex and inhomogeneous skin lesion features with the encoder stage learning the coarse appearance and the decoder learning the lesion borders details. Our FCN is designed with the sub-networks connected through a series of skip pathways that incorporate long skip and short-cut connections unlike, the only long skip connections commonly used in the traditional FCN, for residual learning strategy and effective training. The network also integrates the Conditional Random Field (CRF) module which employs a linear combination of Gaussian kernels for its pairwise edge potentials for contour refinement and lesion boundaries localization. The second stage proposes a novel FCN-based DenseNet framework that is composed of dense blocks that are merged and connected via the concatenation strategy and transition layer. The system also employs hyper-parameters optimization techniques to reduce network complexity and improve computing efficiency. This approach encourages feature reuse and thus requires a small number of parameters and effective with limited data. The proposed model was evaluated on publicly available HAM10000 dataset of over 10000 images consisting of 7 different categories of diseases with 98% accuracy, 98.5% recall, and 99% of AUC score respectively.","Lesions,Skin,Feature extraction,Machine learning,Skin cancer,Training,Support vector machines,Skin lesion,deep leraning,CAD,classification,FCN,CRF,DenseNet,encoder-decoder,hyper-parameter,skin cancer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CANCER,SEGMENTATION,MELANOMA,POPULATION,DIAGNOSIS",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016651,
31,Development of Novel Big Data Analytics Framework for Smart Clothing,8,,146376-146394,"Ahsan Mominul,Hon Siew Teay,Albarbar Alhussein","Ahsan M,Hon ST,Albarbar A",Ahsan M,10.1109/ACCESS.2020.3015152,Manchester Metropolitan University,"Recent advances in micro electro-mechanical systems (MEMS) have produced wide variety of wearable sensors. Owing to their low cost, small size and interfacability, those MEMS based devices have become increasingly commonplace and part of daily life for many people. Large amount of data from heart and breath rates to electrocardiograph (ECG) signals, which contain a wealth of health-related information, can be measured. Hence, there is a timely need for novel interrogation and analysis methods for extracting health related features from such a Big Data. In this paper, the prospects from smart clothing such as wearable devices in generating Big Data are critically analyzed with a focus on applications related to healthcare, sports and fashion. The work also covers state-of-the-art data analytics methods and frameworks for health monitoring purposes. Subsequently, a novel data analytics framework that can provide accurate decision in both normal and emergency health situations is proposed. The proposed novel framework identifies and discusses sources of Big Data from the human body, data collection, communication, data storage, data analytics and decision making using artificial intelligence (AI) algorithms. The paper concludes by identifying challenges facing the integration of Big Data analytics with smart clothing. Recommendation for further development opportunities and directions for future work are also suggested.","Big Data,Medical services,Biomedical monitoring,Data analysis,Distributed databases,Wearable technology,smart clothing,big data,data analytics,artificial intelligence (AI)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ACTIVITY,RECOGNITION,DECISION-MAKING,HEALTH,SYSTEM,MOBILE,SEGMENTATION,PREDICTION,INTERNET",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09162027.pdf,
32,Automated System for Chromosome Karyotyping to Recognize the Most Common Numerical Abnormalities Using Deep Learning,8,,157727-157747,"Al-Kharraz Mona Salem,Elrefaei Lamiaa A.,Fadel Mai Ahmed","Al-Kharraz MS,Elrefaei LA,Fadel MA",Al-Kharraz MS,10.1109/ACCESS.2020.3019937,King Abdulaziz University,"Chromosome analysis is an essential task in a cytogenetics lab, where cytogeneticists can diagnose whether there are abnormalities or not. Karyotyping is a standard technique in chromosome analysis that classifies metaphase image to 24 chromosome classes. The main two categories of chromosome abnormalities are structural abnormalities that are changing in the structure of chromosomes and numerical abnormalities which include either monosomy (missing one chromosome) or trisomy (extra copy of the chromosome). Manual karyotyping is complex and requires high domain expertise, as it takes an amount of time. With these motivations, in this research, we used deep learning to automate karyotyping to recognize the common numerical abnormalities on a dataset containing 147 non-overlapped metaphase images collected from the Center of Excellence in Genomic Medicine Research at King Abdulaziz University. The metaphase images went through three stages. The first one is individual chromosomes detection using YOLOv2 Convolutional Neural Network followed by some chromosome post-processing. This step achieved 0.84 mean IoU, 0.9923 AP, and 100% individual chromosomes detection accuracy. The second stage is feature extraction and classification where we fine-tune VGG19 network using two different approaches, one by adding extra fully connected layer(s) and another by replacing fully connected layers with the global average pooling layer. The best accuracy obtained is 95.04%. The final step is detecting abnormality and this step obtained 96.67% abnormality detection accuracy. To further validate the proposed classification method, we examined the Biomedical Imaging Laboratory dataset which is publicly available online and achieved 94.11% accuracy.","Biological cells,Feature extraction,Machine learning,Image segmentation,Training,Indexes,Computational modeling,Convolutional neural network,deep learning,chromosomes classification,data augmentation,transfer learning,object detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,SEGMENTATION,NETWORKS,DROPOUT",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09178721.pdf,
33,An Effective Bio-Signal-Based Driver Behavior Monitoring System Using a Generalized Deep Learning Approach,8,,135037-135049,"Alamri Atif,Gumaei Abdu,Al-Rakhami Mabrook,Hassan Mohammad Mehedi,Alhussein Musaed,Fortino Giancarlo","Alamri A,Gumaei A,Al-Rakhami M,Hassan MM,Alhussein M,Fortino G",Fortino G,10.1109/ACCESS.2020.3011003,University of Calabria,"Recent years have seen increasing utilization of deep learning methods to analyze large collections of medical data and signals effectively in the Internet of Medical Things (IoMT) environment. Application of these methods to medical signals and images can help caregivers form proper decision-making. One of the important IoMT medical application areas includes aggressive driving behaviors to mitigate road incidents and crashes. Various IoMT-enabled body sensors or camera sensors can be utilized for real-time monitoring and detection of drivers' bio-signal status such as heart rate, blood pressure, and drivers' behaviors. However, it requires a lightweight detection module and a powerful training module with real-time storing and analysis of drivers' behaviors data from these medical devices to detect driving behaviors and provides instant feedback by the administrator for safety, gas emissions, and energy/fuel consumption. Therefore, in this paper, we propose a bio-signal-based system for real-time detection of aggressive driving behaviors using a deep convolutional neural network (DCNN) model with edge and cloud technologies. More precisely, the system consists of three modules, which are the driving behaviors detection module implemented on edge devices in the vehicle, the training module implemented in the cloud platform, and the analyzing module placed in the monitoring environment connected with a telecommunication network. The DCNN model of the proposed system is evaluated using a holdout test set of 30% on two different processed bio-signal datasets. These two processed bio-signal datasets are generated from our collected bio-signal dataset by using two different time windows and two different time steps. The experimental results show that the proposed DCNN model achieves 73.02% of validation accuracy on the processed dataset 1 and 79.15% of validation accuracy on the processed dataset 2. The results confirm the appropriateness and applicability of the proposed deep learning model for detecting driving aggressive behaviors using bio-signal data.","Vehicles,Biological system modeling,Roads,Accidents,Sensors,Monitoring,Acceleration,Internet of Medical Things (IoMT),bio-signal,aggressive driving behaviors,deep convolutional neural networks (DCNNs),cloud computing,Raspberry Pi",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146560.pdf,
34,Brain Tumour Image Segmentation Using Deep Networks,8,,153589-153598,"Ali Mahnoor,Gilani Syed Omer,Waris Asim,Zafar Kashan,Jamil Mohsin","Ali M,Gilani SO,Waris A,Zafar K,Jamil M",Gilani SO,10.1109/ACCESS.2020.3018160,National University of Sciences & Technology - Pakistan,"Automated segmentation of brain tumour from multimodal MR images is pivotal for the analysis and monitoring of disease progression. As gliomas are malignant and heterogeneous, efficient and accurate segmentation techniques are used for the successful delineation of tumours into intra-tumoural classes. Deep learning algorithms outperform on tasks of semantic segmentation as opposed to the more conventional, context-based computer vision approaches. Extensively used for biomedical image segmentation, Convolutional Neural Networks have significantly improved the state-of-the-art accuracy on the task of brain tumour segmentation. In this paper, we propose an ensemble of two segmentation networks: a 3D CNN and a U-Net, in a significant yet straightforward combinative technique that results in better and accurate predictions. Both models were trained separately on the BraTS-19 challenge dataset and evaluated to yield segmentation maps which considerably differed from each other in terms of segmented tumour sub-regions and were ensembled variably to achieve the final prediction. The suggested ensemble achieved dice scores of 0.750, 0.906 and 0.846 for enhancing tumour, whole tumour, and tumour core, respectively, on the validation set, performing favourably in comparison to the state-of-the-art architectures currently available.","Deep learning,BraTS,medical imaging,segmentation,U-Net,CNN,ensembling",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CENTRAL-NERVOUS-SYSTEM,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09171998.pdf,
35,Retinal Fluid Segmentation Using Ensembled 2-Dimensionally and 2.5-Dimensionally Deep Learning Networks,8,,152452-152464,"Alsaih Khaled,Yusoff Mohd Zuki,Faye Ibrahima,Tang Tong Boon,Meriaudeau Fabrice","Alsaih K,Yusoff MZ,Faye I,Tang TB,Meriaudeau F",Alsaih K,10.1109/ACCESS.2020.3017449,Universiti Teknologi Petronas,"Morphological changes related to different diseases that occur in the retina are currently extensively researched. Manual segmentation of retinal fluids is time-consuming and subject to variability, giving prominence to the demand for robust automatic segmentation methods. The standard in assessing the existence and mass of retinal fluids at present is through the optical coherence tomography (OCT) modality. In this study, semantic segmentation deep learning networks were examined in 2.5D and ensembled with 2D networks. This analysis aims to show how these networks can perform in-depth than using only a single B-scan and the effects of 2.5 patches when fitted to the deep networks. All experiments were evaluated using public data from the RETOUCH challenge as well as the OPTIMA challenge dataset and Duke dataset. The networks trained in 2.5D performed slightly better than 2D networks in all datasets. The average performance of the best network was 0.867, using the dice similarity coefficient score (DSC) metric on the RETOUCH dataset. On the DUKE dataset, Deeplabv3CPa outperformed other networks in this study with a dice score of 0.80. Experiments showed a more robust performance when networks were ensembled. Intraretinal fluid (IRF) was recognized better than other fluids with a DSC of 0.924. Deeplabv3CPa model outperformed all other networks with a p-value average of 0.03 on the RETOUCH challenge dataset. Methods used in this study to distinguish retinal disorders outperform human performance as well as showed competitive results to the teams who joined both challenges. Three consecutive B-scans, including partial depth information in training neural networks, were stacked as a single image built for more robust networks compared to providing only 2D information.","25D networks,deep learning,ensembled networks,retinal diseases,SD-OCT segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COHERENCE,TOMOGRAPHY,IMAGES,REGION,LAYER",IEEE ACCESS,https://doi.org/10.1109/access.2020.3017449,
36,Vertebral Tumor Detection and Segmentation Using Analytical Transform Assisted Statistical Characteristic Decomposition Model,8,,145278-145289,"Alsiddiky Abdulmonem,Fouad Hassan,Soliman Ahmed M.,Altinawi Amir,Mahmoud Nourelhoda M.","Alsiddiky A,Fouad H,Soliman AM,Altinawi A,Mahmoud NM",Alsiddiky A,10.1109/ACCESS.2020.3012719,King Saud University,"Recently, vertebral tumor prediction using image-based vertebral bio-mathematical modeling with accurate segmentation has been considered as a significant area of research. Further, precise lumbar spinal segmentation is essential to the clinicians for tumor analysis. Therefore, precise and reliable segmentation process is required to help radiologists and doctors to identify different vertebrae tumors with better prediction ratio. The exact vertebral disks segmentation of spinal bones from medical images is a complex process in dealing with different deformities and pathologies in accordance to the conventional techniques such as Deep Convolutional Neural Network (DCNN), Finite Element Analysis (FEA), Principal Component and Factor Analysis (PCFA), Multi-Parameter Ensemble Learning (MPEL), Hierarchical Conditional Random Forest (HCRF), and Deep Siamese Neural Network (DSNN). Therefore, to overcome the present drawbacks, Analytical Transform Assisted Statistical Characteristic Decomposition Model (ATS-CDM) is proposed in this paper for the accurate prediction of vertebral tumor detection and segmentation. This technique is used for the calibration of the segmentation procedures in vertebral tumor image prediction and Receiver Operating Curve (ROC) grading for the lumbar spines. The significant objective of the model-fitting algorithm iterates the tumor regions and measures the current region's variance for the accurate identification of tumor. The outcomes show potential and promising results at lab scale evaluation through analyzing the vertebral datasets with Intra-Discal Pressure (IDP) images for experimental validation with 98.7% bending and 98.88 % segmentation accuracy leads to 94.2 +/- 0.2 % to 97.02 +/- 0.2 % average ROCgrading.","Tumors,Image segmentation,Biomedical imaging,Transforms,Mathematical model,Analytical models,Spine,Analytical transform,lumbar spine,vertebral segmentation,statistical characteristic decomposition",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,FRAMEWORK,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151936.pdf,
37,Region-of-Interest Based Transfer Learning Assisted Framework for Skin Cancer Detection,8,,147858-147871,"Ashraf Rehan,Afzal Sitara,Rehman Attiq Ur,Gul Sarah,Baber Junaid,Bakhtyar Maheen,Mehmood Irfan,Song Oh-Young,Maqsood Muazzam","Ashraf R,Afzal S,Rehman AU,Gul S,Baber J,Bakhtyar M,Mehmood I,Song OY,Maqsood M",Maqsood M,10.1109/ACCESS.2020.3014701,COMSATS University Islamabad (CUI),"Melanoma is considered the most serious type of skin cancer. All over the world, the mortality rate is much high for melanoma in contrast with other cancer. There are various computer-aided solutions proposed to correctly identify melanoma cancer. However, the difficult visual appearance of the nevus makes it very difficult to design a reliable Computer-Aided Diagnosis (CAD) system for accurate melanoma detection. Existing systems either uses traditional machine learning models and focus on handpicked suitable features or uses deep learning-based methods that use complete images for feature learning. The automatic and most discriminative feature extraction for skin cancer remains an important research problem that can further be used to better deep learning training. Furthermore, the availability of the limited available images also creates a problem for deep learning models. From this line of research, we propose an intelligent Region of Interest (ROI) based system to identify and discriminate melanoma with nevus cancer by using the transfer learning approach. An improved k-mean algorithm is used to extract ROIs from the images. These ROI based approach helps to identify discriminative features as the images containing only melanoma cells are used to train system. We further use a Convolutional Neural Network (CNN) based transfer learning model with data augmentation for ROI images of DermIS and DermQuest datasets. The proposed system gives 97.9% and 97.4% accuracy for DermIS and DermQuest respectively. The proposed ROI based transfer learning approach outperforms existing methods that use complete images for classification.","Feature extraction,Melanoma,Image color analysis,Shape,Skin,Melanoma detection,skin cancer detection,ROI,CNN,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MALIGNANT-MELANOMA,7-POINT,CHECKLIST,ABCD,RULE,DERMOSCOPY,IMAGES,DECISION-SUPPORT,EARLY-DIAGNOSIS,CLASSIFICATION,LESIONS,SYSTEM,COLOR",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09160933.pdf,
38,A Novel Framework for Improving Pulse-Coupled Neural Networks With Fuzzy Connectedness for Medical Image Segmentation,8,,138129-138140,"Bai Peirui,Yang Kai,Min Xiaolin,Guo Ziyang,Li Chang,Fu Yingxia,Han Chao,Lu Xiang,Liu Qingyi","Bai PR,Yang K,Min XL,Guo ZY,Li C,Fu YX,Han C,Lu X,Liu QY",Liu QY,10.1109/ACCESS.2020.3012160,Shandong University of Science & Technology,"A pulse-coupled neural network (PCNN) is a promising image segmentation approach that requires no training. However, it is challenging to successfully apply a PCNN to medical image segmentation due to common but difFIcult scenarios such as irregular object shapes, blurred boundaries, and intensity inhomogeneity. To improve this situation, a novel framework incorporating fuzzy connectedness (FC) is proposed. First, a comparative study of the traditional PCNN models is carried out to analyze the framework and firing mechanism. Then, the characteristic matrix of fuzzy connectedness (CMFC) is presented for the first time. The CMFC can provide more intensity information and spatial relationships at the pixel level, which is helpful for producing a more reasonable firing mechanism in the PCNN models. Third, by integrating the CMFC into the PCNN framework models, a construction scheme of FC-PCNN models is designed. To illustrate this concept, a general solution that can be applied to different PCNN models is developed. Next, the segmentation performances of the proposed FC-PCNN models are evaluated by comparison with the traditional PCNN models, the traditional segmentation methods, and deep learning methods. The test images include synthetic and real medical images from the Internet and three public medical image datasets. The quantitative and visual comparative analysis demonstrates that the proposed FC-PCNN models outperform the traditional PCNN models and the traditional segmentation methods and achieve competitive performance to the deep learning methods. In addition, the proposed FC-PCNN models have favorable capability to eliminate inference from surrounding artifacts.","Medical image segmentation,pulse-coupled neural network,fuzzy connectedness,characteristic matrix",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"MAGNETIC-RESONANCE,MEAN,SHIFT,PCNN,ALGORITHMS,ULTRASOUND,REGION,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09149941.pdf,
39,Approaches for the Prediction of Lead Times in an Engineer to Order Environment-A Systematic Review,8,,142434-142445,"Burggraef Peter,Wagner Johannes,Koke Benjamin,Steinberg Fabian","Burggraf P,Wagner J,Koke B,Steinberg F",Steinberg F,10.1109/ACCESS.2020.3010050,Universitat Siegen,"The interest of manufacturing companies in a sufficient prediction of lead times is continuously increasing - especially in engineer to order environments with typically a large number of individual parts and complex production processes. A multitude of approaches have been proposed in the literature for predicting lead times considering different data and methods or algorithms from operations research (OR) and machine learning (ML). In order to provide guidance at setting up prediction models and developing new approaches, a systematic review of the available approaches for predicting lead times is presented in this paper. Forty-two publications were analyzed and synthetized: Based on a developed framework considering the used data class (e.g. product data or system status), the data origin (master data or real data) and the used method and algorithm from OR and ML, the publications are classified. Based on the classification, a descriptive analysis is performed to identify common approaches in the existing literature as well as implications for further research. One result is, that mostly order data and the status of the production system are used for predicting lead times whereas material data are used seldom. Additionally, ML approaches primarily use artificial neural networks and regression models for predicting lead times, while OR approaches use mainly combinatorial optimization or heuristics. Furthermore, with increasing model complexity the use of real data decreased. Thus, we identified as an implication for further research to set up a complex data model considering material data, which uses real data as data origin.","Production,Systematics,Prediction algorithms,Schedules,Mathematical model,Machine learning,Lead time reduction,machine learning,operations research,prediction methods",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MANUFACTURING,SYSTEMS,MAKESPAN,ESTIMATION,SIMULATION,ALGORITHMS,SHOP",IEEE ACCESS,https://doi.org/10.1109/access.2020.3010050,
40,Decision Support System for Classification Medullary Thyroid Cancer,8,,145216-145226,"Chandio Jamil Ahmed,Mallah Ghulam Ali,Shaikh Noor Ahmed","Chandio JA,Mallah GA,Shaikh NA",Chandio JA,10.1109/ACCESS.2020.3014863,Shah Abdul Latif University,"Due to the complex, heterogeneous and mimic morphological features of medullary thyroid cancer (MTC). It becomes often difficult to diagnose MTC at early stage. Since histopathological complex patterns of cancerous cells and tissues requires a huge effort to classify. Therefore thyroid cancer classification has become one of the significant research area area(s) of Machine Learning. We propose a decision support system to classify initial variation of morphological appearance of nuclei by using Convolutional Neural Networks (CNNs). The system comprises over three major layers, where image preprocessing techniques are used at top layer along with feature selection techniques. Classification model constructed by using CNNs at the second layer and result visualization described at third layer. Due to the unavailability of datasets for medullary thyroid cancer in literature, this research uses real-world datasets consisting upon 20GB cytological medical images and the approximated classification accuracy is measured about 99.00%. Malignant and non - malignant cells are visualized to assist the doctors in better way.","Cancer,Feature extraction,Visualization,Medical diagnostic imaging,Image segmentation,Machine learning,Histopathology,thyroid cancer,classification,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DIAGNOSIS,NODULES,NETWORKS,BREAST,LIVER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09160936.pdf,
41,ScalpEye: A Deep Learning-Based Scalp Hair Inspection and Diagnosis System for Scalp Health,8,,134826-134837,"Chang Wan-Jung,Chen Liang-Bi,Chen Ming-Che,Chiu Yi-Chan,Lin Jian-Yu","Chang WJ,Chen LB,Chen MC,Chiu YC,Lin JY",Chang WJ,10.1109/ACCESS.2020.3010847,Southern Taiwan University of Science & Technology,"Many people suffer from scalp hair problems such as dandruff, folliculitis, hair loss, and oily hair due to poor daily habits, imbalanced nutritional intake, high stress, and toxic substances in their environment. To treat these scalp problems, dedicated services such as scalp hair physiotherapy have emerged in recent years. This article proposes a deep learning-based intelligent scalp inspection and diagnosis system, named ScalpEye, as an efficient inspection and diagnosis system for scalp hair physiotherapy as part of scalp healthcare. The proposed ScalpEye system consists of a portable scalp hair imaging microscope, a mobile device app, a cloud-based artificial intelligence (AI) training server, and a cloud-based management platform. The ScalpEye system can detect and diagnose four common scalp hair symptoms (dandruff, folliculitis, hair loss, and oily hair). In this study, we tested several popular object detection models and adopted a Faster R-CNN with the Inception ResNet_v2_Atrous model in the ScalpEye system for image recognition when inspecting and diagnosing scalp hair symptoms. The experimental results show that the ScalpEye system can diagnose four common scalp hair symptoms with an average precision (AP) ranging from 97.41% to 99.09%.","Hair,Scalp,Training,Inspection,Microscopy,Cloud computing,Artificial intelligence,Artificial intelligence over the Internet of Things (AIoT),deep learning,image processing,image recognition,inspection,haircare,healthcare,scalp hair diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SEGMENTATION,DERMOSCOPY",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09145559.pdf,
42,Optimal Control of Iron-Removal Systems Based on Off-Policy Reinforcement Learning,8,,149730-149740,"Chen Ning,Luo Shuhan,Dai Jiayang,Luo Biao,Gui Weihua","Chen N,Luo SH,Dai JY,Luo B,Gui WH",Chen N,10.1109/ACCESS.2020.3015801,Central South University,"The goethite iron-removal process is an important procedure to remove the iron ions from the zinc hydrometallurgy. However, as a coherent system with complex reaction mechanism, associated uncertainties, and interconnected adjacent reactors, it is difficult for the process to accurately control the ion concentration. Because a large amount of historical data can be obtained during the process, an optimal control algorithm based on off-policy reinforcement learning is proposed in this paper to overcome these difficulties. According to the historical data, the weights of neural network are learned offline, and the optimal control strategy is solved online. Firstly, a bounded function is introduced to define the maximum effect of the coherent system on the subsystem cost function and to extend the cost function of the nominal system, so that the decentralized guaranteed cost control problem can be expressed as the optimal control problem of the nominal system. Then, an approximate iterative control algorithm based on actor-critic structure is proposed. The actor and critic neural networks are used to approximate control strategies and cost functions respectively. To achieve complete off-line, a new neural network is added to the actor-critic structure to approximate a part of the unknown system structure, and the three neural network parameters are optimized by the state transition algorithm. Finally, the strategy update and strategy iteration operations are performed alternately to learn optimal control strategies. The effectiveness and flexibility of the proposed off-policy optimal control method is validated by data from a real industrial goethite iron-removal process.","Optimal control,Inductors,Iron,Zinc,Process control,Leaching,Learning (artificial intelligence),Goethite iron-removal process,optimal control,off-policy,reinforcement learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NONLINEAR,MULTIAGENT,SYSTEMS,PRECIPITATION,OPTIMIZATION,ITERATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09164953.pdf,
43,Single Low-Dose CT Image Denoising Using a Generative Adversarial Network With Modified U-Net Generator and Multi-Level Discriminator,8,,133470-133487,"Chi Jianning,Wu Chengdong,Yu Xiaosheng,Ji Peng,Chu Hao","Chi JN,Wu CD,Yu XS,Ji P,Chu H",Chi JN,10.1109/ACCESS.2020.3006512,Northeastern University - China,"Low-dose CT (LDCT) images have been widely applied in the medical imaging field due to the potential risk of exposing patients to X-ray radiations. Given the fact that reducing the radiation dose may result in increased noise and artifacts, methods that can eliminate the noise and artifacts in the LDCT image have drawn increasing attentions and produced impressive results over the past decades. However, recent proposed methods mostly suffer from noise remaining, over-smoothing structures or false lesions derived from noise. In this paper, we propose a generative adversarial network (GAN) with novel architecture and loss function for restoring the LDCT image. Firstly, the inception-residual block and residual mapping are incorporated in the U-Net structure. The modified U-Net is applied as the generator of the GAN network so that the noise feature can be eliminated during the forward propagation. Secondly, a novel multi-level joint discriminator is designed by concatenating multiple convolutional neural networks (CNNs) where the output of each deconvolutional layer in the generator is compared with the corresponding down-sampled ground truth image. The adversarial training can be sensitive to noise and artifacts in different scales with this discriminator. Thirdly, we novely define a loss function consisting of the least square adversarial loss, VGG based perceptual loss, MSE based pixel loss and the noise loss, so that the differences in pixel, visual perception and noise distribution are comprehensively considered to optimize the network. Experimental results on both simulated and official simulated clinical images have demonstrated that the proposed method can provide superior performance to the state-of-the-art methods in noise removal, structure preservation and false lesions elimination.","Low-dose CT image denoising,deep learning,generative adversarial network,inception block,residual mapping,joint loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SINOGRAM,NOISE-REDUCTION,COMPUTED-TOMOGRAPHY,RECONSTRUCTION,ALGORITHM,RESTORATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09131783.pdf,
44,Estimating Simultaneous and Proportional Finger Force Intention Based on sEMG Using a Constrained Autoencoder,8,,138264-138276,"Cho Younggeol,Kim Pyungkang,Kim Kyung-Soo","Cho Y,Kim P,Kim KS",Kim KS,10.1109/ACCESS.2020.3012741,Korea Advanced Institute of Science & Technology (KAIST),"To boost the usability of a robotic prosthetic hand, providing degrees of freedom to every single finger is inevitable. Under the name of simultaneous proportional control (SPC), many studies have proposed methods to achieve this goal. In this paper, we propose a method to generate a regression model of a neuromuscular system called the Constrained AutoEncoder Network (CAEN) that estimates finger forces using a surface electromyogram (sEMG). Modifying the autoencoder from deep learning, the model is generated in a semi-unsupervised manner where only sEMG data and finger labels are used. In the learning process, the finger labels are used at the central layer of the network, where the three finger forces are estimated, to prevent penetration of other finger signals to each finger node and the network is trained in the constrained manner. This process results in independence among estimated finger forces such that the manipulability of multiple fingers is highly improved. The proposed model was compared with four previously reported SPC models in two tests: offline and online tests. In the offline test, the CAEN showed good results but not the best results. However, in the online test, which involved reaching target positions for three fingers simultaneously and proportionally, the proposed model showed the best results for three of six online performance indices (the completion rate, completion time, and throughput). Emphasizing the independence among estimated finger forces in the training process is the key point of the proposed method distinct from previous studies and the results showed that it was effective in the online control.","Force,Prosthetic hand,Pattern recognition,Neuromuscular,Estimation,Neural networks,Thumb,Autoencoder,finger intention estimation,neural network,surface electromyogram (sEMG)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EMG,PATTERN-RECOGNITION,MYOELECTRIC,CONTROL,FEATURE-PROJECTION,ONLINE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151957.pdf,
45,Can AI Help in Screening Viral and COVID-19 Pneumonia?,8,,132665-132676,"Chowdhury Muhammad E. H.,Rahman Tawsifur,Khandakar Amith,Mazhar Rashid,Kadir Muhammad Abdul,Bin Mahbub Zaid,Islam Khandakar Reajul,Khan Muhammad Salman,Iqbal Atif,Al Emadi Nasser","Chowdhury MEH,Rahman T,Khandakar A,Mazhar R,Kadir MA,Bin Mahbub Z,Islam KR,Khan MS,Iqbal A,Al Emadi N",Chowdhury MEH,10.1109/ACCESS.2020.3010287,Qatar University,"Coronavirus disease (COVID-19) is a pandemic disease, which has already caused thousands of causalities and infected several millions of people worldwide. Any technological tool enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to the healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI) in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public database was created by the authors combining several public databases and also by collecting images from recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and 1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision, sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%, 97.9%, and 98.8%, respectively. The high accuracy of this computer-aided diagnostic tool can significantly improve the speed and accuracy of COVID-19 diagnosis. This would be extremely useful in this pandemic where disease burden and need for preventive measures are at odds with available resources.","Diseases,Lung,Databases,X-ray imaging,Machine learning,Tools,COVID-19,Artificial intelligence,COVID-19 pneumonia,machine learning,transfer learning,viral pneumonia,computer-aided diagnostic tool",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144185.pdf,
46,Data-Driven Visual Characterization of Patient Health-Status Using Electronic Health Records and Self-Organizing Maps,8,,137019-137031,"Chushig-Muzo David,Soguero-Ruiz Cristina,Engelbrecht A. P.,de Miguel Bohoyo Pablo,Mora-Jimenez Inmaculada","Chushig-Muzo D,Soguero-Ruiz C,Engelbrecht AP,Bohoyo PD,Mora-Jimenez I",Mora-Jimenez I,10.1109/ACCESS.2020.3012082,Universidad Rey Juan Carlos,"Hypertension and diabetes have become a global health and economic issue, being among the major chronic conditions worldwide, particularly in developed countries. To face this global problem, a better knowledge about these diseases becomes crucial to characterize chronic patients. Our aim is two-fold: (1) to provide an efficient visual tool for identifying clinical patterns in high-dimensional data; and (2) to characterize the patient health-status through a data-driven approach using electronic health records of healthy, hypertensive and diabetic populations. We propose a two-stage methodology that uses diagnosis and drug codes of healthy and chronic patients associated to the University Hospital of Fuenlabrada in Spain. The first stage applies the Self-Organizing Map on the aforementioned data to get a set of prototype patients which are projected onto a grid of nodes. Each node has associated a prototype patient that captures relationships among clinical characteristics. In the second stage, clustering methods are applied on the prototype patients to find groups of patients with a similar health-status. Clusters with distinctive patterns linked to chronic conditions were found, being the most remarkable highlights: a cluster of pregnant women emerged among the hypertensive population, and two clusters of diabetic individuals with significant differences in drug-therapy (insulin and non-insulin dependant). The proposed methodology showed to be effective to explore relationships within clinical data and to find patterns related to diabetes and hypertension in a visual way. Our methodology raises as a suitable alternative for building appropriate clinical groups, becoming a promising approach to be applied to any population due to its data-driven philosophy. A thorough analysis of these groups could spawn new and fruitful findings.","Self-organizing feature maps,Drugs,Prototypes,Visualization,Diabetes,Diseases,Clustering methods,Electronic health records,machine learning,self organizing maps,clustering,data visualization,chronic conditions",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"CLASS,IMBALANCE,PROBLEM,GESTATIONAL,HYPERTENSION,DATA,SETS,CLUSTER,CLASSIFICATION,VALIDATION,MANAGEMENT,RISK,ALGORITHMS,PREDICTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09148604.pdf,
47,A Deep Biometric Recognition and Diagnosis Network With Residual Learning for Arrhythmia Screening Using Electrocardiogram Recordings,8,,153436-153454,"Dang Hao,Yue Yaru,Xiong Danqun,Zhou Xiaoguang,Xu Xiangdong,Tao Xingxiang","Dang H,Yue YR,Xiong DQ,Zhou XG,Xu XD,Tao XX",Zhou XG; Tao XX,10.1109/ACCESS.2020.3016938,Beijing University of Posts & Telecommunications,"Arrhythmia is one of the most persistent chronic heart diseases in the elderly and is associated with high morbidity and mortality such as stroke, cardiac failure, and coronary artery diseases. It is significant for patients with arrhythmias to automatically detect and classify arrhythmia heartbeats using electrocardiogram (ECG) signals. In this paper, we develop three robust deep convolutional neural network (DCNN) models, including a plain-CNN network and two MSF(multi-scale fusion)-CNN architectures (A and B), to aid in better feature extraction for the detection of arrhythmia and thus significantly improve the performance metrics. The proposed models are trained and tested with a public MIT-BIH arrhythmia database on five types of signals. Six groups of ablation experiments are conducted to analyze the performance of the models. The accuracy, sensitivity, and specificity obtained from MSF-CNN architecture A are higher than those from the plain-CNN model, demonstrating that the different parallel group convolution blocks (1 x 3, 1 x 5, and 1 x 7) dramatically improve a model's performance. Additionally, the best model MSF-CNN architecture B achieves an average accuracy, sensitivity, and specificity of 98.00%, 96.17%, and 96.38%, respectively. This illustrates the method with residual learning and concatenation group convolution blocks has a profound effect on the feature learning of the model. The results of ablation experiments show that our proposed biometric recognition and diagnosis network with residual learning (MSF-CNN B) achieves a rapid and reliable diagnosis approach on ECG signal classification, which has the potential for introduction into clinical practice as an excellent tool for aiding cardiologists in reading ECG heartbeat signals.","Electrocardiography,Feature extraction,Heart beat,Machine learning,Heart rate variability,Classification algorithms,Pregnancy,Heartbeat,arrhythmia,deep learning,convolutional neural network,electrocardiogram signal",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ECG,CLASSIFICATION,NEURAL-NETWORK",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016938,
48,Keratoconus Detection Using the Fusion Features of Anterior and Lateral Segment Photographed Images,8,,142282-142294,"Daud Marizuana M.,Zaki W. Mimi Diyana W.,Hussain Aini,Mutalib Haliza Abdul","Daud MM,Zaki WMDW,Hussain A,Mutalib HA",Zaki WMDW,10.1109/ACCESS.2020.3012583,Universiti Kebangsaan Malaysia,"Keratoconus (KC) is a type of eye disease that involves the thinning of the corneal layer and a change in the semispherical shape of the cornea to a bulging cone shape when viewed laterally. KC is difficult to detect in the early stages of the disease, as the patient does not feel any pain. Hence, the development of a KC detection (KD) method using a digital image processing approach is needed for the early detection of KC so that physicians can provide patients with the subsequent treatment sooner. The objective of this study was to develop a method of KD using a camera from a smart device to capture anterior and lateral segment photographed eye images (A&LSPIs). A total of 280 images comprising 140 KC and 140 normal A&LSPIs were used in this study, and all images were validated by a qualified expert. First, the corneal area of both image views was segmented so the geometric features could be extracted using the automated modified active contour model and the semiautomated spline function for the anterior and lateral images, respectively. Then, the features were selected using infinite latent feature selection (ILFS) by identifying the feature rankings based on the graph weighting that was automatically learned by the probabilistic latent semantic analysis (PLSA). The results showed that the all-combined features, where the proposed and improved features were successfully top ranked, had 96.05% accuracy, 98.41% sensitivity and 93.65% specificity with the RFn=50 classifier, outperforming the 7-NNMaha and SVMRBF classifiers. In conclusion, this study successfully developed a keratoconus detection system based on fusion features using a digital image processing approach for A&LSPIs captured with a smartphone camera.","Keratoconus,lateral segment photographed images,anterior segment photographed images,fusion features,digital image processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"PREVALENCE,CURVATURE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151118.pdf,
49,Large-Scale Analysis of the Head Proximity Effects on Antenna Performance Using Machine Learning Based Models,8,,154060-154071,"Diao Yinliang,Rashed Essam A.,Hirata Akimasa","Diao YL,Rashed EA,Hirata A",Diao YL,10.1109/ACCESS.2020.3017773,Nagoya Institute of Technology,"Owing to the variations in subject-specific body morphology and anatomy, the radiation performance of a wireless device in the presence of human body is different across subjects. To quantify the inter-subject variations, a large number of highly realistic human models are required. One recent approach is the fast development of body models directly from medical images with machine learning. In this study, a total of eighteen anatomical head models were developed using a fast machine learning approach and were then adopted for large-scale evaluation of the inter-subject variations in antenna performance. The antenna impedance, return loss (RL), total radiated power (TRP), directivity, radiation patterns, and specific absorption rate (SAR) were investigated. The results show rather large variations in impedance, RL, and SAR across subjects, while TRP, directivity, and radiation pattern are less likely to be affected by internal tissue distributions when compared with homogeneous models.","Antenna performance,electromagnetic exposure,FDTD method,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HUMAN-BODY,TISSUE,COMPOSITION,ENERGY-ABSORPTION,FREQUENCY-RANGE,DIPOLE,ANTENNA,SAM,PHANTOM,MOBILE,DEPENDENCE,REDUCTION,CHILDREN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09171235.pdf,
50,Control of Walking Assist Exoskeleton With Time-delay Based on the Prediction of Plantar Force,8,,138642-138651,"Ding Ming,Nagashima Mikihisa,Cho Sung-Gwi,Takamatsu Jun,Ogasawara Tsukasa","Ding M,Nagashima M,Cho SG,Takamatsu J,Ogasawara T",Ding M,10.1109/ACCESS.2020.3010644,Nara Institute of Science & Technology,"Many kinds of lower-limb exoskeletons were developed for walking assistance. However, when controlling these exoskeletons, time-delay due to the computation time and the communication delays is still a general problem. In this research, we propose a novel method to prevent the time-delay when controlling a walking assist exoskeleton by predicting the future plantar force and walking status. By using Long Short-Term Memory and a fully-connected network, the plantar force can be predicted using only data measured by inertial measurement unit sensors, not only during the walking period but also at the start and end of walking. From the predicted plantar force, the walking status and the desired assistance timing can also be determined. By considering the time-delay and sending the control commands beforehand, the exoskeleton can be moved precisely on the desired assistance timing. In experiments, the prediction accuracy of the plantar force and the assistance timing are confirmed. The performance of the proposed method is also evaluated by using the trained model to control the exoskeleton.","Legged locomotion,Exoskeletons,Force,Motion measurement,Force measurement,Pressure sensors,Walking exoskeleton,motion prediction,machine learning,plantar force",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,http://arxiv.org/pdf/2007.00837,
51,Identity Recognition Based on the QRS Complex Dynamics of Electrocardiogram,8,,134373-134385,"Dong Xunde,Si Wenjie,Yu Wei","Dong XD,Si WJ,Yu W",Yu W,10.1109/ACCESS.2020.3008953,Foshan University,"Biometric identification based on electrocardiogram signals has attracted increasing attention. As the most dominant feature of the electrocardiogram signal, the QRS complex(i.e., the combination of ECG Q, R, and S waves) has been used for identification in some studies. This study aims to investigate the intra-individual stability of the QRS complex dynamics to assess its potential for human identification. The QRS complex dynamics are used as the unique feature to classify the QRS complex, which differs from the time/frequency domain features used in the literature. It is the fundamental feature of the QRS complex and contains the underlying information of the QRS complex. The dynamics of training QRS complexes are extracted and expressed as a constant radial basis function network by using deterministic learning. A set of estimators is constructed to represent the training QRS complexes using constant radial basis function networks. By comparing this set of estimators with the test QRS complex, a set of recognition errors is generated, and the average L-1 norms of the errors are taken as the similarity measure between the dynamics of the training QRS complexes and that of the test QRS complex. Therefore, the test QRS complex can be recognized according to the smallest error principle. The electrocardiogram is classified according to the vote of the test QRS complexes recognition results. A private database and PTB diagnostic ECG database are used to test the proposed method. Experimental results on the private database (PTB database) showed that the average identification accuracy was 96.12% (97.42%) for 5-fold cross-validation based on one-lead electrocardiogram and 99.50% (99.23%) for 2-fold cross-validation based on two-lead electrocardiogram, respectively. These show that the dynamics of the QRS complex are well-differentiated for different individuals.","Electrocardiogram,QRS complex,identity recognition,radial basis function networks,dynamics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HUMAN,IDENTIFICATION,NEURAL-NETWORK,ECG",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139475.pdf,
52,Estimating Autism Severity in Young Children From Speech Signals Using a Deep Neural Network,8,,139489-139500,"Eni Marina,Dinstein Ilan,Ilan Michal,Menashe Idan,Meiri Gal,Zigel Yaniv","Eni M,Dinstein I,Ilan M,Menashe I,Meiri G,Zigel Y",Eni M,10.1109/ACCESS.2020.3012532,Ben Gurion University,"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder that involves difficulties in social communication. Previous research has demonstrated that these difficulties are apparent in the way ASD children speak, indicating that it may be possible to estimate ASD severity using quantitative features of speech. Here, we extracted a variety of prosodic, acoustic, and conversational features from speech recordings of Hebrew speaking children who completed an Autism Diagnostic Observation Schedule (ADOS) assessment. Sixty features were extracted from the recordings of 72 children and 21 of the features were significantly correlated with the children's ADOS scores. Positive correlations were found with pitch variability and Zero Crossing Rate (ZCR), while negative correlations were found with the speed and number of vocal responses to the clinician, and the overall number of vocalizations. Using these features, we built several Deep Neural Network (DNN) algorithms to estimate ADOS scores and compared their performance with Linear Regression and Support Vector Regression (SVR) models. We found that a Convolutional Neural Network (CNN) yielded the best results. This algorithm predicted ADOS scores with a mean RMSE of 4.65 and a mean correlation of 0.72 with the true ADOS scores when trained and tested on different sub-samples of the available data. Automated algorithms with the ability to predict ASD severity in a reliable and sensitive manner have the potential of revolutionizing early ASD identification, quantification of symptom severity, and assessment of treatment efficacy.","Feature extraction,Autism,Correlation,Energy states,Bandwidth,Prediction algorithms,Jitter,Audio signals,autism,autism diagnostic observation schedule,autism spectrum disorder,convolutional neural network,deep neural network,early detection,outcome measure,pitch,speech,symptom severity,treatment efficacy,zero crossing rate",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SPECTRUM,DISORDER,PROSODY,IDENTIFICATION,PATTERNS,FEATURES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151117.pdf,
53,Prediction of Chronic Diseases With Multi-Label Neural Network,8,,138210-138216,"Ge Ruiquan,Zhang Renfeng,Wang Pu","Ge RQ,Zhang RF,Wang P",Wang P,10.1109/ACCESS.2020.3011374,Hubei University of Arts & Science,"Chronic diseases have seriously affected human activities, especially in many developing countries and underdeveloped countries. The long duration of chronic diseases and the high cost of medical care have placed a huge economic burden on society and families. Meanwhile, chronic patients tend to have a variety of complications over time. So, it is difficult for doctors to find effective diagnosis and appropriate treatment. Machine learning techniques can integrate their heterogeneous data of various body indicators. Meanwhile, for chronic patients, multi-label learning methods can be used to help doctors identify the types of the chronic diseases. This paper proposes a novel multi-label neural network method (ML-NN) to predict the chronic diseases combining neural network and multi-label learning technology based on cross entropy lost function and backward propagation algorithm. Compared with 14 traditional multi-label learning methods on 10 chronic diseases and 19733 patients, the proposed method achieved a consistently best in 5 performance measurements. The results demonstrate the proposed method can effectively predict chronic diseases and assist doctors to diagnose and treat patients.","Diseases,Neural networks,Classification algorithms,Feature extraction,Medical diagnostic imaging,Prediction algorithms,Chronic diseases prediction,multi-label learning,neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CLASSIFIER,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146615.pdf,
54,Feasibility Analysis in Tracking Algorithms for Pattern Recognition Through the Lip Articulators,8,,138907-138921,"Gomes Haroldo,Limao Roberto,Santos Adam","Gomes H,Limao R,Santos A",Gomes H,10.1109/ACCESS.2020.3012089,Universidade Federal do Sul e Sudeste do Para,"Problems in speech and basic emission of vocal sounds are commonly observed in children, however the task of identifying the origin of such disability is complex and prolonged, due to the generic aspect, if by irregular learning or neurobiological disorder, thus causing, in some situations, constant social exclusion. Therefore, it is proposed to use Tracking Algorithms consolidated in specific literature (ACF, Boosting, MIL, Median Flow, KCF, KLT, CRST) for a feasibility analysis in complex computational implementations in the anatomy of human vocal tract from sagittal images. These algorithms are used for understanding the kinematic configuration of multiple dynamic objects and their movements, represented by the upper and lower lips (consequently the ""lip distance"" at the moment of speech), using Brazilian Portuguese language, for the extraction and recognition of patterns automatically. The patterns can be used in innovative applications in therapy for children with poor articulation in the vocal tract, based on ""gaps"" and specific difficulties in speech.","Lips,Tracking,Speech recognition,Heuristic algorithms,Speech processing,Production,Tracking algorithms,feasibility analysis,lip articulators,speech,recognition of patterns",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CHILDHOOD,APRAXIA,DEVELOPMENTAL,APRAXIA,VISUAL,TRACKING,SPEECH",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09149904.pdf,
55,Classification for Dermoscopy Images Using Convolutional Neural Networks Based on the Ensemble of Individual Advantage and Group Decision,8,,155337-155351,"Gong An,Yao Xinjie,Lin Wei","Gong A,Yao XJ,Lin W",Yao XJ,10.1109/ACCESS.2020.3019210,China University of Petroleum,"Skin cancer is a common and deadly cancer. Dermoscopy is an effective tool for the observation of abnormal skin pigmentation. However, dermoscopy images are extremely complex and present great challenges for diagnosis. Therefore, we proposed a classification method based on the ensemble of individual advantage and group decision in dermoscopy images, including the ensemble strategy of group decision, the ensemble strategy of maximizing individual advantage, and the ensemble strategy of block-integrated voting. We used generative adversarial networks (GANs) to create a balanced sample space to better train convolutional neural networks (CNNs). Through transfer learning, the pre-training CNNs were used for fine-tuning, then the effects of different CNNs on the classification of different categories of dermoscopy images were compared, and the CNNs with better classification effect were selected for the ensemble of different strategies. This study is based on the ISIC 2018 dataset and ISIC 2019 dataset. Compared with the different individual CNNs and the frameworks, the proposed ensemble strategies achieve a better improvement in the evaluation criteria.","Feature extraction,Gallium nitride,Training,Skin,Melanoma,Dermoscopy images,ensemble strategies,convolutional neural networks,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MALIGNANT-MELANOMA,SKIN-CANCER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09175002.pdf,
56,Semi-Supervised Breast Histological Image Classification by Node-Attention Graph Transfer Network,8,,158335-158345,"Gong Liheng,Yang Jingjing,Zhang Xiao","Gong LH,Yang JJ,Zhang X",Yang JJ,10.1109/ACCESS.2020.3020149,Hebei North University,"As a major cause of leading female death, breast cancer is often diagnosed by histological images which has been resolved by many deep learning methods with the assistance of large amounts of annotated data. However, their performances are severely limited by the lack of sufficient labeled data in clinical practice. This paper aims to relieve the annotating workload by a semi-supervised transfer learning algorithm to conduct knowledge distillation from a completely labeled source domain. To achieve this goal, we propose a node-attention graph transfer network to exploit the inherent correlation between individual samples by graph convolutional network, along with a cross-domain graph learning module to stimulate the graph construction in target domain. In the meanwhile, we design a node-attention mechanism to learn the individual contribution of each source image for target domain, which can further leverage the domain-gap by our node-attention transfer learning. Results of semi-supervised breast histological image classification with various scales of annotated training images are performable and further experiments demonstrate the significant contributions of each component we proposed.","Feature extraction,Breast cancer,Correlation,Machine learning,Convolutional neural networks,Training,Semi-supervised,histological image classification,graph convolutional network,node-attention,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,DIAGNOSIS,FEATURES,DATASET",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09179776.pdf,
57,BioCNN: A Hardware Inference Engine for EEG-Based Emotion Detection,8,,140896-140914,"Gonzalez Hector A.,Muzaffar Shahzad,Yoo Jerald,Elfadel Ibrahim M.","Gonzalez HA,Muzaffar S,Yoo J,Elfadel IM",Elfadel IM,10.1109/ACCESS.2020.3012900,Khalifa University of Science & Technology,"EEG-based emotion classifiers have the potential of significantly improving the social integration of patients suffering from neurological disorders such as Amyotrophic Lateral Sclerosis or the acute stages of Alzheimer's disease. Emotion classifiers have historically used software on general-purpose computers and operating under off-line conditions. Yet the wearability of such classifiers is a must if they are to enable the socialization of critical-care patients. Such wearability requires the use of low-power hardware accelerators that would enable near real-time classification and extended periods of operations. In this article, we architect, design, implement, and test a handcrafted, hardware Convolutional Neural Network, named BioCNN, optimized for EEG-based emotion detection and other bio-medical applications. The EEG signals are generated using a low-cost, off-the-shelf device, namely, Emotiv Epoc C, and then denoised and pre-processed ahead of their use by BioCNN. For training and testing, BioCNN uses three repositories of emotion classification datasets, including the publicly available DEAP and DREAMER datasets, along with an original dataset collected in-house from 5 healthy subjects using standard visual stimuli. Asubject-specific training approach is used under TensorFlow to train BioCNN, which is implemented using the Digilent Atlys Board with a low-cost Spartan-6 FPGA. The experimental results show a competitive energy efficiency of 11 GOps/W, a throughput of 1:65 GOps that is in line with the real-time specification of a wearable device, and a latency of less than 1 ms, which is smaller than the 150 ms required for human interaction times. Its emotion inference accuracy is competitive with the top software-based emotion detectors.","Emotion recognition,EEG,FPGA,machine learning,hardware accelerator,edge AI,convolutional neural networks,hardware parallelism,pipelining",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORKS,DATABASE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151874.pdf,
58,COVID-19 Detection Through Transfer Learning Using Multimodal Imaging Data,8,,149808-149824,"Horry Michael J.,Chakraborty Subrata,Paul Manoranjan,Ulhaq Anwaar,Pradhan Biswajeet,Saha Manas,Shukla Nagesh","Horry MJ,Chakraborty S,Paul M,Ulhaq A,Pradhan B,Saha M,Shukla N",Chakraborty S,10.1109/ACCESS.2020.3016780,University of Technology Sydney,"Detecting COVID-19 early may help in devising an appropriate treatment plan and disease containment decisions. In this study, we demonstrate how transfer learning from deep learning models can be used to perform COVID-19 detection using images from three most commonly used medical imaging modes X-Ray, Ultrasound, and CT scan. The aim is to provide over-stressed medical professionals a second pair of eyes through intelligent deep learning image classification models. We identify a suitable Convolutional Neural Network (CNN) model through initial comparative study of several popular CNN models. We then optimize the selected VGG19 model for the image modalities to show how the models can be used for the highly scarce and challenging COVID-19 datasets. We highlight the challenges (including dataset size and quality) in utilizing current publicly available COVID-19 datasets for developing useful deep learning models and how it adversely impacts the trainability of complex models. We also propose an image pre-processing stage to create a trustworthy image dataset for developing and testing the deep learning models. The new approach is aimed to reduce unwanted noise from the images so that deep learning models can focus on detecting diseases with specific features from them. Our results indicate that Ultrasound images provide superior detection accuracy compared to X-Ray and CT scans. The experimental results highlight that with limited data, most of the deeper networks struggle to train well and provides less consistency over the three imaging modes we are using. The selected VGG19 model, which is then extensively tuned with appropriate parameters, performs in considerable levels of COVID-19 detection against pneumonia or normal for all three lung image modes with the precision of up to 86% for X-Ray, 100% for Ultrasound and 84% for CT scans.","Computed tomography,Lung,X-ray imaging,Ultrasonic imaging,Machine learning,Diseases,COVID-19 detection,image processing,model comparison,CNN models,X-ray,ultrasound and CT based detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"X-RAY,ULTRASOUND,DIAGNOSIS,ALGORITHMS",IEEE ACCESS,https://opus.lib.uts.edu.au/bitstream/10453/142272/2/Published%20version.pdf,
59,Noise-Robust MRI Upsampling Using Adaptive Local Steering Kernel,8,,158538-158548,"Hu Jing,Li Xinyan,Wang Xiaolong,Li Yan,Wu Xi","Hu J,Li XY,Wang XL,Li Y,Wu X",Hu J,10.1109/ACCESS.2020.3020133,Chengdu University of Information Technology,"Upsampling and denoising of magnetic resonance images are conventionally performed separately, which would introduce unwanted artifacts such as blurring. To address this problem, we propose an innovative adaptive interpolation framework to achieve simultaneous image upsampling, denoising, and detail enhancement. First, local steering kernel (LSK) function is leveraged to adapt the interpolation weights according to geometric structures in the magnetic resonance (MR) images. An adaptive sharpening of the LSK weight matrix and a Rician bias correction are then adopted to remove Rician noise and enhance fine details. In this regard, the adaptive LSK extends the zero-order point estimation framework to higher orders of regression, and therefore facilitates edge preservation and detail reconstruction. The post-processing Rician correction avoids the bias caused by the asymmetry of Rician noise distributions. Experimental results using both real and synthetic clinical MR cranial images (with and without noise) demonstrated that our algorithm produced better reconstruction results than several traditional interpolation-based upsampling methods, including nearest neighbor (NN), non-local means (NLM), self-learning super resolution (SLSR), Gaussian process regression (GPR), and even comparable to four deep-learning-based methods but with less data requirements and computational complexity. The proposed technique resulted in PSNR and SSIM values were similar to 3%-16% higher than any of the other traditional algorithms tested, and our method recovered more clear textures from noisy images compared with deep-learning-based methods. As such, the presented technique is a viable new approach to MR upsampling, particularly for noisy images.","Adaptive sharpening,image upsampling,local steering kernel,magnetic resonance imaging,noise robust",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NONLOCAL,MEANS,ALGORITHM,IMAGE,SUPERRESOLUTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09179731.pdf,
60,Hybrid Model of Mathematical and Neural Network Formulations for Rolling Force and Temperature Prediction in Hot Rolling Processes,8,,153123-153133,"Hwang Rakhoon,Jo Hyeontae,Kim Kyung Seok,Hwang Hyung Ju","Hwang R,Jo H,Kim KS,Hwang HJ",Hwang HJ,10.1109/ACCESS.2020.3016725,Pohang University of Science & Technology (POSTECH),"Steelmaking requires precise calculation at several steps of the manufacturing processes. We focus on the hot rolling process using Steckel mills, almost the end step in steel coil manufacturing. The rolling process is a type of plastic working in which a slab passes between two rolls and is stretched to reach the target thickness. It is necessary to predetermine the exact rolling force to obtain a coil with an accurate thickness after the rolling process. First, we introduced a machine learning model for calculating the rolling force, which can be used in-line in real plants. However, a direct calculation of the rolling force can cause stability problems, because the model output directly affects the process. In order to avoid such a problem, we determined a special temperature of the coil by inverse calculation of the classical mechanical model of hot rolling and set it as the model output value. As learning models, deep neural networks (DNN) and gradient boosting-based decision tree models were used. We preprocessed the collected process history data and added artificial features to the model input by creating physical variables used in the classical models. Moreover, to supplement the black-box nature of DNN, feature importance was analyzed from the decision tree model, and utilization and interpretation of each feature in the process are presented. Thus, our methods take advantage of both the classical mathematical model and the deep neural network model.","Force,Mathematical model,Strain,Neural networks,Machine learning,Temperature,Steel,Hot rolling,machine learning,gradient boosting,neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,STRESS,IEEE ACCESS,https://doi.org/10.1109/access.2020.3016725,
61,Shock Decision Algorithms for Automated External Defibrillators Based on Convolutional Networks,8,,154746-154758,"Jaureguibeitia Xabier,Zubia Gorka,Irusta Unai,Aramendi Elisabete,Chicote Beatriz,Alonso Daniel,Larrea Andima,Corcuera Carlos","Jaureguibeitia X,Zubia G,Irusta U,Aramendi E,Chicote B,Alonso D,Larrea A,Corcuera C",Irusta U,10.1109/ACCESS.2020.3018704,University of Basque Country,"Automated External Defibrillators (AED) incorporate a shock decision algorithm that analyzes the patient's electrocardiogram (EKG), allowing lay persons to provide life saving defibrillation therapy to out-of-hospital cardiac arrest (OHCA) patients. The most accurate shock decision algorithms are based on deep learning, but these algorithms have not been trained and tested using OHCA data. In this study we propose novel deep learning architectures for shock decision algorithms based on convolutional and residual networks. EKG electronic recordings from a cohort of 852 OHCA cases (4216 AED EKG analyses) were used in the study. EKGs were annotated by a pool of six expert clinicians resulting in 3718 nonshockable and 498 shockable EKGs. Data were partitioned patient wise in a stratified way to train and test the models using 10-fold cross validation, and the procedure was repeated 100 times for statistical evaluation. Performance was assessed using sensitivity (shockable), specificity (non-shockable) and accuracy, and the analysis was conducted for EKG segments of decreasing duration. The best model had median (interdecile range) accuracies of 98.6 (98.5-98.7)%, 98.4 (98.2-98.6)%, 98.2 (97.9-98.4)%, and 97.6 (97.4-97.8)%, for 4, 3, 2 and 1 second EKG segments, respectively. The minimum 90% sensitivity and 95% specificity requirements established by the American Heart Association for shock decision algorithms were met, and the best model presented significantly greater accuracy (p<0.05 McNemar test) than previous deep learning solutions for all segment durations. Moreover, the first AHA compliant shock decision algorithm using 1-s segments was demonstrated. This should contribute to a combined optimization of defibrillation and cardiopulmonary resuscitation therapy to improve OHCA survival.","Electrocardiography,Rhythm,Electric shock,Machine learning,Signal processing algorithms,Heart,Medical treatment,Automated external defibrillator (AED),electrocardiogram (EKG),convolutional neural networks (CNN),deep learning,ventricular fibrillation (VF),residual networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"THREATENING,VENTRICULAR-ARRHYTHMIAS,CARDIOPULMONARY-RESUSCITATION,RHYTHM,ANALYSIS,CLASSIFICATION,FIBRILLATION,SPECIFICITY,SENSITIVITY,TACHYCARDIA,UPDATE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09174724.pdf,
62,Pathological Gait Classification Using Kinect v2 and Gated Recurrent Neural Networks,8,,139881-139891,"Jun Kooksung,Lee Yongwoo,Lee Sanghyub,Lee Deok-Won,Kim Mun Sang","Jun K,Lee Y,Lee S,Lee DW,Kim MS",Kim MS,10.1109/ACCESS.2020.3013029,Gwangju Institute of Science & Technology (GIST),"With the development of depth sensors and skeleton tracking algorithms, many skeleton-based pathological gait classification methods have recently been proposed. However, these methods classify only simple gait patterns, and there is no approach to classify complicated gait patterns. In this paper, we classify 1 normal and 5 pathological gaits (antalgic, stiff-legged, lurching, steppage, and Trendelenburg gaits) by using a gated recurrent unit (GRU)-based classifier and 3D skeleton data. We collected skeleton datasets for 1 normal and 5 pathological gaits by using a multiperspective Kinect system. We developed the GRU classifier to classify the pathological gaits and compared its performance with that of other machine learning-based classifiers. Furthermore, we considered various joint groups to identify important and irrelevant joints for pathological gait classification and to improve the performance of the GRU classifier. When all skeleton data are used, the GRU classifier achieves a classification accuracy of 90.13%. A long short-term memory (LSTM)-based classifier achieves the next highest accuracy of 87.25%. The classification accuracy of the GRU classifier depends on the joint groups considered, and the classification accuracy increases to 93.67% when only leg joints are considered. This study indicates that various pathological gaits can be classified by using skeleton data and the GRU classifier. The proposed method can be used to support medical and clinical decisions. Furthermore, the results for various joint groups can be used to develop other methods in cases where only specific joint data are available because of environmental limitations.","Pathology,Skeleton,Sensors,Legged locomotion,Feature extraction,Data collection,Hip,Pathological gait classification,skeleton-based classification,gated recurrent unit,deep learning,kinect",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECOGNITION,DISORDERS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09152991.pdf,
63,Exploring the Structural and Strategic Bases of Autism Spectrum Disorders With Deep Learning,8,,153341-153352,"Ke Fengkai,Choi Seungjin,Kang Young Ho,Cheon Keun-Ah,Lee Sang Wan","Ke FK,Choi S,Kang YH,Cheon KA,Lee SW",Cheon KA,10.1109/ACCESS.2020.3016734,Yonsei University,"Deep learning models are applied in clinical research in order to diagnose disease. However, diagnosing autism spectrum disorders (ASD) remains challenging due to its complex psychiatric symptoms as well as a generally insufficient amount of neurobiological evidence. We investigated the structural and strategic bases of ASD using 14 different types of models, including convolutional and recurrent neural networks. Using an open source autism dataset consisting of more than 1000 MRI scan images and a high-resolution structural MRI dataset, we demonstrated how deep neural networks could be used as tools for diagnosing and analyzing psychiatric disorders. We trained 3D convolutional neural networks to visualize combinations of brain regions, thus representing the most referred-to regions used by the model whilst classifying the images. We also implemented recurrent neural networks to classify the sequence of brain regions efficiently. We found emphatic structural and strategic evidence on which the model heavily relies during the classification process. For instance, we observed that the structural and strategic evidence tends to be associated with subcortical structures, including the basal ganglia (BG). Our work identifies the distinct brain structures that characterize a complex psychiatric disorder while streamlining the deductive reasoning that clinicians can use to ensure an economical and time-efficient diagnosis process.","Magnetic resonance imaging,Three-dimensional displays,Autism,Brain modeling,Diseases,Machine learning,Biological system modeling,Deep learning,sMRI,austism spectrum disorders,neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BRAIN,CLASSIFICATION,CHILDREN,MRI,SCHIZOPHRENIA,PATTERNS,FEATURES,VOXEL,FMRI",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016734,
64,Computer-Aided Gastrointestinal Diseases Analysis From Wireless Capsule Endoscopy: A Framework of Best Features Selection,8,,132850-132859,"Khan Muhammad Attique,Kadry Seifedine,Alhaisoni Majed,Nam Yunyoung,Zhang Yudong,Rajinikanth Venkatesan,Sarfraz Muhammad Shahzad","Khan MA,Kadry S,Alhaisoni M,Nam Y,Zhang YD,Rajinikanth V,Sarfraz MS",Khan MA,10.1109/ACCESS.2020.3010448,NITEC University,"The continuous improvements in the area of medical imaging, makes the patient monitoring a crucial concern. The internet of things (IoT) embedded in a medical technologies to collect data from human body through sensors, wireless connectivity etc. The junction of medicine and IT like medical informatics will transform healthcare, curbing cost, make more efficient, and saving lives. Various computerized techniques are implemented in the area of Artificial Intelligence (AI) for the application of medical imaging to diagnose the infected regions in the images and videos such as WCE and pathology. The famous stomach infections are ulcer, polyp, and bleeding. Stomach cancer is the most common infection and a leading cause of human deaths worldwide. In the USA, since 2019, a total of 27,510 new cases are reported including 17,230 men and 10,230 women. While the number of deaths is 11,140 consists of 6,800 men and 4,340 women. The manual diagnosis of these stomach infections is a difficult and agitated process therefore it is required to design a fully automated system using AI. In this article, we presented a fully automated system for stomach infection recognition based on deep learning features fusion and selection. In this design, ulcer images are assigned manually and support to a saliency-based method for ulcer detection. Later, pre-trained deep learning model named VGG16 is employing and re-trained using transfer learning. Features of re-trained model are extracted from two consecutive fully connected layers and fused by array-based approach. Besides, the best individuals are selected through the metaheuristic approach name PSO along mean value-based fitness function. The selected individuals are finally recognized through Cubic SVM. The experiments are conducted on Private collected dataset and achieved an accuracy of 98.4%, which is best as compared to existing state-of-the-art techniques.","Feature extraction,Stomach,Cancer,Image color analysis,Hemorrhaging,Support vector machines,Gastrointestinal tract,Stomach diseases,WCE,saliency estimation,deep learning,features selection,features classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"NEURAL-NETWORK,CLASSIFICATION,RECOGNITION,FUSION,IMAGES,SEGMENTATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144214.pdf,
65,Efficient Biomedical Image Segmentation on EdgeTPUs at Point of Care,8,,139356-139366,"Kist Andreas M.,Doellinger Michael","Kist AM,Dollinger M",Kist AM,10.1109/ACCESS.2020.3012722,University of Erlangen Nuremberg,"The U-Net architecture is a state-of-the-art neural network for semantic image segmentation that is widely used in biomedical research. It is based on an encoder-decoder framework and its vanilla version shows already high performance in terms of segmentation quality. Due to its large parameter space, however, it has high computational costs on both, CPUs and GPUs. In a research setting, inference time is relevant, but not crucial for the results. However, especially in mobile, clinical applications a light and fast variant would allow deep-learning assisted, objective diagnosis at the point of care. In this work, we suggest an optimized, tiny-weight U-Net for an inexpensive hardware accelerator. We first mined the U-Net architecture to reduce computational complexity to increase runtime performance by simultaneously keeping the accuracy on a high level. Using an open, biomedical dataset for high-speed videoendoscopy (BAGLS), we show that we can dramatically reduce the parameter space and computations by over 99.8% while keeping the segmentation performance at 95% of our baseline. Using a custom upscaling routine, we further successfully deployed our optimized U-Net to an EdgeTPU hardware accelerator to gain cost-effective speed improvements on conventional computers and to showcase the applicability of EdgeTPUs for biomedical imaging processing of large images on portable devices. Combining the optimized architecture and the EdgeTPU, we gain a speedup of >79-times compared to our initial baseline while keeping high accuracy. This combination allows to provide immediate results to the clinician, especially in constrained computational environments, and an objective diagnosis at the point of care.","Computer architecture,Neural networks,Image segmentation,Image edge detection,Biomedical imaging,Hardware,EdgeTPU,convolutional neural network,coral,semantic segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"VOCAL,FOLD,VIBRATIONS,HIGH-SPEED,VIDEO,NEURAL-NETWORK",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09151951.pdf,
66,Spectral CT Reconstruction Based on PICCS and Dictionary Learning,8,,133367-133376,"Kong Huihua,Lei Xiaoxue,Lei Lei,Zhang Yanbo,Yu Hengyong","Kong HH,Lei XX,Lei L,Zhang YB,Yu HY",Kong HH,10.1109/ACCESS.2020.3010228,North University of China,"Photon-counting detector based spectral computed tomography (CT) can obtain energy-discriminative attenuation map of an object in different energy channels, extending the conventional volumetric image along a spectral dimension. However, compared with the full spectrum data, the noise in a narrower energy channel is significantly increased. In order to improve image quality of spectral CT images, this paper proposes an iterative reconstruction algorithm based on the prior image constrained compressed sensing (PICCS) and dictionary learning (DL) theories, which is called PICCS-DL. The PICCS-DL utilizes the correlation of the images reconstructed from different energy channels by taking the broad spectrum image as a prior constraint, and it utilizes the sparse of the images by taking the total variation (TV) and DL as prior constraints. The alternating minimization, Split-Bregman and the steepest descent (SD) methods are used to solve the objective function. The effectiveness of the proposed method is validated with numerical simulations and preclinical applications. The results demonstrate that the proposed algorithm generally produces superior image quality, especially for noisy and sparse projection data.","Computed tomography,Image reconstruction,Dictionaries,TV,Machine learning,Photonics,Correlation,Spectral CT,prior image constrained compressed sensing,total variation,dictionary learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,SPARSE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144184.pdf,
67,Automatic Detection of White Blood Cancer From Bone Marrow Microscopic Images Using Convolutional Neural Networks,8,,142521-142531,"Kumar Deepika,Jain Nikita,Khurana Aayush,Mittal Sweta,Satapathy Suresh Chandra,Senkerik Roman,Hemanth Jude D.","Kumar D,Jain N,Khurana A,Mittal S,Satapathy SC,Senkerik R,Hemanth JD",Senkerik R,10.1109/ACCESS.2020.3012292,Tomas Bata University Zlin,"Leukocytes, produced in the bone marrow, make up around one percent of all blood cells. Uncontrolled growth of these white blood cells leads to the birth of blood cancer. Out of the three different types of cancers, the proposed study provides a robust mechanism for the classification of Acute Lymphoblastic Leukemia (ALL) and Multiple Myeloma (MM) using the SN-AM dataset. Acute lymphoblastic leukemia (ALL) is a type of cancer where the bone marrow forms too many lymphocytes. On the other hand, Multiple myeloma (MM), a different kind of cancer, causes cancer cells to accumulate in the bone marrow rather than releasing them into the bloodstream. Therefore, they crowd out and prevent the production of healthy blood cells. Conventionally, the process was carried out manually by a skilled professional in a considerable amount of time. The proposed model eradicates the probability of errors in the manual process by employing deep learning techniques, namely convolutional neural networks. The model, trained on cells' images, first pre-processes the images and extracts the best features. This is followed by training the model with the optimized Dense Convolutional neural network framework (termed DCNN here) and finally predicting the type of cancer present in the cells. The model was able to reproduce all the measurements correctly while it recollected the samples exactly 94 times out of 100. The overall accuracy was recorded to be 97.2%, which is better than the conventional machine learning methods like Support Vector Machine (SVMs), Decision Trees, Random Forests, Naive Bayes, etc. This study indicates that the DCNN model's performance is close to that of the established CNN architectures with far fewer parameters and computation time tested on the retrieved dataset. Thus, the model can be used effectively as a tool for determining the type of cancer in the bone marrow.","Cancer,Blood,Feature extraction,Bones,Convolutional neural networks,Cells (biology),Machine learning,Acute lymphoblastic leukemia,classification algorithms,deep learning,convolutional neural networks,image processing,multiple myeloma",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,IMMUNE,IEEE ACCESS,https://publikace.k.utb.cz/bitstream/10563/1009889/1/Fulltext_1009889.pdf,
68,Detecting Keratoconus From Corneal Imaging Data Using Machine Learning,8,,149113-149121,"Lavric Alexandru,Popa Valentin,Takahashi Hidenori,Yousefi Siamak","Lavric A,Popa V,Takahashi H,Yousefi S",Lavric A,10.1109/ACCESS.2020.3016060,Stefan cel Mare University of Suceava,"Keratoconus affects approximately one in 2,000 individuals worldwide. It is typically associated with the decrease in visual acuity. Given its wide prevalence, there is an unmet need for the development of new tools that can diagnose the disease at an early stage in order to prevent disease progression and vision loss. The aim of this study is to develop and test a machine learning algorithm that can detect keratoconus at early stages. We applied several machine learning algorithms to detect keratoconus and then tested the algorithms using real world medical data, including corneal topography, elevation, and pachymetry parameters collected from OCT-based topography instruments from several corneal clinics in Japan. We implemented 25 different machine learning models in Matlab and achieved a range of 62% to 94.0% accuracy. The highest accuracy level of 94% was obtained by a support vector machine (SVM) algorithm using a subset of eight corneal parameters with the highest discriminating power. The proposed model may aid physicians in assessing corneal status and detecting keratoconus, which is otherwise challenging through subjective evaluations, particularly at the preclinical and early stages of the disease. The algorithm can be integrated into corneal imaging devices or used as a stand-alone-software for cornea assessment and detecting early stage keratoconus.","Machine learning,Diseases,Computational modeling,Cornea,Surfaces,Imaging,Keratoconus,machine learning,corneal imaging data,data mining,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016060,
69,SessionNet: Feature Similarity-Based Weighted Ensemble Learning for Motor Imagery Classification,8,,134524-134535,"Lee Byeong-Hoo,Jeong Ji-Hoon,Lee Seong-Whan","Lee BH,Jeong JH,Lee SW",Lee SW,10.1109/ACCESS.2020.3011140,Korea University,"A brain-computer interface (BCI) provides a direct communication pathway between user and external devices. Motor imagery (MI) paradigm is widely used in non-invasive BCI to control external devices by decoding user intentions. The traditional MI-BCI problem is to obtain enough EEG data samples for adopting deep learning techniques, as electroencephalography (EEG) data have intricate and non-stationary properties that can cause a discrepancy between different sessions of data. Because of the discrepancy, the recorded EEG data with different sessions cannot be treated as the same. In this study, we recorded a large intuitive EEG dataset that contained nine types of movements of a single-arm across 12 subjects. We proposed a SessionNet that learns generality with EEG data recorded over multiple sessions using feature similarity to improve classification performance. Additionally, the SessionNet adopts the principle of a hierarchical convolutional neural network that shows robust classification performance regardless of the number of classes. The SessionNet outperforms conventional methods on 3-class, 5-class, and two types of 7-class and 9-class of a single-arm task. Hence, our approach could demonstrate the possibility of using feature similarity based on a novel ensemble learning method to train generality from multiple session data for better MI classification performance.","Electroencephalography,Feature extraction,Machine learning,Indexes,Visualization,Training,Protocols,Brain-computer interface (BCI),electroencephalogram (EEG),motor imagery (MI),convolutional neural network (CNN),weighted ensemble learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,EEG,CLASSIFICATION,SUBJECT,ERROR",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146526.pdf,
70,Online Learning for the Hyoid Bone Tracking During Swallowing With Neck Movement Adjustment Using Semantic Segmentation,8,,157451-157461,"Lee Dongheon,Lee Woo Hyung,Seo Han Gil,Oh Byung-Mo,Lee Jung Chan,Kim Hee Chan","Lee D,Lee WH,Seo HG,Oh BM,Lee JC,Kim HC",Oh BM,10.1109/ACCESS.2020.3019532,Seoul National University (SNU),"Swallowing difficulty is a major health concern of the elderly population. The gold standard examination to assess swallowing function is videofluoroscopic swallowing study (VFSS). Hyoid kinematic parameters extracted from VFSS images can be quantitative indicators of swallowing difficulty. In previous studies, its tracking failures are still not resolved when passing through the mandible. Furthermore, it is difficult to be applied in kinematic analysis because the hyoid trajectories can be susceptible to irrelevant neck movements during swallowing. The aim of this study is to develop a robust algorithm for obtaining high-accuracy trajectories of the hyoid bone during swallowing with adjustment of the neck movements. We propose a CNN-based hyoid tracking algorithm which consists of single-domain networks for hyoid tracking and an attention U-Net with conditional random fields for semantic segmentation of the hyoid bone and the cervical vertebrae. The results show that the proposed method can track the hyoid bone robustly compared to the previous methods as measured by a success plot of one-pass evaluation. In addition, the proposed semantic segmentation method achieved the highest dice coefficient for the hyoid bone and the cervical vertebrae. Finally, the obtained hyoid trajectories were evaluated by a root mean squared error, relative error of range of motion, and Pearson's correlation analysis. The proposed algorithm can provide ability to automatically analyze the hyoid motions during swallowing in clinical practice and will potentially enable physician's decision making on diagnostic and therapeutic modalities based on quantitative swallowing assessments.","Bones,Tracking,Trajectory,Kinematics,Neck,Semantics,Manuals,Swallowing difficulty,hyoid bone,cervical vertebrae,online learning,semantic segmentation,convolutional neural networks,videofluoroscopic swallowing study",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DYSPHAGIA,MOTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09178356.pdf,
71,DCSegNet: Deep Learning Framework Based on Divide-and-Conquer Method for Liver Segmentation,8,,146838-146846,"Li Congsheng,Yao Guorong,Xu Xu,Yang Lei,Zhang Yi,Wu Tongning,Sun Junhui","Li CS,Yao GR,Xu X,Yang L,Zhang Y,Wu TN,Sun JH",Wu TN,10.1109/ACCESS.2020.3012990,China Academy of Information & Communication Technology,"Image segmentation plays a vital role in the medical diagnosis and intervention field. The segmentation methods can be classified as fully automated, semiautomated or manual. Among them, manual segmentation can best improve the quality of the results, but it is time-consuming and tedious, and it may lead to operator bias. A continuity-aware probabilistic network based on the divide-and-conquer method was proposed in the current work. The proposed network comprised backbone network, local segmentation and a weight network. The backbone network extracts the features from image. The local segmentation divides the data space, whereas the weight network provides the continuity-aware weights. Therefore, combining those results of the weighted segments can eventually yield precise estimations. In this study, the proposed model was evaluated against several recent methods on the three datasets, and a several performance indexes of segmentation were evaluated for liver segmentation, the results showing that it is the most advanced liver segmentation approach. The source code of this work is publicly shared at https://github.com/licongsheng/DCSegNet for others to easily reproduce the work and build their own models with the introduced mechanisms.","Image segmentation,Liver,Feature extraction,Object segmentation,Two dimensional displays,Three-dimensional displays,Machine learning,Liver segmentation,deep learning,divide-and-conquer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,FUTURE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09152822.pdf,
72,Computer-Aided Diagnosis and Staging of Pancreatic Cancer Based on CT Images,8,,141705-141718,"Li Min,Nie Xiaohan,Reheman Yilidan,Huang Pan,Zhang Shuailei,Yuan Yushuai,Chen Chen,Yan Ziwei,Chen Cheng,Lv Xiaoyi","Li M,Nie XH,Reheman Y,Huang P,Zhang SL,Yuan YS,Chen C,Yan ZW,Chen C,Lv XY",Lv XY,10.1109/ACCESS.2020.3012967,Xinjiang University,"Pancreatic cancer (PC) is a malignant tumor that seriously threatens the survival of patients. Artificial classification has practical difficulties, such as unstable classification accuracy, a heavy workload, and the classification results depend on the subjective judgment of the clinician during the diagnosis and staging of PC. In addition, accurate PC staging could better help clinicians deliver the optimal therapeutic schedule for PC patients of different stages. Therefore, this study proposes a comprehensive medical computer-aided method for preoperative diagnosis and staging of PC based on an ensemble learning-support vector machine (EL-SVM) and computed tomography (CT) images. The least absolute shrinkage and selection operator (LASSO) algorithm was chosen for feature selection. In contrast to no feature selection, the model optimization time decreased by 19.94 seconds while maintaining precision. The EL-SVM learner was used to classify 168 CT images of normal pancreas and different stages of PC. The experimental results demonstrated that the normal pancreas (normal)-pancreatic cancer early stage (early stage) classification accuracy was 86.61%, the normal-pancreatic cancer stage III (stage III) classification accuracy was 87.04%, the normal-pancreatic cancer stage IV (stage IV) classification accuracy was 91.63%, the normal-PC classification accuracy was 87.89%, the early stage-stage III classification accuracy was 75.03%, and the early stage-stage IV classification accuracy was 81.22%, and the stage III-stage IV classification accuracy was 82.48%. Our experimental results prove that our proposed method is feasible and promising for clinical applications for the preoperative diagnosis and staging of PC via CT images.","Computed tomography,Pancreas,Feature extraction,Cancer,Support vector machines,Tumors,Image segmentation,Pancreatic cancer,diagnosis and staging,EL-SVM,CT,LASSO",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FEATURE-SELECTION,TOMOGRAPHY,CLASSIFICATION,ENHANCEMENT,EXPRESSION,PROGNOSIS,MECHANISM,NETWORKS,TUMORS,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09152949.pdf,
73,Automatic Crack Detection and Measurement of Concrete Structure Using Convolutional Encoder-Decoder Network,8,,134602-134618,"Li Shengyuan,Zhao Xuefeng","Li SY,Zhao XF",Zhao XF,10.1109/ACCESS.2020.3011106,Dalian University of Technology,"The detection and measurement of crack at pixel level is a challenge to existing methods. To overcome this challenge, this paper proposes a convolutional encoder-decoder network (CedNet) to detect crack from image, and the maximum widths and orientations of cracks are measured using image post-processing techniques. To realize this, a database including 1800 crack images (with $761\times 569$ pixel resolution) taken from concrete structures is built. Then the CedNet is designed, trained and validated using the built database. The validating results show 98.90% accuracy, 93.58% precision, 94.73% recall, 93.18% F-measure, 87.23% intersection over union (IoU) of crack and 98.82% IoU of background. Subsequently, the robustness and adaptability of the trained model is tested. To measure true maximum widths and orientations of cracks, a laboratory experiment is carried out to calibrate a relation between ratio (pixel distance / real distance) and field of view (camera's view range on concrete surface included in image) and distance from the smartphone to concrete surface. In the post-processing techniques, the perspective transformation is employed to correct distorted images caused by the existence of the oblique angles between the smartphone and concrete surfaces. Then the maximum widths and orientations of cracks in predicted results are measured respectively using the Euclidean distance transformation and least squares principle. As comparison, two existing deep learning-based crack detection and measurement method are used to examine the performance of the proposed approach. The comparison results show that the proposed method substantiates quite good performance to detect cracks and measure maximum widths and orientations of cracks in our database.","Concrete crack,detection and measurement,convolutional encoder-decoder network,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DAMAGE,DETECTION,NOISE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146278.pdf,
74,Metaheuristic for Solving Multi-Objective Job Shop Scheduling Problem in a Robotic Cell,8,,147015-147028,"Li Xiaohui,Yang Xi,Zhao Yi,Teng Ying,Dong Yuan","Li XH,Yang X,Zhao Y,Teng Y,Dong Y",Teng Y,10.1109/ACCESS.2020.3015796,University of Electronic Science & Technology of China,"This paper deals with the multi-objective job shop scheduling problem in a robotic cell (MOJRCSP). All the jobs are processed according to their operations order on workstations. Different from classical job shop scheduling problem, the studied problem considers that jobs' transportation is handled by a robot. Also, the jobs are expected to be finished in a time window, instead of a constant due date. A mixed Integer Programming (MIP) model is proposed to formulate this problem. Due to the special characteristics of the studied problem and its NP-hard computational complexity, a metaheuristic based on Teaching Learning Based Optimization (TLBO) algorithm has been proposed. The proposed algorithm determines simultaneously the operations' assignments on workstations, the robot assignments for transportation operations, and the robot moving sequence. The objective is to minimize the makespan and the total earliness and tardiness. Computational results further validated the effectiveness and robustness of our proposed algorithm.","Job shop scheduling,Approximation algorithms,Service robots,Workstations,Optimal scheduling,Robotic cell,job shop,multi-objective optimization,local search,teaching-learning based optimization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PARTICLE,SWARM,OPTIMIZATION,LOCAL,SEARCH,ALGORITHM,MAKESPAN,MACHINE,DESIGN,TIME",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09164955.pdf,
75,Predicting Scattering From Complex Nano-Structures via Deep Learning,8,,139983-139993,"Li Yongzhong,Wang Yinpeng,Qi Shutong,Ren Qiang,Kang Lei,Campbell Sawyer D.,Werner Pingjuan L.,Werner Douglas H.","Li YZ,Wang YP,Qi ST,Ren Q,Kang L,Campbell SD,Werner PL,Werner DH",Ren Q,10.1109/ACCESS.2020.3012132,Beihang University,"Existing numerical electromagnetic (EM) solvers are usually computationally expensive, time consuming, and memory demanding. Recent advances in deep learning (DL) techniques have demonstrated superior efficiency and provide an alternative pathway for speeding up simulations by serving as effective computational tools. In this paper, we propose a DL framework for real-time predictions of the scattering from an isolated nano-structure in the near-field regime. We find that, to achieve precise approximation of the optical response obtained from numerical simulations, the proposed DL framework only requires a small training data set. The fully trained framework can be three orders of magnitude faster than a conventional EM solver based on the finite difference frequency domain method (FDFD). Furthermore, the proposed DL framework has demonstrated robustness to changes in design variables which govern the nano-structure geometry and material selection as well as properties of the incident wave, shedding light on universal scattering predictions at the nano scale via deep learning techniques. This framework increases the viability of the design and analysis of complex nanostructures, offering great potential for applications pertaining to complex light-matter interaction between electromagnetic fields and nanomaterials.","Mathematical model,Two dimensional displays,Nanostructures,Machine learning,Training,Optical scattering,Deep learning,nanostructure,nano-optics simulation,scattering analysis,computational electromagetics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NANOPHOTONICS,DESIGN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09149921.pdf,
76,Projection-Based Classification of Chemical Groups for Provenance Analysis of Archaeological Materials,8,,152439-152451,"Lopez-Garcia Pedro A.,Argote Denisse L.,Thrun Michael C.","Lopez-Garcia PA,Argote DL,Thrun MC",Thrun MC,10.1109/ACCESS.2020.3016244,Philipps University Marburg,"In provenance analysis, identifying the origin of the archaeological artifacts plays a significant role. Usually, this problem is addressed by discovering natural groups in data measured with spectroscopic techniques. Then, principal component and classical partitioning cluster analysis are employed to reveal the groups that supposedly define the origin of the investigated artefacts. However, this work shows that maximizing the variance and searching for specific cluster structures can be misleading because it fails to discriminate clearly the different archeological sources. In contrast, the new methodology reveals several acknowledged geological sources present in the materials through the exploitation of emergence and swarm intelligence without prior assumptions about the data structures. A combination of unsupervised and semi-supervised machine learning and chemometric is applied on samples of Mesoamerican geological sources and obsidian artefacts collected from the archaeological site of Xalasco in Mexico. The analysis of the artifacts showed a preference of Xalasco inhabitants to local obsidian deposits. The results show that this approach, in terms of robustness, is suitable for handling unbiased quantitative spectral analysis of archaeological materials revealing the natural groups of archeological data.","Clustering algorithms,Chemicals,Principal component analysis,Mathematical model,Object recognition,Classification algorithms,Estimation,Swarm intelligence,emergence,chemometrics,chemical data grouping,provenance analysis,archaeological obsidian",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"X-RAY-FLUORESCENCE,CLUSTER,CERAMICS,IDENTIFICATION,VALIDATION,ALGORITHM,SAMPLES,MEXICO",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016244,
77,A Comparison of Transfer Learning Performance Versus Health Experts in Disease Diagnosis From Medical Imaging,8,,139367-139386,"Malik Hassaan,Farooq Muhammad Shoaib,Khelifi Adel,Abid Adnan,Qureshi Junaid Nasir,Hussain Muzammil","Malik H,Farooq MS,Khelifi A,Abid A,Qureshi JN,Hussain M",Farooq MS,10.1109/ACCESS.2020.3004766,"Univ Management & Technol, Dept Comp Sci, Lahore 54000, Pakistan.","Deep learning methods have huge success in task specific feature representation. Transfer learning algorithms are very much effective when large training data is scarce. It has been significantly used for diagnosis of diseases in medical imaging. This article presents a systematic literature review (SLR) by conducting a comparison of a variety of transfer learning approaches with healthcare experts in diagnosing diseases from medical imaging. This study has been compiled by reviewing research studies published in renowned venues between 2014 and 2019. Moreover, the data for the diagnosis performed by health care experts has also been acquired to perform a detailed comparative analysis for a wide range of diseases. The analysis has been performed on the basis of diseases, transfer learning approaches, type of medical imaging used. The comparative analysis is based on performance indices reported in studies which include diagnostic accuracy, true-positive (TP), false-positive (FP), true-negative (TN), false-negative (FN) sensitivity, specificity, and the area under the receiver operating characteristic curve (AUROC). A total of5,188articles were identified out of which 63 studies were included. Among them 21 research studies contain sufficient data to construct the evaluation tables that enable process of test accuracy of transfer learning having sensitivity ranged from 71% to 100% (mean 85.25%) and specificity ranged from 64% to 100% (mean 81.92%). Furthermore, health experts having sensitivity ranged from 33% to 100% (mean 85.27%) and specificity ranged from 82% to 100% (mean 91.63%).This SLR found that diagnostic accuracy of transfer learning is approximately equivalent to the diagnosis of health experts. The results also revealed that convolutional neural networks (CNN) have been extensively used for disease diagnosis from medical imaging. Finally, inappropriate exposure of diseases in transfer learning studies restricts reliable elucidation of the outcomes of diagnostic accuracy.","Diseases,Sensitivity,Medical diagnosis,Artificial intelligence,Medical diagnostic imaging,Transfer learning,heath experts,disease,medical imaging,SLR",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,ARTIFICIAL-INTELLIGENCE,DEEP,CLASSIFICATION,LEVEL,DISTINCTION,HUMANS,CANCER,PAR",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09123851.pdf,
78,Disease Classification Based on Synthesis of Multiple Long Short-Term Memory Classifiers Corresponding to Eye Movement Features,8,,151624-151633,"Mao Yuxing,He Yinghong,Liu Lumei,Chen Xueshuo","Mao YX,He YH,Liu LM,Chen XS",Mao YX,10.1109/ACCESS.2020.3017680,Chongqing University,"Medical research confirms that eye movement abnormalities are related to a variety of psychological activities, mental disorders and physical diseases. However, as the specific manifestations of various diseases in terms of eye movement disorders remain unclear, the accurate diagnosis of diseases according to eye movement is difficult. In this paper, a deep neural network (DNN) method is employed to establish a disease discrimination model according to eye movement. First, multiple eye-tracking experiments are designed to obtain eye images. Second, pupil characteristics, including position and size, are extracted, and the feature vectors of eye movement are obtained from the normalized pupil information. Based on a long short-term memory (LSTM) network, a classifier that corresponds to each feature, which is referred to as a weak classifier, is built. The experimental samples are preclassified, and the classification ability of each weak classifier for different diseases is also calculated. Last, a strong classifier is achieved for disease discrimination by synthesizing all the weak classifiers and their classification abilities. By classification testing for three categories of healthy controls, brain injury patients and vertigo patients, the experimental results demonstrated the efficiency of this method. With the deep learning method, more medical information can be excavated from eye movement to improve the values in disease diagnosis.","Eye movement,disease discrimination,deep learning,long short-term memory network,classifier",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"POTENTIAL,BIOMARKER,PARKINSONS-DISEASE,ALZHEIMERS-DISEASE,ATTENTIONAL,BIAS,TRACKING,DEPRESSION,NYSTAGMUS",IEEE ACCESS,https://doi.org/10.1109/access.2020.3017680,
79,Detection of Respiratory Sounds Based on Wavelet Coefficients and Machine Learning,8,,155710-155720,"Meng Fei,Shi Yan,Wang Na,Cai Maolin,Luo Zujing","Meng F,Shi Y,Wang N,Cai ML,Luo ZJ",Shi Y; Wang N,10.1109/ACCESS.2020.3016748,Beihang University,"Respiratory sounds reveal important information of the lungs of patients. However, the analysis of lung sounds depends significantly on the medical skills and diagnostic experience of the physicians and is a time-consuming process. The development of an automatic respiratory sound classification system based on machine learning would, therefore, be beneficial. In this study, 705 respiratory sound signals (240 crackles, 260 rhonchi, and 205 normal respiratory sounds) were acquired from 130 patients. We found that similarities between the original and wavelet decomposed signals reflected the frequency of the signals. The Gaussian kernel function was used to evaluate the wavelet signal similarity. We combined the wavelet signal similarity with the relative wavelet energy and wavelet entropy as the feature vector. A 5-fold cross-validation was applied to assess the performance of the system. The artificial neural network model, which was applied, achieved the classification accuracy and classified the respiratory sound signals with an accuracy of 85.43%.","Lung,Time-frequency analysis,Wavelet coefficients,Feature extraction,Filtering algorithms,Machine learning,Respiratory sound,relative wavelet energy,wavelet entropy,wavelet similarity,cross validation,artificial neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EVENT-RELATED,POTENTIALS,CLASSIFICATION,ENTROPY,ALGORITHMS",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016748,
80,Manifold Constrained Low-Rank and Joint Sparse Learning for Dynamic Cardiac MRI,8,,142622-142631,"Meng Qingmin,Xiu Xianchao,Li Yan","Meng QM,Xiu XC,Li Y",Xiu XC,10.1109/ACCESS.2020.3014236,Peking University,"Reconstruction from highly accelerated dynamic magnetic resonance imaging (MRI) is of great significance for medical diagnosis. The application of low-rank and sparse matrix decomposition to MRI can improve imaging speed and efficiency. However, the consistence of the learned low-rank and sparse structures for similar input samples is not well addressed in literature. In this paper, we propose a manifold constrained low-rank and joint sparse learning model that embeds the manifold priors into low-rank and joint sparse decomposition. It is noted that the joint sparsity is investigated to exploit the shared information. Further, the manifold constraints for low-rank and joint sparse parts are forced the optimization process to satisfy the structure preservation requirement. To solve the above manifold learning problem, a manifold constrained alternating direction method of multipliers (McADMM) approach is designed. It is proved theoretically that the sequence generated by McADMM converges to a stationary point. Numerical comparisons on simulation data and real-world dynamic cardiac MRI data are presented to demonstrate its efficiency.","Manifolds,Magnetic resonance imaging,Sparse matrices,Matrix decomposition,Data models,Numerical models,Convex functions,Magnetic resonance imaging (MRI),dynamic cardiac MRI,low-rank and joint sparse decomposition,manifold learning,alternating direction method of multipliers (ADMM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ALTERNATING,DIRECTION,METHOD,MATRIX,DECOMPOSITION,ROBUST-PCA,MULTIPLIERS,IMAGE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09157834.pdf,
81,X-Ray Baggage Inspection With Computer Vision: A Survey,8,,145620-145633,"Mery Domingo,Saavedra Daniel,Prasad Mukesh","Mery D,Saavedra D,Prasad M",Mery D,10.1109/ACCESS.2020.3015014,Pontificia Universidad Catolica de Chile,"In the last decades, baggage inspection based on X-ray imaging has been established to protect environments in which access control is of vital significance. In several public entrances, like airports, government buildings, stadiums and large event venues, security checks are carried out on all baggage to detect suspicious objects (e.g., handguns and explosives). Although improvements in X-ray technology and computer vision have made many X-ray detection tasks that were previously unfeasible a reality, the progress that has been made in automated baggage inspection is very limited compared to what is needed. For this reason, X-ray screening systems are usually being manipulated by human inspectors. Research and development experts who focus on X-ray testing are moving towards new approaches that can be used to aid human operators. This paper reports the state of the art in baggage inspection identifying three research fields that have been used to deal with this problem: i) X-ray energies, because there is enough research evidence to show that multi-energy X-ray testing must be used when the material characterization is required; ii) X-ray multi-views, because they can be an effective option for examining complex objects where the uncertainty of only one view can lead to misinterpretation; and iii) X-ray computer vision algorithms, because there are a plethora of computer vision approaches that can address many 3D object recognition problems. Besides, this paper presents useful public datasets that can be used for training and testing, and also summarizes the reported experimental results in this field. Finally, this paper addresses the general limitations and show new avenues for future research.","Inspection,X-ray imaging,Computer vision,Testing,Explosives,Object recognition,Licenses,X-ray testing,computer vision,machine learning,deep learning,baggage inspection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EXPLOSIVES,DETECTION,GEOMETRIC,FEATURES,CT,RECONSTRUCTION,OBJECT,DETECTION,MODEL,TOMOGRAPHY,RETRIEVAL,NETWORK",IEEE ACCESS,https://opus.lib.uts.edu.au/bitstream/10453/145651/2/09162101.pdf,
82,Segmentation of Lungs in Chest X-Ray Image Using Generative Adversarial Networks,8,,153535-153545,"Munawar Faizan,Azmat Shoaib,Iqbal Talha,Gronlund Christer,Ali Hazrat","Munawar F,Azmat S,Iqbal T,Gronlund C,Ali H",Ali H,10.1109/ACCESS.2020.3017915,COMSATS University Islamabad (CUI),"Chest X-ray (CXR) is a low-cost medical imaging technique. It is a common procedure for the identification of many respiratory diseases compared to MRI, CT, and PET scans. This paper presents the use of generative adversarial networks (GAN) to perform the task of lung segmentation on a given CXR. GANs are popular to generate realistic data by learning the mapping from one domain to another. In our work, the generator of the GAN is trained to generate a segmented mask of a given input CXR. The discriminator distinguishes between a ground truth and the generated mask, and updates the generator through the adversarial loss measure. The objective is to generate masks for the input CXR, which are as realistic as possible compared to the ground truth masks. The model is trained and evaluated using four different discriminators referred to as D1, D2, D3, and D4, respectively. Experimental results on three different CXR datasets reveal that the proposed model is able to achieve a dice-score of 0.9740, and IOU score of 0.943, which are better than other reported state-of-the art results.","Deep learning,generative adversarial networks,lung segmentation,medical imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AUTOMATIC,IDENTIFICATION,RADIOGRAPHS,REGIONS,FIELDS",IEEE ACCESS,http://umu.diva-portal.org/smash/get/diva2:1471015/FULLTEXT01,
83,A State-of-the-Art Survey on Deep Learning Methods for Detection of Architectural Distortion From Digital Mammography,8,,148644-148676,"Oyelade Olaide Nathaniel,Ezugwu Absalom El-Shamir","Oyelade ON,Ezugwu AE",Oyelade ON; Ezugwu AE,10.1109/ACCESS.2020.3016223,University of Kwazulu Natal,"Breast cancer is a type of cancer that has risen to be the second cause of death among women. Classification of breast tissues into normal, benign, or malignant depends on the presence of abnormalities like microcalcifications, masses, architectural distortions, and asymmetries. Architectural distortion (AD) is subtle in detection with no association with masses but shows the abnormal arrangement of tissue strands, often in a radial, spiculation, or random pattern. It is widely rated as the third symptom of breast cancer which is the most commonly missed abnormality. Most computational approaches characterizing abnormalities in breast images often concentrate on the detection of microcalcification and masses with architectural distortions appearing as a secondary finding. The subtle nature and a minimal occurrence of architectural distortions may seem to complicate computational approaches for its detection. As a result, little research interest has been recorded in this area. It is widely reported that some cases of recent breast cancer are wrongly diagnosed due to the omission in detecting the presence of architectural distortion at the early stage of the disease. However, we discovered that most computational solutions to early detection of breast cancer are focused mainly on detecting other abnormalities such as masses and microcalcification, which are some evidence of the advanced stage of the disease. To emphasise the little efforts channeled towards detection of AD compared to other abnormalities, this article aims to detail the review of such studies in the last decade. To the best of our knowledge, this study presents the first review which focuses on the detection of architectural distortion (AD) from mammographic images. Furthermore, this article presents a comprehensive review of approaches, advances, and challenges on the computational methods for detecting AD, with the sole aim of advancing the use of deep learning models in detecting AD. Moreover, a comparative study of performance analyses of articles surveyed in this article is investigated. Our findings revealed that about 70% of the existing literature adopted Gabor Filters, while just less than 10% leveraged on the state-of-the-art performances recorded in computer vision and deep learning, in building outstanding computational models for the detection of AD. The current study also discovered that using a deep learning approach, such as the convolution neural network (CNN) method, can yield a significant increase in performance for the task of detection of architectural distortions. This assertion is based on literature results obtained using the CNN, which generates an accuracy of 99.4% compared to the use of Gabor filters method, which accounts for 95% accuracy.","Breast cancer,Distortion,Machine learning,Gabor filters,Task analysis,Convolutional neural network,CNN,breast cancer,deep learning,Gabor filters,mammography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DIAGNOSIS,MASSES,CLASSIFICATION,LOCALIZATION",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016223,
84,Multi-Granular Semantic Analysis Based on Nasal Endoscopic Video,8,,158317-158326,"Pan Xiaoying,Zhao Hao,Liu Ni,Wang Hongyu","Pan XY,Zhao H,Liu N,Wang HY",Wang HY,10.1109/ACCESS.2020.3017523,Xi'an University of Posts & Telecommunications,"The semantic analysis of nasal endoscopic video is a challenging task since lots of irrelevant and insignificant information exists in the untrimmed surgical video, i.e. background, blur, judder or blood-stained video fragments. It is important to identify the start and end point of the valid surgical fragments automatically and remove the invalid fragments of endoscopic surgery videos for medical education & research. However, the performance of deep-learning based methods, which use a fixed time interval and a sliding window, are severely affected when the interference information appears randomly in the nasal endoscopic video. Specifically, the surgical video is a continuous process globally, while many local discontinuity fragments are brought when endoscope enters and exits the cavity frequently. Hence, we propose a multi-granularity semantic analysis framework that can simultaneously meet the accuracy and timeliness required for endoscopic surgery video semantic analysis. Our approach is an end-to-end solution. First, a joint model is created to extract the temporal-spatial features of the surgical video on a coarse-grained scale. Meanwhile, an attention mechanism is used to automatically select the informative spatial features of endoscopic video. Second, a hierarchical self-correction module is proposed to correct the boundaries of the surgical operation iteratively on a fine-grained scale. Finally, we justify the proposed network through extensive experiments and quantitative comparisons against other state-of-the-art approaches. We achieve a good performance in terms of accuracy and efficiency.","Multi-granular hierarchical,nasal endoscopic surgery,self-correction,video semantic analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECOGNITION,ARCHITECTURE,CANCER",IEEE ACCESS,https://doi.org/10.1109/access.2020.3017523,
85,Low-Dose CT Image Reconstruction With a Deep Learning Prior,8,,158647-158655,"Park Hyoung Suk,Kim Kyungsang,Jeon Kiwan","Park HS,Kim K,Jeon K",Jeon K,10.1109/ACCESS.2020.3020040,National Institute for Mathematical Sciences (NIMS),"In low-dose computed tomography (LDCT), a penalized weighted least squares (PWLS) approach that incorporates the Poisson statistics of X-ray photons can significantly reduce excessive quantum noise. To improve the quality of LDCT images, prior information such as the total variation, Markov random field, and nonlocal mean, can be imposed onto the target image. However, this information may be limited to reflect the characteristics of the target images, thereby resulting in unexpected side effects (e.g. blurry images). In this paper, we propose a PWLS method combined with a deep learning prior, which is learned from standard dose CT (SDCT) images. The proposed model learns a noise reduction function that maps an LDCT image to its corresponding SDCT images and estimates the prior distribution using a Pearson chi(2) divergence. The model can be converted to the least squares generative adversarial network with an added PWLS objective, where the optimal generator acts as the noise reduction function. We reformulate the proposed model as a constrained optimization problem and solve it using the alternating optimization (AO) algorithm. Clinical SDCT and simulated LDCT scans of ten patients were used to show the validity of the proposed method. Results show that the proposed method outperforms other PWLS methods, by imposing priors such as the total variation and the nonlocal mean.","Low-dose computed tomography,penalized weighted least squares,deep learning,denoising",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ITERATIVE,RECONSTRUCTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09179789.pdf,
86,M-GAN: Retinal Blood Vessel Segmentation by Balancing Losses Through Stacked Deep Fully Convolutional Networks,8,,146308-146322,"Park Kyeong-Beom,Choi Sung Ho,Lee Jae Yeol","Park KB,Choi SH,Lee JY",Lee JY,10.1109/ACCESS.2020.3015108,Chonnam National University,"Until now, the human expert segments retinal blood vessels manually in fundus images to inspect human retinal-related diseases, such as diabetic retinopathy and vascular occlusion. Recently, many studies were conducted for automatic retinal vessel segmentation from fundus images through supervised and unsupervised methods to minimize user intervention. However, most of them lack in segmentation robustness and cannot optimize loss functions so that results of the segmentation have made lots of fake or thin branches. This article proposes a new conditional generative adversarial network called M-GAN to conduct accurate and precise retinal vessel segmentation by balancing losses through stacked deep fully convolutional networks. It consists of a newly designed M-generator with deep residual blocks for more robust segmentation and an M-discriminator with a deeper network for more efficient training of the adversarial model. In particular, a multi-kernel pooling block is added between the stacked layers to support the scale-invariance of vessel segmentations of different sizes. The M-generator has down-sampling layers to extract features and up-sampling layers to make segmented retinal blood vessel images from the extracted features. The M-discriminator also has a deeper network similar to the down-sampling of the M-generator, but the final layer is constructed as a fully connected layer for decision making. We conduct pre-processing of the input image using automatic color equalization (ACE) to make the retinal vessels of the input fundus image more clear and perform post-processing that makes the vessel branches smooth and reduces false-negatives using a Lanczos resampling method. To verify the proposed method, we used DRIVE, STARE, HRF, and CHASE-DB1datasets and compared the proposed M-GAN with other studies. We measured accuracy, the intersection of union (IoU), F-1 score, and Matthews correlation coefficient (MCC) for comparative analysis. Results of comparison proved that the proposed M-GAN derived superior performance than other studies.","Image segmentation,Biomedical imaging,Blood vessels,Feature extraction,Retinal vessels,Machine learning,Retinal blood vessel segmentation,medical imaging,generative adversarial networks (GAN),conditional GAN,stacked deep fully convolutional networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE-ANALYSIS,WAVELET",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09162010.pdf,
87,Improving Skin-Disease Classification Based on Customized Loss Function Combined With Balanced Mini-Batch Logic and Real-Time Image Augmentation,8,,150725-150737,"Pham Tri-Cong,Doucet Antoine,Luong Chi-Mai,Tran Cong-Thanh,Hoang Van-Dung","Pham TC,Doucet A,Luong CM,Tran CT,Hoang VD",Luong CM,10.1109/ACCESS.2020.3016653,Vietnam Academy of Science & Technology (VAST),"Skin cancer is one of the most common cancers in the world. However, the disease is curable if detected in the beginning stage. Early detection of malignant lesions through accurate techniques and innovative technologies has a significant impact on reducing skin cancer mortality rates. Recently, artificial intelligence has come to the forefront to facilitate skin cancer diagnosis based on medical images. Many deep learning models have been studied and developed, but the imbalance of performance among classes in the multi-class classification is still a challenging problem. This study proposes a hybrid method for handling class imbalance of skin-disease classification. This method combines the data level method of balanced mini-batch logic followed by real-time image augmentation with the algorithm level method of designing new loss function. The training dataset includes 24,530 dermoscopic images of seven skin disease categories, which is by far the largest dataset of skin cancer. The performance metrics of six proposed methods are evaluated on a test dataset of 2,453 images. Our proposed EfficientNetB4-CLF model achieves the highest accuracy of 89.97% and also the highest mean recall of 86.13% with the smallest recalls' standard deviations of 7.60%. Compared to the original methods, our proposed solution not only surpasses 4.65% (86.13% vs 81.48%) of mean recalls but also reduces 4.24% of the recalls' standard deviations (from +/- 11.84% to +/- 7.60%). This result indicates that our hybrid method is highly effective in training the Deep CNN network on the skin-disease imbalanced dataset. It addresses the problem of slow learning of the minority classes in the networks by combining the data level method of balanced mini-batch logic followed by the real-time image augmentation with the algorithm level method of the newly designed loss function.","Skin,Lesions,Real-time systems,Classification algorithms,Melanoma,Neural networks,Skin disease,imbalanced dataset,deep neural networks,hybrid method,loss function,balanced mini-batch logic",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MELANOMA,DERMATOLOGISTS,DERMOSCOPY,ALGORITHMS,DIAGNOSIS,CANCER",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016653,
88,Inferring Skin Lesion Segmentation With Fully Connected CRFs Based on Multiple Deep Convolutional Neural Networks,8,,144246-144258,"Qiu Yuming,Cai Jingyong,Qin Xiaolin,Zhang Ju","Qiu YM,Cai JY,Qin XL,Zhang J",Qiu YM,10.1109/ACCESS.2020.3014787,"Chengdu Institute of Computer Application, CAS","This article presents a method to infer skin lesion segmentation based on multiple deep convolutional neural network (DCNN) models by employing fully connected conditional random fields (CRFs). This method is on the strength of the synergism between ensemble learning which is responsible for introducing diversity from multiple DCNN models and CRFs inference which is in charge of probabilistic inference based on random fields over dermoscopy images. Contrasting to single DCNN models, the proposed method can gain better segmentation by comprehensively utilizing the advances and performance preferences of multiple different DCNN models. In comparison with simple ensemble schemes, it can effectively and precisely refine the fuzzy lesion boundary by utilizing the information in test images to maximize label agreement between similar pixels. Further, an engineering bonus is the feasibility of parallelization for the heavy operation, predicting on multiple DCNN models. In experiments, we tested the effectiveness and robustness of the proposed method on the mainstream datasets ISIC 2017 and PH2, and the results were competitive with the state-of-art methods. we also confirmed that the proposed method can capture the local information in fuzzy dermoscopy images being able to find more accurate lesion borders with a good boost on Boundary Recall (BR) metric. Moreover, since the hyper-parameters in CRFs are explainable, it is possible to adjust them manually to reach better results case by case, being attractive in practice. This work is of value on integration between the deep learning technologies and probabilistic inference in resolving lesion segmentation, and has great potential to be applied in similar tasks.","Lesions,Image segmentation,Skin,Measurement,Predictive models,Training,Task analysis,Deep convolutional neural networks,ensemble learning,fully connected CRFs,pigmented skin lesion segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DERMOSCOPIC,IMAGE,SEGMENTATION,BORDER,DETECTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09160951.pdf,
89,Automatic Detection of Diabetic Eye Disease Through Deep Learning Using Fundus Images: A Survey,8,,151133-151149,"Sarki Rubina,Ahmed Khandakar,Wang Hua,Zhang Yanchun","Sarki R,Ahmed K,Wang H,Zhang YC",Sarki R,10.1109/ACCESS.2020.3015258,Victoria University,"Diabetes Mellitus, or Diabetes, is a disease in which a person's body fails to respond to insulin released by their pancreas, or it does not produce sufficient insulin. People suffering from diabetes are at high risk of developing various eye diseases over time. As a result of advances in machine learning techniques, early detection of diabetic eye disease using an automated system brings substantial benefits over manual detection. A variety of advanced studies relating to the detection of diabetic eye disease have recently been published. This article presents a systematic survey of automated approaches to diabetic eye disease detection from several aspects, namely: i) available datasets, ii) image preprocessing techniques, iii) deep learning models and iv) performance evaluation metrics. The survey provides a comprehensive synopsis of diabetic eye disease detection approaches, including state of the art field approaches, which aim to provide valuable insight into research communities, healthcare professionals and patients with diabetes.","Diabetes,Retina,Machine learning,Biomedical imaging,Retinopathy,Blood vessels,Diabetic eye disease,diabetic retinopathy,deep leaning,glaucoma,image processing,macular edema,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DIAGNOSIS,RETINOPATHY,GLAUCOMA,SYSTEM,CLASSIFICATION,IDENTIFICATION,PHOTOGRAPHS,VALIDATION",IEEE ACCESS,https://vuir.vu.edu.au/41048/1/09163123.pdf,
90,An Accurate and Fast Cardio-Views Classification System Based on Fused Deep Features and LSTM,8,,135184-135194,"Shahin Ahmed I.,Almotairi Sultan","Shahin AI,Almotairi S",Almotairi S,10.1109/ACCESS.2020.3010326,Majmaah University,"Echocardiography is an ultrasound-based imaging modality that helps the physician to visualize heart chambers and valves motion activity. Recently, deep learning plays an important role in several clinical computer-assisted diagnostic systems. There is a real need to employ deep learning methodologies to increase such systems. In this paper, we proposed a deep learning system to classify several echocardiography views and identify its physiological location. Firstly, the spatial CNN features are extracted from each frame in the echo-motion. Secondly, we proposed novel temporal features based on neutrosophic sets. The neutrosophic temporal motion features are extracted from echo-motion activity. To extract the deep CNN features, we activated a pre-trained deep ResNet model. Then, both spatial and neutrosophic temporal CNN features were fused based on features concatenation technique. Finally, the fused CNN features were fed into deep long short-term memory network to classify echo-cardio views and identify their location. During our experiments, we employed a public echocardiography dataset that consisted of 432 videos for eight cardio-views. We have investigated several pre-trained network activation performance. ResNet architecture activation achieved the best accuracy score among several pre-trained networks. The Proposed system based on fused spatial neutrosophic temporal deep features achieved 96.3% accuracy and 95.75% sensitivity. For the classification of cardio-views location, the proposed system achieved 99.1% accuracy. The proposed system achieved more accuracy than previous deep learning methods with a significant decrease in the training time cost. The experimental results showed promising results for our proposed approach.","Feature extraction,Machine learning,Echocardiography,Medical services,Heart,Training,Ultrasound,echocardiography,cardio-views,deep learning,neutrosophic temporal desriptors,CNN features fusion,LSTM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"VENTRICULAR,EJECTION,FRACTION,ARTIFICIAL-INTELLIGENCE,ULTRASOUND,ECHOCARDIOGRAPHY,SURVEILLANCE,ARCHITECTURE,NETWORK",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144215.pdf,
91,"Neural Speech Decoding During Audition, Imagination and Production",8,,149714-149729,"Sharon Rini A.,Narayanan Shrikanth S.,Sur Mriganka,Murthy A. Hema","Sharon RA,Narayanan SS,Sur M,Murthy AH",Sharon RA,10.1109/ACCESS.2020.3016756,Indian Institute of Technology System (IIT System),"Interpretation of neural signals to a form that is as intelligible as speech facilitates the development of communication mediums for the otherwise speech/motor-impaired individuals. Speech perception, production, and imagination often constitute phases of human communication. The primary goal of this article is to analyze the similarity between these three phases by studying electroencephalogram(EEG) patterns across these modalities, in order to establish their usefulness for brain computer interfaces. Neural decoding of speech using such non-invasive techniques necessitates the optimal choice of signal analysis and translation protocols. By employing selection-by-exclusion based temporal modeling algorithms, we discover fundamental syllable-like units that reveal similar set of signal signatures across all the three phases. Significantly higher than chance accuracies are recorded for single trial multi-unit EEG classification using machine learning approaches over three datasets across 30 subjects. Repeatability and subject independence tests performed at every step of the analysis further strengthens the findings and holds promise for translating brain signals to speech non-invasively.","Electroencephalography,Production,Protocols,Image segmentation,Brain modeling,Correlation,Image reconstruction,Assistive technology,brain computer interface,EEG,imagined speech,speech-EEG correlation,unit classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BRAIN-COMPUTER,INTERFACES,EEG,SIGNALS",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016756,
92,Automatic Identification of Epileptic Seizures From EEG Signals Using Sparse Representation-Based Classification,8,,138834-138845,"Sheykhivand Sobhan,Rezaii Tohid Yousefi,Mousavi Zohreh,Delpak Azra,Farzamnia Ali","Sheykhivand S,Rezaii TY,Mousavi Z,Delpak A,Farzamnia A",Rezaii TY,10.1109/ACCESS.2020.3011877,University of Tabriz,"Identifying seizure activities in non-stationary electroencephalography (EEG) is a challenging task since it is time-consuming, burdensome, and dependent on expensive human resources and subject to error and bias. A computerized seizure identification scheme can eradicate the above problems, assist clinicians, and benefit epilepsy research. So far, several attempts were made to develop automatic systems to help neurophysiologists accurately identify epileptic seizures. In this research, a fully automated system is presented to automatically detect the various states of the epileptic seizure. This study is based on sparse representation-based classification (SRC) theory and the proposed dictionary learning using electroencephalogram (EEG) signals. Furthermore, this work does not require additional preprocessing and extraction of features, which is common in the existing methods. This study reached the sensitivity, specificity, and accuracy of 100% in 8 out of 9 scenarios. It is also robust to the measurement noise of level as much as 0 dB. Compared to state-of-the-art algorithms and other common methods, our method outperformed them in terms of sensitivity, specificity, and accuracy. Moreover, it includes the most comprehensive scenarios for epileptic seizure detection, including different combinations of 2 to 5 class scenarios. The proposed automatic identification of epileptic seizures method can reduce the burden on medical professionals in analyzing large data through visual inspection as well as in deprived societies suffering from a shortage of functional magnetic resonance imaging (fMRI) equipment and specialized physician.","Electroencephalography,Machine learning,Feature extraction,Epilepsy,Dictionaries,Classification algorithms,Matching pursuit algorithms,EEG,epilepsy,seizure,sparse representation-based classification,dictionary learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NONCONVULSIVE,STATUS,EPILEPTICUS,WAVELET,TRANSFORM,FEATURE-EXTRACTION,DIAGNOSIS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09149613.pdf,
93,Feature Extraction and Classification of Lower Limb Motion Based on sEMG Signals,8,,132882-132892,"Shi Xin,Qin Pengjie,Zhu Jiaqing,Zhai Maqiang,Shi Weiren","Shi X,Qin PJ,Zhu JQ,Zhai MQ,Shi WR",Shi X; Qin PJ,10.1109/ACCESS.2020.3008901,"Minist Educ, Key Lab Complex Syst Safety & Control, Chongqing 400044, Peoples R China.","Surface electromyography (sEMG) signals can reflect the body motion information and are widely used in military, medical rehabilitation, industrial production. The lower limb motion classification mainly includes feature extraction and classification model establishment. Firstly, we proposed a feature extraction method based on the wavelet packet transform (WPT) and principal component analysis (PCA). We used the wavelet packet method to decompose the sEMG signals of three muscles in the lower limb and got the 24-dimensional eigenvector. To reduce the calculation and improve the speed of the classification model, we used the PCA method to reduce the dimension of the feature vector and got the 3-dimensional eigenvector. Then, we proposed a method based on the scale unscented Kalman filter (SUKF) and neural network (NN) for lower limb motion classification. Through the scale correction unscented transform (SCUT) could optimize the neural network weight and improve lower limb motion classification accuracy. Finally, the experimental results showed that the average accuracy was 93.7%. Compared with the backpropagation neural network (BPNN) and wavelet neural network (WNN), this method could improve the accuracy and reliability of the lower limb motion classification.","sEMG signals,lower limb motion classification,feature extraction,wavelet packet transform,principal component analysis,unscented Kalman filter,neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"KNEE-JOINT,ANGLE,IDENTIFICATION,MODULE,SURFACE,RECOGNITION,PREDICTION,WALKING,DESIGN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139511.pdf,
94,DoFP-ML: A Machine Learning Approach to Food Quality Monitoring Using a DoFP Polarization Image Sensor,8,,150282-150290,"Takruri Maen,Abubakar Abubakar,Alnaqbi Noora,Al Shehhi Hessa,Jallad Abdul-Halim M.,Bermak Amine","Takruri M,Abubakar A,Alnaqbi N,Al Shehhi H,Jallad AHM,Bermak A",Takruri M,10.1109/ACCESS.2020.3016904,American University of Ras Al Khaimah,"Good nutrition is an important part of leading a healthy lifestyle. This has brought into stark focus the need for efficient and low-cost methods for large scale food quality assessment. This article proposes a non-invasive and non-destructive system for estimating the freshness of apples using polarization images from a Division-of-Focal-Plane (DoFP) polarization camera. The proposed system uses Machine Learning Systems namely, Support Vector Regression (SVR) and Gaussian Process Regression (GPR), to estimate the age of apples and determine if they are fit for consumption even before the external rot appears on the fruit. Initially, the reconstructed images namely, Degree of Linear Polarization (DoLP) and Angle of Polarization (AoP), are generated from the polarization image and their respective correlations with the actual age of apples (in days) are established. These reconstructed images are then fed as input features to the Machine Learning Systems to ultimately estimate the age of the apples. Experiments on real data obtained from the DoFP camera show that the proposed system is non-destructive and capable of non-invasively estimating the age of the apple with an average accuracy of up to 92.57%.","Division of focal plane,food quality monitoring,machine learning,polarization image",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.3016904,
95,An Automatic Recognition of Tooth- Marked Tongue Based on Tongue Region Detection and Tongue Landmark Detection via Deep Learning,8,,153470-153478,"Tang Wenjun,Gao Yuan,Liu Lei,Xia Tingwei,He Li,Zhang Song,Guo Jinhong,Li Weihong,Xu Qiang","Tang WJ,Gao Y,Liu L,Xia TW,He L,Zhang S,Guo JH,Li WH,Xu Q",Xu Q,10.1109/ACCESS.2020.3017725,Chengdu University of Traditional Chinese Medicine,"The tooth-marked tongue refers to the tongue with the edge featured in jagged teeth marks, which is a significant indicator for reflecting the conditions of patients' internal organs in Traditional Chinese Medicine (TCM). From the perspective of computer vision, due to the small variance in the global region (original image) but the large variance in the local region (tongue region), especially in the differential region (tongue edge region around landmarks), the recognition of the tooth-marked tongue is a naturally fine-grained classification task. To address this challenging task, a two-stage method based on tongue region detection and tongue landmark detection via deep learning is proposed in this paper. In the first stage, we introduce a cascaded convolutional neural network to detect the tongue region and tongue landmarks simultaneously for minimizing the redundancy information and maximizing discriminative information explicitly. In the second stage, we send not only the detected tongue region but also the detected tongue landmarks to a fine-grained classification network for the final recognition. Conclusively, our method is highly consistent with human perception. Moreover, to the best of our knowledge, we are the first attempt to manage the tooth-marked tongue recognition via deep learning. We conducted extensive experiments with the proposed method. The experimental results demonstrate the effectiveness of the proposed method.","Tooth-marked tongue,tongue region detection,tongue landmark detection,deep learning,traditional Chinese medicine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CHINESE-MEDICINE,IEEE ACCESS,https://doi.org/10.1109/access.2020.3017725,
96,Diverse Feature Blend Based on Filter-Bank Common Spatial Pattern and Brain Functional Connectivity for Multiple Motor Imagery Detection,8,,155590-155601,"Wang Hongtao,Xu Tao,Tang Cong,Yue Hongwei,Chen Chuangquan,Xu Linfeng,Pei Zian,Dong Jiajun,Bezerianos Anastasios,Li Junhua","Wang HT,Xu T,Tang C,Yue HW,Chen CQ,Xu LF,Pei ZA,Dong JJ,Bezerianos A,Li JH",Wang HT; Li JH,10.1109/ACCESS.2020.3018962,Wuyi University,"Motor imagery (MI) based brain-computer interface (BCI) is a research hotspot and has attracted lots of attention. Within this research topic, multiple MI classification is a challenge due to the difficulties caused by time-varying spatial features across different individuals. To deal with this challenge, we tried to fuse brain functional connectivity (BFC) and one-versus-the-rest filter-bank common spatial pattern (OVR-FBCSP) to improve the robustness of classification. The BFC features were extracted by phase locking value (PLV), representing the brain inter-regional interactions relevant to the MI, whilst the OVR-FBCSP is used to extract the spatial-frequency features related to the MI. These diverse features were then fed into a multi-kernel relevance vector machine (MK-RVM). The dataset with three motor imagery tasks (left hand MI, right hand MI, and feet MI) was used to assess the proposed method. Experimental results not only showed that the cascade structure of diverse feature fusion and MK-RVM achieved satisfactory classification performance (average accuracy: 83.81%, average kappa: 0.76), but also demonstrated that BFC plays a supplementary role in the MI classification. Moreover, the proposed method has a potential to be integrated into multiple MI online detection owing to the advantage of strong time-efficiency of RVM.","Feature extraction,Electroencephalography,Covariance matrices,Eigenvalues and eigenfunctions,Support vector machines,Band-pass filters,Information filtering,Multiple motor imagery,filter-bank common spatial pattern (FBCSP),phase locking value (PLV),brain functional connectivity (BFC),multi-kernel relevance vector machine (MK-RVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,EEG,TASKS",IEEE ACCESS,http://repository.essex.ac.uk/28628/1/09174803.pdf,
97,OCT Image Recognition of Cardiovascular Vulnerable Plaque Based on CNN,8,,140767-140776,Wang Jingbo,Wang JB,Wang JB,10.1109/ACCESS.2020.3007599,Beijing Institute of Technology,"Optical coherence tomography (OCT) shows an important role in the diagnosis of cardiovascular diseases and the detection and intervention of vulnerable plaques. Clinical diagnosis of vulnerable plaques in cardiovascular system based on optical coherence tomography mainly relies on the manual analysis of vulnerable plaques in images by cardiovascular physicians. This analysis process is prone to subjective misjudgments and heavy workload. Studying the recognition technology of cardiovascular vulnerable plaque image will greatly improve the accuracy of diagnosis and reduce the workload of cardiovascular physicians, which is an effective way to achieve efficient diagnosis and treatment. In view of the recognition of cardiovascular vulnerable plaque medical images, a model based on convolution neural network (CNN) recognition is constructed. The CNN is used to learn the features of different levels from the original input OCT images. At the same time, several decision-making levels are designed. These decision-making levels can classify OCT images according to different feature maps, and finally make final recognition decisions according to the classification results. The experimental results on the clinical data set labeled by doctors show that the classification and recognition model of cardiovascular vulnerable plaque OCT image based on CNN has a high recognition rate. Making full use of the multilevel features of convolutional neural networks can effectively classify and recognize the OCT images of vulnerable cardiovascular plaques, provide support for the clinical diagnosis of cardiovascular diseases, and have great significance for the early intervention and prevention of cardiovascular diseases.","Feature extraction,Image recognition,Convolutional neural networks,Convolution,Manuals,Medical services,Convolutional neural network,vulnerable plaque,OCT image,image recognition",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORKS,TERM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146528.pdf,
98,Milling Tool Wear Prediction Method Based on Deep Learning Under Variable Working Conditions,8,,140726-140735,"Wang Mingwei);,Zhou Jingtao,Gao Jing);,Li Ziqiu);,Li Enming","Wang MW,Zhou JT,Gao J,Li ZQ,Li EM",Zhou JT,10.1109/ACCESS.2020.3010378,Northwestern Polytechnical University,"Tool wear prediction is essential to ensure part quality and machining efficiency. Tool wear is affected by factors such as the material, structure, process, and processing time of the parts. Tool wear under the variable working conditions and the above factors show a complex coupling and timing correlation, which makes it challenging to predict tool wear under variable working conditions. This article aims to resolve this issue. First, we establish a unified representation of working condition factors. The stacked autoencoder (SAE) model adaptively extracts tool wear features from the machining signal. The extracted wear features and respective working conditions then combine into a working condition feature sequence for predicting tool wear. Finally, the advantages of the long short-term memory (LSTM) model to solve memory accumulation effects learn the regular wear pattern of the working condition feature sequence to realize the prediction of the tool wear. An experiment illustrates the effectiveness of the proposed method.","Tools,Feature extraction,Employee welfare,Predictive models,Machine learning,Autoregressive processes,Machining,Variable working conditions,tool wear prediction,long short-term memory,stacked auto-encoder",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"USEFUL,LIFE,PREDICTION,ONLINE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09144206.pdf,
99,Deep Fusion Models of Multi-Phase CT and Selected Clinical Data for Preoperative Prediction of Early Recurrence in Hepatocellular Carcinoma,8,,139212-139220,"Wang Weibin,Chen Qingqing,Iwamoto Yutaro,Aonpong Panyanat,Lin Lanfen,Hu Hongjie,Zhang Qiaowei,Chen Yen-Wei","Wang WB,Chen QQ,Iwamoto Y,Aonpong P,Lin LN,Hu HJ,Zhang QW,Chen YW",Chen YW,10.1109/ACCESS.2020.3011145,Ritsumeikan University,"Post-operative early recurrence (ER) of hepatocellular carcinoma (HCC) is one of the leading causes of death. The prediction of the ER of HCC before treatment contributes to guiding treatment and follow-up protocols. In recent years, CT radiomics signatures have been proven effective in several studies in predicting early recurrence of HCC, there are still two major challenges. First, the radiomics features extracted were low or mid-level features, which may not fully characterize HCC heterogeneity. Second, the fusion approach of clinical textual data and image information is in little consensus. In this paper, we proposed a deep-learning based prediction model to extract high-level features from the triple-phase CT images and compare its performance with traditional radiomics model and clinical model. The accuracy and area under the curve (AUC) of receiver operating characteristics of three models was 69.52%/0.723, 67.04%/0.64, 76.03%/0.75, respectively. In addition, we proposed four fusion models to combine clinical data and high-level features. Among them, Fusion model D performed best, achieving a higher prediction accuracy of 78.66% and AUC of 0.8248. Moreover, fusion models with a joint loss function can further improve the prediction performance to 80.49% and 0.8331.","Predictive models,Feature extraction,Tumors,Computed tomography,Liver,Surgery,Data models,Hepatocellular carcinoma,early recurrence,deep learning,multi-phase CT images,clinical data,fusion model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"LIVER,RESECTION,RISK-FACTORS,INTRAHEPATIC,RECURRENCE,LYMPHOCYTE,RATIO,SURVIVAL,HEPATECTOMY,SEGMENTATION,NEUTROPHIL,CANCER,IMAGES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09146115.pdf,
100,Learning Methods of Convolutional Neural Network Combined With Image Feature Extraction in Brain Tumor Detection,8,,152659-152668,"Wang Weiguang,Bu Fanlong,Lin Ziyi,Zhai Shuangqing","Wang WG,Bu FL,Lin ZY,Zhai SQ",Zhai SQ,10.1109/ACCESS.2020.3016282,Beijing University of Chinese Medicine,"Computer-aided detection technology is less applied in brain tumor detection terminals, and it is difficult to eliminate the influence of various interference factors on the diagnosis results. In order to promote the application of computer-aided detection technology in brain tumor detection, this study based on convolutional neural network, combined with MRI detection technology to construct a model adapted to brain tumor feature detection. The main function of this research model is to segment and recognize MRI brain tumors and use convolutional layer to perform convolution operation to improve recognition efficiency and rate and combine artificially selected features with machine learning features. In addition, this article uses feature fusion to further improve the diagnostic results. Finally, this article designs experiments to perform performance analysis. The research shows that the model algorithm designed in this article has certain practical effects and can provide theoretical reference for subsequent related research.","Feature extraction,Tumors,Image segmentation,Magnetic resonance imaging,Medical diagnostic imaging,Convolutional neural network,disease detection,feature extraction,pattern recognition",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,MRI",IEEE ACCESS,https://doi.org/10.1109/access.2020.3016282,
