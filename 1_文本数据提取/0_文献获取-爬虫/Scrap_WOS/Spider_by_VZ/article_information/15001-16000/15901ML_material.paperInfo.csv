,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,ICD-10 Coding of Spanish Electronic Discharge Summaries: An Extreme Classification Problem,8,,100073-100083,"Almagro Mario,Martinez Unanue Raquel,Fresno Victor,Montalvo Soto","Almagro M,Unanue RM,Fresno V,Montalvo S",Almagro M,10.1109/ACCESS.2020.2997241,Universidad Nacional de Educacion a Distancia (UNED),"Objective: Medical coding is used to identify and standardize clinical concepts in the records collected from healthcare services. The tenth revision of the International Classification of Diseases (ICD-10) is the most widely-used coding with more than 11,000 different diagnoses, affecting research, reporting, and funding. Unfortunately, ICD-10 code sets tend to follow biased, unbalanced, and scattered distributions. These distribution attributes, along with high lexical variability, severely restrict performance when coded clinical records are used to infer code sets in uncoded records. To improve that inference, we explore a combination of example-based methods optimized to capture codes with different appearance frequencies in data sets. Materials and Methods: The proposed exploration has been carried out on Spanish hospital discharge reports coded by experts, excluding all sentences without any biomedical concept. Representations based on semantic and lexical features are explored, using both global and label-specific attributes. In turn, algorithms based on binary outputs, groups of subsets and extreme classification are compared. Lists of codes together with their confidence values (certainty probabilities) are suggested by each method. Results: Diverse spectral behaviors are shown for each method. Binary classifiers seem to maximize the capture of more popular codes, while extreme classifiers promote infrequent ones. In order to exploit such differences, ensemble approaches are proposed by weighting every output code according to the method, confidence value and appearance frequency. The rule-based combination reaches a 46% Precision at 10 (P@10), which means a 15% improvement over the best individual proposal. Conclusion: Assembling methods based on weighting each code according to training frequency and performance can achieve better overall Precision scores on extreme distributions, such as ICD-10 coding.","Encoding,Training,Hospitals,Diseases,Proposals,Licenses,Task analysis,Extreme classification,XMTC,ICD-10 coding,text mining",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2997241,
2,An Improved kNN Classifier for Epilepsy Diagnosis,8,,100022-100030,"Wang Zhiping,Na Junying,Zheng Baoyou","Wang ZP,Na JY,Zheng BY",Wang ZP,10.1109/ACCESS.2020.2996946,Dalian Maritime University,"The electroencephalogram (EEG) signals are important for reflecting seizures and the diagnosis of epilepsy. In this paper, a weighted k-nearest neighbor classifier based on Bray Curtis distance (WBCKNN) is proposed to implement automatic detection of epilepsy. The Fourier transform can transform the time-domain characteristics of the signal into frequency domain, which can display more useful information. The WBCKNN classifier can well overcome the sensitivity of the neighborhood size k and has good robustness. Therefore, it can classify EEG signals more accurately for different situations. WBCKNN is applied on public dataset and tested by k-fold cross-validation. Experimental results show that the best accuracy of the two-classification problems and three-classification problems is 99.67% and 99%, respectively. Compared to other classifiers, the accuracy of classification is also improved. In addition, this method is superior to traditional methods in sensitivity, specificity and false alarm rate of epilepsy classification. This method can be applied to the medical market to help doctors diagnose epilepsy.","Electroencephalography,Epilepsy,Classification algorithms,Time-domain analysis,Frequency-domain analysis,Fourier transforms,EEG,epilepsy,Bray Curtis distance,Fourier transform,k-nearest-neighbor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SEIZURE,DETECTION,EEG,NETWORK,PREDICTION,EMD",IEEE ACCESS,https://doi.org/10.1109/access.2020.2996946,
3,APPLICATION OF TEXTURE FEATURES AND MACHINE LEARNING METHODS TO GRAIN SEGMENTATION IN ROCK MATERIAL IMAGES,39,2,73-90,"Nurzynska Karolina,Iwaszenko Sebastian","Nurzynska K,Iwaszenko S",Nurzynska K,10.5566/ias.2186,Silesian University of Technology,"The segmentation of rock grains on images depicting bulk rock materials is considered. The rocks' material images are transformed by selected texture operators, to obtain a set of features describing them. The first order features, second-order features, run-length matrix, grey tone difference matrix, and Laws' energies are used for this purpose. The features are classified using k-nearest neighbours, support vector machines, and artificial neural networks classifiers. The results show that the border of rocks grains can be determined with above 75% accuracy. The multi-texture approach was also investigated, leading to an increase in accuracy to over 79% for the early-fusion of features. Attempts were made to reduce feature space dimensionality by manually picking features as well as by the use of principal component analysis. The outcomes showed a significant decrease in accuracy. The obtained results have been visually compared with the ground truth. The compliance observed can be considered to be satisfactory.","classification,grain sizes,object segmentation,texture features",Article,"INT SOC STEREOLOGY, INST ANATOMY, MEDICAL FACULTY, KORYTKOVA 2, LJUBJANA, SL-1000, SLOVENIA","Materials Science,Mathematics,Mechanics,Imaging Science & Photographic Technology",,0.742,"PARTICLE-SIZE,DISTRIBUTION,VISION,APPROACH,CLASSIFICATION,TECHNOLOGY,BELT,COAL",IMAGE ANALYSIS & STEREOLOGY,https://www.ias-iss.org/ojs/IAS/article/download/2186/1122,
4,A SPICE Model of Phase Change Memory for Neuromorphic Circuits,8,,95278-95287,"Chen Xuhui,Hu Huifang,Huang Xiaoqing,Cai Weiran,Liu Ming,Lam Chung,Lin Xinnan,Zhang Lining,Chan Mansun","Chen XH,Hu HF,Huang XQ,Cai WR,Liu M,Lam C,Lin XN,Zhang LN,Chan MS",Lin XN,10.1109/ACCESS.2020.2995907,Peking University,"A phase change memory (PCM) model suitable for neuromorphic circuit simulations is developed. A crystallization ratio module is used to track the memory state in the SET process, and an active region radius module is developed to track the continuously varying amorphous region in the RESET process. To converge the simulations with bi-stable memory states, a predictive filament module is proposed using a previous state in iterations of nonlinear circuit matrix under a voltage-driven mode. Both DC and transient analysis are successfully converged in circuits with voltage sources. The spiking-time-dependent-plasticity (STDP) characteristics essential for synaptic PCM are successfully reproduced with SPICE simulations verifying the model & x2019;s promising applications in neuromorphic circuit designs. Further on, the developed PCM model is applied to propose a neuron circuit topology with lateral inhibitions which is more bionic and capable of distinguishing fuzzy memories. Finally, unsupervised learning of handwritten digits on neuromorphic circuits is simulated to verify the integrity of models in a large-scale-integration circuits. For the first time in literature an emerging memory model is developed and applied successfully in neuromorphic circuit designs, and the model is applicable to flexible designs of neuron circuits for further performance improvements.","Phase change materials,Integrated circuit modeling,Neuromorphics,Biological system modeling,Electrodes,Biological neural networks,Mathematical model,Neuromorphic circuits,phase change memory,SPICE model,spike-time-dependent plasticity,spiking neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MEMRISTIVE,NEURAL-NETWORKS,SYNCHRONIZATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09097232.pdf,
5,Intelligent Fusion of Deep Features for Improved Waste Classification,8,,96495-96504,"Ahmad Kashif,Khan Khalil,Al-Fuqaha Ala","Ahmad K,Khan K,Al-Fuqaha A",Ahmad K,10.1109/ACCESS.2020.2995681,Hamad Bin Khalifa University-Qatar,"In this article, we address the problem of an image-based automatic classification of waste materials. Given the large number of waste categories and the importance of proper management of waste materials, the problem is known to be critical and of a particular interest. To achieve reliable waste classification capability, we propose a novel approach, that we name double fusion, which optimally combines multiple deep learning models using feature and score-level fusion methods. The double fusion scheme ensures an optimized contribution of the deep models by, firstly, combining their capabilities in an early and late fusion scheme followed by a score-level fusion of the classification results obtained with early and late fusion methods. In total, we employ and compare six different fusion methods including two feature-level fusion schemes, namely (i) Discriminant Correlation Analysis and (ii) simple concatenation of deep features, and four late fusion methods, namely (i) Particle Swarm Optimization, (ii) Genetic modeling of deep features (iii) Induced Ordered Weighted Averaging and (iv) a baseline method where all the deep models are treated equally. Moreover, we also evaluate the performance of the individual deep models, and compare our results against state-of-the-art methods demonstrating a significant improvement of 3.58 & x0025; over state-of-the-art.","Feature extraction,Computer architecture,Analytical models,Computational modeling,Correlation,Waste management,Genetic algorithms,Waste management,waste classification,deep features,fusion,double fusion,particle swarm optimization,genetic algorithms,IOWA",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,OPTIMIZATION,IEEE ACCESS,https://doi.org/10.1109/access.2020.2995681,
6,The Monitoring of Milling Tool Tipping by Estimating Holder Exponents of Vibration,8,,96661-96668,"Zhou Chang'an,Jiang Zhenxi,Sun Chao,Zhu Zhaoju","Zhou CA,Jiang ZX,Sun C,Zhu ZJ",Zhu ZJ,10.1109/ACCESS.2020.2996607,Fuzhou University,"The gradual tool wear is unavoidable in the machining process, it directly influences the surface integrity and dimensional tolerances of the components. The tool condition monitoring (TCM) systems have the capacity to make full use of the cutting potential of the cutting tools, which is of great significance for improving production efficiency and ensuring product quality. In milling titanium alloys, tool tipping is one of the main failure modes. Therefore, this study focuses on establishing a tool tipping monitoring approach for the milling process. The singularity analysis method based on wavelet transform was employed to characterize the variation of vibration waveforms quantitatively with the Holder Exponent (HE) index. The probability density distribution and statistical analysis were adopted to extract effective HE features from the HE indexes to correlate with the different tool conditions. The mutual information method was adopted to rank the discriminability of the HE statistical parameters. Then, several machine learning (ML) models were established with the screened HE features. Finally, the results of the experiments indicate that the Support Vector Machine (SVM) model has the highest classification accuracy and can provide practical guides on the tool changes.","Tools,Vibrations,Milling,Monitoring,Wavelet analysis,Indexes,Titanium alloys,Tool tipping,titanium alloys,vibrations,Holder Exponents,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BREAKAGE,DETECTION,WEAR,SIGNALS,MACHINE,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.2996607,
7,Deep Learning Assisted Efficient AdaBoost Algorithm for Breast Cancer Detection and Early Diagnosis,8,,96946-96954,"Zheng Jing,Lin Denan,Gao Zhongjun,Wang Shuang,He Mingjie,Fan Jipeng","Zheng J,Lin DA,Gao ZJ,Wang S,He MJ,Fan JP",Lin DA,10.1109/ACCESS.2020.2993536,"Shenzhen Ctr Hlth Informat, Shenzhen 518000, Peoples R China.","Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2 & x0025;, Sensitivity 98.3 & x0025;, and Specificity 96.5 & x0025; has been compared to other existing systems.","Breast cancer,Machine learning,Feature extraction,Training,Classification algorithms,Breast cancer detection,deep learning,convolutional neural network,MRI,CT,US,long short-term memory",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MITOSIS,DETECTION,CLASSIFICATION,SEGMENTATION,NUCLEI",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09089849.pdf,
8,Optimized One vs One Approach in Multiclass Classification for Early Alzheimer's Disease and Mild Cognitive Impairment Diagnosis,8,,96981-96993,"Jimenez-Mesa Carmen,Alvarez Illan Ignacio,Martin-Martin Alberto,Castillo-Barnes Diego,Jesus Martinez-Murcia Francisco,Ramirez Javier,Gorriz Juan M.","Jimenez-Mesa C,Illan IA,Martin-Martin A,Castillo-Barnes D,Martinez-Murcia FJ,Ramirez J,Gorriz JM",Gorriz JM,10.1109/ACCESS.2020.2997736,University of Granada,"The detection of Alzheimer's Disease in its early stages is crucial for patient care and drugs development. Motivated by this fact, the neuroimaging community has extensively applied machine learning techniques to the early diagnosis problem with promising results. The organization of challenges has helped the community to address different raised problems and to standardize the approaches to the problem. In this work we use the data from international challenge for automated prediction of MCI from MRI data to address the multiclass classification problem. We propose a novel multiclass classification approach that addresses the outlier detection problem, uses pairwise t-test feature selection, project the selected features onto a Partial-Least-Squares multiclass subspace, and applies one-versus-one error correction output codes classification. The proposed method yields to an accuracy of 67% in the multiclass classification, outperforming all the proposals of the competition.","Alzheimer's disease,CAD,error correcting output codes,mild cognitive impairment,multiclass classification,one versus one,partial least squares,random forests,support vector machines",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PARTIAL,LEAST-SQUARES,FEATURE-SELECTION,MRI,MEASURES,DEMENTIA,PREDICTION,ENSEMBLE,FAILURE,IMAGES,MCI",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09099858.pdf,
9,QRS Complex Detection Using Novel Deep Learning Neural Networks,8,,97082-97089,"Cai Wenjie,Hu Danqin","Cai WJ,Hu DQ",Cai WJ,10.1109/ACCESS.2020.2997473,University of Shanghai for Science & Technology,"Objective: Accurate QRS complex detection is essential for electrocardiography (ECG) diagnosis. Many proposed algorithms don & x2019;t perform satisfactorily on noisy and arrhythmia ECGs. The purpose of this study is to develop a noise resistant and generalizable method to detect QRS complexes accurately. Methods: Two deep learning models based on multi-dilated convolutional blocks are proposed. One model (CNN) is mainly composed of convolutional blocks and Squeeze-and-Excitation networks (SENet). The other model (CRNN) contains a hybrid convolutional and recurrent neural network. With 5-fold cross-validation approach the models are trained and tested on four open-access ECG databases: the China Physiological Signal Challenge (2019) database (CPSCDB), the MIT-BIH Noise Stress Test Database (NSTDB), the MIT-BIH Arrhythmia Database (MITDB) and the QT Database (QTDB). Results: The F1 score of CNN model on CPSCDB, NSTDB, MITDB and QTDB are 0.9929, 0.9892, 0.9994 and 0.9998 respectively. The F1 score of CRNN model on these four databases are 0.9947, 0.9953, 0.9995 and 0.9998 respectively. The ensemble of both models scored the first place in the China Physiological Signal Challenge (2019). Conclusion: The proposed models achieve state-of-the-art performance in QRS complex detection and show good generalization on different databases. This work might help make better ECG diagnosis.","Convolutional neural network,deep learning,electrocardiography,QRS complex,recurrent neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,IMPACT,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09099511.pdf,
10,,"27,  ","3,  ","e5424,  ",,,,"10.1590/0104-530x5424-20,  ",,"Abstract: Proximity movements between vehicles transporting materials in manufacturing plants, or “interfaces”, result in occupational injuries and fatalities. Risk assessment for interfaces is currently limited to techniques such as safety audits, originally designed for static environments. A data-driven alternative for dynamic environments is desirable to quantify interface risks and to enable the development of effective countermeasures. We present a method to estimate the Risk Prioritization Number (RPN) for mobile vehicle interfaces in manufacturing environments, based on the Probability-Severity-Detectability (PSD) formulation. The highlight of the method is the estimation of the probability of occurrence (P) of vehicle interfaces using machine learning and computer vision techniques. A PCA-based sparse feature vector for machine learning characterizes vehicle geometry from a top-down perspective. Supervised classification on sparse feature vectors using Support Vector Machines (SVMs) is employed to detect vehicles. Computer vision techniques are used for position tracking to identify interfaces and to calculate their probability of occurrence (P). This leads to an automated calculation of RPN based on the PSD formulation. Experimental data is collected in the laboratory using a sample work area layout and scale versions of vehicles. Vehicle interfaces and movements were physically simulated to train and test the machine learning model. The performance of the automated system is compared with human annotation to validate the approach."," Risk assessment; FMEA; ,Machine learning,; Work safety ", research-article ,,,,,,,http://www.scielo.br/pdf/gp/v27n3/0104-530X-gp-27-3-e5424.pdf,
11,A 12-Lead ECG-Based System With Physiological Parameters and Machine Learning to Identify Right Ventricular Hypertrophy in Young Adults,8,,,"Lin Gen-Min,Lu Henry Horng-Shing","Lin GM,Lu HHS",Lin GM,10.1109/JTEHM.2020.2996370,Northwestern University,"Objective: The presence of right ventricular hypertrophy (RVH) accounts for approximately 5-10% in young adults. The sensitivity estimated by commonly used 12-lead electrocardiographic (ECG) criteria for identifying the presence of RVH is under 20% in the general population. The aim of this study is to develop a 12-lead ECG system with the related information of age, body height and body weight via machine learning to increase the sensitivity and the precision for detecting RVH. Method: In a sample of 1,701 males, aged 17-45 years, support vector machine is used for the training of 31 parameters including age, body height and body weight in addition to 28 ECG data such as axes, intervals and wave voltages as the inputs to link the output RVH. The RVH is defined on the echocardiographic finding for young males as right ventricular anterior wall thickness > 5.5 mm. Results: On the system goal for increasing sensitivity, the specificity is controlled around 70-75% and all data tested in the proposed method show competent sensitivity up to 70.3%. The values of area under curve of receiver operating characteristic curve and precision-recall curve using the proposed method are 0.780 and 0.285, respectively, which are better than 0.518 and 0.112 using the Sokolow-Lyon voltage criterion, respectively, for detecting unspecific RVH. Conclusion: We present a method using simple physiological parameters with ECG data to effectively identify more than 70% of the RVH among young adults. Clinical Impact: This system provides a fast, precise and feasible diagnosis tool to screen RVH.","Electrocardiography,Machine learning,Training,Support vector machines,Physiology,Sensitivity,Hospitals,Electrocardiographic system,right ventricular hypertrophy,support vector machine,physiological parameters,young adults",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,,"CARDIORESPIRATORY,FITNESS,HOSPITALIZATION,EVENTS,PHYSICAL-FITNESS,RIGHT,HEART,CARDIOMYOPATHY,HYPERTENSION,ASSOCIATION,CRITERIA,TAIWAN,IMPACT",IEEE JOURNAL OF TRANSLATIONAL ENGINEERING IN HEALTH AND MEDICINE,https://europepmc.org/articles/pmc7269457?pdf=render,
12,Determination of Clinical Parameters Sensitive to Functional Voice Disorders Applying Boosted Decision Stumps,8,,,"Schlegel Patrick,Kist Andreas M.,Semmler Marion,Doellinger Michael,Kunduk Melda,Duerr Stephan,Schuetzenberger Anne","Schlegel P,Kist AM,Semmler M,Dollinger M,Kunduk M,Durr S,Schutzenberger A",Schlegel P,10.1109/JTEHM.2020.2985026,University of Erlangen Nuremberg,"Background: Various voice assessment tools, such as questionnaires and aerodynamic voice characteristics, can be used to assess vocal function of individuals. However, not much is known about the best combinations of these parameters in identification of functional dysphonia in clinical settings. Methods: This study investigated six scores from clinically commonly used questionnaires and seven acoustic parameters. 514 females and 277 males were analyzed. The subjects were divided into three groups: one healthy group (N-01) (49 females, 50 males) and two disordered groups with perceptually hoarse (FD23) (220 females, 96 males) and perceptually not hoarse (FD01) (245 females, 131 males) sounding voices. A tree stumps Adaboost approach was applied to find the subset of parameters that best separates the groups. Subsequently, it was determined if this parameter subset reflects treatment outcome for 120 female and 51 male patients by pairwise pre- and post-treatment comparisons of parameters. Results: The questionnaire ""Voice-related-quality-of-Life"" and three objective parameters (""maximum fundamental frequency"", ""maximum Intensity"" and ""Jitter Percent"") were sufficient to separate the groups (accuracy ranging from 0.690 (FD01 vs. FD23, females) to 0.961 (N-01 vs. FD23, females)). Our study suggests that a reduced parameter subset (4 out of 13) is sufficient to separate these three groups. All parameters reflected treatment outcome for patients with hoarse voices, Voice-related-quality-of-Life showed improvement for the not hoarse group (FD01). Conclusion: Results show that single parameters are insufficient to separate voice disorders but a set of several well-chosen parameters is. These findings will help to optimize and reduce clinical assessment time.","Oscillators,Frequency measurement,Tools,Acoustics,Hospitals,Licenses,Acoustic measurements,Parameters,boosted decision Stumps,classification,functional dysphonia",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.192,"VOCAL,FOLD,VIBRATIONS,QUALITY-OF-LIFE,FUNDAMENTAL-FREQUENCY,DYSPHONIC,PATIENTS,HEALTHY,VALIDATION,INSTRUMENT,WORKLOAD,DYNAMICS,SAMPLE",IEEE JOURNAL OF TRANSLATIONAL ENGINEERING IN HEALTH AND MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7274815,
13,"Custom Domain Adaptation: A New Method for Cross-Subject, EEG-Based Cognitive Load Recognition",27,,750-754,"Jimenez-Guarneros Magdiel,Gomez-Gil Pilar","Jimenez-Guarneros M,Gomez-Gil P",Jimenez-Guarneros M,10.1109/LSP.2020.2989663,"Instituto Nacional de Astrofisica, Optica y Electronica","Electroencephalograms (EEG) have shown to be a useful approach to measure the cognitive load in tasks where mental effort is involved. However, EEG signals present a high variability among subjects as well as a non-stationary behavior, so that distributions among samples of different subjects are mismatched. Methods based on Unsupervised Domain Adaptation (UDA) have been used as an effective solution to reduce such discrepancy, while the ones leveraged by deep learning (D-UDA) have improved the classification results over shallow approaches. However, most D-UDA methods assume that even though there are differences in marginal distributions between source and target domains, their conditional distributions remain fixed, which does not hold in many EEG databases. To address this problem, we propose a new D-UDA method, named Custom Domain Adaptation (CDA), which integrates Adaptive Batch Normalization (AdaBN) and Maximum Mean Discrepancy (MMD) into two independent deep neural networks in order to reduce the marginal and conditional distribution differences. CDA was compared with six popular D-UDA methods using a free-available dataset of cognitive loads and obtained an accuracy of , which outperformed these state-of-the-art methods.","Unsupervised domain adaptation,EEG-based classification,cognitive load,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,"NEURAL-NETWORKS,INTELLIGENCE,TESTS",IEEE SIGNAL PROCESSING LETTERS,,
14,A graph TV minimization framework for cardiac motion analysis,11431,,,"Sun Ru,Liu Huafeng","Sun R,Liu HF",Liu HF,10.1117/12.2539453,Zhejiang University,"Myocardial ischemia or coronary artery disease can be identified and located by analyzing the movement and deformation of the heart. Therefore, to accurately and non-invasively diagnose the location and extent of ischemic or infarcted myocardium, it is of great practical significance to quantitatively determine the motion/deformation parameters of myocardial tissue. In this paper, the myocardial material parameters are used as a priori information and combined with a continuum mechanics model to restore the cardiac cycle motion under the spatial constraints of the graph total variation (GTV). In the motion reconstruction, the biomechanical model establishes the relationship between stress and deformation through system dynamics The total variation of the graph proposed in this paper ignores the spatial distance, establishes the connection between similar regions in the image, overcomes the limitation of considering only the similarity with adjacent regions, and preserves the texture details and fine structure. Because GTV uses the K-nearest neighbor algorithm (KNN) to classify regional similarity, the connection between similar regions is stronger, therein achieving computational scalability and lower computational complexity. The accuracy of the strategy with and promising application results from synthetic data, magnetic resonance (MR) phase contrast, and gradient echo cine MR image sequence are demonstrated.","Graph total variation,continuous medium mechanics,k-nearest neighbour algorithm",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
15,A novel exponential loss function for pathological lymph node image classification,11431,,,"Xu Guoping,Cao Hanqiang,Udupa Jayaram K.,Yue Chunyi,Dong Youli,Li Cao,Torigian Drew A.","Xu GP,Cao HQ,Udupa JK,Yue CY,Dong YL,Li C,Torigian DA",Cao HQ,10.1117/12.2537004,Huazhong University of Science & Technology,"Recent progress in deep learning, especially deep convolutional neural networks (DCNNs), has led to significant improvement in natural image classification. However, research is still ongoing in the domain of medical image analysis in part due to the shortage of annotated data sets for training DCNNs, the imbalanced number of positive and negative samples, and the difference between medical images and natural images. In this paper, two strategies are proposed to train a DCNN for pathological lymph node image classification. Firstly, the transfer learning strategy is used to deal with the shortage of training samples. Second, a novel exponential loss function is presented for the imbalance in training samples. Four state-of-the-art DCNNs (GoogleNet, ResNet101, Xception, and MobileNetv2) are tested. The experiments demonstrate that the two strategies are effective to improve the performance of pathological lymph node image classification in terms of accuracy and sensitivity with a mean of 0.13% and 1.50%, respectively, for the four DCNNs. In particular, the proposed exponential loss function improved the sensitivity by 3.9% and 4.0% for Xception and ResNet101, respectively.","lymphadenopathy,pathological lymph nodes,image classification,PET/CT,loss function",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,SEGMENTATION,,,
16,Application of machine learning approach in disordered materials,50,6,,"Wu Jiaqi,Sun Yitao,Wang WeiHua,Li MaoZhi","Wu JQ,Sun YT,Wang WH,Li MZ",Li MZ,10.1360/SSPMA-2019-0345,Renmin University of China,"As a new amorphous material, metallic glass has been widely studied because of its excellent mechanical, physical and chemical properties. Glass-forming ability has always been an important problem restricting the development of amorphous materials. In order to design amorphous materials with good glass-forming ability, a lot of research has been done on the glass-forming ability of amorphous materials. It has been shown that a single factor cannot describe glassforming ability of amorphous materials. Because of the complex and disordered structure of amorphous materials, it is difficult to understand the structure and nature of amorphous materials comprehensively and clearly by traditional methods. Machine learning method, as a new research paradigm, provides new opportunities for exploring these bottleneck scientific issues in disordered materials. In this paper, some machine learning algorithms, such as support vector machine, artificial neural network and K-means clustering, are briefly introduced. Moreover, we briefly review the application of machine learning approach in amorphous materials, including the classification of amorphous structure, the correlation between amorphous structure and properties, and the prediction of macroscopic properties of amorphous materials. We also discuss the future application of machine learning approach to disordered materials, including the development of comprehensive database, high throughput calculation method and the development of machine learning potential function.","machine learning,disordered materials,glass-forming ability,structure-property relationships",Review,"SCIENCE PRESS, 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA","Astronomy & Astrophysics,Physics",,,"POTENTIAL-ENERGY,SURFACES,NEURAL-NETWORKS,DISCOVERY,MODEL",SCIENTIA SINICA-PHYSICA MECHANICA & ASTRONOMICA,https://engine.scichina.com/doi/pdf/F0E060D321854A5EB8D26631678A1634,
17,Radiomics-Based Differentiation of Pleomorphic Adenomas and Warthin Tumors of Salivary Glands,11330,,,"Areiza-Laverde Henry J.,Malpica-Gonzalez Norberto,Brea Beatriz,Castro-Ospina Andres E.,Diaz Gloria M.","Areiza-Laverde HJ,Malpica-Gonzalez N,Brea B,Castro-Ospina AE,Diaz GM",Diaz GM,10.1117/12.2549367,"Inst Tecnol Metropolitano, Grp Invest Maquinas Inteligentes & Reconocimiento, Medellin, Colombia.","Pleomorphic adenomas (PA) and Warthin tumors (WT) are the most common salivary gland tumors. It exhibits very similar characteristics, which make very difficult to distinguish them. To differentiate these it is necessary due that it strongly influences the surgical procedure and treatment. In this paper, we propose the use of radiomic analysis for discriminating PA and WT based on T1 and T2 Magnetic Resonance Images. The proposed approach starts with the extraction of a large number of quantitative features of delineated tumors from both T1 and T2 sequences, then a feature selector is used for selecting the most discriminative, which are used for training an SVM classification model, whose parameters are optimally selected using the Particle Swarm Optimization algorithm. The proposed approach is able to discriminate between PA and WT tumors with a sensitivity of 91.57 +/- 11.07 and specificity of 89.50 +/- 11.07, making this a promising method to characterizing and classifying parotid gland tumors.","Warthin tumor,Pleomorphic adenoma,Automatic classification,Magnetic Resonance Imaging,Radiomics,Machine Learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
18,Automatic Polyp Localization by Low Level Superpixel Features,11330,,,"Bravo Diego,Ruano Josue,Gomez Martin,Romero Eduardo","Bravo D,Ruano J,Gomez M,Romero E",Romero E,10.1117/12.2542583,Universidad Nacional de Colombia,"Colorectal cancer (CRC) is a major public health issue by its high incidence and mortality rate. CRC appears as premalignant lesions growing in the endoluminal wall, called polyps. Currently, a regular screening of CRC during a colonoscopy is the standard procedure to localize and treat polyps. However, evidence suggests 20% - 24% of adenomatous polyps may be missed during a routine colonoscopy. A limited adenoma detection (ADRs) is obtained because colon exploration is a very challenging task: it is highly dependent on the expert training and colon preparation. Hence, a second reader is required to support CRC screening. This paper presents a novel automatic computer-aided method to localize polyps in colonoscopy images. The method starts by segmenting an input frame into a set of superpixels, each of them characterized by concatenating color, texture, and shape features computed either locally, i.e., basic local statistics, or regionally, i.e., any measure is modulated by information in neighboring superpixels. Afterward, this representation feeds a classifier which sets a probability and a polyp is a group of superpixels with high assigned probability. Finally, the resultant groups were enclosed by a bounding box which corresponds to the colorectal polyp localization. The proposed approach was trained with 200 polyps (350 images) and tested with 86 polyps (236 images) of different size. Performance of our method was compared with a baseline based on deep CNN obtaining an average of Annotated Area Covered of 0.90 vs 0:89 and a precision of 0.96 vs 0:95 respectively.","Colorectal Cancer,Polyp Localization,Machine Learning,Curvelet analysis",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,DIAGNOSIS,,,
19,An exploratory study of one-shot learning using siamese convolutional neural network for histopathology image classification in breast cancer from few data examples,11330,,,"Cano Fabian,Cruz-Roa Angel","Cano F,Cruz-Roa A",Cruz-Roa A,10.1117/12.2546488,"Univ Los Llanos, Automat Data Driven Analyt Lab AdaLab, GITECX Res Grp, Villavicencio, Meta, Colombia.","Convolutional Neural Networks have been successfully used in several tasks in the last decade, but this kind of supervised method requires a large number of annotated examples to obtain good results. However, in biomedical domains, such as digital pathology, the amount of annotated samples is very reduced and imbalanced. On the other hand, models trained using supervised methods need to be retrained when a new class (with its samples) is introduced. This process is computationally expensive and can be difficult when you don't have a lot of examples for the same class. In order to address these issues, there are novel approaches that use a few number of annotated examples to achieve an acceptable or good generalization capability of the model. One of these methods is One-shot Learning, which is intended to classify a set of data from different classes from one or a few number of annotated examples, and which allows to incorporate new data from new classes without re-training the model. This work explores a method to classify samples of tissues in breast cancer histopathology images by means of similarity between pairs of image samples using a Siamese Convolutional Neural Networks, which achieved a 90.83% of accuracy test.","Siamese Convolutional Neural Networks,One-shot Learning,Digital Pathology,Breast Cancer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
20,Morphometric Gaussian Process for Landmarking on Grey Matter Tetrahedral Models,11330,,,"Fan Yonghui,Lepore Natasha,Wang Yalin","Fan YH,Lepore N,Wang YL",Fan YH,10.1117/12.2542492,Arizona State University,"High-dimensional manifold modeling increases the precision and performance of cortical morphometry analysis by densely sampling on the grey matters. But this also brings redundant information and increased computational burden. Gaussian process regression has been used to tackle this problem by learning a mapping to a low-dimensional subspace. However, current methods may not take relevant morphometric properties, usually measured by geometric features, into account, and as a result, may generate morphometrically insignificant selections. In this paper, we propose a morphometric Gaussian process (M-GP) as a novel Bayesian model on the gray matter tetrahedral meshes. We also implement an M-GP regression landmarking algorithm as a manifold learning method for non-linear dimensionality reduction. The definition of M-GP involves a scale-invariant wave kernel signature distance map measuring the local similarities of geometric features, and a heat flow entropy which implicitly embeds the global curvature flow. With such a design, the prior knowledge fully encodes the geometric information so that a posterior predictive inference is morphometrically significant. In experiments, we use 518 grey matter tetrahedral meshes generated from structural magnetic resonance images of a publicly available Alzheimer's disease imaging cohort to empirically and numerically evaluate our method. The results verify that our method is theoretically and experimentally valid in selecting a representative subset from the original massive data. Our work may benefit any studies involving large-scale or iterative computations on extensive manifold-valued data, including morphometry analyses and general medical data processing.","Gaussian process on manifolds,Cortical morphometry analysis,Alzheimer's disease,Grey matter tetrahedral mesh",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8112202,
21,An inception deep architecture to differentiate close-related Gleason prostate cancer scores,11330,,,"Leon Fabian,Plazas Miguel,Martinez Fabio","Leon F,Plazas M,Martinez F",Leon F,10.1117/12.2547113,Universidad Industrial de Santander,"Histopathological tissue analysis is the most effective and definitive method to prognosis cancer and stratify the aggressiveness of the disease. The Gleason Score (GS) is the most powerful grading system based on architectural tumor pattern quantification. This score characterizes cancer tumor tissue, such as the level of cell differentiation on histopathological images. The reported GS is described as the sum of two principal grades present in a particular image, and ranged from 6 (cancer grow slowly) to 10 (cancer cells spread more rapidly). A main drawback of GS is the pathological dependency on histopathological region stratification, which strongly impacts the clinical procedure to treat the disease. The agreement among experts has been quantified with a kappa index of: similar to 0.71. Even worse, a higher uncertainty is reported for intermediate grade stratification. This work presents a like-inception deep architecture that is able to differentiate between intermediate and close GS grades. Each image herein evaluated was split-up into regional patches that correspond to a single GS grade. A set of training patches were augmented according to appearance image variations of each grade. Then, a transfer learning scheme was implemented to adapt a bi-Gleason tumor patterns prediction among close levels. The proposed approach was evaluated on public set of 886 tissue H&E stained images with different GS grades, achieving an average accuracy of 0.73% between grades three and four.*","prostate cancer,Gleason scores,inception,histopathology",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"INTEROBSERVER,REPRODUCIBILITY",,,
22,Hidden Markov Model-based Heartbeat Detector Using Different Transformations of ECG and ABP Signals,11330,,,"Monroy Nelson F.,Altuve Miguel","Monroy NF,Altuve M",Altuve M,10.1117/12.2546602,Universidad Pontificia Bolivariana,"The detection of the heartbeat from electrocardiographic (ECG) and arterial blood pressure (ABP) signals, either exploited individually or jointly, has been carried out successfully using different approaches that range from the use of simple digital signal processing techniques until the use of more advanced techniques based on machine learning. In this paper, we employed a heartbeat detector that uses two hidden Markov models (HMM) to characterize the dynamics of the presence and the absence of heartbeats in ECG and ABP signals. The HMM-based detector can exploit univariate observations (ECG or ABP signals) or bivariate observations (ECG an ABP signals jointly, in a centralized manner). Two transformations of the signals were applied as a preprocessing step. absolute value and squared functions. In this sense, six detectors based on univariate observations and nine detectors based on bivariate observations were conceived and validated in ten records of the MGH/MF Waveform Database. The detection performance when the absolute value of ECG and the absolute value of ABP are jointly exploited by the HMM produced TP = 58736, FN = 631, FP = 788, sensitivity = 98.73%, positive predictivity = 98.22%).","Heartbeat Detector,Electrocardiography,Arterial Blood Pressure,Time Series Transformation,Hidden Markov Model",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"BEAT,DETECTION,TIME-SERIES,SENSORS,SYSTEM",,,
23,A Lightweight Deep Learning Model for Mobile Eye Fundus Image Quality Assessment,11330,,,"Perez Andres D.,Perdomo Oscar,Gonzalez Fabio A.","Perez AD,Perdomo O,Gonzalez FA",Perez AD,10.1117/12.2547126,Universidad Nacional de Colombia,"Image acquisition and automatic quality analysis are fundamental stages and tasks to support an accurate ocular diagnosis. In particular, when eye fundus image quality is not appropriate, it can hinder the diagnosis task performed by experts. Portable, smart-phone-based eye fundus image acquisition devices have the advantage of their low cost and easy deployment, however, their main disadvantage is the sacrifice of image quality. This paper presents a deep-learning-based model to assess the eye fundus image quality which is small enough to be deployed in a smart phone. The model was evaluated in a public eye fundus dataset with two sets of annotations. The proposed method obtained an accuracy of 0.911 and 0.856, in the binary classification task and the three-classes classification task respectively. Besides, the presented method has a small number of parameters compared to other state-of-the-art models, being an alternative for a mobile-based eye fundus quality classification system.","Deep Learning,Classification,Quality Assessment,Eye fundus,Non-reference Image Quality,Mobile AI",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
24,Supervised Learning for Semantic Segmentation of Human Spermatozoa,11330,,,"Revollo Natalia V.,Thomsen Felix S. L.,Delrieux Claudio A.,Gonzalez-Jose Rolando","Revollo NV,Thomsen FSL,Delrieux CA,Gonzalez-Jose R",Revollo NV,10.1117/12.2542464,Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET),"Image-based diagnosis is able to spot several diseases and clinical conditions faster and more accurately than traditional manual ones, becoming also an alternative in monitoring and predicting patients responses to specific health treatments. In this work, we present a supervised learning approach to segment pixel-wise parts of spermatozoa using a random forest (RF) classifier. The framework created a multi-channel image combining intensity RGB bands with three neighborhood based bands. The last neighborhood based bands were Sobel's magnitude and orientation and Shannon's entropy. A RF was trained using labeled pixels provided by expert andrologists, biochemists and specialists in reproductive health. We compared results with a simple model on the RGB only. The whole automatic process (segmentation and classification) achieved an average precision of 98%, recall of 98% and F-Score of 98%. Highest improvement in comparison to the RGB model was shown on the segmentation of the tail. We provided a fully automatic spermatozoa semantic segmentation based on local and non-local information. The results are aimed to develop a CASA (Computer Assisted Sperm Analysis) system that can provide results over the Internet. The experiment was conducted on normalized images of a specific microscope. We are planning to extend the experiment in future work to more realistic conditions including different stainings, microscopes and resolutions.","Spermatozoa Segmentation,andrological analysis,sperm,image processing",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"SPERM,HEAD,MORPHOMETRY,CLASSIFICATION,SUBPOPULATIONS,RECOGNITION,MORPHOLOGY,FORESTS",,,
25,An Empirical Study on Global Bone Age Assessment,11330,,,"Torres Felipe,Gonzalez Cristina,Camila Escobar Maria,Daza Laura,Triana Gustavo,Arbelaez Pablo","Torres F,Gonzalez C,Escobar MC,Daza L,Triana G,Arbelaez P",Torres F,10.1117/12.2542431,University of the Andes Colombia,"Bone Age Assessment (BAA) is a task performed by physicians to estimate the skeletal development of a pediatric patient. Tipically physicians perform this exam by doing a manual analysis of the X-ray image of the non-dominant hand of a child, either by taking the image as a whole or paying attention to certain anatomical Regions Of Interest (ROIs). Over the years, several datasets have been proposed in order to generate automated methods to perform this task. Most notably, in 2017 the Radiological Society of North America (RSNA)(1) created the Pediatric Bone Age Challenge, which encouraged the development of machine learning approaches for this task. In this paper, we present GPNet a convolutional neural network capable of performing BAA precisely and effectively by analyzing the whole hand in a single forward pass. We train GPNet using the training data available from the dataset created in the RSNA challenge and evaluate our method using the validation set. We use the testing set to compare our performance with the current state-of-the-art and find that GPNet significantly outperforms previous methods. During our architecture search we perform several experiments to demonstrate the effect of different layers, proving that some blocks do not contribute to the performance of the network, but instead they affect it. As a result, we are able to develop a method that reduces the number of trainable parameters by nearly 82.15 M in comparison to the state-of-the-art, while improving the performance.","Bone Age Assessment,Computer Aided Diagnosis,Convolutional Neural Networks,Machine Learning,Pediatrics",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
26,Analysis and Classification of Lung Tissue in Ultrasound Images for Pneumonia Detection,11330,,,"Valdes-Burgos L.,Contreras-Ojeda S. L.,Dominguez-Jimenez J. A.,Lopez-Bueno J.,Contreras-Ortiz S. H.","Valdes-Burgos L,Contreras-Ojeda SL,Dominguez-Jimenez JA,Lopez-Bueno J,Contreras-Ortiz SH",Contreras-Ortiz SH,10.1117/12.2542615,Universidad Tecnologica de Bolivar,"Pneumonia is an infection of the lungs caused by virus, bacteria or fungi. It affects mainly children under five and can be life-threatening. Diagnosis of pneumonia is usually performed using imaging techniques such as chest radiography, ultrasound, and CT. Several studies have shown that ultrasound is an effective, safe and cost-efficient technique for pneumonia detection. However, due to the low signal-to-noise ratio of the images, this technique is highly dependant on the experience of the practitioner. This paper proposes an approach for pneumonia detection from image texture features. We used empirical mode decomposition for feature extraction, principal component analysis for dimensionality reduction and supervised learning methods for classification. Results show that features of the first mode present large differences between healthy and pneumonia patients according to the Cohen's d index. Pneumonia detection was possible with a rotation forest model with a mean accuracy of 83.33%.","Pneumonia detection,Texture analysis,Empirical mode decomposition,Lung tissue classification,Supervised learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"COMMUNITY-ACQUIRED,PNEUMONIA,DIAGNOSIS",,,
27,Using machine learning and a data-driven approach to identify the small fatigue crack driving force in polycrystalline materials,4,1,7-16,",,,","Rovinelli Andrea,Sangid Michael D,Proudhon Henry,Ludwig Wolfgang",,,Rovinelli Andrea,"The propagation of small cracks contributes to the majority of the fatigue lifetime for structural components. Despite significant interest, criteria for the growth of small cracks, in terms of the direction and speed of crack advancement, have not yet been determined. In this work, a new approach to identify the microstructurally small fatigue crack driving force is presented. Bayesian network and machine learning techniques are utilized to identify relevant micromechanical and microstructural variables that influence the direction and rate of the fatigue crack propagation. A multimodal dataset, combining results from a high-resolution 4D experiment of a small crack propagating in situ within a polycrystalline aggregate and crystal plasticity simulations, is used to provide training data. The relevant variables form the basis for analytical expressions thus representing the small crack driving force in terms of a direction and a rate equation. The ability of the proposed expressions to capture the observed experimental behavior is quantified and compared to the results directly from the Bayesian network and from fatigue metrics that are common in the literature. Results indicate that the direction of small crack propagation can be reliably predicted using the proposed analytical model and compares more favorably than other fatigue metrics.",,Article,,,,,,,,
28,A high-throughput data analysis and materials discovery tool for strongly correlated materials,4,2,75-84,",,,,,,,,,","Hafiz Hasnain,Khair Adnan Ibne,Choi Hongchul,Mueen Abdullah,Bansil Arun,Eidenbenz Stephan,Wills John,Zhu Jianxin,Balatsky Alexander V,Ahmed Towfiq",,,Hafiz Hasnain,"Modeling of f-electron systems is challenging due to the complex interplay of the effects of spin-orbit coupling, electron-electron interactions, and the hybridization of the localized f-electrons with itinerant conduction electrons. This complexity drives not only the richness of electronic properties but also makes these materials suitable for diverse technological applications. In this context, we propose and implement a data-driven approach to aid the materials discovery process. By deploying state-of-the-art algorithms and query tools, we train our learning models using a large, simulated dataset based on existing actinide and lanthanide compounds. The machine-learned models so obtained can then be used to search for new classes of stable materials with desired electronic and physical properties. We discuss the basic structure of our f-electron database, and our approach towards cleaning and correcting the structure data files. Illustrative examples of the applications of our database include successful prediction of stable superstructures of double perovskites and identification of a number of physically-relevant trends in strongly correlated features of f-electron based materials.",,Article,,,,,,,,
29,A machine learning approach to model solute grain boundary segregation,4,2,85-92,",,,","Huber Liam,Hadian Raheleh,Grabowski Blazej,Neugebauer Jorg",,,Huber Liam,"Even minute amounts of one solute atom per one million bulk atoms may give rise to qualitative changes in the mechanical response and fracture resistance of modern structural materials. These changes are commonly related to enrichment by several orders of magnitude of the solutes at structural defects in the host lattice. The underlying concept-segregation-is thus fundamental in materials science. To include it in modern strategies of materials design, accurate and realistic computational modelling tools are necessary. However, the enormous number of defect configurations as well as sites solutes can occupy requires models which rely on severe approximations. In the present study we combine a high-throughput study containing more than 1 million data points with machine learning to derive a computationally highly efficient framework which opens the opportunity to model this important mechanism on a routine basis.",,Article,,,,,,,,
30,Deep-learning-based inverse design model for intelligent discovery of organic molecules,4,2,103-110,,,,,Kim Kyungdoc,"The discovery of high-performance functional materials is crucial for overcoming technical issues in modern industries. Extensive efforts have been devoted toward accelerating and facilitating this process, not only experimentally but also from the viewpoint of materials design. Recently, machine learning has attracted considerable attention, as it can provide rational guidelines for efficient material exploration without time-consuming iterations or prior human knowledge. In this regard, here we develop an inverse design model based on a deep encoder-decoder architecture for targeted molecular design. Inspired by neural machine language translation, the deep neural network encoder extracts hidden features between molecular structures and their material properties,while the recurrent neural network decoder reconstructs the extracted features into new molecular structures having the target properties. In material design tasks, the proposed fully data-driven methodology successfully learned design rules from the given databases and generated promising light-absorbing molecules and host materials for a phosphorescent organic light-emitting diode by creating new ligands and combinatorial rules.",,Article,,,,,,,,
31,Empirical modeling of dopability in diamond-like semiconductors,4,2,123-130,",,,,,","Miller Samuel A,Dylla Maxwell,Anand Shashwat,Gordiz Kiarash,Jeffrey Snyder G,Toberer Eric S",,,Miller Samuel A,"Carrier concentration optimization has been an enduring challenge when developing newly discovered semiconductors for applications (e.g., thermoelectrics, transparent conductors, photovoltaics). This barrier has been particularly pernicious in the realm of high-throughput property prediction, where the carrier concentration is often assumed to be a free parameter and the limits are not predicted due to the high computational cost. In this work, we explore the application of machine learning for high-throughput carrier concentration range prediction. Bounding the model within diamond-like semiconductors, the learning set was developed from experimental carrier concentration data on 127 compounds ranging from unary to quaternary. The data were analyzed using various statistical and machine learning methods. Accurate predictions of carrier concentration ranges in diamond-like semiconductors are made within approximately one order of magnitude on average across both p-and n-type dopability. The model fit to empirical data is analyzed to understand what drives trends in carrier concentration and compared with previous computational efforts. Finally, dopability predictions from this model are combined with high-throughput quality factor predictions to identify promising thermoelectric materials.",,Article,,,,,,,,
32,Efficient search of compositional space for hybrid organic-inorganic perovskites via Bayesian optimization,4,1,141-148,",,,,","Herbol Henry C,Hu Weici,Frazier Peter,Clancy Paulette,Poloczek Matthias",,,Herbol Henry C,"Accelerated searches, made possible by machine learning techniques, are of growing interest in materials discovery. A suitable case involves the solution processing of components that ultimately form thin films of solar cell materials known as hybrid organic-inorganic perovskites (HOIPs). The number of molecular species that combine in solution to form these films constitutes an overwhelmingly large compositional space (at times, exceeding 500,000 possible combinations). Selecting a HOIP with desirable characteristics involves choosing different cations, halides, and solvent blends from a diverse palette of options. An unguided search by experimental investigations or molecular simulations is prohibitively expensive. In this work, we propose a Bayesian optimization method that uses an application-specific kernel to overcome challenges where data is scarce, and in which the search space is given by binary variables indicating whether a constituent is present or not. We demonstrate that the proposed approach identifies HOIPs with the targeted maximum intermolecular binding energy between HOIP salt and solvent at considerably lower cost than previous state-of-the-art Bayesian optimization methodology and at a fraction of the time (less than 10%) needed to complete an exhaustive search. We find an optimal composition within 15  10 iterations in a HOIP compositional space containing 72 combinations, and within 31  9 iterations when considering mixed halides (240 combinations). Exhaustive quantum mechanical simulations of all possible combinations were used to validate the optimal prediction from a Bayesian optimization approach. This paper demonstrates the potential of the Bayesian optimization methodology reported here for new materials discovery.",,Article,,,,,,,,
33,Active learning for accelerated design of layered materials,4,2,145-154,,,,,Bassman Lindsay,"Hetero-structures made from vertically stacked monolayers of transition metal dichalcogenides hold great potential for optoelectronic and thermoelectric devices. Discovery of the optimal layered material for specific applications necessitates the estimation of key material properties, such as electronic band structure and thermal transport coefficients. However, screening of material properties via brute force ab initio calculations of the entire material structure space exceeds the limits of current computing resources. Moreover, the functional dependence of material properties on the structures is often complicated, making simplistic statistical procedures for prediction difficult to employ without large amounts of data collection. Here, we present a Gaussian process regression model, which predicts material properties of an input hetero-structure, as well as an active learning model based on Bayesian optimization, which can efficiently discover the optimal hetero-structure using a minimal number of ab initio calculations. The electronic band gap, conduction/valence band dispersions, and thermoelectric performance are used as representative material properties for prediction and optimization. The Materials Project platform is used for electronic structure computation, while the BoltzTraP code is used to compute thermoelectric properties. Bayesian optimization is shown to significantly reduce the computational cost of discovering the optimal structure when compared with finding an optimal structure by building a regression model to predict material properties. The models can be used for predictions with respect to any material property and our software, including data preparation code based on the Python Materials Genomics (PyMatGen) library as well as python-based machine learning code, is available open source.",,Article,,,,,,,,
34,Gap-Filling Method for Suppressing Grating Lobes in Ultrasound Imaging: Experimental Study With Deep-Learning Approach,8,,76276-76286,"Kumar Viksit,Lee Po-Yang,Kim Bae-Hyung,Fatemi Mostafa,Alizad Azra","Kumar V,Lee PY,Kim BH,Fatemi M,Alizad A",Alizad A,10.1109/ACCESS.2020.2989337,Mayo Clinic,"Sparse arrays reduce the number of active channels that effectively increases the inter-element spacing. Large inter-element spacing results in grating lobe artifacts degrading the ultrasound image quality and reducing the contrast-to-noise ratio. A deep learning-based custom algorithm is proposed to estimate inactive channel data in periodic sparse arrays. The algorithm uses data from multiple active channels to estimate inactive channels. The estimated inactive channel data effectively reduces the inter-element spacing for beamforming, thus suppressing the grating lobes. Estimated inactive element channel data was combined with active element channel data resulting in a pseudo fully sampled array. The channel data was beamformed using a simple delay-and-sum method and compared with the sparse array and fully sampled array. The performance of the algorithm was validated using a wire target in a water tank, multi-purpose tissue-mimicking phantom, and n-vivo carotid data. Grating lobes suppression up to 15.25 dB was observed with an increase in contrast-to-noise (CNR) for the pseudo fully sampled array. Hypoechoic regions showed more improvement in CNR than hyperechoic regions. Root-mean-square error for unwrapped phase between fully sampled array and the pseudo fully sampled array was low, making the estimated data suitable for Doppler and elastography applications. Speckle pattern was also preserved; thus, the estimated data can also be used for quantitative ultrasound applications. The algorithm can improve the quality of sparse array images and has applications in small scale ultrasound devices and 2D arrays.","Arrays,Phantoms,Gratings,Channel estimation,Ultrasonic imaging,Training,Transducers,Convolutional neural networks,deep learning,gap-filling,sparse array,ultrasound imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ARRAYS,ATTENUATION",IEEE ACCESS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7328874,
35,Deep Learning Assisted Predict of Lung Cancer on Computed Tomography Images Using the Adaptive Hierarchical Heuristic Mathematical Model,8,,86400-86410,"Yu Heng,Zhou Zhiqing,Wang Qiming","Yu H,Zhou ZQ,Wang QM",Zhou ZQ,10.1109/ACCESS.2020.2992645,"Pingdingshan Univ, Sch Informat Engn, Pingdingshan 467000, Peoples R China.","Lung cancer is known to be one of the most dangerous diseases which are the main reason for disease and death when diagnosed in primitive stages. Since lung cancer can only be detected more broadly after it spread to lung parts and the occurrence of lung cancer in the earlier stage is very difficult to predict. It causes a greater risk as radiologists and specialist doctors assess the existence of lung cancer. For this reason, it is important to build a smart and automatic cancer prediction system that is accurate and at which stage of cancer or to improve the accuracy of the previous cancer prediction that will help determines the type of treatment and treatment depth depending on the severity of the disease. In this paper, the Adaptive Hierarchical Heuristic Mathematical Model (AHHMM) has been proposed for the deep learning approach. To analyze deep learning based on the historical therapy scheme in the development of Non-Small Cell Lung Cancers (NSCLC) automated radiation adaptation protocols that aim at optimizing local tumor regulation at lower rates of grade 2 RP2 radiation pneumonitis. Furthermore, the system proposed consists of several steps including acquiring the image, preprocessing, binarization, thresholding, and segmentation, extraction of features and detection of deep neural network (DNN). Segmentation of the lung CT image is carried out to extract any significant feature of a segmented image, and a specific feature extraction method is implemented. The test evaluation showed that the model proposed could detect 96.67 & x0025; accuracy of the absence or presence of lung cancer.","Lung cancer detection,deep learning,deep neural network,mathematical model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,CLASSIFICATION,FUSION,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09086786.pdf,
36,Identification of HIV-1 Vif Protein Attributes Associated With CD4 T Cell Numbers and Viral Loads Using Artificial Intelligence Algorithms,8,,87214-87227,"Altamirano-Flores Jose S.,Guerra-Palomares Sandra E.,Hernandez-Sanchez Pedro G.,Ramirez-Garcialuna Jose L.,Rafael Arguello-Astorga J.,Noyola Daniel E.,Cuevas-Tello Juan C.,Garcia-Sepulveda Christian A.","Altamirano-Flores JS,Guerra-Palomares SE,Hernandez-Sanchez PG,Ramirez-Garcialuna JL,Arguello-Astorga JR,Noyola DE,Cuevas-Tello JC,Garcia-Sepulveda CA",Garcia-Sepulveda CA,10.1109/ACCESS.2020.2992240,Universidad Autonoma de San Luis Potosi,"The Human Immunodeficiency Virus (HIV) Viral Infectivity Factor (Vif) is a 192-amino acid accessory protein essential to viral replication which counteracts host APOBEC3 proteins. APOBEC3 proteins interfere with the replication of HIV, hepatitis C virus, hepatitis B virus and retrotransposons. Vif is a recent candidate target for therapeutic and preventative interventions in HIV/AIDS yet little is known about its clinical relevance. We describe the results of applying different machine learning algorithms (Apriori, Multifactor Dimensionality Reductor, C4.5, Artificial Neural Networks and ID3) to the search of associations between HIV-1 Vif protein attributes and clinical endpoints. Final iterations showed that the presence of mutations in BC Boxes, APOBEC motifs and Cullin5 binding motifs were together associated with higher initial CD4 T cells while mutations of specific APOBEC motifs coupled with the conservation of other APOBEC motifs were associated with lower historic CD4 T cells. Conservation of specific APOBEC motifs and BC boxes were linked to lower initial viral loads while different combinations of mutations in the Nuclear Localisation Inhibition Signal and BC Boxes were associated with higher historic viral loads. Further scrutiny of these combinations through traditional statistical methods revealed striking differences in both CD4 T cells and viral loads in patients stratified into those having the previous combinations. While artificial intelligence algorithms do not phase out traditional statistical methods, our Artificial Intelligence (AI)-based approach highlights their use at reducing the dimensionality of large and complex datasets and at proposing novel, unimaginable, associations of biological patterns with functional relevance or clinical roles.","Artificial intelligence,bioinformatics,genomics,machine learning,medicine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"UBIQUITIN,LIGASE,COMPLEX,CYCLE,ARREST,GENE,INFECTION,TROPISM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09086045.pdf,
37,Imaging Analysis and Evaluation of Neural Stem Cell Intracerebral Migration and Functional Reconstruction Based on Deep Learning,8,,87252-87265,"Zhang Ying,Liu Jing,Liu Hongbiao","Zhang Y,Liu J,Liu HB",Zhang Y,10.1109/ACCESS.2020.2993412,Zhejiang University,"Neural stem cell is a type of stem cell with self-renewal ability and multi-directional differentiation potential. Under certain conditions, neural stem cells can differentiate into neurons, oligodendrocytes, and astrocytes, thereby participating in the occurrence of the nervous system. Considering that deep convolutional neural networks have better feature learning capabilities for image data than feedforward neural networks, this paper studies how to apply deep convolutional neural networks to modeling based on imaging features, and constructs convolutional neural networks. In this paper, the distribution of CD133(& x002B;) neural stem cells in different neuroanatomical regions of rat brain and possible migration flow were studied. The experimental results show that there are obvious differences in the distribution of neural stem cells in different neuroanatomical regions. With the growth and development of rats, a large number of CD133(& x002B;) neural stem cells migrate from the subventricular zone to the surrounding ganglia, corpus callosum, and cerebral cortex. Seven days before the operation, the rats were trained in water maze, and the EL (Escape Latency) of the rats was recorded for 1 week, 2 weeks and 1 month. Compared with the control group of sham operation, EL was significantly increased in the cerebral ischemia-reperfusion group. Compared with cerebral ischemia-reperfusion & x002B; acupuncture group and cerebral ischemia-reperfusion group, EL was significantly smaller. The results show that electroacupuncture can induce the proliferation of newborn cells in the brain and promote the differentiation of newborn cells into glial cells and nerve cells. After electroacupuncture intervention, a small number of new nerve cells already have the activity and function of secreting Ach. Electroacupuncture intervention can promote the recovery of rat nerve function after cerebral ischemia and reperfusion.","Stem cells,Neurons,Convolutional neural networks,Rats,Brain modeling,Central nervous system,Injuries,Neural stem cells,migration flow,functional reconstruction,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,SPINAL-CORD,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09090199.pdf,
38,Deep Learning-Based Food Quality Estimation Using Radio Frequency-Powered Sensor Mote,8,,88360-88371,"Lam Minh Binh,Nguyen Trung-Hau,Chung Wan-Young","Lam MB,Nguyen TH,Chung WY",Chung WY,10.1109/ACCESS.2020.2993053,Pukyong National University,"In the past decades, the emerging concern about food safety has led to the increasing demand for monitoring food quality across the world. Aiming towards a novel solution for monitoring food, this study proposes a non-destructive method with self-powering capability for online food monitoring, which can be extendable to IoT applications. Furthermore, the study introduces a novel deep neural network model to predict different states of food quality based on the monitoring results. To monitor the variation in food quality, the paper proposes the detection of total volatile organic compounds (TVOCs) inside the food packages, which have been released during food deterioration. A low-power sensor mote comprised of a capacity humidity sensor and a metal-oxide (MOX) gas sensor was manufactured for this purpose. The self-powering capability of the mote is provided through an energy harvester module, which benefits from the far-field Radio Frequency Energy Harvesting (RFEH) technology. The operating frequency of the module was chosen at the 915-MHz ISM band. The analysis of the harvester performance showed that the harvester could generate 3.3-V dc with an RF input power of as low as -8 dBm, which was sufficient for the mote operation. To verify the proposed solutions, a demonstration to monitor the deterioration of packaged pork and fish was conducted in eight days under ambient and refrigerated storage conditions, using the self-developed RF-powered sensor mote. The raw variations in TVOCs were analyzed to evaluate the reliability of the proposed TVOC-based method. A one-dimensional (1-D) convolutional neural network (CNN) model was trained on the TVOCs dataset to predict different states of food quality. To investigate the applicability of the proposed 1-D CNN to multi-class determination of food quality, two other supervised machine learning algorithms using 2-D inputs, including Multilayer Perceptron (MLP), and Support Vector Machine (SVM), are studied. Their classification accuracies based on the confusion matrix are identified and compared.","Convolutional neural network (CNN),food quality prediction,radio-frequency energy harvesting,total volatile organic compounds,multilayer perceptron (MLP),support-vector machine (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORK,CLASSIFICATION,INDICATORS,GENERATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09089003.pdf,
39,Information Assisted Dictionary Learning for fMRI Data Analysis,8,,90052-90068,"Morante Manuel,Kopsinis Yannis,Theodoridis Sergios,Protopapas Athanassios","Morante M,Kopsinis Y,Theodoridis S,Protopapas A",Morante M,10.1109/ACCESS.2020.2994276,National & Kapodistrian University of Athens,"In this paper, the task-related fMRI problem is treated in its matrix factorization form, focusing on the Dictionary Learning (DL) approach. The proposed method allows the incorporation of a priori knowledge that is associated with both the experimental design and available brain atlases. Moreover, it can cope efficiently with uncertainties in the modeling of the hemodynamic response function. In addition, the method bypasses one of the major drawbacks of the DL methods; namely, the selection of the sparsity-related regularization parameters. Under the proposed formulation, the associated regularization parameters bear a direct relation to the number of the activated voxels for each one of the sources & x2019; spatial maps. This natural interpretation facilitates fine-tuning of the related parameters and allows for exploiting external information from brain atlases. The proposed method is evaluated against several other popular techniques, including the classical General Linear Model (GLM). The obtained performance gains are quantitatively demonstrated via a novel realistic synthetic fMRI dataset as well as real data from a challenging experimental design.","Functional magnetic resonance imaging,Task analysis,Machine learning,Brain modeling,Data analysis,Hemodynamics,Standards,Dictionary learning,fMRI,semi-blind,sparsity,weighted norms",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"INDEPENDENT,COMPONENT,ANALYSIS,MATRIX,FACTORIZATION,CEREBRAL-CORTEX,SPATIAL,ICA,BRAIN,ORGANIZATION,SPARSITY,CONNECTIVITY,ALGORITHMS,SEPARATION",IEEE ACCESS,https://www.duo.uio.no/bitstream/10852/78299/5/09091875.pdf,
40,Design of Automatic Lung Nodule Detection System Based on Multi-Scene Deep Learning Framework,8,,90380-90389,"Zhang Qinghai,Kong Xiaojing","Zhang QH,Kong XJ",Kong XJ,10.1109/ACCESS.2020.2993872,"Third Peoples Hosp Zibo, Imaging Dept, Zibo 255000, Peoples R China.","Nowadays, the efficient identification of the lung nodule greatly leads to the chance of lung cancer risk assessment. Hence, the exact locations of lung nodules are a critical and complicated task. Researchers in this area have been working widely for almost two years. However, previous computer-aided detection (CAD) modules, such as transforming CT, segmenting the lung nodule and extracting the features are mostly complex and time-consuming, because more modules will require the creation of a complete image processing system. In addition, certain state-of-the-art deep learning systems are specified in the database standard. For this purpose, this paper suggests an efficient identification system for lung nodules based on Multi-Scene Deep Learning Framework (MSDLF) by the vesselness filter. A four-channel CNN model is designed to enhance the radiologist & x2019;s knowledge in the detection of four-stage nodules by integrating two image Scenes. This model can be applied in two different classes. The results show that the Multi-Scene Deep Learning Framework (MSDLF) is efficient for increasing the accuracy and significantly reducing false positives in an enormous amount of image data in the detection of lung nodules.","Lung,Computed tomography,Cancer,Machine learning,Image segmentation,Databases,Multi-scene deep learning framework,vesselness filter,convolutional neural network (CNN),lung nodules",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,LEVEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09091120.pdf,
41,Intelligent Assessment of Percutaneous Coronary Intervention Based on GAN and LSTM Models,8,,90640-90651,"Zou Zi-Zhuang,Xie Kai,Zhao Yi-Fei,Wan Jing,Lan Lan,Wen Chang","Zou ZZ,Xie K,Zhao YF,Wan J,Lan L,Wen C",Xie K,10.1109/ACCESS.2020.2992578,Yangtze University,"Coronary artery calcification affects the arteries that supply the heart with blood, and percutaneous coronary intervention (PCI) is a direct and effective surgery to alleviate this symptom. In this paper, we propose a framework to judge if a patient requires surgery, based on cardiac computerized tomography scans. We adopt generative adversarial network to segment the calcified areas from slices. This architecture provides an environment for the generator to perform joint learning from ground truth images and the high-resolution discriminator. We use images reconstructed using two types of filters to test our method. An F1 score of 96.1 & x0025; and 85.0 & x0025; was achieved for the soft and sharp filters. In addition, we explored different recurrent neural networks for making the final decision. Including long short-term memory, which was ultimately used to deal with the calcium score normalized by the age and score threshold. Using the soft reconstruction image as the input, the whole framework achieved an accuracy of 76.6 & x0025;. These results certify that our method can precisely locate lesion in artery, and make a reasonable risk assessment for PCI.","Generative adversarial network,low-dose cardiac CT,recurrent neural network,percutaneous coronary intervention,coronary calcium scoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECURRENT,NEURAL-NETWORKS,ARTERY,CALCIUM,COMPUTED-TOMOGRAPHY,CARDIAC,CT,REPRODUCIBILITY,DISEASE,QUANTIFICATION,CLASSIFICATION,CALCIFICATION,TEXTURE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09086494.pdf,
42,Determination of Optimum Segmentation Schemes for Pattern Recognition-Based Myoelectric Control: A Multi-Dataset Investigation,8,,90862-90877,"Ashraf Hassan,Waris Asim,Jamil Mohsin,Gilani Syed Omer,Niazi Imran Khan,Kamavuako Ernest Nlandu,Gilani Syed Hammad Nazeer","Ashraf H,Waris A,Jamil M,Gilani SO,Niazi IK,Kamavuako EN,Gilani SHN",Waris A; Jamil M,10.1109/ACCESS.2020.2994829,National University of Sciences & Technology - Pakistan,"Pattern recognition (PR) algorithms have shown promising results for upper limb myoelectric control (MEC). Several studies have explored the efficacy of different pre and post processing techniques in implementing PR-based MECs. This paper explores the effect of segmentation type (disjoint and overlap) and segment size on the performance of PR-based MEC, for multiple datasets recorded with different recording devices. Two PR-based methods; linear discriminant analysis (LDA) and support vector machine (SVM) are used to classify hand gestures. Optimum values of segment size, step size and segmentation type were considered as performance measure for a robust MEC. Statistical analysis showed that optimum values of segment size for disjoint segmentation are between 250ms and 300ms for both LDA and SVM. For overlap segmentation, best results have been observed in the range of 250ms-300ms for LDA and 275ms-300ms for SVM. For both classifiers the step size of 20 & x0025; achieved highest mean classification accuracy (MCA) on all datasets for overlap segmentation. Overall, there is no significant difference in MCA of disjoint and overlap segmentation for LDA (P-value & x003D; 0.15) but differ significantly in the case of SVM (P-value & x003C; 0.05). For disjoint segmentation, MCA of LDA is 88.68 & x0025; and for SVM, it is 77.83 & x0025;. Statistical analysis showed that LDA outperformed SVM for disjoint segmentation (P-value & x003C;0.05). For overlap segmentation, MCA of LDA is 89.86 & x0025; and for SVM, it is 89.16 & x0025;, showing that statistically, there is no significant difference between MCA of both classifiers for overlap segmentation (P-value & x003D; 0.45). The indicated values of segment size and overlap size can be used to achieve better performance results, without increasing delay time, for a robust PR-based MEC system.","Electromyography,Support vector machines,Motion segmentation,Control systems,Pattern recognition,Motion artifacts,Robustness,Classification,machine learning,pattern recognition,segmentation,windowing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,SCHEME,EMG,COMBINATION,HAND",IEEE ACCESS,https://doi.org/10.1109/access.2020.2994829,
43,A Comprehensive Review for Breast Histopathology Image Analysis Using Classical and Deep Neural Networks,8,,90931-90956,"Zhou Xiaomin,Li Chen,Rahaman Md Mamunur,Yao Yudong,Ai Shiliang,Sun Changhao,Wang Qian,Zhang Yong,Li Mo,Li Xiaoyan","Zhou XM,Li C,Rahaman MM,Yao YD,Ai SL,Sun CH,Wang Q,Zhang Y,Li M,Li XY",Li C,10.1109/ACCESS.2020.2993788,Northeastern University - China,"Breast cancer is one of the most common and deadliest cancers among women. Since histopathological images contain sufficient phenotypic information, they play an indispensable role in the diagnosis and treatment of breast cancers. To improve the accuracy and objectivity of Breast Histopathological Image Analysis (BHIA), Artificial Neural Network (ANN) approaches are widely used in the segmentation and classification tasks of breast histopathological images. In this review, we present a comprehensive overview of the BHIA techniques based on ANNs. First of all, we categorize the BHIA systems into classical and deep neural networks for in-depth investigation. Then, the relevant studies based on BHIA systems are presented. After that, we analyze the existing models to discover the most suitable algorithms. Finally, publicly accessible datasets, along with their download links, are provided for the convenience of future researchers.","Breast cancer,Machine learning,Neural networks,Image analysis,Breast cancer,histopathology,convolutional neural networks,deep learning,image segmentation,image classification",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONDITIONAL,RANDOM-FIELDS,MITOSIS,DETECTION,CANCER,DIAGNOSIS,CLASSIFICATION,HISTOLOGY,SEGMENTATION,PATHOLOGY,SUPPORT,DATASET",IEEE ACCESS,http://arxiv.org/pdf/2003.12255,
44,Automatic Localization and Discrete Volume Measurements of Hippocampi From MRI Data Using a Convolutional Neural Network,8,,91725-91739,"Basher Abol,Kim Byeong C.,Lee Kun Ho,Jung Ho Yub","Basher A,Kim BC,Lee KH,Jung HY",Jung HY,10.1109/ACCESS.2020.2994388,Chosun University,"Automatic hippocampal volume measurement from brain magnetic resonance imaging (MRI) is a crucial task and an important research area, especially in the study of neurodegenerative diseases; hippocampal volume atrophy is known to be connected with Alzheimer's disease. In this research work, we propose a deep learning-based method to automatically measure the discrete hippocampal volume without prior segmentation of the volumetric MRI scans. We constructed a 2-D convolutional neural network (CNN) model that uses 3-channel 2-D patches to predict the number of voxels attributed to the hippocampus; the number of estimated hippocampal voxels is multiplied by the voxel volume to measure the discrete volume of the hippocampus. In addition, we demonstrate a preprocessing scheme to prepare the data using a relatively small number of MRI scans. The average errors in the measured volumes of the proposed approach and the compared atlas-based system were 4.3173 +/- 3.5436 (avg. error% +/- STD) and 4.1562 +/- 3.5262 (avg. error % +/- STD) for the left and right hippocampi, respectively. The correlation coefficients of the proposed approach with atlas-based volume measurement were statistically significant (p-value < 0.01, R-2=0.834 (left hippocampus) and R-2=0.848 (right hippocampus) based on 0.05 significance level), which suggests that the proposed approach can be used as a proxy method for the atlas-based system. Furthermore, the proposed approach is computationally efficient and requires less than 2 seconds to calculate the number of voxels for an MRI scan. Moreover, our method outperforms the state-of-the-art deep learning approach, such as 2-D U-Net and SegNet in the context of voxel/volume estimation errors% for the left and right hippocampi.","Magnetic resonance imaging,Volume measurement,Hippocampus,Dementia,Image segmentation,Machine learning,MRI,hippocampus,patch,Hough-CNN,localization,CNN,discrete volume",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ALZHEIMERS-DISEASE,SEGMENTATION,ATLAS,FREESURFER,PREDICTION,VIVO",IEEE ACCESS,https://doi.org/10.1109/access.2020.2994388,
45,Retinal Image Classification by Self-Supervised Fuzzy Clustering Network,8,,92352-92362,"Luo Yueguo,Pan Jing,Fan Shaoshuah,Du Zeyu,Zhang Guanghua","Luo YG,Pan J,Fan SS,Du ZY,Zhang GH",Zhang GH,10.1109/ACCESS.2020.2994047,"Shanxi Intelligence Inst Big Data Technol & Innov, Taiyuan 030000, Peoples R China.","Diabetic retinal image classification aims to conduct diabetic retinopathy automatically diagnosing, which has achieved considerable improvement by deep learning models. However, these methods all rely on sufficient network training by large scale annotated data, which is very labor-expensive in medical image labeling. Aiming to overcome these drawbacks, this paper focuses on embedding self-supervised framework into unsupervised deep learning architecture. Specifically, we propose a Self-supervised Fuzzy Clustering Network (SFCN) by a feature learning module, reconstruction module, and a fuzzy self-supervision module. The feature learning and reconstruction modules ensure the representative ability of the network, and fuzzy self-supervision module is in charge of further providing the training direction for the whole network. Furthermore, three losses of reconstruction, self-supervision, and fuzzy supervision jointly optimize the SFCN under an unsupervised manner. To evaluate the effectiveness of the proposed method, we implement the network on three widely used retinal image datasets, which results demonstrate the satisfied performance on unsupervised retinal image classification task.","Retina,Diabetes,Retinopathy,Biomedical imaging,Machine learning,Feature extraction,Task analysis,Retinal image classification,self-supervised,fuzzy clustering,unsupervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DIABETIC-RETINOPATHY,AUTOMATIC,DETECTION,CANCER",IEEE ACCESS,https://doi.org/10.1109/access.2020.2994047,
46,Prediction of the Fresh Performance of Steel Fiber Reinforced Self-Compacting Concrete Using Quadratic SVM and Weighted KNN Models,8,,92647-92658,"Altay Osman,Ulas Mustafa,Alyamac Kursat Esat","Altay O,Ulas M,Alyamac KE",Altay O,10.1109/ACCESS.2020.2994562,Firat University,"Steel fiber reinforced self-compacting concrete (SFRSCC) is a special type of concrete that is widely researched in literature due to its superior properties. As it is difficult to provide its high workability qualities, SFRSCC is thought to be in need of an economic and quick design process. In this study, it is aimed to predict the fresh properties of SFRSCC mixtures following with the standards at the preliminary design stage. With this aim, two different classification methods were applied successfully to a comprehensive dataset collected from international publications. The models used to classify the fresh performance of SFRSCC were Weighted K-Nearest Neighbors (W-KNN) and Quadratic Support Vector Machine (Q-SVM). Consequently, acceptable success rates were obtained from the models. For the prediction of slump-flow, the accuracy values were 0.76 and 0.84 for the W-KNN and Q-SVM models, respectively. For the V-funnel time, the accuracy values were 0.90 and 0.92 for the W-KNN and Q-SVM models, respectively. Owing to the recommended methods, it is expected to reduce the number of trial mixtures in the preliminary design stage of SFRSCC.","Concrete,Machine learning,Steel,Aggregates,Classification algorithms,Support vector machines,Biological system modeling,Fresh properties,self-compacting concrete,steel fiber,quadratic support vector machine,weighted k-nearest neighbor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MIX,DESIGN,METHOD,MECHANICAL-PROPERTIES,COMPRESSIVE,STRENGTH,SCC,WORKABILITY,METHODOLOGY,ALGORITHM,IMAGES",IEEE ACCESS,https://doi.org/10.1109/access.2020.2994562,
47,Hyperspectral Anomaly Detection via Graphical Connected Point Estimation and Multiple Support Vector Machines,8,,94152-94164,"Song Shangzhen,Qin Hanlin,Yang Yixin,Zhang Zhe,Zhou Huixin","Song SZ,Qin HL,Yang YX,Zhang Z,Zhou HX",Qin HL; Zhou HX,10.1109/ACCESS.2020.2995675,Xidian University,"Most hyperspectral anomaly detection algorithms are based on various hypothetical models justified by different methods. The closer to the real-world scene distribution a hypothetical model is, the better detection performance usually results, albeit at the expense of increased model complexity. There is also a challenge in most of the detection methods that anomalous components cannot be completely separated from the background due to the difference between hypothetical models and the real-world scene. To address this problem, a novel strategy based on graph theory and the multiple support vector machines technique is proposed in this paper. Firstly, a graphical connected point-based estimation is utilized as a preprocessing procedure to separate potential anomalies from robust backgrounds of the image. Second, without building a hypothetical model, the hyperspectral image is classified into several categories by a clustering method according to the different characteristics of materials. Consequently, for each category, the support vector machine is used to classify anomalous components and background components belonging to specific categories, and the result map of each classification is obtained. Finally, all maps corresponding to various categories are fused by an effective fusion strategy, and the detection result is generated by our method. In the subsequent experiments, we use several state-of-art anomaly detection algorithms in a comparison with our method using both simulated and real-world HSI datasets. The experimental results demonstrate that the proposed method outperforms others.","Support vector machines,Hyperspectral imaging,Feature extraction,Anomaly detection,Estimation,Learning systems,Hyperspectral image,anomaly detection,graphical data description,clustering,machine learning,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORK,REPRESENTATION,ALGORITHM,PATTERN",IEEE ACCESS,https://doi.org/10.1109/access.2020.2995675,
48,Machine Vision-Based Monitoring Methodology for the Fatigue Cracks in U-Rib-to-Deck Weld Seams,8,,94204-94219,"Wang Dalei,Dong Yiqing,Pan Yue,Ma Rujin","Wang DL,Dong YQ,Pan Y,Ma RJ",Pan Y,10.1109/ACCESS.2020.2995276,Tongji University,"The orthotropic steel-box girder (OSG) is widely used in the construction of a large-scale bridges. Since cumulative damages caused by the heavy vehicles and initial flaws of welding, the bridges with OSGs frequently suffer from fatigue cracks, which are commonly distributed around U-ribs. Hence, the management of fatigue cracks is mandatory in practical engineering. Although some techniques have been adopted for the detection of cracks, the workflow is often labor-intensive, time-consuming, and of low-temporal resolution. Considering the optical visibility of a crack and the limitation of the shape of an over-welding-hole around the U-rib, a machine vision-based monitoring methodology for the fatigue cracks in U-rib-to-deck weld seams is proposed in this paper. To be specific, a specific Internet of Things (IoT) based image acquisition device is first developed and introduced to obtain precisely part-view images of a fatigue crack. As followed, a novel image rectification and stitching method based on a specified coded calibration board is innovated and described for generating a measurable panoramic fatigue crack image. Furthermore, a deep learning-based crack detection-segmentation integrated algorithm is developed to detect and segment the crack areas. Afterwards, a feature extraction procedure based on image processing is explored to obtain the morphological features of a crack, involving its area, length and width. Finally, a field experiment was carried out on a real steel suspension bridge. By comparing the measurements both from manual measuring and vision-based monitoring, the results indicate that the proposed methodology is very promising to monitor the fatigue cracks in U-rib-to-deck weld seams, and the root-mean-square errors in length and width measuring could be 3.0195 mm and 0.003 mm, respectively. This work is not only of practical value to the management and maintenance of the OSG bridges in engineering, but also critical for the researches on fatigue cracks propagation.","Fatigue,Welding,Feature extraction,Monitoring,Steel,Bridges,Machine learning,Orthotropic steel deck,machine vision,IoT based image acquisition system,fatigue crack measuring,image stitching,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SURFACE,CRACKS,IDENTIFICATION,INSPECTION,INVARIANT,SCALE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09094652.pdf,
49,Ubiquitous Depression Detection of Sleep Physiological Data by Using Combination Learning and Functional Networks,8,,94220-94235,"Zhang Bingtao,Zhou Wenying,Cai Hanshu,Su Yun,Wang Jinfeng,Zhang Zhonglin,Lei Tao","Zhang BT,Zhou WY,Cai HS,Su Y,Wang JF,Zhang ZL,Lei T",Zhang BT,10.1109/ACCESS.2020.2994985,Lanzhou Jiaotong University,"Nowadays, depression has become a common mental disorder with high morbidity and mortality. Due to the limitations of traditional interview-based depression detection, it has become an urgent problem to realize objective, convenient and fast detection. This study is to explore ubiquitous methods of depression detection based on combination learning and functional networks, using sleep physiological data. Sleep physiological data were collected using a portable physiological data instrument, and then preprocess and extract several related features. We applied combination learning to discover the best sleep stage, the optimal features subset, and the most effective classifier, which are hidden behind physiological features, to detect depression. Physiological features in the optimal feature subset based on Euclidean distance are mapped to nodes to construct the functional network. The optimal feature subset was combined with the functional network attributes as the input of the most effective classifier to get the ultimate performance of depression detection. Controlled trials based on ubiquitous sleep physiological data were conducted on different genders. Experiments show that the best results for male and female were derived from slow wave sleep (SWS) and rapid eye movement (REM), with performances of 92.21%; and 94.56%, AUC of 0.944 and 0.971, respectively. Thus, our study may provide an effective and ubiquitous method for detect depression.","Physiology,Sleep,Electrodes,Instruments,Feature extraction,Diseases,Data acquisition,Ubiquitous depression detection,functional networks,combination learning,sleep physiological data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FEATURE-SELECTION,METHODS,TIME-FREQUENCY,ANALYSIS,MAJOR,DEPRESSION,EEG,IDENTIFICATION,CONNECTIVITY,RECOGNITION,ADOLESCENTS,DIAGNOSIS,DYNAMICS",IEEE ACCESS,https://doi.org/10.1109/access.2020.2994985,
50,An Embedded System for Collection and Real-Time Classification of a Tactile Dataset,8,,97462-97473,"Kursun Olcay,Patooghy Ahmad","Kursun O,Patooghy A",Patooghy A,10.1109/ACCESS.2020.2996576,University of Central Arkansas,"Tactile perception of the material properties in real-time using tiny embedded systems is a challenging task and of grave importance for dexterous object manipulation such as robotics, prosthetics and augmented reality. As the psychophysical dimensions of the material properties cover a wide range of percepts, embedded tactile perception systems require efficient signal feature extraction and classification techniques to process signals collected by tactile sensors in real-time. For this purpose, we developed two embedded systems, one that served as a vibrotactile stimulator system and one that recorded and classified the vibrotactile signals collected by its sensors. The quality of the collected data was first verified offline using Fourier transform for feature extraction and then applying powerful machine learning classifiers such as support vector machines and neural networks. We implemented the proposed memory-less signal feature extraction method in order to achieve real-time processing as the data is being collected. The experimental results have shown that the proposed method significantly reduces the computational complexity of feature extraction and still has led to high classification accuracy even when fed to the less complex classifiers such as random forests that can be easily implemented on embedded systems. Finally, we have also shown that low-cost, highly accurate, and real-time tactile texture classification can be achieved using the proposed approach with an ensemble of sensors.","Feature extraction,Embedded systems,Real-time systems,Sensors,Frequency-domain analysis,Time-domain analysis,Smoothing methods,Signal processing algorithms,edge computing,tactile sensors,texture analysis,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,SENSOR,IEEE ACCESS,https://doi.org/10.1109/access.2020.2996576,
51,Multiple Lesions Detection of Fundus Images Based on Convolution Neural Network Algorithm With Improved SFLA,8,,97618-97631,"Ding Weiping,Sun Ying,Ren Longjie,Ju Hengrong,Feng Zhihao,Li Ming","Ding WP,Sun Y,Ren LJ,Ju HR,Feng ZH,Li M",Ding WP,10.1109/ACCESS.2020.2996569,Nantong University,"In order to effectively solve the problem of interlaced overlap in the fundus image lesions, large and small blood vessels packed densely and severely affected by light, and to achieve multi-label classification of fundus images. In this paper, a single population leapfrog optimization convolutional neural network algorithm (SFCNN) is proposed to detect and classify various fundus lesions. The algorithm uses the efficient search ability of the shuffled frog leaping algorithm to optimize the weight initialization and back propagation of the convolutional neural network. In order to deal with the problem of fundus image classification in the big data environment, the novel grouping optimization strategy is presented to effectively combine Spark platform and SFCNN algorithm to achieve large-scale fundus image classification and detection of multiple lesions. The experiment of the detection of fundus image lesions shows that the accuracy rate of SFCNN is better improved in both single lesion detection and overall detection, compared with other algorithms.","Convolutional neural networks,Lesions,Convolution,Classification algorithms,Sociology,Statistics,Training,Shuffled frog leaping algorithm,convolutional neural networks,fundus image,detection of multiple lesions,weight optimization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,SEGMENTATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09098890.pdf,
52,Depth Information-Based Automatic Annotation of Early Esophageal Cancers in Gastroscopic Images Using Deep Learning Techniques,8,,97907-97919,"Liu Dingyun,Jiang Hongxiu,Rao Nini,Du Wenju,Luo Chengsi,Li Zhengwen,Zhu Linlin,Gan Tao","Liu DY,Jiang HX,Rao NN,Du WJ,Luo CS,Li ZW,Zhu LL,Gan T",Rao NN,10.1109/ACCESS.2020.2996631,University of Electronic Science & Technology of China,"The early diagnoses of esophageal cancer are of great significance in the clinic because they are critical for reducing mortality. At present, the diagnoses are mainly performed by artificial detection and annotations based on gastroscopic images. However, these procedures are very challenging to clinicians due to the large variability in the appearance of early cancer lesions. To reduce the subjectivity and fatigue in manual annotations and to improve the efficiency of diagnoses, computer-aided annotation methods are highly required. In this work, we proposed a novel method that utilized deep learning (DL) techniques to realize the automatic annotation of early esophageal cancer (EEC) lesions in gastroscopic images. The depth map of gastroscopic images was initially extracted by a DL network. Then, this additional depth information was fused with the original RGB gastroscopic images, which were then sent to another DL network to obtain precise annotations of EEC regions. In total, 4231 gastroscopic images of 732 patients were used to build and validate the proposed method. A total of 3190 of those images were EEC images, and the remaining 1041 were non-EEC images. The experimental results show that the combination of depth information and RGB information improved the annotation performance. The final EEC detection rate and mean Dice Similarity Coefficient (DSC) of our method were 97.54% and 74.43%, respectively. Compared with other state-of-the-art DL-based methods, the proposed method showed better annotation performances and fewer false positive outputs. Therefore, our method offers a good prospect in aiding the clinical diagnoses of EEC.","Lesions,Training,Cancer,Machine learning,Image segmentation,Feature extraction,Licenses,Gastroscopic image,early esophageal cancer,lesion annotation,deep learning,depth map",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,ARTIFICIAL-INTELLIGENCE,CLASSIFICATION,LESIONS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09098864.pdf,
53,Cxnet-M3: A Deep Quintuplet Network for Multi-Lesion Classification in Chest X-Ray Images Via Multi-Label Supervision,8,,98693-98704,"Xu Shuaijing,Yang Xiaoyilei,Guo Junqi,Wu Hao,Zhang Guangzhi,Bie Rongfang","Xu SJ,Yang XYL,Guo JQ,Wu H,Zhang GZ,Bie RF",Bie RF,10.1109/ACCESS.2020.2996217,Beijing Normal University,"Medical image analysis is motivated by the success of deep learning, where annotations are usually expensive and not easy to obtain. In this paper, we propose a deep quintuplet network CXNet-m3, where the classification of lesion type of chest x-ray images (CXRs) could benefit from easily accessible annotations like patient age, gender, identity and view position. To improve classification performance, a novel loss function combining both deep metric learning and deep learning is first designed based on multiple labels. Then, a deep model based on transfer learning is built to optimize the loss function. To solve the problem of slow convergence, a quintuplet mining algorithm is presented to provide valuable training samples for the proposed classification model. The experimental results on Chest X-ray14 database show that our classification method outperforms some state-of-art models under Area Under Curve (AUC) score, reaching 0.824 on an average. Besides, our proposal achieves more than 0.9 AUC values in the case of Infiltration, Atelectasis, Cardiomegaly and Nodule.","Lesions,X-ray imaging,Training,Machine learning,Feature extraction,Biomedical imaging,Measurement,Medical image,chest X-ray image classification,deep neural network,deep metric learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,LUNG,IEEE ACCESS,https://doi.org/10.1109/access.2020.2996217,
54,Deep feature learning for histopathological image classification of canine mammary tumors and human breast cancer,508,,405-421,"Kumar Abhinav,Singh Sanjay Kumar,Saxena Sonal,Lakshmanan K.,Sangaiah Arun Kumar,Chauhan Himanshu,Shrivastava Sameer,Singh Raj Kumar","Kumar A,Singh SK,Saxena S,Lakshmanan K,Sangaiah AK,Chauhan H,Shrivastava S,Singh RK",Kumar A,10.1016/j.ins.2019.08.072,Indian Institute of Technology System (IIT System),"Canine mammary tumors (CMTs) have high incidences and mortality rates in dogs. They are also considered excellent models for human breast cancer studies. Diagnoses of both, human breast cancer and CMTs, are done by histopathological analysis of haematoxylin and eosin (H&E) stained tissue sections by skilled pathologists: a process that is very tedious and time-consuming. The existence of heterogeneous and diverse types of CMTs and the paucity of skilled veterinary pathologists justify the need for automated diagnosis. Deep learning-based approaches have recently gained popularity for analyzing histopathological images of human breast cancer. However, so far, due to the lack of any publicly available CMT database, no studies have focused on the automated classification of CMTs. To the best of our knowledge, we have introduced for the first time a dataset of CMT histopathological images (CMTHis). Further, we have proposed a framework based on VGGNet-16, and evaluated the performance of the fused framework along with different classifiers on the CMT dataset (CMTHis) and human breast cancer dataset (BreakHis). We also explored the effect of data augmentation, stain normalization, and magnification on the performance of the proposed framework. The proposed framework, with support vector machines, resulted in mean accuracies of 97% and 93% for binary classification of human breast cancer and CMT respectively, which validates the efficacy of the proposed system. (C) 2019 Elsevier Inc. All rights reserved.","Canine mammary tumor (CMT),Breast cancer,Deep learning,Histopathological classification",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Computer Science,,,"NEURAL-NETWORKS,DOGS",INFORMATION SCIENCES,,
55,Attention Gate ResU-Net for Automatic MRI Brain Tumor Segmentation,8,,58533-58545,"Zhang Jianxin,Jiang Zongkang,Dong Jing,Hou Yaqing,Liu Bin","Zhang JX,Jiang ZK,Dong J,Hou YQ,Liu B",Liu B,10.1109/ACCESS.2020.2983075,Dalian University of Technology,"Brain tumor segmentation technology plays a pivotal role in the process of diagnosis and treatment of MRI brain tumors. It helps doctors to locate and measure tumors, as well as develop treatment and rehabilitation strategies. Recently, MRI brain tumor segmentation methods based on U-Net architecture have become popular as they largely improve the segmentation accuracy by applying skip connection to combine high-level feature information and low-level feature information. Meanwhile, researchers have demonstrated that introducing attention mechanism into U-Net can enhance local feature expression and improve the performance of medical image segmentation. In this work, we aim to explore the effectiveness of a recent attention module called attention gate for brain tumor segmentation task, and a novel Attention Gate Residual U-Net model, i.e., AGResU-Net, is further presented. AGResU-Net integrates residual modules and attention gates with a primeval and single U-Net architecture, in which a series of attention gate units are added into the skip connection for highlighting salient feature information while disambiguating irrelevant and noisy feature responses. AGResU-Net not only extracts abundant semantic information to enhance the ability of feature learning, but also pays attention to the information of small-scale brain tumors. We extensively evaluate attention gate units on three authoritative MRI brain tumor benchmarks, i.e., BraTS 2017, BraTS 2018 and BraTS 2019. Experimental results illuminate that models with attention gate units, i.e., Attention Gate U-Net (AGU-Net) and AGResU-Net, outperform their baselines of U-Net and ResU-Net, respectively. In addition, AGResU-Net achieves competitive performance than the representative brain tumor segmentation methods.","MRI,brain tumor segmentation,U-Net,attention gate,residual module",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,CLASSIFICATION,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09046011.pdf,
56,Research on Medical Image Classification Based on Machine Learning,8,,93145-93154,"Tang Hai,Hu Zhihui","Tang H,Hu ZH",Tang H,10.1109/ACCESS.2020.2993887,Hubei University of Automotive Technology,"In this paper, we propose a new method for CT pathological image analysis of brain and chest to extract image features and classify images. Because the deep neural network needs a large number of labeled samples to complete the training, and the cost of medical image labeling is very high, the training samples needed to train the deep neural network are insufficient. In this paper, a semi supervised learning based image classification method is proposed, which uses a small amount of labeled pathological image data to train the network model, and then integrates the features extracted by the network to classify the image. The results show that the classification effect of the neural network is better than convolution neural network and other traditional image classification models. To some extent, it can reduce the dependence of neural network on a large number of training samples, and effectively reduce the over fitting phenomenon of the network. Through the analysis of the overall classification accuracy and kappa coefficient of different classification methods under different sample numbers, it is found that the overall classification accuracy and kappa coefficient are increasing with the increasing number of training samples. Especially in the case of a small number of training samples, compared with other deep neural networks and traditional classification methods, the classification accuracy of the counter neural network is about 10 & x0025; higher than that of other neural networks and traditional classification methods, and the advantages are more obvious.","Feature extraction,Biological neural networks,Training,Medical diagnostic imaging,Convolution,Generators,Generative adversarial network,deep learning,feature extraction,image classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SUPPORT,VECTOR,MACHINE,CONVOLUTIONAL,NEURAL-NETWORKS,DEEP,REPRESENTATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09091175.pdf,
57,A Lung Dense Deep Convolution Neural Network for Robust Lung Parenchyma Segmentation,8,,93527-93547,"Chen Ying,Wang Yerong,Hu Fei,Wang Ding","Chen Y,Wang YR,Hu F,Wang D",Wang YR,10.1109/ACCESS.2020.2993953,Nanchang Hangkong University,"Lung parenchyma segmentation is the prerequisite for an automatic diagnosis system to analyze lung CT (computed tomography) images. However, traditional lung segmentation algorithms have poor adaptability and are not effectively robust regarding lung databases with blood vessels and small voids which can interfere the segmentation. The main work of this paper is as follows: Firstly, a lung dense deep convolutional neural network (LDDNet) is proposed, which adopts some popular optimizer methods, such as dense block, batch normalization (BN) and dropout. The performance of LDDNet is tested on the public lung database LIDC-IDRI which contains many cases of interference for segmentation. Secondly, the labeled with blood vessels and small voids are not contained by the public ground-truth masks of the LIDC-IDRI database, therefore these regions are labeled by us with LabelMe software. Thirdly, for the aim of exploring the effect of image preprocessing on segmenting lung CT images with deep neural network, contrast enhancing, median filtering and Laplacian filtering are used to preprocess the image as comparative experiments. Finally, dataset is classified into four classes by the geometrical shapes to test the performance of LDDNet. The accuracy of the segmentation experiment reaches over 99 & x0025; and the four classes can all reach over 95 & x0025;. Additionally, blood vessels and small voids are segmented out from the lung parenchyma which is not achieved by other methods. Experimental results confirm that the proposed LDDNet can segment the lung parenchymal area more accurately and has better robustness in comparison with other neural networks and most of the traditional methods.","Lung,Image segmentation,Computed tomography,Cancer,Clustering algorithms,Biomedical imaging,Neural networks,Deep dense neural network,lung segmentation,robustness",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FUZZY,C-MEANS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09091318.pdf,
58,A Novel Stacked CNN for Malarial Parasite Detection in Thin Blood Smear Images,8,,93782-93792,"Umer Muhammad,Sadiq Saima,Ahmad Muhammad,Ullah Saleem,Choi Gyu Sang,Mehmood Arif","Umer M,Sadiq S,Ahmad M,Ullah S,Choi GS,Mehmood A",Ahmad M,10.1109/ACCESS.2020.2994810,"Khwaja Fareed Univ Engn & Informat Technol KFUEIT, Dept Comp Engn, Rahim Yar Khan 64200, Pakistan.","Malaria refers to a contagious mosquito-borne disease caused by parasite genus plasmodium transmitted by mosquito female Anopheles. As infected mosquito bites a person, the parasite multiplies in the host & x2019;s liver and start destroying the red-cells. The disease is examined visually under the microscope for infected red-cells. This diagnosis depends upon the expertise and experience of pathologists and reports may vary in different laboratories doing a manual examination. Another way around, many machine learning techniques have been applied for spontaneous detection of blood smears. However, feature engineering is a challenging task that requires expertise to adjust positional and morphological features. Therefore, this study proposes a novel Stacked Convolutional Neural Network architecture that improves the automatic detection of malaria without considering the hand-crafted features. The 5-fold cross-validation process on 27, 558 cell images with equal instances of parasitized and uninfected cells on a publicly available dataset from the National Institute of health, the accuracy of our proposed model is 99.98 & x0025;. Furthermore, the statistical results revealed that the proposed model is superior to the state-of-the-art models with 100 & x0025; precision, 99.9 & x0025; recall, and 99 & x0025; f1-measure.","Diseases,Blood,Feature extraction,Sensitivity,Machine learning,Computer architecture,Support vector machines,Convolutional neural network (CNN),Malaria,blood smear images,deep learning,diagnostic approach",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORKS,RECOGNITION,DELAY",IEEE ACCESS,https://doi.org/10.1109/access.2020.2994810,
59,Cardiomegaly Detection on Chest Radiographs: Segmentation Versus Classification,8,,94631-94642,"Sogancioglu Ecem,Murphy Keelin,Calli Erdi,Scholten Ernst T.,Schalekamp Steven,Van Ginneken Bram","Sogancioglu E,Murphy K,Calli E,Scholten ET,Schalekamp S,Van Ginneken B",Sogancioglu E,10.1109/ACCESS.2020.2995567,Radboud University Nijmegen,"In this study, we investigate the detection of cardiomegaly on frontal chest radiographs through two alternative deep-learning approaches - via anatomical segmentation and via image-level classification. We used the publicly available ChestX-ray14 dataset, and obtained heart and lung segmentation annotations for 778 chest radiographs for the development of the segmentation-based approach. The classification-based method was trained with 65k standard chest radiographs with image-level labels. For both approaches, the best models were found through hyperparameter searches where architectural, learning, and regularization related parameters were optimized systematically. The resulting models were tested on a set of 367 held-out images for which cardiomegaly annotations were hand-labeled by two independent expert radiologists. Sensitivity, specificity, positive predictive value, negative predictive value, and area under the receiver operating characteristic curve (AUC) were calculated. The performance of the segmentation-based system with an AUC of 0.977 is significantly better for classifying cardiomegaly than the classification-based model which achieved an AUC of 0.941. Only the segmentation-based model achieved comparable performance to an independent expert reader (AUC of 0.978). We conclude that the segmentation-based model requires 100 times fewer annotated chest radiographs to achieve a substantially better performance, while also producing more interpretable results.","Image segmentation,Heart,Lung,Radiography,Training,Standards,Machine learning,Deep learning,chest radiographs,anatomy segmentations,cardiomegaly",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2995567,
60,Hybrid Deep Learning Model Assisted Data Compression and Classification for Efficient Data Delivery in Mobile Health Applications,8,,94757-94766,"Cao Youshen,Zhang Hanzhi,Choi Yong-Bae,Wang Hao,Xiao Sicheng","Cao YS,Zhang HZ,Choi YB,Wang H,Xiao SC",Cao YS,10.1109/ACCESS.2020.2995442,Dong A University,"With the growing amount of chronic patients, consistent monitoring for health care professionals has been a major concern and a direct incentive to develop mobile health systems that are adaptive and energy-efficient. The data collected from these devices is extremely important and may be affected by wireless communication environments encouraging a preliminary stage that adapts transmission of data to network dynamics. The paper provides compression and classification schemes for data based on a Hybrid Deep Learning Model (HDLM) that represents data characteristics, acquired data, and energy efficiency data delivery dynamics. Further, the EEG and EMG signals are compressed and classified based on Hybrid Deep Learning Model (HDLM) has been mathematically analyzed. Hence, The system is specifically based on the Stacked Auto-Encoder (SAE) architecture which extracts discrimination in the multimodal representation of data; it reconstructs data from the latent description with the help of encoder-decoder layers for data analysis. Furthermore, Multi-Modality Adaptive Compression shows its performance, computational complexity and response to different network states has been experimentally analyzed at lab scale numerical analysis. This method is therefore appropriate for mHealth applications, which can improve energy efficiency, minimize capacity, and minimize transmission latency in the mHealth cloud with intelligent preprocessing.","Data compression,Machine learning,Energy efficiency,Brain modeling,Data models,Medical services,Wireless sensor networks,Deep learning model,wireless network,auto-encoder,data compression,and classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BIG,DATA,ANALYTICS,CARE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09095318.pdf,
61,Automatic Segmentation of Stroke Lesions in Non-Contrast Computed Tomography Datasets With Convolutional Neural Networks,8,,94871-94879,"Tuladhar Anup,Schimert Serena,Rajashekar Deepthi,Kniep Helge C.,Fiehler Jens,Forkert Nils D.","Tuladhar A,Schimert S,Rajashekar D,Kniep HC,Fiehler J,Forkert ND",Forkert ND,10.1109/ACCESS.2020.2995632,University of Calgary,"Non-contrast computed tomography (NCCT) is commonly used for volumetric follow-up assessment of ischemic strokes. However, manual lesion segmentation is time-consuming and subject to high inter-observer variability. The aim of this study was to develop and establish a baseline convolutional neural network (CNN) model for automatic NCCT lesion segmentation. A total of 252 multi-center clinical NCCT datasets, acquired from 22 centers, and corresponding manual segmentations were used to train (204 datasets) and validate (48 datasets) a 3D multi-scale CNN model for lesion segmentation. Post-processing methods were implemented to improve the CNN-based lesion segmentations. The final CNN model and post-processing method was evaluated using 39 out-of-distribution holdout test datasets, acquired at seven centers that did not contribute to the training or validation datasets. Each test image was segmented by two or three neuroradiologists. The Dice similarity coefficient (DSC) and predicted lesion volumes were used to evaluate the segmentations. The CNN model achieved a mean DSC score of 0.47 on the validation NCCT datasets. Post-processing significantly improved the DSC to 0.50 (P < 0.01). On the holdout test set, the CNN model achieved a mean DSC score of 0.42, which was also significantly improved to 0.45 (P < 0.05) by post-processing. Importantly, the automatically segmented lesion volumes were not significantly different from the lesion volumes determined by the expert observers (P > 0.05) and showed excellent agreement with manual lesion segmentation volumes (intraclass correlation coefficient, ICC = 0.88). The proposed CNN model can automatically and reliably segment ischemic stroke lesions in clinical NCCT datasets. Post-processing techniques can further improve accuracy. As the model was trained and evaluated on datasets from multiple centers, it is broadly applicable and is publicly available.","Lesions,Image segmentation,Observers,Training,Manuals,Computed tomography,Computational modeling,Artificial neural networks,brain,computed tomography,computer-assisted image analysis,convolutional neural networks,deep learning,machine learning,stroke",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CT,IEEE ACCESS,https://doi.org/10.1109/access.2020.2995632,
62,Unsupervised Deep Learning CAD Scheme for the Detection of Malaria in Blood Smear Microscopic Images,8,,94936-94946,"Pattanaik Priyadarshini Adyasha,Mittal Mohit,Khan Mohammad Zubair","Pattanaik PA,Mittal M,Khan MZ",Mittal M,10.1109/ACCESS.2020.2996022,Kyoto Sangyo University,"Recent advances in deep learning, coupled with the onslaught of unlabelled medical data have drawn ever-increasing research interests by discovering multiple levels of distributed representations and solving complex medical related problems. Malaria disease detection in early stage requires an accurate and precise diagnosis in order to achieve successful patient remission. This paper proposes a comprehensive computer-aided diagnosis (CAD) scheme for identifying the presence of malaria parasites in thick blood smear images. The parameters of the scheme are pre-trained by functional link artificial neural network followed by sparse stacked autoencoder. The optimum size of the CAD scheme used in this research is 12500-2500-100-50-2, where the input layer has 12500 nodes and Softmax classifier output layer has 2 nodes. Moreover, the 10- fold cross validation reflects that the classification is reliable and is applicable to new patient blood smear images. The proposed CAD scheme has been evaluated using malaria blood smear image data set, achieving a detection accuracy of 89.10 & x0025;, a sensitivity of 93.90 & x0025; and specificity of 83.10 & x0025;. The extensive comparative experiment suggests that the proposed CAD scheme provides richer effectiveness and efficiency for malaria data set compared to other deep learning techniques for better diagnosis decision and management. This work implements a novel approach to fast processing and will be a beneficial tool in disease identification.","Diseases,Machine learning,Solid modeling,Blood,Microscopy,Biomedical imaging,Neural networks,Computer-aided diagnosis (CAD),Deep learning,malaria parasite detection,microscopic blood smear images,digital pathology,K-fold cross-validation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SALIENT,OBJECT,DETECTION,NEURAL-NETWORKS,AUTOENCODER,COMPRESSION,DIAGNOSIS,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09097238.pdf,
63,Research on Recognition of Medical Image Detection Based on Neural Network,8,,94947-94955,"Wang Shaoqiang,Wang Shudong,Zhang Song,Fan Fangfang,He Gewen","Wang SQ,Wang SD,Zhang S,Fan FF,He GW",Fan FF,10.1109/ACCESS.2020.2995466,Harvard University,"Bowel cancer, which is easily affected by diet and drugs, has some restrictive factors such as the fecal occult blood test (FOBT) in the routine detection and the high cost and inconvenience of microscopy. In order to break through these restrictive factors, a possible alternative method of FOBT is sought. In this paper, error back propagation neural network (BPNN) algorithm is used, and expression spectrum is used as an auxiliary method to detect medical images, and a colorectal cancer (CRC) diagnosis model based on neural network is constructed. The results show that the accuracy of the model on the training set and the test set are 0.943 and 0.935, respectively, the AUC reaches more than 0.95. Therefore, the CRC diagnosis model based on neural network provides a possible alternative method of FOBT. Experimental results show that the proposed algorithm have high robustness and accuracy, which meets the current clinical needs.","Cancer,Tumors,Magnetic resonance imaging,Pancreas,Medical diagnostic imaging,Neural networks,Neural network,fecal occult blood detection,error back propagation neural network,medical image",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RESECTION,MARGIN,CT-COLONOGRAPHY,RECTAL-CANCER,COLONOSCOPY,METAANALYSIS,POPULATION,PREDICTION,EMPHASIS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09095330.pdf,
64,A semi-automated machine learning-aided approach to quantitative analysis of centrosomes and microtubule organization.,133,14,,",,,,","Sankaran Divya Ganapathi,Stemm-Wolf Alexander J,McCurdy Bailey L,Hariharan Bharath,Pearson Chad G",,10.1242/jcs.243543,, © 2020. Published by The Company of Biologists Ltd.,"Centrosome amplification; Centrosomes; EB3; Image processing; ,Machine learning,; Microtubules","Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't",,,,,,,,
65,Predicting Language Difficulties in Middle Childhood From Early Developmental Milestones: A Comparison of Traditional Regression and Machine Learning Techniques,61,8,1926-1944,"Armstrong Rebecca,Symons Martyn,Scott James G.,Arnott Wendy L.,Copland David A.,McMahon Katie L.,Whitehouse Andrew J. O.","Armstrong R,Symons M,Scott JG,Arnott WL,Copland DA,McMahon KL,Whitehouse AJO",Armstrong R,10.1044/2018_JSLHR-L-17-0210,University of Queensland,"Purpose: The current study aimed to compare traditional logistic regression models with machine learning algorithms to investigate the predictive ability of (a) communication performance at 3 years old on language outcomes at 10 years old and (b) broader developmental skills (motor, social, and adaptive) at 3 years old on language outcomes at 10 years old.
Method: Participants (N = 1,322) were drawn from the Western Australian Pregnancy Cohort (Raine) Study (Straker et al., 2017). A general developmental screener, the Infant Monitoring Questionnaire (Squires, Bricker, & Potter, 1990), was completed by caregivers at the 3-year follow-up. Language ability at 10 years old was assessed using the Clinical Evaluation of Language Fundamentals-Third Edition (Semel, Wiig, & Secord, 1995). Logistic regression models and interpretable machine learning algorithms were used to assess predictive abilities of early developmental milestones for later language outcomes.
Results: Overall, the findings showed that prediction accuracies were comparable between logistic regression and machine learning models using communication-only performance as well as performance on communication and broader developmental domains to predict language performance at 10 years old. Decision trees are incorporated to visually present these findings but must be interpreted with caution because of the poor accuracy of the models overall.
Conclusions: The current study provides preliminary evidence that machine learning algorithms provide equivalent predictive accuracy to traditional methods. Furthermore, the inclusion of broader developmental skills did not improve predictive capability. Assessment of language at more than 1 time point is necessary to ensure children whose language delays emerge later are identified and supported.","EXPRESSIVE VOCABULARY DEVELOPMENT,AT-RISK INFANTS,RECEPTIVE VOCABULARY,SCHOOL ENTRY,MOTOR-SKILLS,LATE-TALKING,CHILDREN,OUTCOMES,DELAY,COMMUNICATION",Article,"AMER SPEECH-LANGUAGE-HEARING ASSOC, 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA","Audiology & Speech-Language Pathology,Linguistics,Rehabilitation",,,"EXPRESSIVE,VOCABULARY,DEVELOPMENT,AT-RISK,INFANTS,RECEPTIVE,VOCABULARY,SCHOOL,ENTRY,MOTOR-SKILLS,LATE-TALKING,CHILDREN,OUTCOMES,DELAY,COMMUNICATION",JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH,,
66,ADMIR-Affine and Deformable Medical Image Registration for Drug-Addicted Brain Images,8,,70960-70968,"Tang Kun,Li Zhi,Tian Lili,Wang Lihui,Zhu Yuemin","Tang K,Li Z,Tian LL,Wang LH,Zhu YM",Li Z,10.1109/ACCESS.2020.2986829,Guizhou University,"We proposed an unsupervised end-to-end Affine and Deformable Medical Image Registration (ADMIR) method based on convolutional neural network (ConvNet). ADMIR includes three key components: an affine registration module for learning the affine transformation parameters, a deformable registration module for learning the displacement vector field, and a spatial transformer for getting the final warped image from both affine and deformable transformation parameters. To evaluate its performance, the magnetic resonance images of drug-addicted brains were used to train and test the model, and we compared it with two state-of-art methods in terms of Dice score, Hausdorff distance, and average symmetric surface distance. The experimental results demonstrated that our proposed ADMIR model outperforms existing methods even with the images without pre-alignment, which suggests that the ADMIR model can be used to achieve quick medical image registration with high accuracy.","Deformable image registration,affine registration,convolutional neural network,unsupervised learning,end-to-end registration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,MAXIMIZATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09062524.pdf,
67,Internet of Medical Things-Based on Deep Learning Techniques for Segmentation of Lung and Stroke Regions in CT Scans,8,,71117-71135,"Han Tao,Nunes Virginia Xavier,De Freitas Souza Luis Fabricio,Marques Adriell Gomes,Lima Silva Iagson Carlos,Araujo Ferreira Junior Marcos Aurelio,Sun Jinghua,Reboucas Filho Pedro P.","Han T,Nunes VX,Souza LFD,Marques AG,Silva ICL,Ferreira MAA,Sun JH,Reboucas PP",Han T,10.1109/ACCESS.2020.2987932,Dongguan University of Technology,"The classification and segmentation of pathologies through intelligent systems is a significant challenge for medical image analysis and computer vision systems. Diseases, such as lung problems and strokes, have a serious effect on human health worldwide. Lung diseases are among the leading causes of death worldwide, lagging behind strokes that in 2016 became the second leading cause of death from illnesses. Computed tomography (CT) is one of the main clinical diagnostic exams, linked to Computerized Diagnostic Assistance Systems (CAD), which are becoming solutions for health technologies. In this work, we propose a method based on the health of things for the classification and segmentation of CT images of the lung and hemorrhagic stroke. The system called HTSCS - Medical Images: Health-of-Things System for the Classification and Segmentation of Medical Images, uses transfer learning between models based on deep learning combined with classical methods for fine-tuning. The proposed method obtained excellent results for the classification of hemorrhagic stroke and pulmonary regions, with values of up to 100% accuracy. The models also achieved outstanding performances for segmentation, with Accuracy above 99 % and Dice coefficient above 97% in the best cases with an average segmentation time between 0.095 and 1.7 seconds. To validate our approach, we compared our best models for the segmentation of lung and hemorrhagic stroke in CTs, with related works found in state of the art. Our method brings an innovative approach to classification and segmentation through the use of the Health of Things for different types of medical images with promising results for medical image analysis and computer vision fields.","Image segmentation,Medical diagnostic imaging,Computed tomography,Lung,Hemorrhaging,Diseases,Health of things,classification and segmentation,CTs lung and stroke,transfer learning,fine-tuning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,QUANTITATIVE,COMPUTED-TOMOGRAPHY,IMAGE,SEGMENTATION,ACTIVE,CONTOUR,BRAIN,DISEASE,EQUALITY,SYSTEM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09066845.pdf,
68,Metalearning approach for leukemia informative genes prioritization,17,1,,"Rodrigues Vania,Deusdado Sergio","Rodrigues V,Deusdado S",Deusdado S,10.1515/jib-2019-0069,Instituto Politecnico de Braganca,"The discovery of diagnostic or prognostic biomarkers is fundamental to optimize therapeutics for patients. By enhancing the interpretability of the prediction model, this work is aimed to optimize Leukemia diagnosis while retaining a high-performance evaluation in the identification of informative genes. For this purpose, we used an optimal parameterization of Kernel Logistic Regression method on Leukemia microarray gene expression data classification, applying metalearners to select attributes, reducing the data dimensionality before passing it to the classifier. Pearson correlation and chi-squared statistic were the attribute evaluators applied on metalearners, having information gain as single-attribute evaluator. The implemented models relied on 10-fold cross-validation. The metalearners approach identified 12 common genes, with highest average merit of 0.999. The practical work was developed using the public datamining software WEKA.","informative genes,leukemia,machine learning,metalearning,microarray",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Mathematical & Computational Biology,,,"EXPRESSION,TCL1,APOPTOSIS,ISOFORMS",JOURNAL OF INTEGRATIVE BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734502,
69,CT-based Radiomic Signatures for Predicting Histopathologic Features in Head and Neck Squamous Cell Carcinoma.,2,3,e190039,",,,,,,,","Mukherjee Pritam,Cintra Murilo,Huang Chao,Zhou Mu,Zhu Shankuan,Colevas A Dimitrios,Fischbein Nancy,Gevaert Olivier",,10.1148/rycan.2020190039,,"Purpose: To determine the performance of CT-based radiomic features for noninvasive prediction of histopathologic features of tumor grade, extracapsular spread, perineural invasion, lymphovascular invasion, and human papillomavirus status in head and neck squamous cell carcinoma (HNSCC).Results: The trained radiomic model demonstrated moderate capability of predicting HNSCC features. In the training cohort and the test cohort, the model achieved a mean area under the receiver operating characteristic curve (AUC) of 0.75 (95% confidence interval [CI]: 0.68, 0.81) and 0.66 (95% CI: 0.45, 0.84), respectively, for tumor grade; a mean AUC of 0.64 (95% CI: 0.55, 0.62) and 0.70 (95% CI: 0.47, 0.89), respectively, for perineural invasion; a mean AUC of 0.69 (95% CI: 0.56, 0.81) and 0.65 (95% CI: 0.38, 0.87), respectively, for lymphovascular invasion; a mean AUC of 0.77 (95% CI: 0.65, 0.88) and 0.67 (95% CI: 0.15, 0.80), respectively, for extracapsular spread; and a mean AUC of 0.71 (95% CI: 0.29, 1.0) and 0.80 (95% CI: 0.65, 0.92), respectively, for human papillomavirus status. 2020 by the Radiological Society of North America, Inc.",,"Journal Article; Research Support, N.I.H., Extramural",,,,,,,,
70,The virtue of simplicity: On machine learning models in algorithmic trading,7,1,,Hansen Kristian Bondo,Hansen KB,Hansen KB,10.1177/2053951720926558,Copenhagen Business School,"Machine learning models are becoming increasingly prevalent in algorithmic trading and investment management. The spread of machine learning in finance challenges existing practices of modelling and model use and creates a demand for practical solutions for how to manage the complexity pertaining to these techniques. Drawing on interviews with quants applying machine learning techniques to financial problems, the article examines how these people manage model complexity in the process of devising machine learning-powered trading algorithms. The analysis shows that machine learning quants use Ockham's razor - things should not be multiplied without necessity - as a heuristic tool to prevent excess model complexity and secure a certain level of human control and interpretability in the modelling process. I argue that understanding the way quants handle the complexity of learning models is a key to grasping the transformation of the human's role in contemporary data and model-driven finance. The study contributes to social studies of finance research on the human-model interplay by exploring it in the context of machine learning model use.","Ockham's razor,algorithmic trading,distributed cognition,model overfitting,explainability",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA",Social Sciences - Other Topics,,8.118,"MATERIAL,POLITICAL-ECONOMY,DISTRIBUTED,COGNITION,HISTORICAL,SOCIOLOGY,MARKET,SCIENCE,VALUES,COSTS,FRAME",BIG DATA & SOCIETY,https://journals.sagepub.com/doi/pdf/10.1177/2053951720926558,
71,Robust random forest based non-fullerene organic solar cells efficiency prediction,76,,,Lee Min-Hsuan,Lee MH,Lee MH,10.1016/j.orgel.2019.105465,Industrial Technology Research Institute - Taiwan,"Non-fullerene materials have attracted attention as high-performance molecular acceptors in organic solar cells (OSCs). A proper understanding of the energy level alignment between donors and non-fullerene acceptors is crucial for photoactive materials selection in designing high-performance non-fullerene OSCs. However, the quantitative assessment for the proper selection of donors and non-fullerene acceptors is still rarely studied, which is seen as time-consuming and complicated tasks. In this study, the optimized Random Forest model based on the electronic descriptors (e.g., highest occupied molecular orbitals levels, lowest unoccupied molecular orbitals levels, and band gap) provides the high predictive power, reaching the coefficient of determination (R-2) of 0.85 and 0.80 for the training set and testing set, respectively. The use of machine learning approach benefits the development of non-fullerene OSCs in two ways: (1) it helps to extract complex correlation between various descriptors and device performance, and (2) it indicates that the band gap of acceptors is the more critical feature for improving the efficiency of non-fullerene OSCs. The machine-learning model for predicting the efficiency of non-fullerene OSCs (macroscopic performance) from frontier molecular orbital energy levels of the organic materials (microscopic properties) is developed, as an important guide to design the heterojunction blends and accelerate the research for non-fullerene OSCs.","Non-fullerene organic solar cells,Machine-learning,Random forest",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Materials Science,Physics",,3.375,"RECENT,PROGRESS,ACCEPTORS,OPTIMIZATION,POLYMER",ORGANIC ELECTRONICS,,
72,Evaluation of Acute Tonic Cold Pain From Microwave Transcranial Transmission Signals Using Multi-Entropy Machine Learning Approach,8,,2780-2791,"Geng Daoshuang,Yang Daoguo,Cai Miao,Hao Weidong","Geng DS,Yang DG,Cai M,Hao WD",Geng DS,10.1109/ACCESS.2019.2962515,Guilin University of Electronic Technology,"This study aims to improve the accuracy of detecting acute tonic cold pain (CP) perception from microwave transcranial transmission (MTT) signals. Two different types of CP and no-pain (NP) MTT signals are obtained from 15 subjects. Four features, namely, power spectral exponential entropy, improved multiscale permutation entropy, refined composite multiscale dispersion entropy, and refined composite multiscale fuzzy entropy, are extracted in the variational modal decomposition domain. The feature datasets are divided into training datasets and test datasets in a 3:1 ratio. Random forest (RF) and support vector machine (SVM) are selected as classifiers. The training datasets are imported into the classifier, and the optimal training dataset is obtained with a 10-fold cross validation strategy. The feature dimension reduction algorithm of the principal component analysis is used to reduce the complexity of the feature datasets and select the most recognizable features. The classification performance of the test datasets is evaluated by the optimal classifiers. Results showed that the RF classifier performs better than the SVM classifier. The RF classifier provides high values of specificity (91.67%), sensitivity (95.83%), positive predictive value (92.00%), accuracy (93.75%), and area under curve (0.867). The combination of the microwave detection approach and machine learning algorithm can effectively detect brain activity induced by nociceptive stimulation. This approach is important in improving the accuracy of pain detection.","Pain recognition,microwave scattering,random forest,performance evaluation,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ELECTROMAGNETIC-FIELDS,DISPERSION,ENTROPY,MODE,DECOMPOSITION,EEG,CLASSIFICATION,PERCEPTION,ELECTROENCEPHALOGRAM,TRANSFORM,EXPOSURE,PHONES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08943395.pdf,
73,Data-Driven Designing of Microstructures and Properties of Magnesium Alloys,39,1,1-11,",,,,,,","Zeng Xiaoqin,Xie Tian,Ying Tao,Zhu Hong,Liu Yanwei,Wang Leyun,Ding Wenjiang",,,Zeng Xiaoqin,"With the proposal of Material Genome Initiative and the rapid development of big data technology and artificial intelligence(AI),data-driven new material design has received widespread attention and gradually become an important method for researching and developing new materials.In recent years,researchers worldwide have carried out a lot of work on high-throughput calculations and AI-based materials design.They have obtained a large number of physical parameters that are difficult to obtain directly by experimental methods.That is the essence of data-driven materials design.Magnesium alloys have shown good application prospects in aerospace,electronic information and biomedical fields,but their low strength,poor plasticity,and low corrosion resistance have limited their further applications.This paper summarizes the recent researches for magnesium alloys based on first-principles calculation of density functional theory and the machine learning method of computer artificial intelligence,focusing on the mechanical properties,structures,microstructures of magnesium alloys(such as thermodynamic stability,energy barriers starting slip systems,relations between mechanical properties and constitutions /processes /microstructures),and corrosion resistance(such as the calculation of anode electrode potential,work function,cathode surface hydrolysis and hydrogen evolution reaction).Finally,the problems needed to be solved in the future are discussed.","magnesium alloy; first-principles calculation; ,machine learning,; mechanical properties; corrosion resistance",Article,,,,,,,,
74,Deep Convolutional Network for Stereo Depth Mapping in Binocular Endoscopy,8,,73241-73249,"Wang Xiong-Zhi,Nie Yunfeng,Lu Shao-Ping,Zhang Jingang","Wang XZ,Nie YF,Lu SP,Zhang JG",Zhang JG,10.1109/ACCESS.2020.2987767,Chinese Academy of Sciences,"Depth mapping from binocular endoscopy images plays an important role in stereoscopic surgical treatment. Owing to the development of deep convolutional neural networks (CNNs), binocular depth estimation models have achieved many exciting results in the fields of autonomous driving and machine vision. However, the application of these methods to endoscopic imaging is greatly limited by the fact that binocular endoscopic images not only are rare, but also have unsatisfying features such as no texture, no ground truth, bad contrast, and high gloss. Aiming at solving the above-mentioned problems, we have built a precise gastrointestinal environment by the open-source software blender to simulate abundant binocular endoscopy data and proposed a 23-layer deep CNNs method to generate real-time stereo depth mapping. An efficient scale-invariant loss function is introduced in this paper to accommodate the characteristics of endoscope images, which improves the accuracy of achieved depth mapping results. Regarding the considerable training data for typical CNNs, our method requires only a few images resolution) at 45 frames per second on an NVIDIA GTX 1080 GPU module, then the depth mapping information is generated in real-time with satisfactory accuracy. The effectiveness of the developed method is validated by comparing with state-of-the-art methods on processing the same datasets, demonstrating a faster and more accurate performance than other model frames.","Estimation,Surgery,Real-time systems,Cameras,Endoscopes,Three-dimensional displays,Gastrointestinal tract,Binocular endoscopes,deep convolutional neutral network,real-time evaluation,stereo depth mapping",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BELIEF,PROPAGATION,COST,AGGREGATION,ACCURATE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09064889.pdf,
75,Hybrid Automatic Lung Segmentation on Chest CT Scans,8,,73293-73306,"Peng Tao,Xu Thomas Canhao,Wang Yihuai,Zhou Hailing,Candemir Sema,Zaki Wan Mimi Diyana Wan,Ruan Shanq-Jang,Wang Jing,Chen Xinjian","Peng T,Xu TC,Wang YH,Zhou HL,Candemir S,Zaki WMDW,Ruan SJ,Wang J,Chen XJ",Xu TC,10.1109/ACCESS.2020.2987925,Suzhou University,"Accurate lung segmentation in chest Computed Tomography (CT) scans is a challenging problem because of variations in lung volume shape, susceptibility to partial volume effects that affect thin antero-posterior junction lines, and lack of contrast between the lung and surrounding tissues. To address the need for a robust method for lung segmentation, we present a new method, called Pixel-based two-Scan Connected Component Labeling-Convex Hull-Closed Principal Curve method (PSCCL-CH-CPC), which automatically detects lung boundaries, and surpasses state-of-the-art performance. The proposed method has two main steps: 1) an image preprocessing step to extract coarse lung contours, and 2) a refinement step to refine the coarse segmentation result on the basis of the improved principal curve model and the machine learning model. Experimental results show that the proposed method has good performance, with a Dice Similarity Coefficient (DSC) as high as 98.21%. When compared with state-of-the-art methods, our proposed method achieved superior segmentation results, with an average DSC of 96.9%.","Lung,Image segmentation,Computed tomography,Shape,Machine learning,Biomedical imaging,Flowcharts,Automatic lung segmentation,chest CT scans,principal curve,closed principal curve method,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PULMONARY,NODULES,CONVEX-HULL,ALGORITHM,DIAGNOSIS,DISEASE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09066949.pdf,
76,Cross-Section Bead Image Prediction in Laser Keyhole Welding of AISI 1020 Steel Using Deep Learning Architectures,8,,73359-73372,"Oh Sehyeok,Ki Hyungson","Oh S,Ki H",Ki H,10.1109/ACCESS.2020.2987858,Ulsan National Institute of Science & Technology (UNIST),"A deep learning model was applied for predicting a cross-sectional bead image from laser welding process parameters. The proposed model consists of two successive generators. The first generator produces a weld bead segmentation map from laser intensity and interaction time, which is subsequently translated into an optical microscopic (OM) image by the second generator. Both generators exhibit an encoder-decoder structure based on a convolutional neural network (CNN). In the second generator, a conditional generative adversarial network (cGAN) was additionally employed with multiscale discriminators and residual blocks, considering the size of the OM image. For a training dataset, laser welding experiments with AISI 1020 steel were conducted on a large process window using a 2 KW fiber laser, and a total of 39 process conditions were used for the training. High-resolution OM images were successfully generated, and the predicted bead shapes were reasonably accurate (R-Squared: 89.0% for penetration depth, 93.6% for weld bead area).","Welding,Laser beams,Laser modes,Machine learning,Generators,Power lasers,Fiber lasers,Laser welding,weld-bead prediction,deep learning,image-to-image translation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PENETRATION,DEPTH,PARAMETERS,MODEL,SHAPE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09066982.pdf,
77,CNN With Large Data Achieves True Zero-Training in Online P300 Brain-Computer Interface,8,,74385-74400,"Lee Jongmin,Won Kyungho,Kwon Moonyoung,Jun Sung Chan,Ahn Minkyu","Lee J,Won K,Kwon M,Jun SC,Ahn M",Ahn M,10.1109/ACCESS.2020.2988057,Handong Global University,"Each person has his or her own distinct event-related potential (ERP) signals. Thus, traditional brain-computer interface (BCI) systems require a calibration process in which the subject & x2019;s data are extracted in order to train machine-learning classifiers. Despite past efforts to eliminate this process, often referred to as & x201C;zero-training,& x201D; BCI systems & x2019; best performance is achievable only with some level of calibration. This tedious process is one of the factors that have limited the use of BCI systems in the real world. Meanwhile, convolutional neural networks (CNN) have been proven to be useful in distinguishing neurophysiological features. In this study, we investigated whether an existing convolutional neural network (CNN) combined with large ERP samples (n & x003D; 99,000) can achieve zero-training in a P300 BCI speller system. As a result, the zero-trained CNN achieved comparable performance (89 & x0025;, p & x003C; 0.05) when compared to traditional approaches (94 & x0025;) in an offline study. We also demonstrate that the constructed CNN works successfully in an online experiment in which twelve BCI subjects achieved 85 & x0025; mean accuracy without calibration, compared to 82 & x0025; (but the difference was not significant, p & x003E; 0.05) with calibration. Additionally, we illustrate a hybrid approach in order to further enhance performance, which adaptively updates a linear classifier using label information generated from a zero-trained CNN. With this technique, the hybrid approach achieved reasonable performance (92 & x0025;), showing no statistical difference (p & x003E; 0.05) when compared to the traditional approach in the same offline data.","Calibration,Training,Machine learning,Brain-computer interfaces,Linear discriminant analysis,Robustness,Electroencephalography,Brain-computer interface,machine learning,P300 speller,zero-training",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,GAMES,BCI",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09068248.pdf,
78,Crack Detection in Paintings Using Convolutional Neural Networks,8,,74535-74552,"Sizyakin Roman,Cornelis Bruno,Meeus Laurens,Dubois Helene,Martens Maximiliaan,Voronin Viacheslav,Pizurica Aleksandra","Sizyakin R,Cornelis B,Meeus L,Dubois H,Martens M,Voronin V,Pizurica A",Sizyakin R; Pizurica A,10.1109/ACCESS.2020.2988856,Ghent University,"The accurate detection of cracks in paintings, which generally portray rich and varying content, is a challenging task. Traditional crack detection methods are often lacking on recent acquisitions of paintings as they are poorly adapted to high-resolutions and do not make use of the other imaging modalities often at hand. Furthermore, many paintings portray a complex or cluttered composition, significantly complicating a precise detection of cracks when using only photographic material. In this paper, we propose a fast crack detection algorithm based on deep convolutional neural networks (CNN) that is capable of combining several imaging modalities, such as regular photographs, infrared photography and X-Ray images. Moreover, we propose an efficient solution to improve the CNN-based localization of the actual crack boundaries and extend the CNN architecture such that areas where it makes little sense to run expensive learning models are ignored. This allows us to process large resolution scans of paintings more efficiently. The proposed on-line method is capable of continuously learning from newly acquired visual data, thus further improving classification results as more data becomes available. A case study on multimodal acquisitions of the Ghent Altarpiece, taken during the currently ongoing conservation-restoration treatment, shows improvements over the state-of-the-art in crack detection methods and demonstrates the potential of our proposed method in assisting art conservators.","Painting,Convolutional neural networks,Machine learning,Art,Imaging,Paints,X-ray imaging,Digital painting analysis,crack detection,virtual restoration,machine learning,morphological filtering,convolutional neural networks,transfer learning,multimodal data,Ghent Altarpiece",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE,CLASSIFICATION,REMOVAL",IEEE ACCESS,https://doi.org/10.1109/access.2020.2988856,
79,End-Face Localization and Segmentation of Steel Bar Based on Convolution Neural Network,8,,74679-74690,"Zhu Yongjian,Tang Chuliu,Liu Hao,Huang Pengchi","Zhu YJ,Tang CL,Liu H,Huang PC",Tang CL,10.1109/ACCESS.2020.2989300,Guangxi Normal University,"Both number manually-counting method and traditional Machine-Vision (MV) number counting strategy are laborious and very time-consuming (sometimes several hours). Thus a new deep learning (DL) fusion model is proposed, which includes object detection and semantic segmentation. It can solve the problems of end-face localization and segmentation of steel bars at the same time. In this fusion model, firstly, an improved data augmentation method namely, Sliding Window Data Augmentation (SWDA) is adopted to compensate less training data concerning object detection, based on which a new object-detection architecture, Inception-RFB-FPN is presented to improve the accuracy and inference time. Secondly, a novel AI labeling method, Fibonacci-incremental mask labeling method (FIMLM) is introduced to accelerate the generation of annotation mask. Furthermore, by contrast, three FCN (Fully Convolutional Networks) architectures of data segmentation, namely, VGG16-FCN, ResNet18-FCN, and ResNet34-FCN are used to conduct the end-face segmentations of steel bars separately. Finally, a series of experiments show that the proposed Inception-RFB-FPN model can reach 98.17 & x0025; in F1 score (harmonic mean value of precision and recall) with respect to object detection, and its inference time only needs 0.0306 seconds, much faster than some related reports. In addition, the FIMLM-based ResNet34-FCN model can reach 97.47 & x0025; in mean Intersection-Over-Union (mIOU) with respect to semantic segmentation, higher than both VGG16-FCN and ResNet18-FCN.","Steel,Bars,Object detection,Semantics,Labeling,Image segmentation,Data models,Steel bar,data augmentation,object detection,semantic segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2989300,
80,DeTrac: Transfer Learning of Class Decomposed Medical Images in Convolutional Neural Networks,8,,74901-74913,"Abbas Asmaa,Abdelsamea M. O. H. A. M. M. E. D. M.,Gaber Mohamed Medhat","Abbas A,Abdelsamea MM,Gaber MM",Abdelsamea MM,10.1109/ACCESS.2020.2989273,Egyptian Knowledge Bank (EKB),"Due to the high availability of large-scale annotated image datasets, paramount progress has been made in deep convolutional neural networks (CNNs) for image classification tasks. CNNs enable learning highly representative and hierarchical local image features directly from data. However, the availability of annotated data, especially in the medical imaging domain, remains the biggest challenge in the field. Transfer learning can provide a promising and effective solution by transferring knowledge from generic image recognition tasks to the medical image classification. However, due to irregularities in the dataset distribution, transfer learning usually fails to provide a robust solution. Class decomposition facilitates easier to learn class boundaries of a dataset, and consequently can deal with any irregularities in the data distribution. Motivated by this challenging problem, the paper presents Decompose, Transfer, and Compose (DeTraC) approach, a novel CNN architecture based on class decomposition to improve the performance of medical image classification using transfer learning and class decomposition approach. DeTraC enables learning at the subclass level that can be more separable with a prospect to faster convergence. We validated our proposed approach with three different cohorts of chest X-ray images, histological images of human colorectal cancer, and digital mammograms. We compared DeTraC with the state-of-the-art CNN models to demonstrate its high performance in terms of accuracy, sensitivity, and specificity.","Biomedical imaging,Feature extraction,Lung,Task analysis,Machine learning,Computed tomography,Training,Convolution neural networks,class decomposition,data irregularity,medical image classification,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DEEP,CLASSIFICATION,PREDICTION",IEEE ACCESS,http://www.open-access.bcu.ac.uk/9172/1/DeTraC.pdf,
81,Mammographic Classification Based on XGBoost and DCNN With Multi Features,8,,75011-75021,"Song Runyu,Li Taoying,Wang Yan","Song RY,Li TY,Wang Y",Li TY,10.1109/ACCESS.2020.2986546,Dalian Maritime University,"The classification of benign and malignant masses in mammograms by Computer-Aided Diagnosis (CAD) is one of the most difficult and important tasks in the development of CAD systems. This classification has commonly been automated by extracting a set of handcrafted features from mammograms and relating the responses to breast cancer. Recently, the application of Deep Learning (DL) technology in medical imaging informatics has been attracting extensive research interest. However, limited medical image datasets and feature expression often reduce the performance of DL-based schemes. Therefore, this study aims to develop a new combined feature CAD method based on DL for classifying mammographic masses into three classes: normal, benign and cancer (malignant) masses. Three kinds of breast masses were scored by using Deep Convolution Neural Network (DCNN) as a feature extractor. Then the scoring features are combined with the image texture features as input to the classifier. This features including the scoring features, Gray-Level Co-occurrence Matrix (GLCM) and Histogram of Oriented Gradient (HOT) were employed to extract the breast mass information in mammograms and the classifier of Support Vector Machine (SVM) and Extreme Gradient Boosting (XGBoost) were trained for the classification task. Accuracy (ACC), Precision (Pre), Recall (Rec), F1-score (F1), and Overall Accuracy (Overall ACC) are used to evaluate the performance of the proposed system and the results show that the proposed multi-features combination model performs the best results. The performance of the XGBoost classifier has proved to be better in comparison to the SVM classification algorithms. As a result, when XGBoost was used as a classifier, the correct identification rate of the Overall ACC was 92.80 & x0025; and that of malignant tumors was 84 & x0025;, with reasonable and best results. These results indicate that the proposed method may help in more accurately diagnosing cases that are difficult to classify on images.","Deep learning,computer-aided diagnosis,deep convolution neural network,mammograms classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMPUTER-AIDED,DIAGNOSIS,DENSITY,SEGMENTATION,ORIENTED,GRADIENTS,TEXTURAL,FEATURES,NEURAL-NETWORKS,MASSES,PERFORMANCE,ARCHITECTURES,HISTOGRAMS,SIMILARITY",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09060963.pdf,
82,A Spatiotemporal Agent for Robust Multimodal Registration,8,,75347-75358,"Luo Ziwei,Wang Xin,Wu Xi,Yin Youbing,Cao Kunlin,Song Qi,Hu Jing","Luo ZW,Wang X,Wu X,Yin YB,Cao KL,Song Q,Hu J",Hu J,10.1109/ACCESS.2020.2989150,Chengdu University of Information Technology,"Multimodal image registration is a crucial step for a variety of medical applications to provide complementary information from the combination of various data sources. Conventional image registration methods aim at finding a suited similarity metric as well as a descriptive image feature, which is quite challenging due to the high diversity of tissue appearance across modalities. In this paper, we present a novel approach to register images via an asynchronously trained reinforcement learning agent automatically. Within this approach, convolutional gated recurrent units (ConvGRU) is incorporated after stacked convolutional layers to extract both spatial and temporal features of the neighboring frames and implicitly learn the similarity metric. Moreover, we propose a customized reward function driven by fixed points error (FPE) to guide the agent to the correct registration direction. A Monte Carlo rollout strategy is also leveraged to perform a look-ahead inference to the elimination of jitter in the test stage. Evaluation is performed on paired CT and MR images from patients diagnosed as nasopharyngeal carcinoma. The results demonstrate that our method achieves state-of-the-art performance in medical image registration.","Medical image,reinforcement learning,multimodal registration,actor-critic,convolutional GRU",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,NETWORKS,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09075173.pdf,
83,Deep Fusion Feature Extraction and Classification of Pellet Phase,8,,75428-75436,"Li Jie,Zhang Liyan,Wang Yang,Li Fei,Li Daliang,Han Yang","Li J,Zhang LY,Wang Y,Li F,Li DL,Han Y",Han Y,10.1109/ACCESS.2020.2988831,North China University of Science & Technology,"Pellet quality including chemical composition, physical properties and metallurgical performance of three parts, its quality and mineral composition, properties and structure of the pellets has the close relation, studies show that the mineralogical micro structure and distribution of pellets had significant effects on the metallurgical properties, so the analysis and determination of pellets of mineral composition and micro structure is very important to improve the quality of pellets. Paper to pellets micro mineral as the research object, mainly studies the CNN and PCA two kinds of image processing algorithm, in the heart of the traditional model of CNN structure characteristics obtained by convolution PCA dimension reduction at a time, will be the main features of PCA to extract into the depth of the CNN learning, realize the mineral phase of shallow and deep information of the image to do effective fusion, in a larger extent, reflects the mineralogical characteristics, thus more intuitive response metallurgical properties. The location and alkalinity of the ore phase were identified by the extracted deep fusion feature, and the results were compared with those of the traditional CNN algorithm. It was found that the accuracy of location and alkalinity recognition of PCA and CNN coupling algorithm was 93.82 & x0025; and 91.26 & x0025;, respectively, which were higher than the accuracy of traditional CNN algorithm 92.73 & x0025; and 88.93 & x0025;, which verified the accuracy of PCA and CNN coupling model and its applicability in mineral phase recognition.","Feature extraction,Principal component analysis,Ores,Convolution,Couplings,Dimensionality reduction,CNN,feature fusion,PCA",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09076164.pdf,
84,Deep Learning Initialized and Gradient Enhanced Level-Set Based Segmentation for Liver Tumor From CT Images,8,,76056-76068,"Zhang Yue,Jiang Benxiang,Wu Jiong,Ji Dongcen,Liu Yilong,Chen Yifan,Wu Ed X.,Tang Xiaoying","Zhang Y,Jiang BX,Wu J,Ji DC,Liu YL,Chen YF,Wu E,Tang XY",Tang XY,10.1109/ACCESS.2020.2988647,Southern University of Science & Technology,"Liver and liver tumor segmentation provides vital biomarkers for surgical planning and hepatic diagnosis. In this paper, we propose and validate a novel level-set method integrating an enhanced edge indicator and an automatically derived initial curve for CT based liver tumor segmentation. At the preprocessing step, the CT image intensity values were truncated to lie in a fixed range to enhance the image contrast surrounding liver and liver tumor. To remove non-liver tissues for subsequent tumor segmentation, liver was firstly segmented using two convolutional neural networks in a coarse-to-fine manner. A 2D slice-based U-net was used to roughly localize the liver and a 3D patch-based fully convolutional network was used to refine the liver segmentation as well as to roughly localize the liver tumor. A novel level-set method was then presented to further refine the tumor segmentation. Specifically, the probabilistic distribution of the liver tumor was estimated using unsupervised fuzzy c-means clustering, which was then utilized to enhance the edge-detector used in level-set. Effectiveness of the proposed pipeline was validated on two publicly-available datasets. Experimental results identified the superior segmentation performance of the proposed pipeline over state-of-the-art methods.","Liver,Tumors,Image segmentation,Computed tomography,Three-dimensional displays,Machine learning,Two dimensional displays,Segmentation,convolutional neural network,liver tumor,level-set,fuzzy c-means",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MODEL,MRI",IEEE ACCESS,https://doi.org/10.1109/access.2020.2988647,
85,Point Supervised Extended Scenario Nuclear Analysis Framework Based on LSTM-CFCN,8,,76867-76879,"Sui Dong,Guo Maozu,Yang Fei,Zhang Lei","Sui D,Guo MZ,Yang F,Zhang L",Sui D,10.1109/ACCESS.2020.2984996,Beijing University of Civil Engineering & Architecture,"Cells and cell like particles detection and segmentation are of significant interest to many biological and clinical studies. Traditionally, these tasks are usually performed by visual inspection, which is time consuming, labor intensity and prone to induce subjective bias between different people. These make automatic cell analysis protocols essential for large-scale and objective studies. In recent years, imaging technical has been significantly advanced following the great success by computer vision. In addition, these technologies enable the cross module microscopy analysis, and make the task of cell analysis extremely challenging. Over these decades, computer aided cell detection, counting and segmentation have evolved from earlier filter based methods to the state-of-art deep learning protocols. However, there are still few suitable frameworks that can process multiple source cell images at the same time. In this paper, we seek a different route and propose a novel efficient framework for robust cell analysis based on Long Short Term Memory Channeled Fully Convolution Neural Networks (LSTM-CFCN). The results demonstrates that our framework is able to perform most of cell detection, counting and segmentation tasks from different cell type, and it can also cover most kinds of microscopy images scenarios including dark field, bright field, pathological and electron images. We have perform substantial experiments on several benchmark datasets, the LSTM-CFCN achieves the highest or at least top-2 performance in terms of F1-score, compared with other state-of-the-art methods.","Cell analysis,LSTM-CFCN,multi-task learning,multi-scale image processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COUNTING,METHOD,CELL,DETECTION,SEGMENTATION,FILTER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09052720.pdf,
86,Alzheimer's Diseases Detection by Using Deep Learning Algorithms: A Mini-Review,8,,77131-77141,"Al-Shoukry Suhad,Rassem Taha H.,Makbol Nasrin M.","Al-Shoukry S,Rassem TH,Makbol NM",Rassem TH,10.1109/ACCESS.2020.2989396,Universiti Malaysia Pahang,"The accurate diagnosis of Alzheimer's disease (AD) plays an important role in patient treatment, especially at the disease's early stages, because risk awareness allows the patients to undergo preventive measures even before the occurrence of irreversible brain damage. Although many recent studies have used computers to diagnose AD, most machine detection methods are limited by congenital observations. AD can be diagnosed-but not predicted-at its early stages, as prediction is only applicable before the disease manifests itself. Deep Learning (DL) has become a common technique for the early diagnosis of AD. Here, we briefly review some of the important literature on AD and explore how DL can help researchers diagnose the disease at its early stages.","Dementia,Magnetic resonance imaging,Brain,Single photon emission computed tomography,Biomedical imaging,Alzheimer's disease,deep learning,early stage detection and diagnosis",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,SEGMENTATION,INFORMATION,BIOMARKERS,NETWORKS,YOUNG,FMRI",IEEE ACCESS,https://doi.org/10.1109/access.2020.2989396,
87,Classification of Focal and Non-Focal Epileptic Patients Using Single Channel EEG and Long Short-Term Memory Learning System,8,,77255-77262,"Fraiwan Luay,Alkhodari Mohanad","Fraiwan L,Alkhodari M",Fraiwan L,10.1109/ACCESS.2020.2989442,Abu Dhabi University,"The process of inspecting electroencephalography (EEG) signals of patients with epilepsy to distinguish between focal and non-focal seizure source is a crucial step prior to surgical interference. In this paper, a deep learning approach using a long short-term memory (LSTM) algorithm is investigated for the purpose of automatic discrimination between focal and non-focal epileptic EEG signals. The study is carried out by acquiring 7500 pairs of x and y EEG channels signals from the publicly available Bern-Barcelona EEG database. The manual classification of each signal type was visually done by two board-certified electroencephalographers and neurologists. Initially, every channel signals are pre-processed using -score normalization and Savitzky-Golay filtering. The signals are used as inputs to a pre-defined Bi-directional LSTM algorithm for the training process. The classification is performed using a k-fold cross-validation following 4-, 6-, and 10-fold schemes. At the end, the performance of the algorithm is evaluated using several metrics with a complete summary table of the recent state-of-art studies in the field. The developed algorithm achieved an overall Cohen & x2019;s kappa , accuracy, sensitivity, and specificity values of 99.20 & x0025;, 99.60 & x0025;, 99.55 & x0025;. and 99.65 & x0025;, respectively, using x channels and 10-fold cross-validation scheme. The study pave the ways toward implementing deep learning algorithms for the purpose of EEG signals identification in a clinical environment to overcome human errors resulting from visually inspection.","Electroencephalography,Epilepsy,Surgery,Logic gates,Training,Computer architecture,Machine learning,Classification,electroencephalography (EEG),epilepsy,focal,long-short-term memory (LSTM),non-focal,training",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AUTOMATED,DETECTION,SIGNALS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09076014.pdf,
88,Unsupervised Multi-Discriminator Generative Adversarial Network for Lung Nodule Malignancy Classification,8,,77725-77734,"Kuang Yan,Lan Tian,Peng Xueqiao,Selasi Gati Elvis,Liu Qiao,Zhang Junyi","Kuang Y,Lan T,Peng XQ,Selasi GE,Liu Q,Zhang JY",Lan T,10.1109/ACCESS.2020.2987961,University of Electronic Science & Technology of China,"Computer-aided diagnosis systems with deep learning frameworks have been used to identify benign and malignant pulmonary nodules in lung cancer diagnosis. It & x2019;s commonly known that a premise of training complex deep neural nets is the large-scale labeled datasets. However, the abundance of labeled datasets is usually unavailable in many medical image domains. This factor can lead to the poor generalization performance of deep learning models. In this paper, we propose a novel multi-discriminator generative adversarial network model combined with an encoder for the classification of benign and malignant pulmonary nodules. To the best of our knowledge, we are the first to apply unsupervised learning to identify benign and malignant lung nodules. Firstly, we use a multi-discriminator generative adversarial network to build a generative model trained with unlabeled benign lung nodule images. Then an encoder is combined with the trained generative model to establish a mapping of benign pulmonary nodule images to the latent space. The benign and malignant lung nodules are scored by calculating the GAN discriminator feature loss and image reconstruction loss. The model yields high anomaly scores on malignant images and low anomaly scores on benign images. Experimental results show that our method with only a small number of unlabeled datasets could achieve more competitive results compared with other supervised deep learning approaches.","Cancer,Lung,Training,Generative adversarial networks,Gallium nitride,Machine learning,Biomedical imaging,Computer-aided diagnosis (CAD),lung nodule,malignancy classification,unsupervised learning,generative adversarial networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FALSE-POSITIVE,REDUCTION,PULMONARY,NODULE,CT,IMAGES,FEATURES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09066829.pdf,
89,Visualization of Generic Utility of Sequential Patterns,8,,78004-78014,"Wiktorski Tomasz,Krolak Aleksandra,Rosinska Karolina,Strumillo Pawel,Lin Jerry Chun-Wei","Wiktorski T,Krolak A,Rosinska K,Strumillo P,Lin JCW",Wiktorski T,10.1109/ACCESS.2020.2989165,Universitetet i Stavanger,"Most of the literature on utility pattern mining (UPM) assumes that the particular patterns & x2019; utility in known in advance. Concurrently, in frequent pattern mining (FPM) it is assumed that all patterns take the same value. In reality, the information about the utility of patterns is not or hardly available in most cases. Moreover, the utility and frequency of the particular pattern are not directly proportional. An algorithm for estimating a generic pattern utility has been recently proposed, but the numeric results might be difficult to interpret. In particular, in datasets with many independent instances or groups. In this paper, we present an approach to generating utility bitmaps that provide visual representation of the numeric data obtained using generic pattern utility algorithm. We demonstrate validity of this approach on two datasets: PAMAP2 Physical Activity Monitoring Data Set, an open dataset from the UCI Machine Learning Repository, and an ECG dataset collected using Biopac Student Lab during Ruffier & x2019;s test. For PAMAP2 dataset, utility bitmaps allow for immediate separation of various physical activities. Variation between participants are present, but do not overshadow differences between the activity types. For the ECG dataset, utility bitmaps immediately indicate age and fitness differences between the participants, even thought this information was not available to the algorithm. In both cases, partial similarity in bitmaps can be traced back to partial similarity in activities or participants generating the data. Based on these tests, the approach seems to be promising for exploratory analysis of large collections of long time series and possibly other sequential patterns such as distance series common in sports data analysis and depth series common in petroleum engineering.","Time series analysis,Visualization,Data visualization,Electrocardiography,Discrete Fourier transforms,Signal processing algorithms,Heart rate,Data visualization,DTW,exploratory data analysis,intelligent icons,SAX,sequential pattern,utility,utility visualization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"TIME,REPRESENTATION",IEEE ACCESS,https://uis.brage.unit.no/uis-xmlui/bitstream/11250/2671219/1/Postnr%2b1820853.pdf,
90,An Anchor-Free Convolutional Neural Network for Real-Time Surgical Tool Detection in Robot-Assisted Surgery,8,,78193-78201,"Liu Yuying,Zhao Zijian,Chang Faliang,Hu Sanyuan","Liu YY,Zhao ZJ,Chang FL,Hu SY",Zhao ZJ,10.1109/ACCESS.2020.2989807,Shandong University,"Robot-assisted surgery (RAS), a type of minimally invasive surgery, is used in a variety of clinical surgeries because it has a faster recovery rate and causes less pain. Automatic video analysis of RAS is an active research area, where precise surgical tool detection in real time is an important step. However, most deep learning methods currently employed for surgical tool detection are based on anchor boxes, which results in low detection speeds. In this paper, we propose an anchor-free convolutional neural network (CNN) architecture, a novel frame-by-frame method using a compact stacked hourglass network, which models the surgical tool as a single point: the center point of its bounding box. Our detector eliminates the need to design a set of anchor boxes, and is end-to-end differentiable, simpler, more accurate, and more efficient than anchor-box-based detectors. We believe our method is the first to incorporate the anchor-free idea for surgical tool detection in RAS videos. Experimental results show that our method achieves 98.5 & x0025; mAP and 100 & x0025; mAP at 37.0 fps on the ATLAS Dione and Endovis Challenge datasets, respectively, and truly realizes real-time surgical tool detection in RAS videos.","Anchor-free,center point,RAS,single-stage,stacked hourglass network,and surgical tool detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ENDOSCOPIC,VISION,TRACKING,INSTRUMENTS,RECOGNITION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09076706.pdf,
91,Obstetric Imaging Diagnostic Platform Based on Cloud Computing Technology Under the Background of Smart Medical Big Data and Deep Learning,8,,78265-78278,"Lie Weiwei,Jiang Bin,Zhao Wenjing","Lie WW,Jiang B,Zhao WJ",Lie WW,10.1109/ACCESS.2020.2988563,China Medical University,"The deep learning methods in the field of computer vision and big data are becoming more and more mature. Through the application of big data and deep learning technology, the diagnosis of artificial intelligence medical image can be realized, which provides a new opportunity for the automatic analysis of obstetrics medical image and the assistance of doctors to realize high-precision intelligent diagnosis of diseases. The current medical obstetric image diagnosis platform mainly targets low-resolution medical obstetric image files, and does not consider the data-sharing problem of the distributed file system in different storage nodes, which greatly reduces the efficiency of obstetric image storage and diagnosis. Based on this, this article designs an obstetric image diagnostic platform based on cloud computing technology. First, a medical imaging platform was designed by combining cloud computing technology, caching technology, and a distributed file system. Secondly, the use of contrast-enhanced ultrasound technology provides a more accurate ultrasound image for assessing the structure, size, location, and developmental abnormalities of the placenta. Finally, the effectiveness of the obstetric imaging diagnostic platform proposed in this paper is verified by experiments. The results show that the platform has fast data processing speed and convenient use, which greatly reduces the cost of medical equipment and improves efficiency. The hospital only needs to collect the obstetric image of the patient at the front end, transfer it to the cloud for image processing, and finally diagnose the disease.","Cloud computing,Medical diagnostic imaging,Computers,Big Data,Ultrasonic imaging,Smart medicine,big data,cloud computing technology,obstetric imaging,diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FILE,SYSTEM,STORAGE,ULTRASOUND",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09069953.pdf,
92,Deep Regression via Multi-Channel Multi-Modal Learning for Pneumonia Screening,8,,78530-78541,"Wang Qiuli,Yang Dan,Li Zhihuan,Zhang Xiaohong,Liu Chen","Wang QL,Yang D,Li ZH,Zhang XH,Liu C",Zhang XH,10.1109/ACCESS.2020.2990423,Chongqing University,"Pneumonia screening is one of the most crucial steps in the pneumonia diagnosing system, which can improve the work efficiency of the radiologists and prevent delayed treatments. In this paper, we propose a deep regression framework for automatic pneumonia screening, which jointly learns the multi-channel images and multi-modal information (i.e., clinical chief complaints, age, and gender) to simulate the clinical pneumonia screening process. We demonstrate the advantages of the framework in three ways. First, visual features from multi-channel images (Lung Window Images, High Attenuation Images, Low Attenuation Images) can provide more visual features than single image channel, and improve the ability of screening pneumonia with severe diseases. Second, the proposed framework treats chest CT scans as short video frames and analyzes them by using Recurrent Convolutional Neural Network, which can automatically extract multiple image features from multi-channel image slices. Third, chief complaints and demographic information can provide valuable prior knowledge enhancing the features from images and further promote performance. The proposed framework has been extensively validated in 900 clinical cases. Compared to the baseline, the proposed framework improves the accuracy by 2.3% and significantly improves the sensitivity by 3.1%. To the best of our knowledge, we are the first to screen pneumonia using multi-channel images, multi-modal demographic and clinical information based on the large scale clinical raw dataset.","Computed tomography,clinical diagnosis,biomedical imaging,pneumonia screening",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2990423,
93,Counting and Classification of Malarial Parasite From Giemsa-Stained Thin Film Images,8,,78663-78682,"Kudisthalert Wasu,Pasupa Kitsuchart,Tongsima Sissades","Kudisthalert W,Pasupa K,Tongsima S",Pasupa K,10.1109/ACCESS.2020.2990497,King Mongkuts Institute of Technology Ladkrabang,"Malaria is a life-threatening disease causing by an infection of the protozoan parasite Plasmodium. Plasmodium falciparum is the deadliest and most common human infected parasites hosted by anopheles mosquito vector. To cure a malaria infected patient and prevent further spreading, malaria diagnosis using microscopy to visualize Giemsa-stained parasites is commonly done. The microscopy diagnosis is somewhat time consuming and requires well-trained malaria experts to interpret what they see under the microscope. To address this limitation, an automated malaria infected diagnosis is needed. This work proposed a computer-aided automated diagnosis system that can perform remote field diagnosis with high accuracy while requiring less computational demands. The proposed framework consists of two main parts that are red blood cell counting and parasite life-cycle stage classification. The counting process is performed by computer vision techniques, namely Hough transform. Different machine learning techniques, i.e., Multilayer Perceptron, Linear Discriminant Analysis, Support Vector Machine, and Weighted Similarity Extreme Learning Machine, are employed in the classification task. We also demonstrated that combining hand-crafted and deep-learned features can enhance the overall performance of the framework. The experimental results showed that the proposed methods could correctly count and classify at 97.94% and 98.12% accuracy, respectively. The overall proposal system can achieve at 96.18% accuracy. This is achieved by WELM in conjunction with deep-learned (AlexNet_FC7) and the hand-crafted (color) features.","Combining features,Giemsa-stained thin film,malaria",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BLOOD,DIAGNOSIS,MACHINE,SHAPE",IEEE ACCESS,https://doi.org/10.1109/access.2020.2990497,
94,AI-Driven Maintenance Support for Downhole Tools and Electronics Operated in Dynamic Drilling Environments,8,,78683-78701,"Kirschbaum Lucas,Roman Darius,Singh Gulshan,Bruns Jens,Robu Valentin,Flynn David","Kirschbaum L,Roman D,Singh G,Bruns J,Robu V,Flynn D",Kirschbaum L,10.1109/ACCESS.2020.2990152,Heriot Watt University,"Downhole tools are complex electro-mechanical systems that perform critical functions in drilling operations. The electronics within these systems provide vital support, such as control, navigation and front-end data analysis from sensors. Due to the extremely challenging operating conditions, namely high pressure, temperature and vibrational forces, electronics can be subjected to complex failure modes and incur operational downtime. A novel Artificial Intelligence (AI)-driven Condition Based Maintenance (CBM) support system is presented, combining Bottom Hole Assembly (BHA) data with Big Data Analytics (BDA). The key objective of this system is to reduce maintenance costs along with an overall improvement of fleet reliability. As evidenced within the literature review, the application of AI methods to downhole tool maintenance is underrepresented in terms of oil and gas application. We review the BHA electronics failure modes and propose a methodology for BHA-Printed Component Board Assemblies (PCBA) CBM. We compare the results of a Random Forest Classifier (RFC) and a XGBoost Classifier trained on BHA electronics memory data cumulated during 208 missions over a 6 months period, achieving an accuracy of 90 % for predicting PCBA failure. These results are extended into a commercial analysis examining various scenarios of infield failure costs and fleet reliability levels. The findings of this paper demonstrate the value of the BHA-PCBA CBM framework by providing accurate prognosis of operational equipment health leading to reduced costs, minimised Non-Productive Time (NPT) and increased operational reliability.","Bottom hole assembly,oil drilling,printed component board assembly,dynamic environments,failure modes,condition based maintenance,diagnostics,prognostics,machine learning,artificial intelligence",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"OF-THE-ART,MACHINE,PROGNOSTICS",IEEE ACCESS,https://ir.cwi.nl/pub/30569/09078086.pdf,
95,Learning Set Representations for LWIR In-Scene Atmospheric Compensation,13,,1438-1449,"Westing Nicholas,Gross Kevin C.,Borghetti Brett J.,Martin Jacob,Meola Joseph","Westing N,Gross KC,Borghetti BJ,Martin J,Meola J",Westing N,10.1109/JSTARS.2020.2980750,Air Force Institute of Technology (AFIT),"Atmospheric compensation of long-wave infrared (LWIR) hyperspectral imagery is investigated in this article using set representations learned by a neural network. This approach relies on synthetic at-sensor radiance data derived from collected radiosondes and a diverse database of measured emissivity spectra sampled at a range of surface temperatures. The network loss function relies on LWIR radiative transfer equations to update model parameters. Atmospheric predictions are made on a set of diverse pixels extracted from the scene, without knowledge of blackbody pixels or pixel temperatures. The network architecture utilizes permutation-invariant layers to predict a set representation, similar to the work performed in point cloud classification. When applied to collected hyperspectral image data, this method shows comparable performance to Fast Line-of-Sight Atmospheric Analysis of Hypercubes-Infrared (FLAASH-IR), using an automated pixel selection approach. Additionally, inference time is significantly reduced compared to FLAASH-IR with predictions made on average in 0.24 s on a 128 pixel by 5000 pixel data cube using a mobile graphics card. This computational speed-up on a low-power platform results in an autonomous atmospheric compensation method effective for real-time, onboard use, while only requiring a diversity of materials in the scene.","Atmospheric compensation,dimension reduction,hyperspectral imagery,neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physical Geography,Remote Sensing,Imaging Science & Photographic Technology",,,,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,https://ieeexplore.ieee.org/ielx7/4609443/8994817/09055124.pdf,
96,Rapid screening and quantitative analysis of adulterant Lonicerae Flos in Lonicerae Japonicae Flos by Fourier-transform near infrared spectroscopy,104,,,"Zhao Jing,Cui Pengdi,Liu Huan,Wang Chunhua,Liu Ming,Li Gang,Pan Mingzhong,Li Zheng,Suo Tongchuan","Zhao J,Cui PD,Liu H,Wang CH,Liu M,Li G,Pan MZ,Li Z,Suo TC",Li Z,10.1016/j.infrared.2019.103139,Tianjin University of Traditional Chinese Medicine,"Adulteration of Lonicerae Flos (LF) in Lonicerae Japonicae Flos (LJF) is difficult to detect with naked eyes, and significantly affect the clinical efficacy. The rapid screening and quantitative analysis of adulterant LF in LJF is important in the raw material preparation. In this study, Fourier-transform near infrared spectroscopy (FT-NIRs) and chemometrics are used for rapid analysis of adulterant LF in LJF. The powder of the pure LJF, LF and adulteration, and the corresponding extract solutions are prepared. FT-NIR spectra are modeled for comparison. Successive Projections Algorithm (SPA) is used for characteristic bands selection; Savitzky-Golay smoothing (SG), multiplicative scatter correction (MSC), first deviation (1stD) and standard normal variate (SNV) are adopted for spectra preprocessing; Principal component analysis (PCA), and back propagation artificial neural network (BPANN) are employed as qualitative analysis method for screening whether or not containing adulteration; BPANN and partial least squares (PLS) are used for quantitative analysis. The optimal results of screening and quantitative models are obtained from ""S - G + MSC + SNV + BPANN"" and ""S - G + SNV + BPANN"" of powder samples. It indicates that FT-NIRs can provide a rapid and efficient tool for screening and quantitative analysis of adulterant LF in LJF.","Lonicerae Japonicae Flos,Lonicerae Flos,Adulteration,Screening,Quantitative analysis,Fourier-transform near infrared spectroscopy",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,2.581,"PERFORMANCE,LIQUID-CHROMATOGRAPHY,QUALITY,ASSESSMENT,NIR,SPECTROSCOPY,FLOWER,BUDS,IDENTIFICATION,CLASSIFICATION,QUANTIFICATION,DISCRIMINATION,FLAVONOIDS,SEQUENCES",INFRARED PHYSICS & TECHNOLOGY,,
97,Exploring uncertainty measures in deep networks for Multiple sclerosis lesion detection and segmentation,59,,,"Nair Tanya,Precup Doina,Arnold Douglas L.,Arbel Tal","Nair T,Precup D,Arnold DL,Arbel T",Nair T,10.1016/j.media.2019.101557,McGill University,"Deep learning networks have recently been shown to outperform other segmentation methods on various public, medical-image challenge datasets, particularly on metrics focused on large pathologies. For diseases such as Multiple Sclerosis (MS), however, monitoring all the focal lesions visible on MRI sequences, even very small ones, is essential for disease staging, prognosis, and evaluating treatment efficacy. Small lesion segmentation presents significant challenges to popular deep learning models. This, coupled with their deterministic predictions, hinders their clinical adoption. Uncertainty estimates for these predictions would permit subsequent revision by clinicians. We present the first exploration of multiple uncertainty estimates based on Monte Carlo (MC) dropout (Gal and Ghahramani, 2016) in the context of deep networks for lesion detection and segmentation in medical images. Specifically, we develop a 3D MS lesion segmentation CNN, augmented to provide four different voxel-based uncertainty measures based on MC dropout. We train the network on a proprietary, large-scale, multi-site, multi-scanner, clinical MS dataset, and compute lesion-wise uncertainties by accumulating evidence from voxel-wise uncertainties within detected lesions. We analyze the performance of voxel-based segmentation and lesion-level detection by choosing operating points based on the uncertainty. Uncertainty filtering improves both voxel and lesion-wise TPR and FDR on remaining, certain predictions compared to sigmoid-based TPR/FDR curves. Small lesions and lesion-boundaries are the most uncertain regions, which is consistent with human-rater variability. (C) 2019 Elsevier B.V. All rights reserved.","Uncertainty,Deep learning,Segmentation,Detection,Multiple sclerosis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,,MEDICAL IMAGE ANALYSIS,http://escholarship.mcgill.ca/downloads/m900nw84x,
98,The Utility of Applying Various Image Preprocessing Strategies to Reduce the Ambiguity in Deep Learning-based Clinical Image Diagnosis,19,2,92-98,"Tachibana Yasuhiko,Obata Takayuki,Kershaw Jeff,Sakaki Hironao,Urushihata Takuya,Omatsu Tokuhiko,Kishimoto Riwa,Higashi Tatsuya","Tachibana Y,Obata T,Kershaw J,Sakaki H,Urushihata T,Omatsu T,Kishimoto R,Higashi T",Tachibana Y,10.2463/mrms.mp.2019-0021,National Institutes for Quantum & Radiological Science & Technology (QST)-Japan,"Purpose: A general problem of machine-learning algorithms based on the convolutional neural network (CNN) technique is that the reason for the output judgement is unclear. The purpose of this study was to introduce a strategy that may facilitate better understanding of how and why a specific judgement was made by the algorithm. The strategy is to preprocess the input image data in different ways to highlight the most important aspects of the images for reaching the output judgement.
Materials and Methods: T-2-weighted brain image series falling into two age-ranges were used. Classifying each series into one of the two age-ranges was the given task for the CNN model. The images from each series were preprocessed in five different ways to generate five different image sets: (1) subimages from the inner area of the brain, (2) subimages from the periphery of the brain, (3-5) subimages of brain parenchyma, gray matter area, and white matter area, respectively, extracted from the subimages of (2). The CNN model was trained and tested in five different ways using one of these image sets. The network architecture and all the parameters for training and testing remained unchanged.
Results: The judgement accuracy achieved by training was different when the image set used for training was different. Some of the differences was statistically significant. The judgement accuracy decreased significantly when either extra-parenchymal or gray matter area was removed from the periphery of the brain (P < 0.05).
Conclusion: The proposed strategy may help visualize what features of the images were important for the algorithm to reach correct judgement, helping humans to understand how and why a particular judgement was made by a CNN.","convolutional neural network,deep learning,diagnosis,magnetic resonance imaging",Article,"JPN SOC MAGNETIC RESONANCE MEDICINE, GOTANDA PARK SIDE BLDG 4F, 5 24 9 HIGASHI-GOTANDA, SHINAGAWA-KU, TOKYO, 141-0022, JAPAN","Radiology, Nuclear Medicine & Medical Imaging",,1.917,,MAGNETIC RESONANCE IN MEDICAL SCIENCES,https://europepmc.org/articles/pmc7232029?pdf=render,
99,,,,,,,,,,,,,,,,,,,,
