,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A Novel MI-EEG Imaging With the Location Information of Electrodes,8,,3197-3211,"Li Ming-Ai,Han Jian-Fu,Duan Li-Juan","Li MA,Han JF,Duan LJ",Li MA,10.1109/ACCESS.2019.2962740,Beijing University of Technology,"Combination of the Motor Imagery EEG (MI-EEG) imaging and Deep Convolutional Neural Network is a prospective recognition method in brain computer interface. Nowadays, the frequency or time-frequency analysis has been applied to each channel of MI-EEG signal to obtain a spatio-frequency or time-frequency image, and even the images from several channels are infused to generate a combined image. However, the real position information of channels or electrodes is lost in these MI-EEG images, and this is contradictory to the activation area of MI-tasks. In this paper, the MI period and the frequency band covered by mu and beta rhythms are divided into ten time windows and three sub-bands, respectively. Then, for each electrode, Fast Fourier Transform (FFT) is employed to transform each time window to spectrum, and its inverse FFT is calculated for each sub-band. The time-domain powers of ten time windows are averaged for the same sub-band. So, three average powers are generated as the time-frequency features of each electrode of MI-EEG. They are further arranged to the electrode coordinate figure by using Clough-Tocher interpolation algorithm, and a complicated image, in which the time-frequency features are correctly located at the real position of each electrode, is obtained to embody the MI-EEG in detail. Furthermore, a VGG network is modified to perform effective recognition for MI-EEG image, and it is called mVGG. Extensive experiments are conducted on three publicly available datasets, and the 10-folds cross validation accuracies of 88.62%, 92.28% and 96.86% are achieved respectively, and they are higher than that of the state-of-the-art imaging methods. Kappa values and ROC curves demonstrate our method has lower class skew and error costs. The experimental results show that the effectiveness of proposed MI-EEG imaging method, and it is well-matched with mVGG.","Brain computer interface,convolutional neural network,interpolation method,machine learning,MI-EEG imaging method",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,MOTOR,IMAGERY",IEEE ACCESS,https://doi.org/10.1109/access.2019.2962740,
2,Intelligent Emotion Detection Method Based on Deep Learning in Medical and Health Data,8,,3802-3811,"Xu Jianqiang,Hu Zhujiao,Zou Junzhong,Bi Anqi","Xu JQ,Hu ZJ,Zou JZ,Bi AQ",Zou JZ,10.1109/ACCESS.2019.2961139,East China University of Science & Technology,"Emotional abnormality may be brought out by physiological fatigue. In order to solve the problem, an emotion detection method based on deep learning in medical and health data is proposed in this paper. First of all, the related content of emotional fatigue is studied. The concept and the classification of emotional fatigue are introduced. Then, a multi-modal data emotional fatigue detection system is designed. In the system, multi-channel convolutional aotoencoder neural network is used to extract electrocardiograms (ECG) data features and emotional text features for emotional fatigue detection. Secondly, the network structure of learning ECG features by multi-channel convolutional aotoencoder model is introduced in detail. And the network structure of learning emotional text features by convolutional aotoencoder model is also described in detail. Finally, multi-modal data features are combined for emotional detection. It is shown by the experimental results that the proposed model has an average accuracy of more than 85% in predicting emotional fatigue.","Emotion detection model,multi-channel convolutional aotoencoder (MCAE),medical health,deep learning,emotional text features,intelligent data analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2019.2961139,
3,Skin Lesion Segmentation in Dermoscopic Images With Ensemble Deep Learning Methods,8,,4171-4181,"Goyal Manu,Oakley Amanda,Bansal Priyanka,Dancey Darren,Yap Moi Hoon","Goyal M,Oakley A,Bansal P,Dancey D,Yap MH",Yap MH,10.1109/ACCESS.2019.2960504,Manchester Metropolitan University,"Early detection of skin cancer, particularly melanoma, is crucial to enable advanced treatment. Due to the rapid growth in the number of skin cancers, there is a growing need of computerised analysis for skin lesions. The state-of-the-art public available datasets for skin lesions are often accompanied with a very limited amount of segmentation ground truth labeling. Also, the available segmentation datasets consist of noisy expert annotations reflecting the fact that precise annotations to represent the boundary of skin lesions are laborious and expensive. The lesion boundary segmentation is vital to locate the lesion accurately in dermoscopic images and lesion diagnosis of different skin lesion types. In this work, we propose the fully automated deep learning ensemble methods to achieve high sensitivity and high specificity in lesion boundary segmentation. We trained the ensemble methods based on Mask R-CNN and DeeplabV3 C methods on ISIC-2017 segmentation training set and evaluate the performance of the ensemble networks on ISIC-2017 testing set and PH2 dataset. Our results showed that the proposed ensemble methods segmented the skin lesions with Sensitivity of 89.93% and Specificity of 97.94% for the ISIC-2017 testing set. The proposed ensemble method Ensemble-A outperformed FrCN, FCNs, U-Net, and SegNet in Sensitivity by 4.4%, 8.8%, 22.7%, and 9.8% respectively. Furthermore, the proposed ensemble method Ensemble-S achieved a specificity score of 97.98% for clinically benign cases, 97.30% for the melanoma cases, and 98.58% for the seborrhoeic keratosis cases on ISIC-2017 testing set, exhibiting better performance than FrCN, FCNs, U-Net, and SegNet.","Skin cancer,skin lesion segmentation,ensemble segmentation methods,deep learning,melanoma,instance segmentation,semantic segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DIAGNOSIS,NETWORKS,MELANOMA",IEEE ACCESS,https://doi.org/10.1109/access.2019.2960504,
4,A Deep Model for Lung Cancer Type Identification by Densely Connected Convolutional Networks and Adaptive Boosting,8,,4799-4805,"Pang Shanchen,Zhang Yaqin,Ding Mao,Wang Xun,Xie Xianjin","Pang SC,Zhang YQ,Ding M,Wang X,Xie XJ",Wang X,10.1109/ACCESS.2019.2962862,China University of Petroleum,"Timely diagnosis and determination to the type of lung cancer has important clinical significance. Generally, it requires multiple imaging methods to complement each other to obtain a comprehensive diagnosis. In this work, we propose a deep learning model to identify lung cancer type from CT images for patients in Shandong Provincial Hospital. It has a two-fold challenge: artificial intelligent models trained by public datasets cannot meet such practical requires, and the amount of collected patients' data is quite few. To solve the two-fold problem, we use image rotation, translation and transformation methods to expand and balance our training data, and then densely connected convolutional networks (DenseNet) is used to classify malignant tumor from images collected from, and finally adaptive boosting (adaboost) algorithm is used to aggregate multiple classification results to improve classification performance. Experimental results show that our method can achieve identifying accuracy 89:85%, which performs better than DenseNet without adaboost, ResNet, VGG16 and AlexNet. This provides an efficient, non-invasive detection tool for pathological diagnosis to lung cancer type.","Adaboost algorithm,data enhancement,densely connected convolutional networks,lung cancer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SUBTYPE,ADENOCARCINOMA,CLASSIFICATION,STATISTICS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08945194.pdf,
5,Can a Smartband be Used for Continuous Implicit Authentication in Real Life,8,,59402-59411,"Ekiz Deniz,Can Yekta Said,Dardagan Yagmur Ceren,Ersoy Cem","Ekiz D,Can YS,Dardagan YC,Ersoy C",Ekiz D,10.1109/ACCESS.2020.2982852,Bogazici University,"The use of cloud services that process privacy-sensitive information such as digital banking, pervasive healthcare, smart home applications requires an implicit continuous authentication solution, which will make these systems less vulnerable to the spoofing attacks. Physiological signals can be used for continuous authentication due to their uniqueness. Ubiquitous wrist-worn wearable devices are equipped with photoplethysmogram sensors, which enable us to extract heart rate variability (HRV) features. In this study, we show that these devices can be used for continuous physiological authentication for enhancing the security of the cloud, edge services, and IoT devices. A system that is suitable for the smartband framework comes with new challenges such as relatively low signal quality and artifacts due to placement, which were not encountered in full lead electrocardiogram systems. After the artifact removal, cleaned physiological signals are fed to the machine learning algorithms. In order to train our machine learning models, we collected physiological data using off-the-shelf smartbands and smartwatches in a real-life event. By applying a minimum quality threshold, we achieved a 3.96% Equal Error Rate. Performance evaluation shows that HRV is a strong candidate for continuous unobtrusive implicit physiological authentication.","Smartband,smartwatch,heart rate variability,continuous authentication",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HEART-RATE-VARIABILITY,PERSON,IDENTIFICATION,ECG,STRESS,SOUND",IEEE ACCESS,http://arxiv.org/pdf/1912.04760,
6,Supervised Brain Network Learning Based on Deep Recurrent Neural Networks,8,,69967-69978,"Zhao Shijie,Cui Yan,Huang Linwei,Xie Li,Chen Yaowu,Han Junwei,Guo Lei,Zhang Shu,Liu Tianming,Lv Jinglei","Zhao SJ,Cui Y,Huang LW,Xie L,Chen YW,Han JW,Guo L,Zhang S,Liu TM,Lv JL",Zhang S,10.1109/ACCESS.2020.2984948,Northwestern Polytechnical University,"Task-based functional magnetic resonance imaging (tfMRI) is a widely used neuroimaging technique in exploring brain networks and functions associated with cognitive behaviors. Traditionally, the general linear model (GLM) is the most popular method in tfMRI data analysis due to its simpleness and robustness. This model-driven method adopts a canonical hemodynamic response function (HRF) and its various derivatives to construct regressors in the design matrix and estimate changes in the tfMRI data. However, a possible limitation of current model-driven methods is that the HRF is fixed and non-adaptive which may overlook other diverse and concurrent brain networks. In order to overcome these limitations, we proposed a novel hybrid framework, supervised brain network learning based on deep recurrent neural networks (SUDRNN), to reconstruct the diverse and concurrent functional brain networks. Specifically, this hybrid framework first takes advantage of the great capacity of deep recurrent neural networks (DRNN) in modeling sequential data to learn the diverse regressors from real tfMRI data. After that, it utilizes the effective supervised dictionary learning (SDL) method to reconstruct both the task-related functional brain networks and other latent brain networks simultaneously. Extensive experiment results on different tfMRI datasets from Human connectome project (HCP) demonstrated the superiority of the proposed framework.","Task fMRI,brain networks,recurrent neural network,supervised dictionary learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"INDEPENDENT,COMPONENT,ANALYSIS,EVENT-RELATED,FMRI,FUNCTIONAL,CONNECTIVITY,TASK-FMRI,ARCHITECTURE,ATLASES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09052686.pdf,
7,Dermoscopy Image Classification Based on StyleGANs and Decision Fusion,8,,70640-70650,"Gong An,Yao Xinjie,Lin Wei","Gong A,Yao XJ,Lin W",Yao XJ,10.1109/ACCESS.2020.2986916,China University of Petroleum,"Skin cancer is one of the most common cancers in humans in recent years, affecting people of all ages. If skin cancer is treated in time, the curative effect and prognosis are favorable. At present, dermoscopy is an effective way for the early diagnosis of skin cancer. However, manual detection is highly dependent on the clinical experience of doctors, and the complexity of the dermoscopy image itself poses a great challenge to the classification. Therefore, we propose a decision fusion method. Through transfer learning, based on multiple pre-trained convolutional neural networks (CNNs), we use the block to combine multiple CNNs and finally make decisions through multiple blocks. The method of decision fusion can solve the generalization capability of a individual convolutional neural network (CNN) model, and is more robust and stable than the traditional fusion strategy. Based on ISIC 2019 dataset, we use StyleGANs to generate high-quality images to alleviate the problem of less and uneven distribution of the dermoscopy image dataset and improve the classification effect of CNNs. Our proposed method can improve the accuracy of dermoscopy image classification and provide help for dermatologists.","Feature extraction,Training,Skin,Gallium nitride,Melanoma,Lesions,Dermoscopy images,decision fusion,convolutional neural networks,StyleGANs",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SKIN-LESIONS,MALIGNANT-MELANOMA,DIAGNOSIS,ACCURACY,CANCER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09062473.pdf,
8,Super Resolution of B-Mode Ultrasound Images With Deep Learning,8,,78808-78820,"Temiz Hakan,Bilge Hasan S.","Temiz H,Bilge HS",Temiz H,10.1109/ACCESS.2020.2990344,Artvin Coruh University,"Ultrasound offers a safe, non-invasive, and inexpensive way of imaging. However, due to its natural intrinsic imaging characteristics, it produces poor quality images with low resolution (LR) compared to other medical imaging modalities. Various image enhancement techniques have been extensively studied to overcome these shortcomings. Super-resolution (SR) is one of these methods, which endeavor to obtain high resolution (HR) images from LR images while enlarging them. Numerous studies have already utilized different SR techniques in various stages of ultrasound imaging (USI). Unlike other studies, which aimed at obtaining SR in the pre-processing phase or early stages of the post-processing phase of USI, we achieved SR on B-mode ultrasound images, which is the last stage of USI. We constructed a deep convolutional neural network (CNN) and trained it with a very large dataset of B-mode ultrasound images for the scale factors 2, 3, 4, and 8. We evaluated the performance of our proposed model quantitatively with eight image quality measures. The quantitative results revealed that our algorithm is much more successful than other methods at each magnification factor. Furthermore, we also verified that there is a statistically significant difference between our approach and others. Besides, qualitative analysis of the reconstructed images also confirms that it produces much better quality HR images than other methods in terms of the human visual system.","Ultrasound,super-resolution,deep learning,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ADVERSARIAL,NETWORK,SUPERRESOLUTION,ENHANCEMENT",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09078131.pdf,
9,CGHF: A Computational Decision Support System for Glioma Classification Using Hybrid Radiomics- and Stationary Wavelet-Based Features,8,,79440-79458,"Kumar Rahul,Gupta Ankur,Arora Harkirat Singh,Pandian Ganesh Namasivayam,Raman Balasubramanian","Kumar R,Gupta A,Arora HS,Pandian GN,Raman B",Kumar R; Gupta A,10.1109/ACCESS.2020.2989193,Indian Institute of Technology System (IIT System),"Brain tumors are the most prominent neurologically malignant cancers with the highest injury and death rates worldwide. Glioma classification is crucial for the prognosis, assessment of prognostication and the planning of clinical guidelines before surgery. Herein, we introduce a novel stationary wavelet-based radiomics approach to classify the grade of glioma more accurately and in a non-invasive manner. The training dataset of Brain Tumor Segmentation (BraTS) Challenge 2018 is used for performance evaluation and calculation is done based on the radiomics features for three different regions of interest. The classifier, Random Forest, is trained on these features and predicted the grade of glioma. At last, the performance is validated by using five-fold cross-validation scheme. The state-of-the-art performance is achieved considering metric < Acc, Sens, Spec, Score, MCC, AUC > equivalent to < 97.54%; 97.62%; 97.33%; 98.3%; 94.12%; 97.48%> with machine learning predictive model Random Forest (RF) for brain tumor patients' classification. Considering the importance of glioma classification for the assessment of prognosis, our approach could be useful in the planning of clinical guidelines prior to surgery.","Feature extraction,Tumors,Magnetic resonance imaging,Biomedical imaging,Decision support systems,Forestry,Cancer,Radiomics,machine learning,random forest,filter,feature extraction,grading of glioma",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"TEXTURE,CLASSIFICATION,VECTOR,MACHINE,GRADE,GLIOMAS,BRAIN,IMAGES,INFORMATION,TRANSFORM,TUMORS,SELECTION",IEEE ACCESS,https://doi.org/10.1109/access.2020.2989193,
10,Standard Plane Identification in Fetal Brain Ultrasound Scans Using a Differential Convolutional Neural Network,8,,83821-83830,"Qu Ruowei,Xu Guizhi,Ding Chunxia,Jia Wenyan,Sun Mingui","Qu RW,Xu GZ,Ding CX,Jia WY,Sun MG",Xu GZ,10.1109/ACCESS.2020.2991845,Hebei University of Technology,"Ultrasound scanning has become a highly recommended examination in prenatal diagnosis in many countries. The accurate identification of fetal brain ultrasound scans is crucial to accurate head measurement and brain lesion detection, such as the measurement of the biparietal diameter and the detection of hydrocephalus. In recent years, deep learning has made great progress in the field of image processing. However, there are two difficulties in the identification of fetal brain ultrasound standard planes (FBSPs). First, since the fetal brain tissue is not mature, the fetal brain tissue features are not easy to be detected. Second, because of the expensive collection costs, the amount of labeled image data is limited, which can cause over-fitting and decrease the identification precision. In this study, we proposed a differential convolutional neural network (differential-CNN) to automatically identify six fetal brain standard planes (FBSPs) from the non-standard planes. In this differential-CNN framework, the additional differential feature maps were derived from the feature maps in the original CNN using differential operators. The derivation process did not increase the number of convolution layers and parameters. Moreover, the differential convolution maps have the large advantage of analyzing the directional pattern of pixels and their neighborhoods using additional variation calculations. Therefore, the differential convolution maps would result in good identification performance and cost no extra computational burden. To test the performance of these algorithms, we constructed a dataset consisting of 30,000 2D ultrasound images from 155 fetal subjects ranging from 16 to 34 weeks. The experimental results showed that this method achieved an accuracy of 92.93%. Our work shows that the differential-CNN can be used to facilitate the implementation of the automated identification of FBSPs.","Convolutional neural network,ultrasound scan image,medical image processing,convolution techniques,differential operator",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGES,CLASSIFICATION,LOCALIZATION,SEGMENTATION,RECOGNITION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09084099.pdf,
11,Truly Generalizable Radiograph Segmentation With Conditional Domain Adaptation,8,,84037-84062,"Oliveira Hugo N.,Ferreira Edemir,Dos Santos Jefersson A.","Oliveira HN,Ferreira E,Dos Santos JA",Oliveira HN,10.1109/ACCESS.2020.2991688,Universidade Federal de Minas Gerais,"Digitization techniques for biomedical images yield disparate visual patterns in radiological exams. These pattern differences, which can be viewed as a domain-shift problem, may hamper the use of data-driven approaches for inference over these images, such as Deep Neural Networks. Another noticeable difficulty in this field is the lack of labeled data, even though in many cases there is an abundance of unlabeled data available. Therefore, an important step in improving the generalization capabilities of these methods and mitigate domain-shift effects is to perform unsupervised or semi-supervised adaptation between different domains of biomedical images. In this work, we propose a novel approach for segmentation of biomedical images based on Generative Adversarial Networks. The proposed method, named Conditional Domain Adaptation Generative Adversarial Network (CoDAGAN), merges unsupervised networks with supervised deep semantic segmentation architectures in order to create a semi-supervised method capable of learning from both unlabeled and labeled data, whenever labeling is available. We conducted experiments to compare our method with traditional and state-of-the-art baselines by using several domains, datasets, and segmentation tasks. The proposed method yielded consistently better results than the baselines in scarce labeled data scenarios, achieving Jaccard values greater than 0.9 and good segmentation quality in most tasks. Unsupervised Domain Adaptation results were observed to be close to the Fully Supervised Domain Adaptation used in the traditional procedure of fine-tuning pretrained networks.","Deep learning,domain adaptation,biomedical images,semantic segmentation,image translation,semi-supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CHEST,RADIOGRAPHS,DATABASE,IMAGES,DATASETS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09084116.pdf,
12,Novel Multi Center and Threshold Ternary Pattern Based Method for Disease Detection Method Using Voice,8,,84532-84540,"Tuncer Turker,Dogan Sengul,Ozyurt Fatih,Belhaouari Samir Brahim,Bensmail Halima","Tuncer T,Dogan S,Ozyurt F,Belhaouari SB,Bensmail H",Belhaouari SB,10.1109/ACCESS.2020.2992641,Hamad Bin Khalifa University-Qatar,"Smart health is one of the most popular and important components of smart cities. It is a relatively new context-aware healthcare paradigm influenced by several fields of expertise, such as medical informatics, communications and electronics, bioengineering, ethics, to name a few. Smart health is used to improve healthcare by providing many services such as patient monitoring, early diagnosis of disease and so on. The artificial neural network (ANN), support vector machine (SVM) and deep learning models, especially the convolutional neural network (CNN), are the most commonly used machine learning approaches where they proved to be performance in most cases. Voice disorders are rapidly spreading especially with the development of medical diagnostic systems, although they are often underestimated. Smart health systems can be an easy and fast support to voice pathology detection. The identification of an algorithm that discriminates between pathological and healthy voices with more accuracy is needed to obtain a smart and precise mobile health system. The main contribution of this paper consists of proposing a multiclass-pathologic voice classification using a novel multileveled textural feature extraction with iterative feature selector. Our approach is a simple and efficient voice-based algorithm in which a multi-center and multi threshold based ternary pattern is used (MCMTTP). A more compact multileveled features are then obtained by sample-based discretization techniques and Neighborhood Component Analysis (NCA) is applied to select features iteratively. These features are finally integrated with MCMTTP to achieve an accurate voice-based features detection. Experimental results of six classifiers with three diagnostic diseases (frontal resection, cordectomy and spastic dysphonia) show that the fused features are more suitable for describing voice-based disease detection.","MCMTTP,discrete wavelet transform,voice disease detection,smart health,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"LOCAL,BINARY,PATTERN,FEATURE-EXTRACTION,FACE,RECOGNITION,CLASSIFICATION,SELECTION,NETWORK,SIGNALS,SYSTEMS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09086442.pdf,
13,Automation of Spine Curve Assessment in Frontal Radiographs Using Deep Learning of Vertebral-Tilt Vector,8,,84618-84630,"Kim Kang Cheol,Yun Hye Sun,Kim Sungjun,Seo Jin Keun","Kim KC,Yun HS,Kim S,Seo JK",Kim S,10.1109/ACCESS.2020.2992081,Yonsei University,"In this paper, an automated and visually explainable system is proposed for a scoliosis assessment from spinal radiographs, which deals with the drawback of manual measurements, which are known to be time-consuming, cumbersome, and operator dependent. Deep learning techniques have been successfully applied in the accurate extraction of Cobb angle measurements, which is the gold standard for a scoliosis assessment. Such deep learning methods directly estimate the Cobb angle without providing structural information of the spine which can be used for diagnosis. Although conventional segmentation-based methods can provide the spine structure, they still have limitations in the accurate measurement of the Cobb angle. It would be desirable to build a clinician-friendly diagnostic system for scoliosis that provides not only an automated Cobb angle assessment but also local and global structural information of the spine. This paper addresses this need through the development of a hierarchical method which consisting of three major parts. (1) A confidence map is used to selectively localize and identify all vertebrae in an accurate and robust manner, (2) vertebral-tilt field is used to estimate the slope of an individual vertebra, and (3) the Cobb angle is determined by combining the vertebral centroids with the previously obtained vertebral-tilt field. The performance of the proposed method was validated, resulting in circular mean absolute error of 3.51 degrees and symmetric mean absolute percentage error of 7.84% for the Cobb angle.","Frontal radiographs,spine,scoliosis,Cobb angle,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COBB,ANGLE,SCOLIOSIS",IEEE ACCESS,https://ir.ymlib.yonsei.ac.kr/bitstream/22282913/176226/1/T202001661.pdf,
14,Risk Assessment of Transmission Tower in Typhoon Based on Spatial Multi-source Heterogeneous Data,44,10,127-134,",,,,,","Hou Hui,Yu Shiwen,Xiao Xiang,Huang Yong,Geng Hao,Yu Jufang",,,Hou Hui,"Risk assessment and visualization of power system under typhoon disasters has scientific significance and engineering application value for disaster prevention and mitigation of power systems. In order to predict high-risk areas and optimize the emergency material allocation and risk-based dispatch of power flow, the data layer, knowledge extraction layer and visualization layer are used to construct the risk assessment system for power transmission towers under typhoon disasters. Firstly, based on equipment operation information, meteorological information and geographic information, a spatial multi-source heterogeneous information database is built. Then, based on parameter optimization, six machine learning algorithms are used to establish intelligent models for tower damage risk prediction, and a relative optimal model is selected through index comparison. At the same time, a combined model based on goodness of fit method with unequal weight is proposed. The tower damage risk in a Chinese coastal city under the typhoonMujigaeis assessed and visualized with dimension of 1 km*1 km. The relative optimal model is compared with the combined model in detail. The results show that both relative optimal model and combined model can identify the most severely damaged area, but the combined model has better prediction with the same risk threshold, which verifies the feasibility and rationality of the proposed method. Finally, the model universality and the influence of sample magnitude on prediction effect are analyzed.","typhoon disaster; power transmission tower; risk assessment; ,machine learning,; risk visualization; multi-source heterogeneous information",Article,,,,,,,,
15,A study of deep learning approaches for medication and adverse drug event extraction from clinical text,27,1,13-21,"Wei Qiang,Ji Zongcheng,Li Zhiheng,Du Jingcheng,Wang Jingqi,Xu Jun,Xiang Yang,Tiryaki Firat,Wu Stephen,Zhang Yaoyun","Wei Q,Ji ZC,Li ZH,Du JC,Wang JQ,Xu J,Xiang Y,Tiryaki F,Wu S,Zhang YY",Xu H,10.1093/jamia/ocz063,University of Texas System,"Objective: This article presents our approaches to extraction of medications and associated adverse drug events (ADEs) from clinical documents, which is the second track of the 2018 National NLP Clinical Challenges (n2c2) shared task.
Materials and Methods: The clinical corpus used in this study was from the MIMIC-III database and the organizers annotated 303 documents for training and 202 for testing. Our system consists of 2 components: a named entity recognition (NER) and a relation classification (RC) component. For each component, we implemented deep learning-based approaches (eg, BI-LSTM-CRF) and compared them with traditional machine learning approaches, namely, conditional random fields for NER and support vector machines for RC, respectively. In addition, we developed a deep learning-based joint model that recognizes ADEs and their relations to medications in 1 step using a sequence labeling approach. To further improve the performance, we also investigated different ensemble approaches to generating optimal performance by combining outputs from multiple approaches.
Results: Our best-performing systems achieved F1 scores of 93.45% for NER, 96.30% for RC, and 89.05% for end-to-end evaluation, which ranked #2, #1, and #1 among all participants, respectively. Additional evaluations show that the deep learning-based approaches did outperform traditional machine learning algorithms in both NER and RC. The joint model that simultaneously recognizes ADEs and their relations to medications also achieved the best performance on RC, indicating its promise for relation extraction.
Conclusion: In this study, we developed deep learning approaches for extracting medications and their attributes such as ADEs, and demonstrated its superior performance compared with traditional machine learning algorithms, indicating its uses in broader NER and RC tasks in the medical domain.","adverse drug events,electronic health records,deep learning,named entity recognition,relation extraction",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"ELECTRONIC,HEALTH,RECORDS,INFORMATION,EXTRACTION,SAFETY,SURVEILLANCE,PHARMACOVIGILANCE,CHALLENGES",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc6913210?pdf=render,
16,Identifying relations of medications with adverse drug events using recurrent convolutional neural networks and gradient boosting,27,1,65-72,"Yang Xi,Bian Jiang,Fang Ruogu,Bjarnadottir Ragnhildur I,Hogan William R.,Wu Yonghui","Yang X,Bian J,Fang RG,Bjarnadottir RI,Hogan WR,Wu YH",Wu YH,10.1093/jamia/ocz144,"Clin & Translat Res Bldg,2004 Mowry Rd,POB 100177, Gainesville, FL 32610 USA.","Objective: To develop a natural language processing system that identifies relations of medications with adverse drug events from clinical narratives. This project is part of the 2018 n2c2 challenge.
Materials and Methods: We developed a novel clinical named entity recognition method based on an recurrent convolutional neural network and compared it to a recurrent neural network implemented using the long-short term memory architecture, explored methods to integrate medical knowledge as embedding layers in neural networks, and investigated 3 machine learning models, including support vector machines, random forests and gradient boosting for relation classification. The performance of our system was evaluated using annotated data and scripts provided by the 2018 n2c2 organizers.
Results: Our system was among the top ranked. Our best model submitted during this challenge (based on recurrent neural networks and support vector machines) achieved lenient F1 scores of 0.9287 for concept extraction (ranked third), 0.9459 for relation classification (ranked fourth), and 0.8778 for the end-to-end relation extraction (ranked second). We developed a novel named entity recognition model based on a recurrent convolutional neural network and further investigated gradient boosting for relation classification. The new methods improved the lenient F1 scores of the 3 subtasks to 0.9292, 0.9633, and 0.8880, respectively, which are comparable to the best performance reported in this challenge.
Conclusion: This study demonstrated the feasibility of using machine learning methods to extract the relations of medications with adverse drug events from clinical narratives.","named entity recognition,relation extraction,recurrent convolutional neural network,deep learning,clinical natural language processing",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"CLINICAL,INFORMATION,EXTRACTION,OF-THE-ART,SYSTEM,RECOGNITION,ASSERTIONS,ENTITIES",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7489076,
17,Automatic extraction of cancer registry reportable information from free-text pathology reports using multitask convolutional neural networks,27,1,89-98,"Alawad Mohammed,Gao Shang,Qiu John X.,Yoon Hong Jun,Christian J. Blair,Penberthy Lynne,Mumphrey Brent,Wu Xiao-Cheng,Coyle Linda,Tourassi Georgia","Alawad M,Gao S,Qiu JX,Yoon HJ,Christian JB,Penberthy L,Mumphrey B,Wu XC,Coyle L,Tourassi G",Tourassi G,10.1093/jamia/ocz153,United States Department of Energy (DOE),"Objective: We implement 2 different multitask learning (MTL) techniques, hard parameter sharing and cross-stitch, to train a word-level convolutional neural network (CNN) specifically designed for automatic extraction of cancer data from unstructured text in pathology reports. We show the importance of learning related information extraction (IE) tasks leveraging shared representations across the tasks to achieve state-of-the-art performance in classification accuracy and computational efficiency.
Materials and Methods: Multitask CNN (MTCNN) attempts to tackle document information extraction by learning to extract multiple key cancer characteristics simultaneously. We trained our MTCNN to perform 5 information extraction tasks: (1) primary cancer site (65 classes), (2) laterality (4 classes), (3) behavior (3 classes), (4) histological type (63 classes), and (5) histological grade (5 classes). We evaluated the performance on a corpus of 95 231 pathology documents (71 223 unique tumors) obtained from the Louisiana Tumor Registry. We compared the performance of the MTCNN models against single-task CNN models and 2 traditional machine learning approaches, namely support vector machine (SVM) and random forest classifier (RFC).
Results: MTCNNs offered superior performance across all 5 tasks in terms of classification accuracy as compared with the other machine learning models. Based on retrospective evaluation, the hard parameter sharing and cross-stitch MTCNN models correctly classified 59.04% and 57.93% of the pathology reports respectively across all 5 tasks. The baseline models achieved 53.68% (CNN), 46.37% (RFC), and 36.75% (SVM). Based on prospective evaluation, the percentages of correctly classified cases across the 5 tasks were 60.11% (hard parameter sharing), 58.13% (cross-stitch), 51.30% (single-task CNN), 42.07% (RFC), and 35.16% (SVM). Moreover, hard parameter sharing MTCNNs outperformed the other models in computational efficiency by using about the same number of trainable parameters as a single-task CNN.
Conclusions: The hard parameter sharing MTCNN offers superior classification accuracy for automated coding support of pathology documents across a wide range of cancers and multiple information extraction tasks while maintaining similar training and inference time as those of a single task-specific model.","deep learning,multitask learning,convolutional neural network,cancer pathology reports,natural language processing,information extraction",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"CLINICAL,INFORMATION",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7489089,
18,Imputation and characterization of uncoded self-harm in major mental illness using machine learning,27,1,136-146,"Kumar Praveen,Nestsiarovich Anastasiya,Nelson Stuart J.,Kerner Berit,Perkins Douglas J.,Lambert Christophe G.","Kumar P,Nestsiarovich A,Nelson SJ,Kerner B,Perkins DJ,Lambert CG",Lambert CG,10.1093/jamia/ocz173,University of New Mexico,"Objective: We aimed to impute uncoded self-harm in administrative claims data of individuals with major mental illness (MMI), characterize self-harm incidence, and identify factors associated with coding bias.
Materials and Methods: The IBM MarketScan database (2003-2016) was used to analyze visit-level self-harm in 10 120 030 patients with >= 2 MMI codes. Five machine learning (ML) classifiers were tested on a balanced data subset, with XGBoost selected for the full dataset. Classification performance was validated via random data mislabeling and comparison with a clinician-derived ""gold standard."" The incidence of coded and imputed self-harm was characterized by year, patient age, sex, U.S. state, and MMI diagnosis.
Results: Imputation identified 1 592 703 self-harm events vs 83 113 coded events, with areas under the curve >0.99 for the balanced and full datasets, and 83.5% agreement with the gold standard. The overall coded and imputed self-harm incidence were 0.28% and 5.34%, respectively, varied considerably by age and sex, and was highest in individuals with multiple MMI diagnoses. Self-harm undercoding was higher in male than in female individuals and increased with age. Substance abuse, injuries, poisoning, asphyxiation, brain disorders, harmful thoughts, and psychotherapy were the main features used by ML to classify visits.
Discussion: Only 1 of 19 self-harm events was coded for individuals with MMI. ML demonstrated excellent performance in recovering self-harm visits. Male individuals and seniors with MMI are particularly vulnerable to self-harm undercoding and may be at risk of not getting appropriate psychiatric care.
Conclusions: ML can effectively recover unrecorded self-harm in claims data and inform psychiatric epidemiological and observational studies.","self-harm,suicide,machine learning,coding,electronic health records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"SUICIDAL-BEHAVIOR,E-CODES,INJURY,RISK,US,IDENTIFICATION,MULTICENTER,DISCHARGE,MULTIPLE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647246,
19,Derivation and validation of a machine learning record linkage algorithm between emergency medical services and the emergency department,27,1,147-153,"Redfield Colby,Tlimat Abdulhakim,Halpern Yoni,Schoenfeld David W.,Ullman Edward,Sontag David A.,Nathanson Larry A.,Horng Steven","Redfield C,Tlimat A,Halpern Y,Schoenfeld DW,Ullman E,Sontag DA,Nathanson LA,Horng S",Horng S,10.1093/jamia/ocz176,Harvard University,"Objective: Linking emergency medical services (EMS) electronic patient care reports (ePCRs) to emergency department (ED) records can provide clinicians access to vital information that can alter management. It can also create rich databases for research and quality improvement. Unfortunately, previous attempts at ePCR and ED record linkage have had limited success. In this study, we use supervised machine learning to derive and validate an automated record linkage algorithm between EMS ePCRs and ED records.
Materials and Methods: All consecutive ePCRs from a single EMS provider between June 2013 and June 2015 were included. A primary reviewer matched ePCRs to a list of ED patients to create a gold standard. Age, gender, last name, first name, social security number, and date of birth were extracted. Data were randomly split into 80% training and 20% test datasets. We derived missing indicators, identical indicators, edit distances, and percent differences. A multivariate logistic regression model was trained using 5-fold cross-validation, using label k-fold, L2 regularization, and class reweighting.
Results: A total of 14 032 ePCRs were included in the study. Interrater reliability between the primary and secondary reviewer had a kappa of 0.9. The algorithm had a sensitivity of 99.4%, a positive predictive value of 99.9%, and an area under the receiver-operating characteristic curve of 0.99 in both the training and test datasets. Date-of-birth match had the highest odds ratio of 16.9, followed by last name match (10.6). Social security number match had an odds ratio of 3.8.
Conclusions: We were able to successfully derive and validate a record linkage algorithm from a single EMS ePCR provider to our hospital EMR.","electronic patient care records,prehospital care,machine learning,record linkage,emergency medical services,clinical informatics,patient matching",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"PROBABILISTIC,LINKAGE,AIRWAY,MANAGEMENT,ASSOCIATION,DATABASES",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647245,
20,Machine Learning is Accelerating Materials Research,34,5A,09001-09002,",,","Zhang Qi,Zheng Yujie,Sun Kuan",,,Zhang Qi,"The development of artificial intelligence is reshaping our human society. As a branch of artificial intelligence,machine learning can learn from existing data and establish correlations between input data and the output. The performance of the model can be improved through training,helping us to discover hidden laws in the database. Progress has been made in applying machine learning to the field of materials science[1]. For example,machine learning is employed to establish the structure-property relationship in various material systems[2-3],quickly screen new materials[4-5], discover novel structures[6] and optimize experimental parameters [7],etc. It seems machine learning is revolutionizing the way of materials research by providing new approaches to materials design,synthesis,characterization,and application[8].",,Article,,,,,,,,
21,Fourth Industrial Revolution: An Impact on Health Care Industry,965,,58-69,"Jayanthi Prisilla);,Iyyanki Muralikrishna,Mothkuri Aruna,Vadakattu Prakruthi","Jayanthi P,Iyyanki M,Mothkuri A,Vadakattu P",,10.1007/978-3-030-20454-9_6,"
","The World Economic Forum annual meeting, held in Davos, Switzerland, emphasized the Fourth Industrial Revolution as one of the most cutting-edge innovative techniques to be seen in the forthcoming era. This has a greater impact on the future of production and the role of government, business and academia in all developing technologies and innovation where industries, communication and technologies meet. The fourth industrial revolution combines the physical, digital, and biological spaces and is changing the healthcare industry. The FCN-32 semantic segmentation was performed on the brain tumor images which produced better results for identifying the tumors as ground truths and predicted images was achieved. The best calculated loss = 0.0108 and accuracy = 0.9964 for the given tumor images was achieved. The earlier detecting and analysis of any disease can help diagnosing and treatment in better means through artificial intelligence techniques. The healthcare industry can serve better with faster and quality services to remote, rural and unreachable areas and thereafter reduces the cost of hospitalization.","Artificial Intelligence,Accuracy,Health care,Industrial revolution,Machine learning,Semantic segmentation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
22,"Targeting the uncertainty of predictions at patient-level using an ensemble of classifiers coupled with calibration methods, Venn-ABERS, and Conformal Predictors: A case study in AD",101,,,"Pereira Telma,Cardoso Sandra,Guerreiro Manuela,de Mendonca Alexandre,Madeira Sara C.","Pereira T,Cardoso S,Guerreiro M,de Mendonca A,Madeira SC",Pereira T; Madeira SC,10.1016/j.jbi.2019.103350,Universidade de Lisboa,"Despite being able to make accurate predictions, most existing prognostic models lack a proper indication about the uncertainty of each prediction, that is, the risk of prediction error for individual patients. This hampers their translation to primary care settings through decision support systems. To address this problem, we studied different methods for transforming classifiers into probabilistic/confidence-based predictors (here called uncertainty methods), where predictions are complemented with probability estimates/confidence regions reflecting their uncertainty (uncertainty estimates). We tested several uncertainty methods: two well-known calibration methods (Platt Scaling and Isotonic Regression), Conformal Predictors, and Venn-ABERS predictors. We evaluated whether these methods produce valid predictions, where uncertainty estimates reflect the ground truth probabilities. Furthermore, we assessed the proportion of valid predictions made at high-certainty thresholds (predictions with uncertainty measures above a given threshold) since this impacts their usefulness in clinical decisions. Finally, we proposed an ensemble-based approach where predictions from multiple pairs of (classifier, uncertainty method) are combined to predict whether a given MCI patient will convert to AD. This ensemble should putatively provide predictions for a larger number of patients while releasing users from deciding which pair of (classifier, uncertainty method) is more appropriate for data under study. The analysis was performed with a Portuguese cohort (CCC) of around 400 patients and validated in the publicly available ADNI cohort. Despite our focus on MCI to AD prognosis, the proposed approach can be applied to other diseases and prognostic problems.","Prognostic prediction,Mild cognitive impairment,Alzheimer's disease,Uncertainty at patient-level,Venn-ABERS,Conformal prediction",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,5.221,"MILD,COGNITIVE,IMPAIRMENT,CLASSIFICATION",JOURNAL OF BIOMEDICAL INFORMATICS,http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf,
23,Reactive molecular dynamics simulations and machine learning,1461,,,"Krishnamoorthy Aravind,Rajak Pankaj,Hong Sungwook,Nomura Ken-ichi,Tiwari Subodh,Kalia Rajiv K.,Nakano Aiichiro,Vashishta Priya","Krishnamoorthy A,Rajak P,Hong S,Nomura K,Tiwari S,Kalia RK,Nakano A,Vashishta P",Vashishta P,10.1088/1742-6596/1461/1/012182,University of Southern California,"Machine learning (ML) is revolutionizing scientific and engineering disciplines owing to its ability to capture hidden patterns in large amounts of data. The recent success of ML can be attributed to increasing amount of data, simulation resources, and improving understanding of statistical inference. For these reasons computational materials science is undergoing a paradigm shift. The main reason is that trial-and-error approach to materials design is inefficient: laboratory trials require a lot of time, and the results of previous trials are not utilized in a systematic fashion. A data-driven approach, which draws upon all relevant data from experiments, and reactive and quantum molecular dynamics simulations, can address these issues. The MAGICS (Materials Genome Innovation for Computational Software) Center develops to aid the synthesis of stacked layered materials by chemical vapor deposition, exfoliation, and intercalation. The identification of different phases is a classification problem and can be solved using ML techniques. We have used feed-forward neural network with three hidden layers to identify the different phases present during computational synthesis of MoSe2. Our goal is to carry out exascale MD simulations using forces for multimillion-atom quantum dynamics simulations from neural networks and deep learning using small QMD simulations.","MOS2 ATOMIC LAYERS,FORCE-FIELD,PERFORMANCE,REAXFF",Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Science & Technology - Other Topics,Materials Science,Optics,Imaging Science & Photographic Technology,Physics",,,"MOS2,ATOMIC,LAYERS,FORCE-FIELD,PERFORMANCE,REAXFF",,https://doi.org/10.1088/1742-6596/1461/1/012182,
24,Assessing the Heterogeneity of Complaints Related to Tinnitus and Hyperacusis from an Unsupervised Machine Learning Approach: An Exploratory Study.,25,4,174-189,",,","Palacios Guillaume,Norena Arnaud,Londero Alain",,10.1159/000504741,,"INTRODUCTION: Subjective tinnitus (ST) and hyperacusis (HA) are common auditory symptoms that may become incapacitating in a subgroup of patients who thereby seek medical advice. Both conditions can result from many different mechanisms, and as a consequence, patients may report a vast repertoire of associated symptoms and comorbidities that can reduce dramatically the quality of life and even lead to suicide attempts in the most severe cases. The present exploratory study is aimed at investigating patients' symptoms and complaints using an in-depth statistical analysis of patients' natural narratives in a real-life environment in which, thanks to the anonymization of contributions and the peer-to-peer interaction, it is supposed that the wording used is totally free of any self-limitation and self-censorship.DISCUSSION/CONCLUSION: We claim that the LDA non-supervised approach would permit to gain knowledge on the patterns of ST- and HA-related complaints and on patients' centered domains of interest. The merits and limitations of the LDA algorithms are compared with other natural language processing methods and with more conventional methods of qualitative analysis of patients' output. Future directions and research topics emerging from this innovative algorithmic analysis are proposed. © 2020 The Author(s) Published by S. Karger AG, Basel.","Computational predictive medicine; Hyperacusis; ,Machine learning,; Text mining; Tinnitus",Journal Article,,,,,,,,
25,Authentication of Remote IoT Users Based on Deeper Gait Analysis of Sensor Data,8,,101784-101796,"Batool Samera,Hassan Ali,Saqib Nazar Abbas,Khattak Muazzam A. Khan","Batool S,Hassan A,Saqib NA,Khattak MAK",Batool S,10.1109/ACCESS.2020.2998412,National University of Sciences & Technology - Pakistan,"In IoT based systems, authentication of users and devices is a major challenge where the traditional authentication mechanisms such as login-password are no longer supportable. It requires continuous authentication methods to ensure authenticity of the users and devices specifically for long sessions. The authentication through the IoT-Sensors based data has already gained the attention of a considerable number of researchers as it does not require direct involvement of the users and provide an extra layer of security and user privacy. Due to the instability of IoT-Sensor data, the authentication techniques need to extract a large number of features to produce high-accurate results. Moreover, the limited capabilities of computation, communication, storage, and the small battery power of IoT devices further makes its implementation hard. In this paper, we have introduced a user authentication framework for remote IoT users based on unique walking patterns to extract gait-related features with minimum data samples and cycle length. For an in-depth analysis of the distinctive features of the sensor-based gait profiles, we have applied an ECG signal processing technique. The proposed approach applies to a diverse range of IoT devices such as cellphones, smartwatches, and wearable sensors. The main contribution of the proposed approach is the deeper gait analysis with the least number of features and data for authentication purposes. We have introduced an authentication algorithm for feature comparison. The machine learning models have been applied to the gait based profiles for validation of the proposed approach. The detailed experimental analysis of different data sets has achieved an accuracy of 94% and an equal error rate (EER) of 6% higher than the existing approaches.","Authentication,Feature extraction,Electrocardiography,Accelerometers,Machine learning,Legged locomotion,Data analytics,gait analysis,human activity recognition,Internet of Things,sensor data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"INTERNET,THINGS,PRIVACY,SCHEME",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09103069.pdf,
26,Deep Cerebellar Nuclei Segmentation via Semi-Supervised Deep Context-Aware Learning from 7T Diffusion MRI,8,,101550-101568,"Kim Jinyoung,Patriat Remi,Kaplan Jordan,Solomon Oren,Harel Noam","Kim J,Patriat R,Kaplan J,Solomon O,Harel N",Kim J,10.1109/ACCESS.2020.2998537,University of Minnesota System,"Deep cerebellar nuclei are a key structure of the cerebellum that are involved in processing motor and sensory information. It is thus a crucial step to accurately segment deep cerebellar nuclei for the understanding of the cerebellum system and its utility in deep brain stimulation treatment. However, it is challenging to clearly visualize such small nuclei under standard clinical magnetic resonance imaging (MRI) protocols and therefore precise segmentation is not feasible. Recent advances in 7 Tesla (T) MRI technology and great potential of deep neural networks facilitate automatic patient-specific segmentation. In this paper, we propose a novel deep learning framework (referred to as DCN-Net) for fast, accurate, and robust patient-specific segmentation of deep cerebellar dentate and interposed nuclei on 7T diffusion MRI. DCN-Net effectively encodes contextual information on the patch images without consecutive pooling operations and adding complexity via proposed dilated dense blocks. During the end-to-end training, label probabilities of dentate and interposed nuclei are independently learned with a hybrid loss, handling highly imbalanced data. Finally, we utilize self-training strategies to cope with the problem of limited labeled data. To this end, auxiliary dentate and interposed nuclei labels are created on unlabeled data by using DCN-Net trained on manual labels. We validate the proposed framework using 7T B0 MRIs from 60 subjects. Experimental results demonstrate that DCN-Net provides better segmentation than atlas-based deep cerebellar nuclei segmentation tools and other state-of-the-art deep neural networks in terms of accuracy and consistency. We further prove the effectiveness of the proposed components within DCN-Net in dentate and interposed nuclei segmentation.","Image segmentation,Magnetic resonance imaging,Training,Cerebellum,Task analysis,Biomedical imaging,Convolution,7T diffusion MRI,deep cerebellar nuclei,deep neural networks,self-training,segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SUBTHALAMIC,NUCLEUS,BRAIN-STIMULATION,DENTATE,NUCLEUS,NETWORKS,ASSOCIATION,ATLAS",IEEE ACCESS,http://arxiv.org/pdf/2004.09788,
27,Classifying Melanoma Skin Lesions Using Convolutional Spiking Neural Networks With Unsupervised STDP Learning Rule,8,,101309-101319,"Zhou Qian,Shi Yan,Xu Zhenghua,Qu Ruowei,Xu Guizhi","Zhou Q,Shi Y,Xu ZH,Qu RW,Xu GZ",Xu ZH,10.1109/ACCESS.2020.2998098,Hebei University of Technology,"Deep learning methods have made some achievements in the automatic skin lesion recognition, but there are still some problems such as limited training samples, too complicated network structure, and expensive computational costs. Considering the inherent power-efficiency, biological plausibility and good image recognition performance of spiking neural networks (SNNs), in this paper we make malignant melanoma and benign melanocytic nevi skin lesions classification using convolutional SNNs with unsupervised spike-timing-dependent plasticity (STDP) learning rule. Efficient temporal coding, event driven learning rule and winner-take-all (WTA) mechanism together ensure sparse spike coding and efficient learning of our networks which achieve an average accuracy of 83.8%. We further propose to use feature selection to select more diagnostic features to improve the classification performance of our networks. Our SNNs with feature selection reach an average accuracy of 87.7%. Experimental results show that comparing to CNNs that need to be trained from scratch, our SNNs (with and without feature selection) not only achieve much better classification accuracies but also have much better runtime efficiency. Moreover, although the pretrained CNNs models can achieve similar running time, our proposed SNNs are more stable and easier to use than the pretrained CNNs because we do not need to try many pretrained models any more, and our SNNs also have much better classification accuracies than the pretrained CNNs. In addition, our networks have only three convolutional layers, and the complexity of the model and the parameters that need to be trained in the networks are greatly reduced. Our works show that STDP-based SNNs are very beneficial for the implementation of automated skin lesion classifiers on small portable devices.","Lesions,Feature extraction,Skin,Melanoma,Biomedical imaging,Training,Melanoma recognition,convolutional spiking neural networks,STDP,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,CANCER,PREDICTION,COINCIDENCE,FEEDFORWARD,DIAGNOSIS,PATTERNS,CORTEX,TRAINS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09103079.pdf,
28,Development of a new polarized hyperspectral imaging microscope,11213,,,"Zhou Ximing,Ma Ling,Halicek Martin,Dormer James,Fei Baowei","Zhou XM,Ma L,Halicek M,Dormer J,Fei BW",Fei BW,10.1117/12.2549676,University of Texas System,"In this study, we proposed and designed a transmission mode polarized hyperspectral imaging microscope (PHSIM). The hyperspectral imaging (HSI) component is based on the snapscan with a hyperspectral camera. The HSI wavelength range is from 467-700 nm. Polarized light imaging is realized by the integration of two polarizers and two liquid crystal variable retarders (LCVR), which is capable of full Stokes polarimetric imaging. The new imaging device was tested for the detection of squamous cell carcinoma (SCC) in H&E stained oral tissue slides of 8 patients. One normal area and one cancerous area on each slide are selected to make the comparison. The preliminary results indicated that the spectral curves of the Stokes vector parameters (S0, S1, S2, S3) of the normal area on the H&E stained oral tissue slides are different from those of SCC in certain wavelength range. Further work is required to apply the new polarized hyperspectral imaging microscope to a large number of patient samples and to test the PHSIM system in different cancer types.","Hyperspectral imaging,polarized light imaging,Stokes vector,head and neck cancer,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology,Surgery",,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309561,
29,Development of machine learning based predictive algorithm for thruster orifice diameter in rocket engine,28,,693-697,"Prudviraj K.,Deshmukh Sandip,Supradeepan K.","Prudviraj K,Deshmukh S,Supradeepan K",Deshmukh S,10.1016/j.matpr.2019.12.280,Birla Institute of Technology & Science Pilani (BITS Pilani),"Development of models to predict dimensions of a component is a highly researched topic to achieve a higher level of accuracy in their application. Machine Learning (ML) based predictive techniques now been used by researchers worldwide. ML techniques can help to develop models which can analyze big- ger and more complex problems, wherein the data can either be discrete data without numerical rela- tionship or ranked or binary or count data or time data or interval data, etc. During the present study, the ML -based mathematical technique (Artificial Neural Network) is used to predict the orifice diameter of a thruster used in a rocket engine. This approach can help to monitor the pressure drop before the thruster. 70% data sets are used for training the model, 15% data sets are used for testing purpose and 15% data sets are used for checking the accuracy of the model in predicting orifice diameter for different pressure drops. These results were compared with the laboratory data and observed that the accuracy was above 95% for the predicted diameter of the orifice for a required drop in pressure. (c) 2019 Elsevier Ltd. All rights reserved. Selection and peer -review under responsibility of the scientific committee of the 2nd International Con- ference on Recent Advances in Materials & Manufacturing Technologies.","Machine leaning,Artificial neural networks,Neurons,Orifice diameter,Pressure drop",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,"ARTIFICIAL,NEURAL-NETWORK",MATERIALS TODAY-PROCEEDINGS,,
30,Automatic classification of melanocytic skin tumors based on hyperparameters optimized by cross-validation using support vector machines,11211,,,"Gokkan Ozan,Tozburun Serhat","Gokkan O,Tozburun S",Gokkan O,10.1117/12.2542161,"Izmir Biomed & Genome Ctr, TR-35330 Izmir, Turkey.","Melanocytic lesions may occur in various areas of the skin and may eventually develop into malignant tissue types as a result of abnormal tissue growth. Although the gold standard for the diagnosis of melanoma is still a histopathological examination, dermatologists often use dermoscopic examination in their routine practice to reduce unnecessary excisions or to prevent misdiagnosis of clinically suspected melanocytic lesions. However, dermoscopic examinations may require special training and experience. Furthermore, even among experts, different evaluation results may occur. For these reasons, image processing and artificial intelligence application studies are performed on dermoscopic images based on information technologies developed in recent years. This study investigated the automatic classification of superficial spreading melanoma and nevocellular nevus using support vector machines. A publicly available and histopathologically verified MED-NODE data set (70 superficial spreading melanomas and 100 nevocellular naevi) was used. For the classification task, first, the energy distributions (power spectral densities) of each image in the spectral domain were obtained. Second, gray-level co-occurrence matrices were created, and the textural features of the matrices were extracted. Finally, the learning model was developed with these features as input for classification. Support vector machines were trained using validation methods, including holdout validation and stratified cross-validation. The hyperparameters were optimized using the regularization factor of 10, the radial basis kernel function, and the gamma factor of 0.0098. Using 10-fold cross-validation, we achieved a mean accuracy of 98.9% (+/- 0.01 standard deviation), 99.4% sensitivity, and 97.5% specificity.","Melanocytic skin,superficial spreading melanoma,nevocellular nevus,support vector machines,machine learning,binary classification,feature extraction,hyperparameter optimization",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Surgery",,,DERMOSCOPY,,,
31,Rapid Handheld Screening Device to Detect Skin and Soft Tissue Infections,11211,,,"Radhakrishnan Geethanjali,Gupta Aayush,King John,Ganvir Devina","Radhakrishnan G,Gupta A,King J,Ganvir D",Radhakrishnan G,10.1117/12.2546404,"Adiuvo Diagnost Private Ltd, Chennai, Tamil Nadu, India.","Skin and soft tissue infections (SSTIs) are one of the most common infections in India affecting 10-12% of Indian population. They are caused by a variety of bacteria and fungus, which makes it harder to diagnose and propose an effective treatment immediately especially in low resource settings due to the lack of access to qualified physicians. Management of SSTIs requires early expert infection assessment and remains a major challenge for the clinicians. A hand-held device is developed leveraging the inherent autofluorescence properties of the bacterial and fungal species that can non-invasively and rapidly identify the pathogens on SSTI using multispectral imaging followed by image processing and machine learning algorithms. The device can classify the gram type of bacteria with > 85% accuracy.","Multispectral imaging,SSTI,Wound,Handheld device,Multispectral imaging,Machine Learning,Gram type classification,autofluorescence(1)",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Surgery",,,,,,
32,Detecting nodular basal cell carcinoma in pathology imaging using deep learning image segmentation,11211,,,"Ren Jeannie,Lax Rivka,Krueger James G.,Browning James,Carucci John,White Kevin,Lish Samantha,Gareau Daniel S.","Ren J,Lax R,Krueger JG,Browning J,Carucci J,White K,Lish S,Gareau DS",Ren J,10.1117/12.2549950,Rockefeller University,"With over 4.3 million new cases in the U.S. every year, basal cell carcinoma (BCC), is the most common form of skin cancer. Pathologists must examine pathology images to diagnose BCC, potentially resulting in delay, error, and inconsistency. To address the need for standardized, expedited diagnosis, we created an automated diagnostic machine to identify BCC given pathology images. In MATLAB, we adapted a deep neural network image segmentation model, U-Net, to train on BCC images and their corresponding masks, which can learn to highlight these nodules in pathology images by outputting a computer-generated mask. We trained the U-Net on one image from the dataset and compared the computer-generated mask output from testing on three types of images: an image from a different region of the same image taken with the same microscope, an image from a different tissue sample with a different microscope, and an image taken with a confocal microscope. We observed good, medium and poor results, respectively, illustrating that performance depends on the similarity between test and training data. In subsequent tests using data augmentation, we achieved sensitivity of 0.82 +/- 0.07 and specificity of 0.87 +/- 0.16 on N = 6 sample sections from 3 different BCCs imaged with the same microscope system. These data show that the U-Net performed well with a relatively few number of training images. Examining the errors raised interesting questions regarding what the errors mean and how they possibly arose. By creating a surgeon interface for rapid pathological assessment and machine learning diagnostics for pathological features, the BCC diagnosis process will be expedited and standardized.","Basal Cell Carcinoma,skin cancer,deep learning,machine learning,image segmentation,automated diagnosis",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Surgery",,,,,,
33,Discriminative Feature Selection-Based Motor Imagery Classification Using EEG Signal,8,,98255-98265,"Molla Md Khademul Islam,Al Shiam Abdullah,Islam Md Rabiul,Tanaka Toshihisa","Molla MKI,Al Shiam A,Islam MR,Tanaka T",Molla MKI,10.1109/ACCESS.2020.2996685,University of Rajshahi,"Achieving a reliable classification of motor imagery (MI) tasks is a major challenge in brain-computer interface (BCI) implementation. The set of relevant and discriminative features plays an important role in the classification scheme. This paper presents a supervised approach to select discriminative features for the enhancement of MI classification using multichannel electroencephalography (EEG) signal. The dimension of multiband feature space is reduced using the feature selection method. Each trial of the multichannel EEG signal representing MI tasks is decomposed into a finite set of narrowband signals. The common spatial pattern-based features are extracted from each subband. The features obtained from the multiple subbands are combined to derive a high-dimensional feature vector. The neighborhood component analysis-based feature selection method is implemented to select the features that are relevant in performing an accurate classification. It is a nearest-neighbor-based approach to learn the feature weights with regularization by maximizing the average leave-one-out classification accuracy over the labeled training data. The selected features are used to train the support vector machine for classification. The features relatively irrelevant to the classification task are discarded, yielding a reduction of feature dimension. The evaluation of the proposed method is performed using BCI Competition III dataset 4a and IV dataset 2b. Both are publicly available datasets and are used as types of benchmark data to evaluate the MI classification algorithm to implement BCI. The obtained simulation results confirm the superiority of the proposed method compared to the recently developed algorithms.","Feature extraction,Electroencephalography,Task analysis,Narrowband,Training,Training data,Support vector machines,Brain-computer interface (BCI),electroencephalography (EEG),machine learning,motor imagery (MI),subband decomposition,supervised feature selection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SINGLE-TRIAL,EEG,SPATIAL-PATTERNS,NEUROREHABILITATION,INTERFACES,MACHINE",IEEE ACCESS,https://doi.org/10.1109/access.2020.2996685,
34,Synthetic Blood Smears Generation Using Locality Sensitive Hashing and Deep Neural Networks,8,,102530-102539,"Al-Qudah Rabiah,Suen Ching Y.","Al-Qudah R,Suen CY",Al-Qudah R,10.1109/ACCESS.2020.2999349,Concordia University - Canada,"Peripheral Blood Smear (PBS) analysis is a vital routine test carried out by hematologists to assess some aspects of humans' health status. PBS analysis is prone to human errors and utilizing computer-based analysis can greatly enhance this process in terms of accuracy and cost. Recent approaches in learning algorithms, such as deep learning, are data hungry, but due to the scarcity of labeled medical images, researchers had to find viable alternative solutions to increase the size of available datasets. Synthetic datasets provide a promising solution to data scarcity, however, the complexity of blood smears' natural structure adds an extra layer of challenge to its synthesizing process. In this work, we propose a methodology that utilizes Locality Sensitive Hashing (LSH) to create a novel balanced dataset of 2500 synthetic blood smears. This dataset, which was automatically annotated during the generation phase, will be made public for research purposes and covers 17 essential categories of blood cells. We proved the effectiveness of the proposed dataset by utilizing it for training a deep neural network, this model got a very high accuracy score of 98.72% when tested with the well known ALL-IDB dataset. The dataset also got the approval of 5 experienced hematologists to meet the general standards of making thin blood smears.","Automatic annotation,blood films,blood smears,deep learning,LSH,medical data,synthetic dataset",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,LEUKEMIA",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09106310.pdf,
35,Data Efficient Segmentation of Various 3D Medical Images Using Guided Generative Adversarial Networks,8,,102022-102031,"Asma-Ull Hosna,Yun Il Dong,Han Dongjin","Asma-Ull H,Yun I,Han D",Yun I,10.1109/ACCESS.2020.2998735,Hankuk University Foreign Studies,"The recent significant increase in accuracy of medical image processing is attributed to the use of deep neural networks as manual segmentation generates errors in interpretation besides, is very arduous and inefficient. Generative adversarial networks (GANs) is a particular interest to medical researchers, as it implements adversarial loss without explicit modeling of the probability density function. Medical image segmentation methods face challenges of generalization and over-fitting, as medical data suffers from various shapes and diversity of organs. Furthermore, generating a sufficiently large annotated dataset at a clinical site is costly. To generalize learning with a small amount of training data, we propose guided GANs (GGANs) that can decimate samples from an input image and guide networks to generate images and corresponding segmentation mask. The decimated sampling is the key element of the proposed method employed to reduce network size using only a few parameters. Moreover, this method yields promising results by generating several outputs, such as bagging approach. Furthermore, errors of loss function increase, during the generation of original images and corresponding segmentation mask, in comparison to generating only the segmentation mask. Minimization of increased error leads (GGANs) to enhance the performance of segmentation using smaller datasets and less testing time. This method can be applied to a wide range of segmentation problems for different modalities and various organs (such as aortic root, left atrium, knee cartilage, and brain tumors) during a real-time crisis in hospitals. The proposed network also yields high accuracy compared to state-of-the-art networks.","Image segmentation,Biomedical imaging,Gallium nitride,Tumors,Generative adversarial networks,Shape,Valves,Medical image segmentation,generative adversarial network,aortic valve,left atrium,knee cartilage,brain tumor,decimated sample",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AUTOMATIC,SEGMENTATION,ARTICULAR-CARTILAGE,CT,AORTA",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09103512.pdf,
36,A Novel Multi-Scale Adversarial Networks for Precise Segmentation of X-Ray Breast Mass,8,,103772-103781,"Chen Juan,Chen Liangyong,Wang Shengsheng,Chen Peng","Chen J,Chen LY,Wang SS,Chen P",Wang SS,10.1109/ACCESS.2020.2999198,Jilin University,"With the constant changes of people's lifestyle and living environment, the morbidity of breast cancer is increasing year by year. It is highly imperative to develop an effective breast mass segmentation method for early breast cancer diagnosis. However, segmenting breast masses in mammograms is still one hot issue with enormous challenges because of masses' irregular shapes and various sizes. In this study, we propose multi-adversarial learning to capture multi-scale image information for accurate breast mass segmentation. To effectively reinforce higher-order consistency in the segmentation results, the proposed network introduces the idea of adversarial networks, mainly consisting of a segmentation network and a discrimination network. An improved U-Net is introduced as the segmentation network to generate masks of the suspicious regions, while the discrimination network combines three convolutional critic networks that operate at different scales to discriminate the input masks. To weaken the unbalanced class problem and produce fine-grained segmentation results, weighted cross entropy loss and Earth-Mover distance are jointly used as an integrated loss function to guide the optimization process. Furthermore, the spectral normalization is adopted to the critics to alleviate the instability of training. The effectiveness of the proposed method is evaluated on two public datasets (INbreast and CBIS-DDSM). Experimental results empirically demonstrate that our method outperforms FCNs-based methods and the state-of-the-art method with dice of 81.64% for INbreast and 82.16% for CBIS-DDSM.","Deep learning,semantic segmentation,adversarial learning,breast mass,mammography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AIDED,DIAGNOSIS,SYSTEM,DIGITAL,MAMMOGRAMS,CLASSIFICATION,CANCER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09104967.pdf,
37,Online Tracking and Relocation Based on a New Rotation-Invariant Haar-Like Statistical Descriptor in Endoscopic Examination,8,,101867-101883,"Gong Haifan,Chen Limin,Li Changhao,Zeng Jun,Tao Xichen,Wang Yue","Gong HF,Chen LM,Li CH,Zeng J,Tao XC,Wang Y",Chen LM,10.1109/ACCESS.2020.2994440,Nanchang University,"In the gastrointestinal biopsy, online tracking and relocation of the region-of-interest are essential to early diagnosis and surgical intervention of colorectal cancer. However, it is challenging for the examiner to track and retarget the optical biopsy site due to interfering factors, e.g. violent rotation of the lens, illumination variation, shape deformation, and target long-time-lost. Previous works may not effectively handle the mentioned challenges due to the complexity of gastrointestinal environment and the limitation of data. In this work, we construct an online tracking and relocation framework based on the concept of detection and tracking, which is dramatically adapted to the inherent characteristics of the gastrointestinal biopsy image. To effectively distinguish the target area from the gastrointestinal biopsy, we designed a new rotated invariant Haar-like statistical descriptor which is robust for rotating and illumination changes. The descriptor is based on the sector-ring difference under the circular sampling area. A simplified statistical random forest discriminator based on confidence statistics is proposed to complete the preliminary screening of the potential tracking target. In order to further estimate the location of the target, a supervised support vector machine is introduced to rank the candidate target regions. Based on proposals of Siamese network and the random forest, a location refinement fusion has been proposed to determine the location and the confidence of the tracking area. Extensive experiments on various gastrointestinal videos, which consists of open source and self-collected data, demonstrate that the proposed framework is superior to the mainstreams methods in accuracy and robustness.","Gastrointestinal tract,Target tracking,Biopsy,Feature extraction,Robustness,Cancer,Relocation,online tracking,Haar-like feature,random forest,Siamese network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2994440,
38,Machine Learning Algorithms and Quantitative Electroencephalography Predictors for Outcome Prediction in Traumatic Brain Injury: A Systematic Review,8,,102075-102092,"Noor Nor Safira Elaina Mohd,Ibrahim Haidi","Noor NSEM,Ibrahim H",Ibrahim H,10.1109/ACCESS.2020.2998934,Universiti Sains Malaysia,"Recent developments in the field of machine learning (ML) have led to a renewed interest in the use of electroencephalography (EEG) to predict the outcome after traumatic brain injury (TBI). This systematic review aims to determine how previous studies have taken into consideration the important modeling issues for quantitative EEG (qEEG) predictors in developing prognostic models. A systematic search in the PubMed and Google Scholar databases was performed to identify all predictive models for the extended Glasgow outcome scale (GOSE) and Glasgow outcome scale (GOS) based on EEG data. Fourteen studies were identified that evaluated ML algorithms using qEEG predictors to predict outcome in patients with moderate to severe TBI. In each model, a maximum of five qEEG predictors were selected to determine the association between these parameters, and favorable or unfavorable predicted outcomes. The most common ML technique used was logistic regression, but the algorithms varied depending on the types and numbers of qEEG predictors selected in each model. The qEEG variability for the relative and absolute band powers were the most common qEEG predictors included in the models (46%) followed by total EEG power of all frequency bands (31%), EEG-reactivity (31%) and coherence (15%). Model performance was often quantified by the area under the receiving-operating characteristic curve (AUROC) rather than by accuracy rate. Various ML models have demonstrated great potential, especially using qEEG predictors, to predict outcome in patients with moderate to severe TBI.","Electroencephalography,prediction methods,reviews",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PERCENT-ALPHA-VARIABILITY,RESTING-STATE,EEG,PROGNOSTIC,MODELS,RECOVERY,CONSCIOUSNESS,CONNECTIVITY,MORTALITY,SEVERITY,VALIDITY,NETWORK",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09104717.pdf,
39,Global Cortical Network Distinguishes Motor Imagination of the Left and Right Foot,8,,103734-103745,"Phang Chun-Ren,Ko Li-Wei","Phang CR,Ko LW",Ko LW,10.1109/ACCESS.2020.2999133,National Yang Ming Chiao Tung University,"Conventional passive lower limb rehabilitation is suboptimal since the brain is not actively involved in the training. An autonomous motor imagery brain-computer interface (MI-BCI) could potentially improve rehabilitation outcomes. However, motor cortex regions associated with the individual feet are anatomically close to each other. This presents a difficulty in distinguishing the left and right foot MI during rehabilitation therapy. To overcome this difficulty, we extracted functional connectivity to measure the global cortical network via electroencephalography (EEG) signals. Fourteen spatial connections (P3-Fp1, P3-F3, P3-F7, P3-C3, T5-F7, T5-C3, T5-T3, Fp2-T5, Fp2-P3, T6-Fp2, T6-T4, Cz-Fp1, Cz-F7 and Fp2-F7) found across twelve subjects significantly differed between the left and right foot MI, evidencing nonlocalized brain activity during MI. Foot MI were distinguished using machine learning algorithms in terms of the time- and frequency-domain connectivities extracted from Pearson's correlation, multivariate autoregression (MVAR), bandpass correlation, and partial directed coherence (PDC) models. The results showed that connectivity extracted by pairwise Pearson's correlation could be distinguished with 86.26 +/- 9.95%, while in the frequency-domain, the gamma band presented the best classification accuracy of 73.55 +/- 17.11%. We attempted to simulate asynchronous real-time classification paradigms in order to evaluate the classification performance of connectivity features compared to common spatial pattern (CSP) and band power (BP). The results indicate correlation-connectivity has the best outcome, attaining an accuracy of 80.75 +/- 9.51% in asynchronous classification.","Brain-computer interface,brain connectivity networks,machine learning,EEG,foot motor imagery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FUNCTIONAL,CONNECTIVITY,PARIETAL,CORTEX,BCI,SYSTEM,IMAGERY,EEG,EXECUTION,REHABILITATION,CLASSIFICATION,EXOSKELETON,MUSIC",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09104995.pdf,
40,Diabetic Retinopathy Detection Using Prognosis of Microaneurysm and Early Diagnosis System for Non-Proliferative Diabetic Retinopathy Based on Deep Learning Algorithms,8,,104292-104302,"Qiao Lifeng,Zhu Ying,Zhou Hui","Qiao LF,Zhu Y,Zhou H",Zhou H,10.1109/ACCESS.2020.2993937,Sichuan Provincial People's Hospital,"Predicting the presence of Microaneurysms in the fundus images and the identification of diabetic retinopathy in early-stage has always been a major challenge for decades. Diabetic Retinopathy (DR) is affected by prolonged high blood glucose level which leads to microvascular complications and irreversible vision loss. Microaneurysms formation and macular edema in the retinal is the initial sign of DR and diagnosis at the right time can reduce the risk of non proliferated diabetic retinopathy. The rapid improvement of deep learning makes it gradually become an efficient technique to provide an interesting solution for medical image analysis problems. The proposed system analysis the presence of microaneurysm in fundus image using convolutional neural network algorithms that embeds deep learning as a core component accelerated with GPU(Graphics Processing Unit) which will perform medical image detection and segmentation with high-performance and low-latency inference. The semantic segmentation algorithm is utilized to classify the fundus picture as normal or infected. Semantic segmentation divides the image pixels based on their common semantic to identify the feature of microaneurysm. This provides an automated system that will assist ophthalmologists to grade the fundus images as early NPDR, moderate NPDR, and severe NPDR. The Prognosis of Microaneurysm and early diagnosis system for non - proliferative diabetic retinopathy system has been proposed that is capable to train effectively a deep convolution neural network for semantic segmentation of fundus images which can increase the efficiency and accuracy of NPDR (non proliferated diabetic retinopathy) prediction.","Diabetes,Retinopathy,Retina,Lesions,Image segmentation,Semantics,Biomedical imaging,Microaneurysm,diabetic retinopathy,deep convolution neural network,semantic segmentation,non proliferated diabetic retinopathy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,VALIDATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09091167.pdf,
41,Volumetric Segmentation of Brain Regions From MRI Scans Using 3D Convolutional Neural Networks,8,,103697-103709,"Ramzan Farheen,Khan Muhammad Usman Ghani,Iqbal Sajid,Saba Tanzila,Rehman Amjad","Ramzan F,Khan MUG,Iqbal S,Saba T,Rehman A",Iqbal S,10.1109/ACCESS.2020.2998901,Bahauddin Zakariya University,"Automated brain segmentation is an active research domain due to the association of various neurological disorders with different regions of the brain, to help medical professionals in prognostics and diagnostics. Traditional techniques like atlas-based and pattern recognition-based methods led to the development of various tools for automated brain segmentation. Recently, deep learning techniques are outperforming classical state-of-the-art methods and gradually becoming more mature. Consequently, deep learning has been extensively employed as a tool for precise segmentation of brain regions because of its capability to learn the intricate features of the high-dimensional data. In this work, a network for the segmentation of multiple brain regions has been proposed that is based on 3D convolutional neural networks and utilizes residual learning and dilated convolution operations to efficiently learn the end-to-end mapping from MRI volumes to the voxel-level brain segments. This research is focused on the segmentation of up to nine brain regions including cerebrospinal fluid, white matter and gray matter as well as their sub-regions. Mean dice scores of 0.879 and 0.914 have been achieved for three and nine brain regions, respectively by using the data from three different sources. Comparative analysis shows that our network gives better dice scores for most of the brain regions than state-of-the-artwork. Moreover, the mean dice score of 0.903, obtained for eight brain regions segmentation with MRBrains18 dataset, is better than 0.876 which was achieved in the previous work.","Brain segmentation,convolutional neural networks,magnetic resonance imaging,volumetric segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AUTOMATIC,SEGMENTATION,ALZHEIMERS-DISEASE,STRUCTURAL-CHANGES,DEEP,IMAGES,DIAGNOSIS,RESOURCE,TISSUES,FUSION,MODEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09104657.pdf,
42,Real-World Gait Bout Detection Using a Wrist Sensor: An Unsupervised Real-Life Validation,8,,102883-102896,"Soltani Abolfazl,Paraschiv-Ionescu Anisoara,Dejnabadi Hooman,Marques-Vidal Pedro,Aminian Kamiar","Soltani A,Paraschiv-Ionescu A,Dejnabadi H,Marques-Vidal P,Aminian K",Aminian K,10.1109/ACCESS.2020.2998842,Ecole Polytechnique Federale de Lausanne,"Gait bouts (GB), as a prominent indication of physical activity, contain valuable fundamental information closely associated with human's health status. Therefore, objective assessment of the GB (e.g. detection, spatio-temporal analysis) during daily life is very important. A feasible and effective way of GB detection in real-world situations is using a wrist-mounted inertial measurement unit. However, the high degree of freedom of the wrist movements during daily-life situations imposes serious challenges for a precise and robust automatic detection. In this study, we deal with such challenges and propose an accurate algorithm to detect GB using a wrist-mounted accelerometer. Features, derived based on biomechanical criteria (intensity, periodicity, posture, and other non-gait dynamicity), along with a Bayes estimator followed by two physically-meaningful post-classification procedures are devised to optimize the performance. The proposed method has been validated against a shank-based reference algorithm on two datasets (29 young and 37 elderly healthy people). The method has achieved a high median [interquartile range] of 90.2 [80.4, 94.6] (%), 97.2 [95.8, 98.4] (%), 96.6 [94.4, 97.8] (%), 80.0 [65.1, 85.9] (%) and 82.6 [72.6, 88.5] (%) for the sensitivity, specificity, accuracy, precision, and F1-score of the detection of GB, respectively. Moreover, a high correlation (R-2 = 0 :95) was observed between the proposed method and the reference for the total duration of GB detected for each subject. The method has been also implemented in real time on a low power consumption prototype.","Real-world gait bout,physical activity,wrist accelerometer,machine learning,low power,and real-time",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PHYSICAL-ACTIVITY,ACTIVITY,CLASSIFICATION,ACTIVITY,RECOGNITION,TRIAXIAL,ACCELEROMETER,AMBULATORY,SYSTEM,ALGORITHM,POSTURE,DURATION,MACHINE,WALKING",IEEE ACCESS,https://infoscience.epfl.ch/record/278795/files/09104680.pdf,
43,Rail Weld Defect Prediction and Related Condition-Based Maintenance,8,,103746-103758,"Yao Nan,Jia Yuejun,Tao Kai","Yao N,Jia YJ,Tao K",Yao N,10.1109/ACCESS.2020.2999385,"China Acad Railway Sci Corp Ltd, Beijing 100081, Peoples R China.","Rail weld defects are major threats to railroad transportation. Enormous resources have been required for related maintenance. This paper presents a creative solution to predict weld defects and to classify railroads into different conditions based on the predictions. The results are based on features extracted from manufacturing technologies of welds, from related materials and from influential factors in the environments. Features such as marks for welding engineers are defined. Maintenance can be selectively implemented based on the predicted conditions. Safety is the foundation of the railroad business, and a very strict safety requirement is utilized as one of the main constraints in this research. Additionally, 11 key risk factors leading to rail defects and their risk levels are identified. Extreme learning machine (ELM), random forest, logistic regression, principal component analysis (PCA), support vector machine (SVM) and other data science approaches are utilized. The evaluation results show that the related rail maintenance workload can decrease significantly under high safety standards. Labor costs of weld inspection will be reduced substantially because of the decreased workload for the sections predicted to not have any defects with a 100% recall rateyyy (approximately 30% of the total sections), contributing to a massive cost reduction. Consequently, rail companies are expected to achieve enhanced management and operation.","Condition-based maintenance,extreme learning machine,logistic regression,rail weld defect prediction,random forests,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EXTREME,LEARNING-MACHINE,REGRESSION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09106330.pdf,
44,Detection of Cutaneous Tumors in Dogs Using Deep Learning Techniques,965,,83-91,"Zapata Lorena,Chalco Lorena,Aguilar Lenin,Pimbosa Esmeralda,Ramirez-Morales Ivan,Hidalgo Jairo,Yandun Marco,Arias-Flores Hugo,Guevara Cesar","Zapata L,Chalco L,Aguilar L,Pimbosa E,Ramirez-Morales I,Hidalgo J,Yandun M,Arias-Flores H,Guevara C",Guevara C,10.1007/978-3-030-20454-9_8,"Univ Indoamer, Inst Res Dev & Innovat MIST, EC-170301 Quito, Ecuador.","Cytological diagnosis is useful in the practical context compared to the histopathology, since it can classify pathologies among the cutaneous masses, the samples can be collected easily without anesthetizing the patient, at very low cost. However, an experimented veterinarian performs the cytological diagnosis in approximately 25 min. Artificial intelligence is being used for the diagnosis of many pathologies in human medicine, the experience gained by years of work in the area of work allow to issue correct diagnoses, this experience can be trained in an intelligent system. In this work, we collected a total of 1500 original cytologic images, performed some preliminary tests and also propose a deep learning based approach for image analysis and classification using convolutional neural networks (CNN). To adjust the parameters of the classification model, we recommend to perform a random and grid search will be applied, modifying the batch size of images for training, the number of layers, the learning speed and the selection of three optimizers: Adadelta, RMSProp and SGD. The performance of the classifiers will be evaluated by measuring the accuracy and two loss functions: cross-categorical entropy and mean square error. These metrics will be evaluated in a set of images different from those with which the model was trained (test set). By applying this model, an image classifier can be generated that efficiently identifies a cytology diagnostic in a short time and with an optimal detection rate. This is the first approach for the development of a more complex model of skin mass detection in all its types.","Deep learning,Cancer,Veterinary,Cytology,Convolutional Neural Networks",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,"ARTIFICIAL,NEURAL-NETWORKS,CANCER",,,
45,Cascading Convolutional Neural Network for Steel Surface Defect Detection,965,,202-212,"Lin Chih-Yang,Chen Cheng-Hsun,Yang Ching-Yuan,Akhyar Fityanul,Hsu Chao-Yung,Ng Hui-Fuang","Lin CY,Chen CH,Yang CY,Akhyar F,Hsu CY,Ng HF",Lin CY,10.1007/978-3-030-20454-9_20,Yuan Ze University,"Steel is the most important material in the world of engineering and construction. Modern steelmaking relies on computer vision technologies, like optical cameras to monitor the production and manufacturing processes, which helps companies improve product quality. In this paper, we propose a deep learning method to automatically detect defects on the steel surface. The architecture of our proposed system is separated into two parts. The first part uses a revised version of single shot multibox detector (SSD) model to learn possible defects. Then, deep residual network (ResNet) is used to classify three types of defects: Rust, Scar, and Sponge. The combination of these two models is investigated and discussed thoroughly in this paper. This work additionally employs a real industry dataset to confirm the feasibility of the proposed method and make sure it is applicable to real-world scenarios. The experimental results show that the proposed method can achieve higher precision and recall scores in steel surface defect detection.","Fully convolutional networks,Defect detection,SSD,ResNet",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
46,Multimodal fNIRS-EEG Classification Using Deep Learning Algorithms for Brain-Computer Interfaces Purposes,953,,209-220,"Saadati Marjan,Nelson Jill,Ayaz Hasan","Saadati M,Nelson J,Ayaz H",Saadati M,10.1007/978-3-030-20473-0_21,George Mason University,"The development of brain-computer interface (BCI) systems has received considerable attention from neuroscientists in recent years. BCIs can serve as a means of communication and for the restoration of motor function for patients with motor disorders. An essential part of the design of a BCI is correctly classifying the brain signals, historically collected using electroen-cephalography (EEG). However, recent studies have shown more robust classification results when EEG is combined with other neuroimaging methods such as fNIRS. Conventional classification methods need a priori feature preprocessing to train the model; such feature selection is a difficult and heavily studied problem. By using deep neural networks (DNN), in which recordings can be fed directly to the algorithm for training, we avoid the need for feature selection. In this study, the capabilities of DNNs in the classification of the hybrid EEG-fNIRS recordings of motor imagery (MI) and mental workload (MWL) tasks are investigated. A five-layer fully connected network is used for classification. This study makes use of two open-source meta-datasets collected at the Technische Universitat Berlin. The first dataset includes brain activity recordings of 26 healthy participants during three cognitive tasks: (1) n-back (0-, 2- and 3-back), (2) discrimination/selection response task (DSR) and (3) word generation (WG) tasks. The second dataset, motor imagery, consists of left and right-hand motor imagery tasks, each for 29 healthy participants. Our results show that classification accuracy is considerably higher for multimodal recordings when compared to EEG or fNIRS recordings alone. The proposed algorithm improves classification performance relative to a conventional support vector machine (SVM), reaching 90% average accuracy for both tasks, 8% higher than SVM performance. These results demonstrate the feasibility of achieving strong classification performance using multimodal BCI and deep learning.","EEG,fNIRS,Deep neural networks,Deep learning,Brain imaging,Brain computer interfaces,Human machine interfaces",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Neurosciences & Neurology",,,PERFORMANCE,,,
47,Convolutional Neural Network for Hybrid fNIRS-EEG Mental Workload Classification,953,,221-232,"Saadati Marjan,Nelson Jill,Ayaz Hasan","Saadati M,Nelson J,Ayaz H",Saadati M,10.1007/978-3-030-20473-0_22,George Mason University,"The classification of workload memory tasks based on fNIRS and EEG signals requires solving high-dimensional pattern classification problems with a relatively small number of training patterns. In the use of conventional machine learning algorithms, feature selection is a fundamental difficulty given the large number of possible features and the small amount of available data. In this study, we bypass the challenges of feature selection and investigate the use of Convolutional Neural Networks (CNNs) for classifying workload memory tasks. CNNs are well suited for learning from the raw data without any a priori feature selection. CNNs take as input two-dimensional images, which differ in structure from the neural time series obtained on the scalp surface using EEG and fNIRS. Therefore, both the existing CNN architectures and fNIRS-EEG input must be adapted to allow fNIRS-EEG input to a CNN. In this work, we describe this adaptation, evaluate the performance of CNN classification of mental workload tasks. This study makes use of an open-source meta-dataset collected at the Technische Universitat Berlin; including simultaneous EEG and fNIRS recordings of 26 healthy participants during n-back tests. A CNN with three convolution layers and two fully connected layers is adapted to suit the given dataset. ReLU and ELU activation functions are employed to take advantage of their better dampening property in the vanishing gradient problem, fast convergence, and higher accuracy. The results achieved with the two activation functions are compared to select the best performing function. The proposed CNN approach achieves a considerable average improvement relative to conventional methods such as Support Vector Machines. The results across differences in time window length, activation functions, and other hyperparameters are benchmarked for each task. The best result is obtained with a three-second window and the ELU activation function, for which the CNN yields 89% correct classification, while the SVM achieves only 82% correct classification.","EEG,fNIRS,Convolutional neural networks,Deep learning,Brain imaging,Brain computer interfaces,Human machine interfaces",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Neurosciences & Neurology",,,PERFORMANCE,,,
48,On Stability of Feature Selection Based on MALDI Mass Spectrometry Imaging Data and Simulated Biopsy,1033,,82-93,"Wilk Agata,Gawin Marta,Fratczak Katarzyna,Widlak Piotr,Fujarewicz Krzysztof","Wilk A,Gawin M,Fratczak K,Widlak P,Fujarewicz K",Fujarewicz K,10.1007/978-3-030-29885-2_8,Silesian University of Technology,"In this work we analyse MALDI mass spectrometry imaging data for thyroid cancer samples. Such a data, containing information about spatial distribution of proteins/peptides, makes possible to make a virtual analysis how a technique of fine needle aspiration (FNA) biopsy, a routine diagnosis procedure for thyroid, influences the outcome i.e. a set of discriminative features between cancerous and normal tissue. We hypothesised that an impure dataset (consisting of normal cell contaminated cancer samples) would be beneficial in the terms of stable feature selection. We compared several methods of predictor selection on different datasets to perform an in-depth feature ranking stability analysis for thyroid cancer mass spectrometry data. Furthermore we examined the impact of sample contamination level on the selection.","MALDI imaging mass spectrometry,Machine learning,Feature selection,Fine needle biopsy",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering,Medical Laboratory Technology",,,PROFILES,,,
49,Detection of Epileptic Seizures via Deep Long Short-Term Memory,1033,,166-178,"Patan Krzysztof,Rutkowski Grzegorz","Patan K,Rutkowski G",Patan K,10.1007/978-3-030-29885-2_15,University of Zielona Gora,"The paper deals with the designing and implementation of a computer-aided system capable to detect seizures by classification of EEG records. The system is based on deep learning method using a recurrent long short-term memory neural network. The main purpose of the system is to help neurologists in detecting seizures fast and reliably. The research was carried out using real EEG recordings of epileptic patients as well as healthy subjects prepared with the cooperation of the medical staff of the Clinical Ward of Neurology of the University Hospital of Zielona Gora, Poland.","EEG signals,Seizure detection,Deep learning,Long short-term memory,Classification",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering,Medical Laboratory Technology",,,"FEATURE-EXTRACTION,CLASSIFICATION",,,
50,RMID: A Novel and Efficient Image Descriptor for Mammogram Mass Classification,945,,229-240,"Obaidullah Sk Md,Ahmed Sajib,Goncalves Teresa,Rato Luis","Obaidullah SM,Ahmed S,Goncalves T,Rato L",Obaidullah SM,10.1007/978-3-030-18058-4_18,University of Evora,"For mammogram image analysis, feature extraction is the most crucial step when machine learning techniques are applied. In this paper, we propose RMID (Radon-based Multi-resolution Image Descriptor), a novel image descriptor for mammogram mass classification, which perform efficiently without any clinical information. For the present experimental framework, we found that, in terms of area under the ROC curve (AUC), the proposed RMID outperforms, upto some extent, previous reported experiments using histogram based hand-crafted methods, namely Histogram of Oriented Gradient (HOG) and Histogram of Gradient Divergence (HGD) and also Convolution Neural Network (CNN). We also found that the highest AUC value (0.986) is obtained when using only the carniocaudal (CC) view compared to when using only the mediolateral oblique (MLO) (0.738) or combining both views (0.838). These results thus proves the effectiveness of CC view over MLO for better mammogram mass classification.","Image descriptor,Mammogram image,Breast cancer,Classification",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Physics",,,"AUTOMATIC,DETECTION,MICROCALCIFICATIONS,ALGORITHM,FILM",,,
51,Optimization methods for deep neural networks classifying OCT images to detect dental caries,11217,,,"Salehi Hassan S.,Barchini Majd,Mandian Mina","Salehi HS,Barchini M,Mandian M",Salehi HS,10.1117/12.2545421,California State University System,"Dental caries are common chronic infectious oral diseases affecting most teenagers and adults worldwide. Optical coherence tomography (OCT) has been studied extensively for the detection of early carious lesions. Deep learning techniques are a rapidly emerging new area of biomedical research and have yielded impressive results in diagnosis and prediction in the field of oral radiology. Deep learning models particularly deep convolutional neural networks (CNN) can be employed along with OCT imaging system to more accurately identify early dental caries. In this work, after OCT data acquisition, data augmentation was performed to obtain a large amount of training data in order to effectively learn, where collection of such training data is often expensive and laborious. For the backpropagation process, seven optimization methods, namely Adadelta, AdaGrad, Adam, AdaMax, Nadam, RMSProp, and Stochastic Gradient Descent (SGD) were utilized to improve the accuracy of a CNN classifier for diagnosing dental caries. In this study, 75% of the data were utilized for training and 25% for testing. The diagnostic accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and receiver operating characteristic (ROC) curve were calculated for detection and diagnostic performance of the deep CNN algorithm. This study highlighted the performance of various optimization methods for deep CNN models with OCT images to detect dental caries.","optimization methods,image processing,machine learning,deep learning,convolutional neural networks,optical coherence tomography,dental caries detection",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Dentistry, Oral Surgery & Medicine,Optics",,,"OPTICAL,COHERENCE,TOMOGRAPHY,SEGMENTATION,ENAMEL",,,
52,Dynamic entropy-based pattern learning to identify emotions from EEG signals across individuals,150,,,"Lu Yun,Wang Mingjiang,Wu Wanqing,Han Yufei,Zhang Qiquan,Chen Shixiong","Lu Y,Wang MJ,Wu WQ,Han YF,Zhang QQ,Chen SX",Wang MJ,10.1016/j.measurement.2019.107003,Harbin Institute of Technology,"Emotion plays an important role in mental and physical health, decision-making, and social communication. An accurate detection of human emotions is critical to ensure effective interaction and activate proper emotional feedback. In the existing emotion recognition methods, poor generalization capability caused by individual differences in emotion experiences is still a problem. This article proposes a new framework of dynamic entropy-based pattern learning to enable subject-independent emotion recognition from electroencephalogram (EEG) signals with good generalization. Firstly, we exploit dynamic entropy measures in quantitative EEG measurement to extract consecutive entropy values from EEG signals over time. Then, based on the concatenation of consecutive entropy values to form feature vectors, the dynamic entropy-based patterning learning can be able to achieve subject-independent emotion recognition across individuals to obtain excellent identification accuracy. Experiment results show that the best average accuracy of 85.11% is reached to identify the negative and positive emotions. Besides, by comparison with the recent researches, the results have fully demonstrated that our method can achieve excellent performance for emotion recognition across individuals. In summary, an universal and subject-independent emotion recognition method with excellent generalization capability is developed by the proposed dynamic entropy-based pattern learning, which may have the great application potential to address the emotion detection in healthcare decision-making and human-computer interaction systems. (C) 2019 Elsevier Ltd. All rights reserved.","Emotion recognition,Entropy measures,Sample entropy,Machine learning,EEG,SEED dataset",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"APPROXIMATE,ENTROPY,FEATURE-SELECTION,SAMPLE,ENTROPY,RECOGNITION,SYSTEM,RESPONSES,EMG",MEASUREMENT,,
53,X-ray luminescence imaging for small-animals,11224,,,"Lun Michael C.,Cong Wenxiang,Arifuzzaman Md,Ranasinghe Meenakshi,Bhattacharya Sriparna,Anker Jeffrey,Wang Ge,Li Changqing","Lun MC,Cong WX,Arifuzzaman M,Ranasinghe M,Bhattacharya S,Anker J,Wang G,Li CQ",Li CQ,10.1117/12.2544601,University of California System,"X-ray luminescence imaging emerged for about a decade and combines both the high spatial resolution of x-ray imaging with the high measurement sensitivity of optical imaging, which could result in a great molecular imaging tool for small animals. So far, there are two types of x-ray luminescence computed tomography (XLCT) imaging. One uses a pencil beam x-ray for high spatial resolution at a cost of longer measurement time. The other uses cone beam x-ray to cover the whole mouse to obtain XLCT images at a very short time but with a compromised spatial resolution. Here we review these two methods in this paper and highlight the synthesized nanophosphors by different research groups.
We are building a focused x-ray luminescence tomography (FXLT) imaging system, developing a machinelearning based FXLT reconstruction algorithm, and synthesizing nanophosphors with different emission wavelengths. In this paper, we will report our current progress from these three aspects. Briefly, we mount all main components, including the focused x-ray tube, the fiber detector, and the x-ray tube and x-ray detector for a microCT system, on a rotary which is a heavy-duty ring track. A microCT scan will be performed before FXLT scan. For a FXLT scan, we will have four PMTs to measure four fiber detectors at two different wavelengths simultaneously for each linear scan position. We expect the spatial resolution of the FXLT imaging will be around 100 micrometers and a limit of detection of approximately 2 mu g/mL (for Gd2O2S:Eu).","x-ray luminescence computed tomography,optical imaging,x-ray imaging,optical tomography,tomographic imaging,mice imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,"FLUORESCENCE,MOLECULAR,TOMOGRAPHY,SENSITIVITY",,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7875188,
54,Automated Classification and Measurement of Fetal Ultrasound Images with Attention Feature Pyramid Network,11427,,,"Liu Pengfei,Zhao Huaici,Li Peixuan,Cao Feidao","Liu PF,Zhao HC,Li PX,Cao FD",Liu PF,10.1117/12.2552701,Chinese Academy of Sciences,"Segmentation of anatomical structures in ultrasound images required radiological technology and a great deal of ultrasonic experience. The manual segmentation is often dependent on expertise of clinicians and time-consuming. Therefore, we present an automatic system for segmentation and measurement of ultrasound images. We propose a scale attention feature pyramid network (SAFNet) for fetal biometric measurements from two-dimensional ultrasound images. The scale attention module is steered to form feature pyramid at each level. Auxiliary layer is used to learn object boundary definition with deep supervision. Further, we present a two-stage framework which is an automatic classification measurement system (ACMS), firstly classifies the image type which has three labels: head, abdomen and femur. Then outputs the final segmentation result. The SAFNet results better performance on our datasets compared to the baseline U-Net. Experiments show that the ACMS results in classification accuracy of 95.27%/90.94%/94.93% of fetal head, abdomen and femur test set, respectively. Feature pyramid and attention mechanism inside the network for feature selection results in improvement in the segmentation accuracy. The ACMS can conveniently obtain segmentation result no matter what type is given.","Fetal biometric measurement,ultrasound image segmentation,attention mechanism,deep supervision",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics",,,,,,
55,Ultrasonic characterization of thermal barrier coatings porosity through BP neural network optimizing Gaussian process regression algorithm,100,,,"Ma Zhiyuan,Zhang Wei,Luo Zhongbing,Sun Xu,Li Zongyi,Lin Li","Ma ZY,Zhang W,Luo ZB,Sun X,Li ZY,Lin L",Lin L,10.1016/j.ultras.2019.105981,Dalian University of Technology,"Porosity is an integral part of thermal barrier coatings (TBCs) and is required to provide thermal insulation and to accommodate operational thermal stresses. Accurate characterization of the TBCs porosity is difficult due to the complex pore morphology and ultra-thin coating thickness. In this paper, a BP neural network optimizing Gaussian process regression (GPR) algorithm, termed BP-GPR, is presented to characterize the TBCs porosity based on a constructed ultrasonic reflection coefficient amplitude spectrum (URCAS). The characteristic parameters of URCAS are optimized through the BP neural network combined with a high determination coefficient R-2 rule. Then the optimized parameters are utilized to train the GPR algorithm for predicting the unknown TBCs porosity. The proposed BP-GPR method was demonstrated through a series of finite element method (FEM) simulations, which were implemented on random pore models (RPMs) of plasma spraying ZrO2 coating with a thickness of 300 mu m and porosities of 1%, 3%, 5%, 7%, and 9%. Simulation results indicated the relative errors of the predicted porosity of RPMs were 6.37%, 7.62%, 1.07%, and 1.07%, respectively, which has 32% and 48% accuracy higher than that predicted only by BP neural network or GPR algorithm. It is verified that the proposed BP-GPR method can accurately characterize the porosity of TBCs with complex pore morphology.","Thermal barrier coating,Porosity,Ultrasonic,BP neural network,Gaussian process regression",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Acoustics,Radiology, Nuclear Medicine & Medical Imaging",,2.786,"NONDESTRUCTIVE,MEASUREMENT,ELASTIC-MODULUS,COEFFICIENT",ULTRASONICS,,
56,Neural network for mechanical property estimation of multilayered laminate composite,28,,982-985,"Barbosa Allan,Upadhyaya Priyank,Iype Eldhose","Barbosa A,Upadhyaya P,Iype E",Iype E,10.1016/j.matpr.2019.12.336,"BITS Pilani, Dept Chem Engn, Dubai Campus, Dubai, U Arab Emirates.","Composites are made of combining two or more materials wherein the favorable properties of each mate-rial is contributed to improve the overall properties of the final material. In a multi-layered composite, layers of different laminates are stacked on top of each other in different alignments, such that it can meet the overall functional needs of the material such as desired bending, stretching, shearing, etc. with applied forces/moments. The layers are stacked on top of each other depending on the strength or thick-ness requirement. The mechanical properties of the composite or organized stack of layers are defined by the ABD matrix. The ABD matrix is a 6x6 matrix that links the applied loads and the associated strains in the laminate. 'A' represents the extensional stiffness which relates in-plane forces with mid-plane strains. 'B' represents the coupling stiffness which relates in-plane forces with mid-plane curvatures. 'D' repre-sents bending stiffness which relates resultant moments with mid-plane curvatures. In this work, a neu-ral network is constructed to predict the eigen values of the ABD matrix as a function of the number of layers and angles of orientation. The purpose of this model is to demonstrate the applicability of neural networks for modeling the mechanical properties of composites from the stacking pattern of the laminates. (C) 2019 Elsevier Ltd. All rights reserved. Selection and peer-review under responsibility of the scientific committee of the 2nd International Conference on Recent Advances in Materials & Manufacturing Technologies.","Composites,Machine Learning,Neural Network,ABD Matrix,Mechanical property",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,"WEAR,PREDICTION",MATERIALS TODAY-PROCEEDINGS,,
57,Creating a classification model for diagnosis of joint lesions type,11369,,,"Talakh M. V,Holub S. V,Ushenko Yu A.,Gantiuk V. K.","Talakh MV,Holub SV,Ushenko YA,Gantiuk VK",Talakh MV,10.1117/12.2553971,Ministry of Education & Science of Ukraine,"The work combines methods of multidimensional polarization microscopy, statistical processing of data and algorithms of machine learning with the purpose of constructing a methodology for creation of intelligent systems for multi-level medical monitoring of joint lesions . The task of classifying the results of the study of biological materials for obtaining a diagnosis was solved. To obtain informative features, a model of biological tissue was developed and the main diagnostic parameters were determined (statistical moments of 1-4 orders of coordinate distributions of the values of azimuths and the ellipticity of polarization and their autocorrelation functions, as well as wavelet coefficients of the corresponding distributions). The classification of these data was provided on the raw input data and on generated data with different degree of overlapping classes by machine learning algorithms and inductive modeling.","medical monitoring,polarization microscopy,informative features,classification,machine learning,inductive modeling",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
58,Real-Time Human Intention Recognition of Multi-Joints Based on MYO,8,,4235-4243,"Sun Lei,An Honglei,Ma Hongxu,Gao Jialong","Sun L,An HL,Ma HX,Gao JL",An HL,10.1109/ACCESS.2019.2942108,National University of Defense Technology - China,"Hill musculoskeletal model (HMM) is commonly used to estimate human motion intentions. HMM utilizes electromyography (EMG) signals as the nonlinear model input to obtain muscle forces or torques. However, due to the fact that it contains many physiological parameters that are difficult to measure, HMM is generally applied in simple continuous intention estimation of a single joint. In this work, we aimed at recogonizing shoulder and elbow joints angles and their angular vecocities continuously in real time. Firstly, we used MYO armband as the EMG sensor. Then, a reasonable prediction model was deduced based on HMM and human dynamics to realize online continuous recognition of the four angles and angular velocities of shoulder and elbow joints. Nonlinear autoregressive with external input neural network (NARX) replaced the prediction equation. In addition, the framework of state space model was completed by constructing an observation equation. Thus, the closed-loop characteristic was realized to eliminate the influence of cumulative error and ensure good estimation performance. Experimental results verified the feasibility and accuracy of the algorithm. For predefined trajectory and random trajectory seperately, the RMSE were 0.955 and 1.15 (degree) for angles estimation and 2.8, 3.40 for angular velocities (degree/s). Compared with the normally used back-propagation neural network (BPNN), the method proposed in this paper obviously got more accurate and smooth results.","Intention recognition,EMG,HMM,closed-loop estimation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"INTERFACE,MOTION",IEEE ACCESS,https://doi.org/10.1109/access.2019.2942108,
59,Time Series Data for Equipment Reliability Analysis With Deep Learning,8,,105484-105493,"Chen Baotong,Liu Yan,Zhang Chunhua,Wang Zhongren","Chen BT,Liu Y,Zhang CH,Wang ZR",Zhang CH,10.1109/ACCESS.2020.3000006,South China University of Technology,"With the deep integration of cyber physical production systems in the era of Industry 4.0, smart workshop dramatically increases the amount of data collected by smart device. A key factor in achieving smart manufacturing is to use data analysis methods for evaluating the equipment reliability and for supporting the predictive maintenance of equipment. Based on these insights, this paper proposes a deep learning-based approach that uses time series data for equipment reliability analysis. First, a framework of the TensorFlow-enabled deep neural networks (DNN) model for equipment reliability analysis is presented. Secondly, using time series equipment data, an evaluation strategy of equipment reliability based on deep learning is proposed. Finally, the reliability of a cylinder, an important part of the small trolley in automobile assembly line, is evaluated in a case study. Compared with the traditional reliability analysis method such as PCA and HMM, the prediction results show a significant improvement in prediction accuracy. This work contributes to promoting artificial intelligence algorithms for realizing highly efficient manufacturing.","Reliability,Time series analysis,Data models,Analytical models,Computational modeling,Manufacturing,Maintenance engineering,Reliability analysis,time series data,deep learning,smart manufacturing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09108271.pdf,
60,Glioma Grade Prediction Using Wavelet Scattering-Based Radiomics,8,,106564-106575,"Chen Qijian,Wang Lihui,Wang Li,Deng Zeyu,Zhang Jian,Zhu Yuemin","Chen QJ,Wang LH,Wang L,Deng ZY,Zhang J,Zhu YM",Wang LH,10.1109/ACCESS.2020.3000895,Guizhou University,"Glioma grading before surgery is very critical for the prognosis prediction and treatment plan making. We present a novel wavelet scattering-based radiomic method to predict noninvasively and accurately the glioma grades. The method consists of wavelet scattering feature extraction, dimensionality reduction, and glioma grade prediction. The dimensionality reduction was achieved using partial least squares (PLS) regression and the glioma grade prediction using support vector machine (SVM), logistic regression (LR) and random forest (RF). The prediction obtained on multimodal magnetic resonance images of 285 patients with well-labeled intratumoral and peritumoral regions showed that the area under the receiver operating characteristic curve (AUC) of glioma grade prediction was increased up to 0.99 when considering both intratumoral and peritumoral features in multimodal images, which represents an increase of about 13& x0025; compared to traditional radiomics. In addition, the features extracted from peritumoral regions further increase the accuracy of glioma grading.","Wavelet scattering,radiomics,machine learning,glioma grading,peritumoral",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BRAIN,CLASSIFICATION,INFORMATION,REGRESSION,TEXTURE,IMAGES",IEEE ACCESS,http://arxiv.org/pdf/1905.09589,
61,Estimation of the Microbiological Quality of Meat Using Rapid and Non-Invasive Spectroscopic Sensors,8,,106614-106628,"Fengou Lemonia-Christina,Mporas Iosif,Spyrelli Evgenia,Lianou Alexandra,Nychas George-John","Fengou LC,Mporas I,Spyrelli E,Lianou A,Nychas GJ",Nychas GJ,10.1109/ACCESS.2020.3000690,Agricultural University of Athens,"Spectroscopic methods in tandem with machine learning methodologies have attracted considerable research interest for the estimation of food quality. The objective of this study was the evaluation of Fourier transform infrared (FTIR) spectroscopy and multispectral imaging (MSI) coupled with appropriate machine learning regression algorithms for assessing meat microbiological quality. For this purpose, minced pork patties were stored aerobically and under modified atmosphere packaging (MAP) conditions, at isothermal and dynamic temperature conditions. At regular time intervals during storage, samples were subjected to (i) microbiological analysis, (ii) FTIR measurements and (iii) MSI acquisition. The collected FTIR data were processed by feature extraction methods to reduce dimensionality, and subsequently Support Vector Machines (SVM) regression models were trained using spectral features (FTIR and MSI) to estimate microbiological quality of meat (microbial population). The regression models were evaluated with different experimental replicates using distinct meat batches. The performance of the models was evaluated in terms of correlation coefficient (r), root mean square error (RMSE), mean absolute error (MAE) and residual prediction deviation (RPD). The RMSE values for the microbial population estimation models using FTIR were 1.268 and 1.024 for aerobic and MAP storage, respectively. The performance in terms of RMSE for the MSI-based models was 1.144 for aerobic and 0.923 for MAP storage, while the combination of FTIR and MSI spectra resulted in models with RMSE equal to 1.146 for aerobic and 0.886 for MAP storage. The experimental results demonstrated the potential of estimating the microbiological quality of minced pork meat from spectroscopic data.","Sociology,Statistics,Packaging,Aerodynamics,Atmospheric measurements,Temperature measurement,Estimation,Food technology,microbiological quality,Fourier transform infrared spectroscopy,multispectral imaging,machine learning,support vector regression",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"TRANSFORM,INFRARED-SPECTROSCOPY,MINCED,BEEF,NONDESTRUCTIVE,DETERMINATION,NIR,SPECTROSCOPY,SPOILAGE,FOOD,PORK,RAMAN,CONTAMINATION,PREDICTION",IEEE ACCESS,http://uhra.herts.ac.uk/bitstream/2299/22841/1/09110566.pdf,
62,Application of Machine Learning and Word Embeddings in the Classification of Cancer Diagnosis Using Patient Anamnesis,8,,106198-106213,"Ramos Magna Andres Alejandro,Allende-Cid Hector,Taramasco Carla,Becerra Carlos,Figueroa Rosa L.","Magna AAR,Allende-Cid H,Taramasco C,Becerra C,Figueroa RL",Magna AAR,10.1109/ACCESS.2020.3000075,Pontificia Universidad Catolica de Valparaiso,"Currently, one of the main challenges for information systems in healthcare is focused on support for health professionals regarding disease classifications. This work presents an innovative method for a recommendation system for the diagnosis of breast cancer using patient medical histories. In this proposal, techniques of natural language processing (NLP) were implemented on real datasets: one comprised 160, 560 medical histories of anonymous patients from a hospital in Chile for the following categories: breast cancer, cysts and nodules, other cancer, breast cancer surgeries and other diagnoses; and the other dataset was obtained from the MIMIC III dataset. With the application of word-embedding techniques, such as word2vec's skip-gram and BERT, and machine learning techniques, a recommendation system as a tool to support the physician's decision-making was implemented. The obtained results demonstrate that using word embeddings can define a good-quality recommendation system. The results of 20 experiments with 5-fold cross-validation for anamnesis written in Spanish yielded an F1 of 0.980 +/- 0.0014 on the classification of 'cancer' versus 'not cancer' and 0.986 +/- 0.0014 for 'breast cancer' versus 'other cancer'. Similar results were obtained with the MIMIC III dataset.","History,Medical diagnostic imaging,Breast cancer,Natural language processing,Natural language processing (NLP),machine learning,deep learning,recommendation system,anamnesis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BIDIRECTIONAL,LSTM,ICD-9-CM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09108225.pdf,
63,Decision Boundary-Based Anomaly Detection Model Using Improved AnoGAN From ECG Data,8,,108664-108674,"Shin Dong-Hoon,Park Roy C.,Chung Kyungyong","Shin DH,Park RC,Chung K",Chung K,10.1109/ACCESS.2020.3000638,Kyonggi University,"Arrhythmia detection through deep learning is mainly classified through supervised learning. Supervised learning progresses through the labeled data. However, in the medical field, it is challenging to collect ECG data of patients with arrhythmia than ECG data of healthy people, and thus data bias occurs. Therefore, if you use a supervised learning model, there are problems with lack of data and imbalance between labels that arise during learning. Accordingly, this study proposes the decision boundary-based Anomaly detection model using improved AnoGAN from ECG data. In this study, at the time of learning, the loss of the Generator does not reduce, but the loss of a Discriminator lowers. Even if the Generator and Discriminator were designed to have the same learning count, the learning competency of Generator was judged to be lowered. In repeated experiments, it was found that the best loss balance was achieved when the learning count of Discriminator was 1 and that of Generator was 4. Another problem is that the decision boundary of AnoGAN is subjective. Accordingly, the repeated experiments based on F-measure are conducted to determine a decision boundary. For performance evaluation, the accuracy of the model is evaluated on the basis of Epoch, and the goodness-of-fit of the model is evaluated on the basis of AUC and F-measure. According to the evaluation of F-measure, the model has the best performance when the decision boundary is 200. In terms of Epoch, the model has the highest accuracy when the Epoch is 10. In addition, the proposed model has better goodness-of-fit than AnoGAN.","Electrocardiography,Anomaly detection,Data models,Heart,Generative adversarial networks,Generators,Diseases,Heart disease,arrhythmia,health care,deep learning,electrocardiogram,generative adversarial network,decision boundary,anomaly detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECALL,PCA",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09110549.pdf,
64,A CNN-RBPNN Model With Feature Knowledge Embedding and its Application to Time-Varying Signal Classification,8,,108503-108513,"Wu Lu,Wang Yinglong,Xu Shaohua,Liu Kun,Li Xuegui","Wu L,Wang YL,Xu SH,Liu K,Li XG",Xu SH,10.1109/ACCESS.2020.3000798,Shandong University of Science & Technology,"A novel technique, combining the feature extraction mechanisms of a convolutional neural network (CNN) with the classification method of a radial basis probability neural network (RBPNN), is proposed for small sample set modeling and feature knowledge embedding in multi-channel time-varying signal classification. This CNN-RBPNN consists of a signal input layer, signal feature parallel extraction and integration units, and an RBPNN classifier. Each channel signal in a feature extraction unit corresponds to a 1D CNN. The extracted features are represented as feature vectors, and these vectors constitute a comprehensive feature matrix. The RBPNN classifier was designed using signal feature embedding mechanism based on radial basis kernels and the property of combining pattern subclasses into pattern classes to form complex class boundaries. A dynamic clustering algorithm was used to divide each pattern class sample into several subclasses. Typical signal samples in each pattern subclass were designated as kernel centers, in order to achieve signal categories features embedding. This process was also used to determine the number of nodes in the RBPN layer. The RBPN layer outputs were selectively summed in the pattern layer according to kernel center category, which can generate irregular class boundaries, reducing the overlap among different pattern class boundary. The proposed CNN-RBPNN replaces the full-connection layer and classifier unit of conventional CNN with RBPNN, which can extract and represent signals distribution features and structural properties, implement structural and data constraints. This can reduce the structural risks of small sample set modeling. In this study, the properties of CNN-RBPNN are analyzed and an integrated learning algorithm is proposed. An experiment was conducted using 12-lead ECG signals in a seven-classification in the case of small sample set. Results demonstrated that, the correct recognition rate is 5.7& x0025; higher than other methods in the experiment, the performance evaluation index also showed significant improvement.","Time-varying signal classification,CNN feature extraction,radial basis probability network,prior feature knowledge embedding,small sample set modelling",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SMALL,SAMPLE-SIZE,NEURAL-NETWORK,FACE,RECOGNITION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09110890.pdf,
65,Integrated methodology of structural health monitoring for civil structures,27,,1066-1072,"Alla Suseela,Asadi S. S.","Alla S,Asadi SS",Alla S,10.1016/j.matpr.2020.01.435,"Vignan's Foundation for Science, Technology & Research (VFSTR)","The majority of the constructions are facing the damages due to design and environmental pollution aspects. The improvement of monitoring strategies can allow the safety as well as cost benefits. In civil engineering, the applicable discipline regarding damage recognition is usually called Structural Health Monitoring (SHM). The main focus of Structural Health Monitoring is to get, the life of a construction and is to diagnosis the materials used, the different parts in a structure, and the detection of these parts present in the construction. This activity is analogously new when compared to other engineering fields, innovative methods have been set and dissertations have to be note. The SHM can be divided into Model - Based SHM and Data -Based SHM. The first is majorly based on the physical parameters of the undamaged conditioned structure; when sub-sequent data has accumulated and they have been checked. Any dis- crepancies can be used during the diagnosis to get the structure more reliable. Likewise, the Data - Based SHM use different methodologies from damage recognition and machine learning communities. The processed data from the structure may not reference to the physical -based model. Both SHM models have their own supporters and pros and cons are still in discussion. This paper deals the health monitor- ing of different structures which are located in Industrial area, Residential area, Coastal area and Seismic area by consider the Data -Based Evaluation SHM method. ? 2019 Elsevier Ltd. All rights reserved. Selection and peer -review under responsibility of the scientific committee of the First International con- ference on Advanced Lightweight Materials and Structures.","Structural health monitoring,Environmental impact,Damage findings,Integrated analysis",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,,MATERIALS TODAY-PROCEEDINGS,,
66,Condition monitoring of FSW tool using vibration analysis - A machine learning approach,27,,2970-2974,"Balachandar K.,Jegadeeshwaran R.,Gandhikumar D.","Balachandar K,Jegadeeshwaran R,Gandhikumar D",Balachandar K,10.1016/j.matpr.2020.04.903,VIT Chennai,"Friction stir welding (FSW) is a new kind of solid state welding technique. Rigid and reliable joints in intricate shapes are possible with FSW. Mutual transfer of material occurs between two work pieces when heat is generated by continuous stirring of the welding tool. This type of welding process is fre- quently used in many commercial applications like automobile, ship building, aerospace and many more. In this scenario, monitoring the FSW tool condition is essential in order to avoid the early defects and breakdown of the machine. The FSW tool condition monitoring offers numerous benefits in the fabrica- tion of aluminium products with less weld defects. Condition monitoring of friction stir welding tool is an advanced predictive maintenance technique for collecting real time data from the operating machine through sensors. The collected data can be analyzed using a machine learning approaches. In this study Al alloy was used for experimentation by using vibration analysis techniques signals were captured for good and faulty conditions of the tool. Statistical information was extracted from the raw vibration sig- natures and selection of feature was carried out. The selected features were then classified using Best first tree (BFT) classifier. The post pruned best first tree produced 93.07% as the classification accuracy. (C) 2019 Elsevier Ltd. All rights reserved. Selection and peer-review under responsibility of the scientific committee of the International conference on Materials and Manufacturing Methods.","Friction Stir Welding,Condition Monitoring,Statistical Features,Best First Tree classifier,Confusion matrix",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,"FAULT-DIAGNOSIS,DECISION,TREE",MATERIALS TODAY-PROCEEDINGS,,
67,Accelerating Development of Materials for Industrial and High-Tech Applications with Data-Driven Analysis and Simulations,5,29-30,1497-1511,Barabash Sergey V.,Barabash SV,Barabash SV,10.1557/adv.2020.189,"Intermolecular Inc, 3011 N First St, San Jose, CA 95134 USA.","We describe how the development of advanced materials via high-throughput experimentation at Intermolecular (R) is accelerated using guidance from modelling, machine learning (ML) and other data-driven approaches. Focusing on rapid development of materials for the semiconductor industry at a reasonable cost, we review the strengths and the limitations of data-driven methods. ML applied to the experimental data accelerates the development of record-breaking materials, but needs a supply of physically meaningful descriptors to succeed in a practical setting. Theoretical materials design greatly benefits from the external modelling ecosystems that have arisen over the last decade, enabling a rapid theoretical screening of materials, including additional material layers introduced to improve the performance of the material stack as a whole, ""dopants"" to stabilize a given phase of a polymorphic material, etc. We discuss the relative importance of different approaches, and note that the success rates for seemingly similar problems can be drastically different. We then discuss the methods that assist experimentation by providing better phase identification. Finally, we compare the strengths of different approaches, using as an example the problem of identifying regions of thermodynamic stability in multi component systems.",,Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA",Materials Science,,,,MRS ADVANCES,,
68,Accelerated Development of Refractory Nanocomposite Solar Absorbers using Bayesian Optimization,5,29-30,1537-1545,"Guan Qiangshun,Alketbi Afra S.,Raza Aikifa,Zhang TieJun","Guan QS,Alketbi AS,Raza A,Zhang TJ",Zhang TJ,10.1557/adv.2019.468,Khalifa University of Science & Technology,"Machine learning-based approach is desired for accelerating materials design, development and discovery in combination with high-throughput experiments and simulation. In this work we propose to apply a Bayesian optimization method to design ultrathin multilayer tungsten-silicon carbide (W-SiC) nanocomposite absorber for high-temperature solar power generation. Based on a semi-analytical scattering matrix method, the design of spectrally selective absorber is optimized over a variety of layer thicknesses to maximize the overall solar absorptance. Our nanofabrication and experimental characterization results demonstrate the capability of the proposed approach for accelerated development of refractory light-absorbing materials. Comparison with other global optimization methods, such as random search, simulated annealing and particle swarm optimization, shows that the Bayesian optimization method can expedite the design of multilayer nanocomposite absorbers and significantly reduce the development cost. This work sheds light on the discovery of novel materials for solar energy and sustainability applications.","DESIGN,FABRICATION,COATINGS",Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA",Materials Science,,,"DESIGN,FABRICATION,COATINGS",MRS ADVANCES,,
69,Prediction of physical properties of thermosetting resin by using machine learning and structural formulas of raw materials,5,29-30,1567-1575,"Nakajin Kokin,Minami Takuya,Kawata Masaaki,Fujita Toshio,Murofushi Katsumi,Uchida Hiroshi,Omori Kazuhiro,Okuno Yoshishige","Nakajin K,Minami T,Kawata M,Fujita T,Murofushi K,Uchida H,Omori K,Okuno Y",Nakajin K,10.1557/adv.2020.266,"Res Assoc High Throughput Design & Dev Adv Funct, Tsukuba, Ibaraki 3058568, Japan.","Thermosetting resins are one of the most widely used functional materials in industrial applications. Although some of the physical properties of thermosetting resins are controlled by changing the functional groups of the raw materials or adjusting their mixing ratios, it was conventionally challenging to construct machine learning (ML) models, which include both mixing ratio and chemical information such as functional groups. To overcome this problem, we propose a machine learning approach based on extended circular fingerprint (ECFP) in this study. First, we predicted the classification of raw materials by the random forest, where ECFP was used as the explanatory variable. Then, we aggregated ECFP for each classification predicted by the random forest. After that, we constructed the prediction model by using the aggregated ECFP, feature quantities of reaction intermediates, and curing conditions of resin as explanatory variables. As a result, the model was able to predict in high accuracy (R boolean AND 2 = 0.8), for example, the elastic modulus of thermosetting resins. Furthermore, we also show the result of verification of prediction accuracy in first step, such as using the one-hot-encording. Therefore, we confirmed that the properties of thermosetting resins could be predicted using mixed raw materials by the proposed method.",POLYMER,Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA",Materials Science,,,POLYMER,MRS ADVANCES,,
70,Small Angle Scattering Data Analysis Assisted by Machine Learning Methods,5,29-30,1577-1584,"Do Changwoo,Chen Wei-Ren,Lee Sangkeun","Do C,Chen WR,Lee S",Do C,10.1557/adv.2020.130,United States Department of Energy (DOE),"Small angle scattering (SAS) is a widely used technique for characterizing structures of wide ranges of materials. For such wide ranges of applications of SAS, there exist a large number of ways to model the scattering data. While such analysis models are often available from various suites of SAS data analysis software packages, selecting the right model to start with poses a big challenge for beginners to SAS data analysis. Here, we present machine learning (ML) methods that can assist users by suggesting scattering models for data analysis. A series of one-dimensional scattering curves have been generated by using different models to train the algorithms. The performance of the ML method is studied for various types of ML algorithms, resolution of the dataset, and the number of the dataset. The degree of similarities among selected scattering models is presented in terms of the confusion matrix. The scattering model suggestions with prediction scores provide a list of scattering models that are likely to succeed. Therefore, if implemented with extensive libraries of scattering models, this method can speed up the data analysis workflow by reducing search spaces for appropriate scattering models.","small angle scattering,data analysis,machine learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Materials Science,,,"MATERIALS,DISCOVERY,RETRIEVAL,MODEL",MRS ADVANCES,https://www.osti.gov/biblio/1633165,
71,Selected problems of image data preprocessing used to perform examination in Parkinson's disease,11442,,,"Bialek Kamila,Jakubowski Jacek,Potulska-Chromik Anna,Chmielinska Jolanta,Majda-Zdancewicz Ewelina);,Nojszewska Monika,Kostera-Pruszczyk Anna,Dobrowolski Andrzej","Bialek K,Jakubowski J,Potulska-Chromik A,Chmielinska J,Majda-Zdancewicz E,Nojszewska M,Kostera-Pruszczyk A,Dobrowolski A",Bialek K,10.1117/12.2565138,Military University of Technology in Warsaw,"Engineering support in the field of distinguishing Parkinson's disease from other diseases, diagnosing its progression and monitoring the effectiveness of drug treatment is nowadays implemented by way of recording and analyzing equipment fitted with motion sensors. The time series they provide enable quantitative evaluation of a set of symptoms describing daily activities and motor abilities of patients. The paper presents the preliminary results of fundamental research, which based on known medical observations indicating the diminution of facial expressions and micrographic apart from general motor deterioration, suggest that the clinical studies could utilize the techniques of processing image data acquired during the medical history taking. The image data includes video recording of the face and limbs conducted in the course of the coercions suggested in the study and manual drawings by patients. The image data are redundant and require processing for presentations facilitating their interpretation by a physician and enabling efficient utilization of machine learning algorithms in the next study stage. Within the framework of preliminary processing of acquired images, attempts were made to determine the quantitative measures, such as, e g blinking frequency and the indicators generated as a result of analyzing the position of characteristic points within the facial image. In the case of limbs, it is suggested to reproduce the motion on the image using a time series acquired thanks to the fixed markers. Preliminary processing of data coming from a graphic tablet also guarantees the generation of time series for images created by patients.","Parkinson's disease,image processing,analysis of handwriting,biosignals",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics",,,,,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11442/114420G/Selected-problems-of-image-data-preprocessing-used-to-perform-examination/10.1117/12.2565138.pdf,
72,Interpretable Diagnosis of Breast Cancer from Histological Images Using Siamese Neural Networks,11433,,,"Hradel Dominik,Hudec Lukas,Benesova Wanda","Hradel D,Hudec L,Benesova W",Hradel D,10.1117/12.2557802,Slovak University of Technology Bratislava,"Breast cancer is one of the most widespread causes of women's death worldwide. Successful treatment can be achieved only by the early and accurate tumor diagnosis. The main method of tissue diagnosis taken by biopsy is based on the observation of its significant structures. We propose a novel approach of classifying microscopy tissue images into 4 main cancer classes (normal, benign, In Situ and invasive). Our method is based on comparing and determining the similarity of the new tissue sample with previously by specialists annotated examples that are compiled in the collection with other labeled samples. The most probable class is statistically determined by comparing a new sample with several annotated samples. The usual problem of medical datasets is the small number of training images. We have applied suitable dataset augmentation techniques, using the fact that flipping or mirroring of the sample does not change the information about the diagnosis. Our other contribution is that we show the histopathologist the reason why the algorithm has classified tissue into the particular cancer class by ordering the collection of correctly annotated samples by their similarity to the input sample. Histopathologists can focus on searching for the key structures corresponding to the predicted classes.","Breast cancer,biopsy image analysis,Siamese neural networks,classification interpretation",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
73,Multi-modal Brain Tumor Segmentation Utilizing Convolutional Neural Networks,11433,,,"Jakab Marek,Stevuliak Marek,Benesova Wanda","Jakab M,Stevuliak M,Benesova W",Jakab M,10.1117/12.2557599,Slovak University of Technology Bratislava,"In this work, we deal with a brain tumor segmentation problem from magnetic resonance imaging (MRI), considered financially and time demanding when carrying out manually. To tackle this specific and complex domain problem, convolutional networks have proved competent due to significantly better performance than standard segmentation approaches. Therefore, within our research, we propose an approach which is dealing with tumor segmentation. During the elaboration, we propose multiple architectures, training phases and evaluation metrics in order to facilitate reliable and automatic delineation of tumorous tissues. For this purpose, we proposed a novel adaptation of the Tversky index loss formula to avoid label imbalance.","tumor segmentation,medical imaging,image processing,deep learning,neural networks",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
74,Convolutional Neural Network for Early Detection of Gastric Cancer by Endoscopic Video Analysis,11433,,,"Lebedev Anton,Khryashchev Vladimir,Stefanidi Anton,Stepanova Olga,Kashin Sergey,Kuvaev Roman","Lebedev A,Khryashchev V,Stefanidi A,Stepanova O,Kashin S,Kuvaev R",Lebedev A,10.1117/12.2559446,Yaroslavl State University,"Computer-aided diagnosis of cancer based on endoscopic image analysis is a promising area in the field of computer vision and machine learning. Convolutional neural networks are one of the most popular approaches in the endoscopic image analysis. The paper presents an endoscopic video analysis algorithm based on the use of convolutional neural network. To analyze the quality of the algorithm on the video data from the endoscope, the intersection over union (IoU) metric for object detection is used. The experimental results shows that the average value of IoU coefficient for the developed algorithm is 0.767, which corresponds to a high degree of intersection of areas identified by an expert and the algorithm.","Machine learning,convolution neural network,endoscopic image analyses,gastric cancer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,,,,
75,Detecting Pneumonia in Chest Radiographs Using Convolutional Neural Networks,11433,,,"Ureta Jennifer,Aran Oya,Rivera Pauline","Ureta J,Aran O,Rivera P",Ureta J,10.1117/12.2559527,De La Salle University,"Pneumonia is an infection of the lungs that can cause mild to severe illness and affects millions of people worldwide. Imaging studies are therefore crucial for the detection and management of patients with pneumonia, and radiography is currently the best method for diagnosis. However, clinical diagnosis of chest X-rays can be a challenging task as it requires interpretation by highly trained clinicians. This study uses deep learning to perform binary classification of frontal-view chest X-ray images to detect signs of childhood pneumonia. The effectiveness of the classifiers was validated using a dataset that was collected by [5] containing 5,856 labeled X-ray images from children. The classifiers were able to identify the presence or absence of childhood pneumonia with an accuracy between 96-97%.","Convolutional Neural Networks,pneumonia detection,chest radiographs",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA",Optics,,,"COMPUTER-AIDED,DIAGNOSIS",,,
76,Outlier Generation and Anomaly Detection Based on Intelligent One-Class Techniques over a Bicomponent Mixing System,950,,399-410,"Jove Esteban,Casteleiro-Roca Jose-Luis,Quintian Hector,Albino Mendez-Perez Juan,Luis Calvo-Rolle Jose","Jove E,Casteleiro-Roca JL,Quintian H,Mendez-Perez JA,Calvo-Rolle JL",Jove E,10.1007/978-3-030-20055-8_38,Universidade da Coruna,"One of the most important points to improve the profits in an industrial process lies on the fact of achieving a good optimisation and applying a smart maintenance plan. Under this circumstances an early anomaly plays an important role. Then, the implementation of classifiers for anomaly detection is an important challenge. As many of the anomalies that can occur in a plant have an unknown behaviour, it is necessary to generate artificial outliers to check these classifiers. This work presents different one-class intelligent techniques to perform anomaly detection in an industrial facility, used to obtain the main material for wind generator blades production. Furthermore, artificial anomaly data are generated to check the performance of each technique. The final results achieved are successful in general terms.","Anomaly detection,Control system,Outlier generation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,"ASSIST,MODEL",,,
77,Ensemble-Based Machine Learning Algorithms for Classifying Breast Tissue Based on Electrical Impedance Spectroscopy,965,,260-266,"Rahman Sam Matiur,Ali Md Asraf,Altwijri Omar,Alqahtani Mahdi,Ahmed Nasim,Ahamed Nizam U.","Rahman SM,Ali MA,Altwijri O,Alqahtani M,Ahmed N,Ahamed NU",Rahman SM,10.1007/978-3-030-20454-9_26,Daffodil International University,"The initial identification of breast cancer and the prediction of its category have become a requirement in cancer research because they can simplify the subsequent clinical management of patients. The application of artificial intelligence techniques (e.g., machine learning and deep learning) in medical science is becoming increasingly important for intelligently transforming all available information into valuable knowledge. Therefore, we aimed to classify six classes of freshly excised tissues from a set of electrical impedance measurement variables using five ensemble-based machine learning (ML) algorithms, namely, the random forest (RF), extremely randomized trees (ERT), decision tree (DT), gradient boosting tree (GBT) and AdaBoost (Adaptive Boosting) (ADB) algorithms, which can be subcategorized as bagging and boosting methods. In addition, the ranked order of the variables based on their importance differed across the ML algorithms. The results demonstrated that the three bagging ensemble ML algorithms, namely, RF ERT and DT, yielded better classification accuracies (78-86%) compared with the two boosting algorithms, GBT and ADB (60-75%). We hope that these our results would help improve the classification of breast tissue to allow the early prediction of cancer susceptibility.","Breast tissue,Machine learning,Ensemble learning,Classification,Electrical impedance",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,"CANCER,CLASSIFICATION,PREDICTION,IMPEDIVITY",,,
78,Automated Clash Free Rebar Design in Precast Concrete Exterior Wall via Generative Adversarial Network and Multi-agent Reinforcement Learning,965,,546-558,"Liu Pengkun,Liu Jiepeng,Feng Liang,Wu Wenbo,Lan Hao","Liu PK,Liu JP,Feng L,Wu WB,Lan H",Liu JP,10.1007/978-3-030-20454-9_54,Chongqing University,"The adoption of precast concrete elements (PCEs) are becoming popular in civil infrastructures. Since quality of connections determines the structure property, design of rebar in PCEs is a mandatory stage in constructions. Due to large number of rebar, complicated shapes of PCEs and complicated rules for arrangement, it is labor-intensive and error-prone for designers to avoid all clashes even using computer software. With the aid of BIM, it is desirable to have an automated and clash-free rebar design. Taking this cue, we introduce a framework with generative adversarial network (GAN) and multi-agent reinforcement learning (MARL) for generating design and automatically avoiding clash of rebar in PCES. We use GAN to generate 2D rebar designs. Then, 2D rebar designs are transformed into digital environments for MARL. In addition, layout of rebar is modelled as path planning of agents in MARL. An illustrative example is presented to test the proposed framework.","Building information modeling,Generative adversarial network,Reinforcement learning,Multi-agent,Rebar design,Clash free,Precast concrete elements,Precast concrete exterior wall",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
79,Fast Brain Volumetric Segmentation from T1 MRI Scans,943,,402-415,"Anand Ananya,Anand Namrata","Anand A,Anand N",Anand A,10.1007/978-3-030-17795-9_30,Brown University,"In this paper, we train a state-of-the-art deep neural network segmentation model to do fast brain volumetric segmentation from T1 MRI scans. We use image data from the ADNI and OASIS image collections and corresponding FreeSurfer automated segmentations to train our segmentation model. The model is able to do whole brain segmentation across 13 anatomical classes in seconds; in contrast, FreeSurfer takes several hours per volume. We show that this trained model can be used as a prior for other segmentation tasks, and that pre-training the model in this manner leads to better brain structure segmentation performance on a small dataset of expert-given manual segmentations.","Magnetic resonance imaging,Neural networks (computer),Artificial intelligence,Computer vision systems",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,SYSTEM,,,
80,An Attention-Based CNN for ECG Classification,943,,671-677,"Kuvaev Alexander,Khudorozhkov Roman","Kuvaev A,Khudorozhkov R",Kuvaev A,10.1007/978-3-030-17795-9_49,Gazprom,"The paper considers the problem of improving the interpretability of a convolutional neural network on the example of ECG classification task. This is done by using an architecture based on attention modules. Each module generates a mask that selects only those features that are required to make the final prediction. By visualizing these masks, areas of the signal that are important for decision-making can be identified. The model was trained both on raw signals and on their logarithmic spectrograms. In the case of raw signals, generated masks did not perform any meaningful feature maps filtering, but in the case of spectrograms, interpretable masks responsible for noise reduction and arrhythmic parts detection were obtained.","Convolutional neural networks,Attention mechanism,ECG classification",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,,,,
81,Forecasting Food Sales in a Multiplex Using Dynamic Artificial Neural Networks,944,,69-80,"Ganesan V. Adithya,Divi Siddharth,Moudhgalya Nithish B.,Sriharsha Uppu,Vijayaraghavan Vineeth","Ganesan VA,Divi S,Moudhgalya NB,Sriharsha U,Vijayaraghavan V",Divi S,10.1007/978-3-030-17798-0_8,SSN College of Engineering,"In India, food sales are emerging to be a major revenue generator for multiplex operators currently amounting to over $367 million a year. Efficient food sales forecasting techniques are the need of the hour as they help minimize the wastage of resources for the multiplex operators. In this paper, the authors propose a model to make a day-ahead prediction of food sales in one of the top multiplexes in India. Online learning and feature engineering by data correlative analysis in conjecture with a densely connected Neural Network, address the concept drifts and latent time correlations present in the data respectively. A scale independent metric, eta(comp) is also introduced to measure the success of the models across all food items from the business perspective. The proposed model performs better than the traditional time-series models, and also performs better than the corporate's currently existing model by a factor of 7.7%. This improved performance also leads to a saving of 170 units of food everyday.","Time-series,Neural networks,Concept drift,Forecasting,Feature engineering,Online learning",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,,,,
82,Automatic Nucleus Segmentation with Mask-RCNN,944,,399-407,Johnson Jeremiah W.,Johnson JW,Johnson JW,10.1007/978-3-030-17798-0_32,University System Of New Hampshire,"Mask-RCNN is a recently proposed state-of-the-art algorithm for object detection, object localization, and object instance segmentation of natural images. In this paper, it is demonstrated that Mask-RCNN can be used to perform highly effective and efficient automatic segmentations of a wide range of microscopy images of cell nuclei, for a variety of cells acquired under a variety of conditions. In addition, it is shown that a cyclic learning rate regime allows effective training of a Mask-RCNN model without any need to finetune the learning rate, thereby eliminating a manual and time-consuming aspect of the training procedure. The results presented here will be of interest to those in the medical imaging field and to computer vision researchers more generally.","Deep learning,Neural networks,Microscopy,Instance segmentation,Detection,Mask-RCNN",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,,,,
83,Performance Evaluation of Autoencoders for One-Shot Classification of Infectious Chlamydospore,944,,436-446,"Alampay Raphael B.,Ong Josh Daniel,Estuar Regina Justina E.,Abu Patricia Angela R.","Alampay RB,Ong JD,Estuar RJE,Abu PAR",Alampay RB,10.1007/978-3-030-17798-0_35,Ateneo de Manila University,"In the Philippines, there is a growing need for the protection of banana plantation from various diseases that directly affects the livelihood of farmers, markets and overall ecosystem. One such fatal disease is Fusarium oxysporum cubense (TR4 Chlamydospores) which allows growth of such fungi in banana crops that permanently damages the soil for further fertility. As of this writing, there is very small visual distinction between TR4 Chlamydospores and non-infectious Chlamydospores. This paper proposes the use of autoencoders to engineer relevant features in order to distinguish Fusarium Oxysporum from similar fungi or other artifacts present in the soil. Furthermore, the paper tries to address the problem with minimal data available for supervised learning as opposed to traditional methods that require thousands of data points for classification. The purpose of the experiments presented here will aid towards the creation of more sophisticated models to visually discriminate Fusarium Oxysporum.","Autoencoders,Fusarium oxysporum,One-shot learning,Computer vision",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,,,,
84,XMIAR: X-ray Medical Image Annotation and Retrieval,944,,638-651,"Abdulrazzaq M. M.,Yaseen I. F. T.,Noah S. A.,Fadhil M. A.,Ashour M. U.","Abdulrazzaq MM,Yaseen IFT,Noah SA,Fadhil MA,Ashour MU",Abdulrazzaq MM,10.1007/978-3-030-17798-0_51,International Islamic University Malaysia,"The huge development of the digitized medical image has been steered to the enlargement and research of the Content Based Image Retrieval (CBIR) systems. Those systems retrieve and extract the images by their own low level features, like texture, shape and color. But those visual features did not aloe the users to request images by the semantic meanings. The image annotation or classification systems can be considered as the solution for the limitations of the CBIR, and to reduce the semantic gap, this has been aimed annotating or to make the classification of the image with few controlled keywords. In this paper, we suggest a new hierarchal classification for the X-ray medical image using the machine learning techniques, which are called the Support Vector Machine (SVM) and k-Nearest Neighbour (k-NN). Hierarchy classification design was proposed based on the main body region. Evaluation was conducted based on ImageCLEF2005 database. The obtained results in this research were improved compared to the previous related studies.","Machine learning,Support vector machines,Medical image analysis",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Engineering",,,CLASSIFICATION,,http://irep.iium.edu.my/76758/13/76758_XMIAR%20X-ray%20medical%20image%20annotation_SCOPUS.pdf,
85,A Test Setting to Compare Spatial Awareness on Paper and in Virtual Reality Using EEG Signals,953,,199-208,"Van Goethem Sander,Adema Kimberly,van Bergen Britt,Viaene Emilia,Wenborn Eva,Verwulgen Stijn","Van Goethem S,Adema K,van Bergen B,Viaene E,Wenborn E,Verwulgen S",Verwulgen S,10.1007/978-3-030-20473-0_20,University of Antwerp,"Spatial awareness and the ability to analyze spatial objects, manipulate them and assess the effect thereof, is a key competence for industrial designers. Skills are gradually built up throughout most educational design programs, starting with exercises on technical drawings and reconstruction or classification of spatial objects from isometric projections and CAD practice. The accuracy in which spatial assignments are conducted and the amount of effort required to fulfill them, highly depend on individual insight, interests and persistence. Thus each individual has its own struggles and learning curve to master the structure of spatial objects in aesthetic and functional design. Virtual reality (VR) is a promising tool to expose subjects to objects with complex spatial structure, and even manipulate and design spatial characteristics of such objects. The advantage of displaying spatial objects in VR, compared to representations by projecting them on a screen or paper, could be that subjects could more accurately assess spatial properties of and object and its full geometrical and/or mechanical complexity, when exposed to that object in VR. Immersive experience of spatial objects, could not only result in faster acquiring spatial insights, but also potentially with less effort. We propose that acquiring spatial insight in VR could leverage individual differences in skills and talents and that under this proposition VR can be used as a promising tool in design education. A first step in underpinning this hypothesis, is acquisition of cognitive workload that can be used and compared both in VR and in a classical teaching context. We use electroencephalography (EEG) to assess brain activity through wearable plug and play headset (Wearable Sensing-DSI 7). This equipment is combined with VR (Oculus). We use QStates classification software to compare brain waves when conducting spatial assessments on paper and in VR. This gives us a measure of cognitive workload, as a ratio of a resulting from subject records with a presumed 'high' workload. A total number of eight records of subjects were suited for comparison. No significant difference was found between EEG signals (paried t-test, p = 0.57). However the assessment of cognitive workload was successfully validated through a questionnaire. The method could be used to set up reliable constructs for learning techniques for spatial insights.","Spatial awareness,Virtual reality,EEG,Brain-computer interface,Platonic solids,Cognitive workload",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Neurosciences & Neurology",,,,,,
86,The Impact of Binaural Beats on User Performance and Emotions Using a BCI for Robot Control,972,,93-105,"de Wet Lizette,Potgieter Louwrens","de Wet L,Potgieter L",de Wet L,10.1007/978-3-030-19135-1_10,University of the Free State,"This research was prompted by claims that certain sounds or music could increase learning abilities and performance. Binaural beating takes place when separate frequencies are introduced into each ear. The brain then strives to bridge the gap by creating a third tone. The aim of this study was to assess the impact of binaural beats on participants' performance, excitement, engagement, meditation, and frustration while manipulating a robot with a brain-computer interface. Fifty participants were exposed to Alpha, Beta, Delta and Theta binaural tones that changed their dominant brainwaves while they were engaged in the task. A control (no tones) was also established. A mixed methods research design was applied using physiological testing, questionnaires, interviews and observation. The results indicated that different sound frequencies did indeed affect user performance. Sessions where no frequencies were applied (control) were associated with more errors and longer time durations compared to all the other frequencies.","Usability,User experience,UX,Binaural beats,User emotions,Brain-computer interface,BCI",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
87,Abstract Vocabulary as Base for Training with Pattern Recognition EMG Control,972,,844-850,"Haring Erik,Van Akeleyen Seth,Vaes Kristof,Truijen Steven,Verwulgen Stijn","Haring E,Van Akeleyen S,Vaes K,Truijen S,Verwulgen S",Haring E; Verwulgen S,10.1007/978-3-030-19135-1_82,University of Antwerp,"The uprising of multi-channel wearable EMG sensors combined with machine learning pattern recognition algorithms offers the possibility to control multiple degree of freedom hand prosthetics. Such human-machine interaction systems require training from the user, mostly to link gestures with underlying EMG patterns. As intended end users have a missing hand, the question arises how to train them to use myo-electric prosthetics without instructing them to perform gestures; A key element to start training with pattern recognition EMG based prosthetic control is creating a shared vocabulary with the participant/patient. The shared vocabulary forms the base for the explanation and communication about the pattern recognition EMG. In this research an abstract form of communication based on animal sounds is used to form a shared vocabulary for a child with missing hands. We found that the abstract communication worked well and motivating when explaining pattern recognition EMG to a child. The communication tool that gives additional interaction makes the explanation much clearer since the participant starts directly with experiencing the pattern recognition EMG. Also, it is concluded that the abstract nature of the tested communication allows the participant to keep an open mind for gestures other than normal healthy hand movements when exploring the possible control contractions. Thus, abstract based communication can offer benefits during the training with pattern recognition EMG.","EMG,Pattern recognition EMG,Training,Children,Prosthetic control",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
88,Prediction Model of Milling Surface Roughness Based on Genetic Algorithms,928,,1315-1320,"Chen Ying,Sun Yanhong,Lin Han,Zhang Bing","Chen Y,Sun YH,Lin H,Zhang B",Chen Y,10.1007/978-3-030-15235-2_179,"Jilin Teachers Inst Engn & Technol, Changchun 130000, Jilin, Peoples R China.","According to the orthogonal test results, the surface roughness prediction model based on BP artificial neural network algorithm combined with genetic algorithm and considering material removal rate, a multi-objective optimization mathematical model for high-speed milling process parameters optimization was established, and the optimal combination of parameters satisfying the requirements was found within the given parameters range. The method is validated by comparing the surface roughness and processing efficiency with the optimization parameters determined by range analysis method.","Surface roughness,High speed milling,Genetic algorithm,Prediction model",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
89,Deep Convolution Neural Network for Big Data Medical Image Classification,8,,105659-105670,"Ashraf Rehan,Habib Muhammad Asif,Akram Muhammad,Latif Muhammad Ahsan,Malik Muhammad Sheraz Arshad,Awais Muhammad,Dar Saadat Hanif,Mahmood Toqeer,Yasir Muhammad,Abbas Zahoor","Ashraf R,Habib MA,Akram M,Latif MA,Malik MSA,Awais M,Dar SH,Mahmood T,Yasir M,Abbas Z",Habib MA,10.1109/ACCESS.2020.2998808,National Textile University - Pakistan,"Deep learning is one of the most unexpected machine learning techniques which is being used in many applications like image classification, image analysis, clinical archives and object recognition. With an extensive utilization of digital images as information in the hospitals, the archives of medical images are growing exponentially. Digital images play a vigorous role in predicting the patient disease intensity and there are vast applications of medical images in diagnosis and investigation. Due to recent developments in imaging technology, classifying medical images in an automatic way is an open research problem for researchers of computer vision. For classifying the medical images according to their relevant classes a most suitable classifier is most important. Image classification is beneficial to predict the appropriate class or category of unknown images. The less discriminating ability and domain-specific categorization are the main drawbacks of low-level features. A semantic gap that exists between features of low-level as machine understanding and features of human understanding as high-level perception. In this research, a novel image representation method is proposed where the algorithm is trained for classifying medical images by deep learning technique. A pre-trained deep convolution neural network method with the fine-tuned approach is applied to the last three layers of deep neural network. The results of the experiment exhibit that our method is best suited to classify various medical images for various body organs. In this manner, data can sum up to other medical classification applications which supports radiologist's efforts for improving diagnosis.","Medical image classification,pre-trained DCNN,convolution neural network,big data,image analysis,image enhancement,biomedical image processing,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"REPRESENTATION,SEGMENTATION,RETRIEVAL,NODULES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09104735.pdf,
90,Classification of Lung Sounds With CNN Model Using Parallel Pooling Structure,8,,105376-105383,"Demir Fatih,Ismael Aras Masood,Sengur Abdulkadir","Demir F,Ismael AM,Sengur A",Ismael AM,10.1109/ACCESS.2020.3000111,"Sulaimani Polytech Univ, Tech Coll Informat, Informat Technol Dept, Sulaimani, Iraq.","The recognition of various lung sounds recorded using electronic stethoscopes plays a significant role in the early diagnoses of respiratory diseases. To increase the accuracy of specialist evaluations, machine learning techniques have been intensely employed during the past 30 years. In the current study, a new pretrained Convolutional Neural Network (CNN) model is proposed for the extraction of deep features. In the CNN architecture, an average-pooling layer and a max-pooling layer are connected in parallel in order to boost classification performance. The deep features are utilized as the input of the Linear Discriminant Analysis (LDA) classifier using the Random Subspace Ensembles (RSE) method. The proposed method was evaluated against a challenge dataset known as ICBHI 2017. The deep features and the LDA with RSE method provided the best accuracy score when compared to other existing methods using the same dataset, improving the classification accuracy by 5.75%.","Lung sound,CNN model,parallel pooling,deep features,RSE method",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CRACKLE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09108294.pdf,
91,Adaptive Laser Welding Control: A Reinforcement Learning Approach,8,,103803-103814,"Masinelli Giulio,Tri Le-Quang,Zanoli Silvio,Wasmer Kilian,Shevchik Sergey A.","Masinelli G,Tri LQ,Zanoli S,Wasmer K,Shevchik SA",Wasmer K,10.1109/ACCESS.2020.2998052,Swiss Federal Laboratories for Materials Science & Technology (EMPA),"Despite extensive research efforts in the field of laser welding, the imperfect repeatability of the weld quality still represents an open topic. Indeed, the inherent complexity of the underlying physical phenomena prevents the implementation of an effective controller using conventional regulators. To close this gap, we propose the application of Reinforcement Learning for closed-loop adaptive control of welding processes. The presented system is able to autonomously learn a control law that achieves a predefined weld quality independently from the starting conditions and without prior knowledge of the process dynamics. Specifically, our control unit influences the welding process by modulating the laser power and uses optical and acoustic emission signals as sensory input. The algorithm consists of three elements: a smart agent interacting with the process, a feedback network for quality monitoring, and an encoder that retains only the quality critic events from the sensory input. Based on the data representation provided by the encoder, the smart agent decides the output laser power accordingly. The corresponding input signals are then analyzed by the feedback network to determine the resulting process quality. Depending on the distance to the targeted quality, a reward is given to the agent. The latter is designed to learn from its experience by taking the actions that maximize not just its immediate reward, but the sum of all the rewards that it will receive from that moment on. Two learning schemes were tested for the agent, namely S-Learning and Policy Gradient. The required training time to reach the targeted quality was 20 min for the former technique and 33 min for the latter.","Welding,Optical sensors,Process control,Power lasers,Laser modes,Laser welding,laser material processing,reinforcement learning,policy gradient,< italic xmlns:ali=""http:,www,niso,org,schemas,ali,1,0,"" xmlns:mml=""http:,www,w3,org,1998,Math,MathML"" xmlns:xlink=""http:,www,w3,org,1999,xlink"" xmlns:xsi=""http:,www,w3,org,2001,XMLSchema-instance""> Q <,italic >-learning,closed-loop control",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,KEYHOLE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09102251.pdf,
92,An Application of Transfer Learning and Ensemble Learning Techniques for Cervical Histopathology Image Classification,8,,104603-104618,"Xue Dan,Zhou Xiaomin,Li Chen,Yao Yudong,Rahaman Md Mamunur,Zhang Jinghua,Chen Hao,Zhang Jinpeng,Qi Shouliang,Sun Hongzan","Xue D,Zhou XM,Li C,Yao YD,Rahaman MM,Zhang JH,Chen H,Zhang JP,Qi SL,Sun HZ",Li C,10.1109/ACCESS.2020.2999816,Northeastern University - China,"In recent years, researches are concentrating on the effectiveness of Transfer Learning (TL) and Ensemble Learning (EL) techniques in cervical histopathology image analysis. However, there have been very few investigations that have described the stages of differentiation of cervical histopathological images. Therefore, in this article, we propose an Ensembled Transfer Learning (ETL) framework to classify well, moderate and poorly differentiated cervical histopathological images. First of all, we have developed Inception-V3, Xception, VGG-16, and Resnet-50 based TL structures. Then, to enhance the classification performance, a weighted voting based EL strategy is introduced. After that, to evaluate the proposed algorithm, a dataset consisting of 307 images, stained by three immunohistochemistry methods (AQP, HIF, and VEGF) is considered. In the experiment, we obtain the highest overall accuracy of 97.03% and 98.61% on AQP staining images and poor differentiation of VEGF staining images, individually. Finally, an additional experiment for classifying the benign cells from the malignant ones is carried out on the Herlev dataset and obtains an overall accuracy of 98.37%.","Cervical cancer,differentiation stages,histopathology images,transfer learning,ensemble learning,classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EVOLUTIONARY,OPTIMIZATION,CANCER,DIAGNOSIS,TEXTURE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09107128.pdf,
93,Mining Domain Knowledge: Improved Framework Towards Automatically Standardizing Anatomical Structure Nomenclature in Radiotherapy,8,,105286-105300,"Yang Qiming,Chao Hongyang,Nguyen Dan,Jiang Steve","Yang QM,Chao HY,Nguyen D,Jiang S",Jiang S,10.1109/ACCESS.2020.2999079,University of Texas System,"The automatic standardization of nomenclature for anatomical structures in radiotherapy (RT) clinical data is a critical prerequisite for data curation and data-driven research in the era of big data and artificial intelligence, but it is currently an unmet need. Existing methods either cannot handle cross-institutional datasets or suffer from heavy imbalance and poor-quality delineation in clinical RT datasets. To solve these problems, we propose an automated structure nomenclature standardization framework, 3D Nonlocal Network with Voting (3DNNV). This framework consists of an improved data processing strategy, namely, adaptive sampling and adaptive cropping (ASAC) with voting, and an optimized feature extraction module. The framework simulates clinicians' domain knowledge and recognition mechanisms to identify small-volume organs at risk (OARs) with heavily imbalanced data better than other methods. We used partial data from an open-source head-and-neck cancer dataset to train the model, then tested the model on three cross-institutional datasets to demonstrate its generalizability. 3DNNV outperformed the baseline model, achieving higher average true positive rates (TPR) over all categories on the three test datasets ( +8.27%, +2.39%, and +5.53%, respectively). More importantly, the 3DNNV outperformed the baseline on the test dataset, 28.63% to 91.17%, in terms of F1 score for a small-volume OAR with only 9 training samples. The results showthat 3DNNV can be applied to identifyOARs, even error-prone ones. Furthermore, we discussed the limitations and applicability of the framework in practical scenarios. The framework we developed can assist in standardizing structure nomenclature to facilitate data-driven clinical research in cancer radiotherapy.","Nomenclature standardization,radiotherapy,deep learning,3D classification,voting",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HEAD,SEGMENTATION,DATABASES,ONCOLOGY",IEEE ACCESS,http://arxiv.org/pdf/1912.02084,
94,Multimodal Sleep Signals-Based Automated Sleep Arousal Detection,8,,106157-106164,"Zhou Guangxin,Li Runzhi,Zhang Shuo,Wang Jing,Ma Jingzhe","Zhou GX,Li RZ,Zhang S,Wang J,Ma JZ",Li RZ,10.1109/ACCESS.2020.3000272,Zhengzhou University,"Excessive sleep arousal affects one's sleep quality that would induce disease. Polysomnography is a powerful tool for sleep related monitoring. Clinically, there are being two kinds of causes on sleep arousal. One is apnea and hypopnea related arousal and the other is non-apnea and non-hypopnea arousal. The latter is relatively hidden and is difficult to determine in clinical. We aim to classify the sleep arousal caused by non-apnea and non-hypopnea from apnea and hypopnea related arousal. We propose an improved ensemble deep learning architecture that use a positional embedding based multi-head attention method to keep temporal relations of multimodal physiological signals. The experimental datasets are based on an open access dataset from the public cardiology challenge 2018. We conduct several groups of comparison experiments among our proposed convolutional-residual network with positional embedding and multi-head attention (CRPEMA) method and other methods that includes methods presented on the cardiology challenge 2018. The results show that CRPEMA has high efficiency and accuracy. When the parameters decrease by more than 50%, the accuracy is keeping improved. Experiment results reflect that CRPEMA outperforms others and obtains the Area Under the Precision-Recall curve (AUPRC) of 0.391.","Sleep arousal classification,multimodal signals,deep learning,multi-head attention",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,EEG,IEEE ACCESS,https://doi.org/10.1109/access.2020.3000272,
95,Non-contact monitoring of human respiration using infrared thermography and machine learning,104,,,"Jagadev Preeti,Giri Lalat Indu","Jagadev P,Giri LI",Jagadev P,10.1016/j.infrared.2019.103117,National Institute of Technology (NIT System),"The respiration rate (RR) is an important indicator of human health condition. The well-established RR monitoring techniques are mostly contact processes, which have many limitations, especially for premature neonates with fragile skin. The present study reports application of Infrared Thermography for continuous and reliable monitoring of the RR, through a non-invasive and non-contact approach. Here, the temperature modulation across the nostrils during the respiration process is monitored using a thermal camera. The signal to noise ratio (SNR) of the obtained breathing waveform, is improved by subjecting it to suitable filtering techniques. The performance of the filters is compared using various parameters such as SNR, Mean square error, magnitude response, and group delay. Further, a computer vision algorithm ""Ensemble of regression trees"" is implemented to track the nostrils (region of interest) in the presence of significant head movement as well as object occlusion, in an automated manner. A novel ""Breath detection algorithm"" (BDA) is also developed to differentiate normal and abnormal breaths by predefined thresholds and obtain the breaths per minute, without any manual intervention. The robustness of the proposed algorithm is tested by implementing it on 80 breathing waveforms under various conditions, such as constant respiration, slow and fast breathing, different focal conditions, and presence and absence of air conditioner and fan. The performance of the algorithm is determined by computing its Precision, Sensitivity, Spurious cycle rate, and Missed cycle rate values, which are 98.76%, 99.07%, 0.92%, and 1.23% respectively. The parameters obtained from the proposed BDA are further fed to a 10-fold cross-validation k-Nearest Neighbour (k-NN) classifier, which uses multi-class classification to decide whether the human volunteer has normal or abnormal respiration in general, or is suffering from Bradypnea (slow breathing) or Tachypnea (fast breathing) in particular. The robustness and performance of the k-NN classifier is determined by computing its Training accuracy, Validation accuracy, and Testing accuracy, obtained as 98.59%, 99.5% and 98%, respectively. Other performance metrics such as Sensitivity, Specificity, Precision, and F-measure values are calculated as well, for each class separately. Finally, a standard deviation value of 0.0102 is obtained from the outputs of the 10-fold cross-validation method. Further, the pattern between the data points fed to the k-NN classifier is observed using the t-Stochastic Neighbour Embedding algorithm.",,Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,2.581,,INFRARED PHYSICS & TECHNOLOGY,,
96,FLAG-PDFe: Features Oriented Metadata Extraction Framework for Scientific Publications,8,,99458-99469,"Ahmed Muhammad Waqas,Afzal Muhammad Tanvir","Ahmed MW,Afzal MT",Ahmed MW,10.1109/ACCESS.2020.2997907,"Capital Univ Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.","The unprecedented growth of the research publications in diversified domains has overwhelmed the research community. It requires a cumbersome process to extract this enormous information by manually analyzing these research documents. To automatically extract content of a document in a structured way, metadata and content must be annotated. Scientific community has been focusing on automatic extraction of content by forming different heuristics and applying different machine learning techniques. One of the renowned conference organizers, ESWC organizes state-of-the-art challenge to extract metadata like authors, affiliations, countries in affiliations, supplementary material, sections, table, figures, funding agencies, and EU funded projects from PDF files of research articles. We have proposed a feature centric technique that can be used to extract logical layout structure of articles from publishers with diversified composition styles. To extract unique metadata from a research article placed in logical layout structure, we have developed a four-staged novel approach ""FLAG-PDFe"". The approach is built upon distinct and generic features based on the textual and the geometric information from the raw content of research documents. At the first stage, the distinct features are used to identify different physical layout components of an individual article. Since research journals follow their unique publishing styles and layout formats, therefore, we develop generic features to handle these diversified publishing patterns. We employ support vector classification (SVC) in the third stage to extract the logical layout structure (LLS)/ sections of an article, after performing comprehensive evaluation of generic features and machine learning models. Finally, we further apply heuristics on LLS to extract the desired metadata of an article. The outcomes of the study are obtained using the gold standard data set. The results yields 0.877 recall, precision 0.928 and 0.897 F-measure. Our approach has achieved a 16% gain on f-measure when compared to the best approach of the ESWC challenge.","Feature extraction,Metadata,Layout,Portable document format,Data mining,Machine learning,Support vector machines,Machine learning,research article,metadata extraction,text patterns,document structure analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DOCUMENT,STRUCTURE-ANALYSIS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09102282.pdf,
97,Contour-Aware Polyp Segmentation in Colonoscopy Images Using Detailed Upsamling Encoder-Decoder Networks,8,,99495-99508,"Ngoc-Quang Nguyen,Duc My Vo,Lee Sang-Woong","Nguyen NQ,Vo DM,Lee SW",Lee SW,10.1109/ACCESS.2020.2995630,Gachon University,"Colorectal cancer has become one of the most common cause of cancer mortality worldwide, with a five-year survival rate of over 50%. Additionally, the potential of some common polyp types to progress to colorectal cancer is considered high. Colonoscopy is the most common method for finding and removing polyps. However, during colonoscopy, a significant number of polyps is missed as a result of human error mistakes. Thus, this study was primarily motivated by the need to obtain an early and accurate diagnosis of polyps detected in colonoscopy images. In this paper, we propose a new polyp segmentation method based on an architecture of multi-model deep encoder-decoder networks called MED-Net. Not only does this architecture obtain multi-level contextual information by extracting discriminative features at different effective fields-of-view and multiple image scales, it also can substantially do upsample more correctly to produce better prediction. It is also able to capture more accurate polyp boundaries by using multi-scale effective decoders. Moreover, we also present a complementary strategy for improving the method's segmentation performance based on a combination of a boundary-aware data augmentation method and an effective weighted loss function. The purpose of this strategy is to allow our deep learning network to sequentially focus on poorly defined polyp boundaries, which are caused by the non-specular transition zone between the polyp and non-polyp regions. To provide a general view of the proposed method, our network was trained and evaluated on four well-known dataset CVC-ColonDB, CVC-ClinicDB, ASU-Mayo Clinic Colonoscopy Video Database, and ETIS-LaribPolypDB. Our results show that our MED-Net significantly outperforms state-of-the-art methods.","Cancer,Image segmentation,Colonoscopy,Feature extraction,Training,Decoding,Colon,Polyp segmentation,hierarchical collaborative representation-based classification,local ternary patterns,deep convolutional neural network,colorectal segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2995630,
98,Automatic Skin Cancer Detection in Dermoscopy Images Based on Ensemble Lightweight Deep Learning Network,8,,99633-99647,"Wei Lisheng,Ding Kun,Hu Huosheng","Wei LS,Ding K,Hu HS",Ding K,10.1109/ACCESS.2020.2997710,Anhui Polytechnic University,"The complex detection background and lesion features make the automatic detection of dermoscopy image lesions face many challenges. The previous solutions mainly focus on using larger and more complex models to improve the accuracy of detection, there is a lack of research on significant intra-class differences and inter-class similarity of lesion features. At the same time, the larger model size also brings challenges to further algorithm application; In this paper, we proposed a lightweight skin cancer recognition model with feature discrimination based on fine-grained classification principle. The propose model includes two common feature extraction modules of lesion classification network and a feature discrimination network. Firstly, two sets of training samples (positive and negative sample pairs) are input into the feature extraction module (Lightweight CNN) of the recognition model. Then, two sets of feature vectors output from the feature extraction module are used to train the two classification networks and feature discrimination networks of the recognition model at the same time, and the model fusion strategy is applied to further improve the performance of the model, the proposed recognition method can extract more discriminative lesion features and improve the recognition performance of the model in a small amount of model parameters; In addition, based on the feature extraction module of the proposed recognition model, U-Net architecture, and migration training strategy, we build a lightweight semantic segmentation model of lesion area of dermoscopy image, which can achieve high precision lesion area segmentation end-to-end without complicated image preprocessing operation; The performance of our approach was appraised through widespread experiments comparative and feature visualization analysis, the outcome indicates that the proposed method has better performance than the start-of-the-art deep learning-based approach on the ISBI 2016 skin lesion analysis towards melanoma detection challenge dataset.","Lesions,Feature extraction,Melanoma,Image recognition,Image segmentation,Skin,Training,Dermoscopy images,skin cancer detection,lightweight deep learning network,fine-grained feature",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,CLASSIFICATION,COLOR,SEGMENTATION,MELANOMA,STATISTICS,DIAGNOSIS,NODULES,TEXTURE,SYSTEM",IEEE ACCESS,https://doi.org/10.1109/access.2020.2997710,
99,Geometry Optimization of Sheet Specimen for the Measurement Accuracy Improvement in the Hopkinson Bar Based on Intelligent Algorithm,8,,99655-99664,"Wang Qinghua,Xu Feng,Yang Bo,Feng Lijie,Huang Dedong,Wang Chen,Wu Bin","Wang QH,Xu F,Yang B,Feng LJ,Huang DD,Wang C,Wu B",Xu F,10.1109/ACCESS.2020.2998115,Northwestern Polytechnical University,"At present, the split Hopkinson tensile bar (SHTB) is widely used to determine the dynamic tensile properties of materials under high strain rates, in which sheet specimen with dogbone-shaped structure is commonly adopted. However, the geometry dimensions of the specimen used in different literatures vary widely and no uniform criterion has been formulated. In order to obtain the optimal specimen geometry associated with the best measurement accuracy in SHTB experiments, the specimen geometry influence on the measurement accuracy of SHTB experiments is investigated by using the finite element (FE) method, and several key indicators which can characterize the measurement accuracy of specimen are proposed based on simulation analysis. Orthogonal tests are designed to generate training samples for BP (back propagation) neural network, and the complex and highly nonlinear mapping between the structure parameters and measurement accuracy indicators of specimen is fitted by BP and then utilized for the fitness function design of genetic algorithm (GA). Finally, the optimal geometry as well dimensions of the SHTB sheet specimen are determined using GA. Meantime, the finite element simulations are carried out in further to verify the effectiveness of the optimized geometry of specimen. The results of this investigation will provide a recommendation for specimen geometry design and a basis for data reliability analysis in SHTB experiments.","Bars,Geometry,Strain,Stress,Electron tubes,Finite element analysis,Load modeling,Split Hopkinson tensile bar,specimen geometry,measurement accuracy,BP neural network,genetic algorithm",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"HIGH-STRAIN,RATES,TENSILE,TEST,BEHAVIOR,COMPRESSION,PROPERTY,ALLOY,TESTS,MODEL,STEEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09103042.pdf,
100,A Brute-Force CNN Model Selection for Accurate Classification of Sensorimotor Rhythms in BCIs,8,,101014-101023,"Abibullaev Berdakh,Dolzhikova Irina,Zollanvari Amin","Abibullaev B,Dolzhikova I,Zollanvari A",Zollanvari A,10.1109/ACCESS.2020.2997681,Nazarbayev University,"The ultimate goal of Brain-Computer Interface (BCI) research is to enable individuals to interact with their environment by translating their mental imagery. In this regard, a salient issue is the identification of brain activity patterns that can be used to classify intention. Using Electroencephalographic (EEG) signals as archetypical, this classification problem generally possesses two stages: (i) extracting features from collected EEG waveforms; and (ii) constructing a classifier using extracted features. With the advent of deep learning, however, the former stage is generally absorbed into the latter. Nevertheless, the burden has now shifted from trying a number of feature extraction methods to tuning a large number of hyperparameters and architectures. Among existing deep learning architectures used in BCI, Convolutional Neural Networks (CNN) have become an attractive choice. Most of the existing studies that use these networks are based on well-known architectures such as AlexNet or ResNet, use the domain knowledge to construct the final architecture or have an unclear strategy deployed for model selection. This raises the question as to whether constructing accurate CNN-based classifiers is possible using a principled model selection, with the most straightforward one being the brute-force search or, alternatively, experience and developing high intuition regarding hyperparameters combined with an ad hoc approach is the most prudent way to go about designing them. To this end, in this paper, we first define a space of hyperparameters restricted by our computing power. Then we show that an exhaustive search within this limited space of CNN hyperparameters leads to accurate classification of sensorimotor rhythms that arise during motor imagery tasks.","Electroencephalography,Brain modeling,Convolution,Feature extraction,Task analysis,Robot sensing systems,Machine learning,Brain-computer interfaces,motor imagery,deep learning,convolutional neural network,model selection,brute-force search,sensory-motor rhythms",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BRAIN-COMPUTER,INTERFACES,CONVOLUTIONAL,NEURAL-NETWORK,COMMUNICATION,ALGORITHMS",IEEE ACCESS,https://doi.org/10.1109/access.2020.2997681,
