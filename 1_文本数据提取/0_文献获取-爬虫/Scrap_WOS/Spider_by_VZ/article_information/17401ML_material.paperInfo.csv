,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Holistic decomposition convolution for effective semantic segmentation of medical volume images,57,,149-164,"Zeng Guodong,Zheng Guoyan","Zeng GD,Zheng GY",Zeng GD,10.1016/j.media.2019.07.003,Shanghai Jiao Tong University,"Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in many different 2D medical image analysis tasks. In clinical practice, however, a large part of the medical imaging data available is in 3D, e.g, magnetic resonance imaging (MRI) data, computed tomography (CT) data and data generated by many other modalities. This has motivated the development of 3D CNNs for volumetric image segmentation in order to benefit from more spatial context. Due to GPU memory restrictions caused by moving to fully 3D, state-of-the-art methods depend on subvolume/patch processing and the size of the input patch is usually small, limiting the incorporation of larger context information for a better performance. In this paper, we propose a novel Holistic Decomposition Convolution (HDC), which learns a number of separate kernels within the same layer and can be regarded as an inverse operation to the previously introduced Dense Upsampling Convolution (DUC), for an effective and efficient semantic segmentation of medical volume images. HDC consists of a periodic down-shuffling operation followed by a conventional 3D convolution. HDC has the advantage of significantly reducing the size of the data for sub-sequential processing while using all the information available in the input irrespective of the down-shuffling factors. We apply HDC directly to the input data, whose output will be used as the input to sub-sequential CNNs. In order to achieve volumetric dense prediction at final output, we need to recover full resolution, which is done by using DUC. We show that both HDC and DUC are network agnostic and can be combined with different CNNs for an improved performance in both training and testing phases. Results obtained from comprehensive experiments conducted on both MRI and CT data of different anatomical regions demonstrate the efficacy of the present approach. (C) 2019 Elsevier B.V. All rights reserved.","Semantic segmentation,Volume images,Deep learning,Convolutional neural networks",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"INTERVERTEBRAL,DISC,LOCALIZATION,3D,MR-IMAGES,AUTOMATIC,SEGMENTATION,NEURAL-NETWORKS,CARTILAGE",MEDICAL IMAGE ANALYSIS,,
2,TOP-GAN: Stain-free cancer cell classification using deep learning with a small training set,57,,176-185,"Rubin Moran,Stein Omer,Turko Nir A.,Nygate Yoav,Roitshtain Darina,Karako Lidor,Barnea Itay,Giryes Raja,Shaked Natan T.","Rubin M,Stein O,Turko NA,Nygate Y,Roitshtain D,Karako L,Barnea I,Giryes R,Shaked NT",Shaked NT,10.1016/j.media.2019.06.014,Tel Aviv University,"We propose a new deep learning approach for medical imaging that copes with the problem of a small training set, the main bottleneck of deep learning, and apply it for classification of healthy and cancer cell lines acquired by quantitative phase imaging. The proposed method, called transferring of pre-trained generative adversarial network (TOP-GAN), is hybridization between transfer learning and generative adversarial networks (GANs). Healthy cells and cancer cells of different metastatic potential have been imaged by low-coherence off-axis holography. After the acquisition, the optical path delay maps of the cells are extracted and directly used as inputs to the networks. In order to cope with the small number of classified images, we use GANs to train a large number of unclassified images from another cell type (sperm cells). After this preliminary training, we change the last layers of the network and design automatic classifiers for the correct cell type (healthy/primary cancer/metastatic cancer) with 90-99% accuracies, although small training sets of down to several images are used. These results are better in comparison to other classic methods that aim at coping with the same problem of a small training set. We believe that our approach makes the combination of holographic microscopy and deep learning networks more accessible to the medical field by enabling a rapid, automatic and accurate classification in stain-free imaging flow cytometry. Furthermore, our approach is expected to be applicable to many other medical image classification tasks, suffering from a small training set. (C) 2019 Published by Elsevier B.V.","Holography,Quantitative phase imaging,Deep learning,Image classification,Biological cells",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"QUANTITATIVE,PHASE,MICROSCOPY,CONVOLUTIONAL,NEURAL-NETWORKS,IDENTIFICATION,VISUALIZATION,RECOGNITION,COMPACT",MEDICAL IMAGE ANALYSIS,,
3,Accurate and robust deep learning-based segmentation of the prostate clinical target volume in ultrasound images,57,,186-196,"Karimi Davood,Zeng Qi,Mathur Prateek,Avinash Apeksha,Mandavi Sara,Spadinger Ingrid,Abolmaesumi Purang,Salcudean Septimiu E.","Karimi D,Zeng Q,Mathur P,Avinash A,Mandavi S,Spadinger I,Abolmaesumi P,Salcudean SE",Karimi D,10.1016/j.media.2019.07.005,University of British Columbia,"The goal of this work was to develop a method for accurate and robust automatic segmentation of the prostate clinical target volume in transrectal ultrasound (TRUS) images for brachytherapy. These images can be difficult to segment because of weak or insufficient landmarks or strong artifacts. We devise a method, based on convolutional neural networks (CNNs), that produces accurate segmentations on easy and difficult images alike. We propose two strategies to achieve improved segmentation accuracy on difficult images. First, for CNN training we adopt an adaptive sampling strategy, whereby the training process is encouraged to pay more attention to images that are difficult to segment. Secondly, we train a CNN ensemble and use the disagreement among this ensemble to identify uncertain segmentations and to estimate a segmentation uncertainty map. We improve uncertain segmentations by utilizing the prior shape information in the form of a statistical shape model. Our method achieves Hausdorff distance of 2.7 +/- 2.3 mm and Dice score of 93.9 +/- 3.5%. Comparisons with several competing methods show that our method achieves significantly better results and reduces the likelihood of committing large segmentation errors. Furthermore, our experiments show that our approach to estimating segmentation uncertainty is better than or on par with recent methods for estimation of prediction uncertainty in deep learning models. Our study demonstrates that estimation of model uncertainty and use of prior shape information can significantly improve the performance of CNN-based medical image segmentation methods, especially on difficult images. (C) 2019 Elsevier B.V. All rights reserved.","Image segmentation,Model uncertainty,Shape models,Clustering,Deep learning",Article; Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"ACTIVE,SHAPE,MODELS,BRACHYTHERAPY,FRAMEWORK,RECOMMENDATIONS,OPTIMIZATION,INFORMATION,ALGORITHM",MEDICAL IMAGE ANALYSIS,,
4,Towards quantitative imaging biomarkers of tumor dissemination: A multi-scale parametric modeling of multiple myeloma,57,,214-225,"Piraud Marie,Wennmann Markus,Kintzele Laurent,Hillengass Jens,Keller Ulrich,Langs Georg,Weber Marc-Andre,Menze Bjoern H.","Piraud M,Wennmann M,Kintzele L,Hillengass J,Keller U,Langs G,Weber MA,Menze BH",Piraud M,10.1016/j.media.2019.07.001,Technical University of Munich,"The advent of medical imaging and automatic image analysis is bringing the full quantitative assessment of lesions and tumor burden at every clinical examination within reach. This opens avenues for the development and testing of functional disease models, as well as their use in the clinical practice for personalized medicine. In this paper, we introduce a Bayesian statistical framework, based on mixed-effects models, to quantitatively test and learn functional disease models at different scales, on population longitudinal data. We also derive an effective mathematical model for the crossover between initially detected lesions and tumor dissemination, based on the Iwata-Kawasaki-Shigesada model. We finally propose to leverage this descriptive disease progression model into model-aware biomarkers for personalized risk-assessment, taking all available examinations and relevant covariates into account. As a use case, we study Multiple Myeloma, a disseminated plasma cell cancer, in which proper diagnostics is essential, to differentiate frequent precursor state without end-organ damage from the rapidly developing disease requiring therapy. After learning the best biological models for local lesion growth and global tumor burden evolution on clinical data, and computing corresponding population priors, we use individual model parameters as biomarkers, and can study them systematically for correlation with external covariates, such as sex or location of the lesion. On our cohort of 63 patients with smoldering Multiple Myeloma, we show that they perform substantially better than other radiological criteria, to predict progression into symptomatic Multiple Myeloma. Our study paves the way for modeling disease progression patterns for Multiple Myeloma, but also for other metastatic and disseminated tumor growth processes, and for analyzing large longitudinal image data sets acquired in oncological imaging. It shows the unprecedented potential of model-based biomarkers for better and more personalized treatment decisions and deserves being validated on larger cohorts to establish its role in clinical decision making. (C) 2019 Elsevier B.V. All rights reserved.","FOCAL LESIONS,GROWTH,MANAGEMENT,DIAGNOSIS,CRITERIA,DISEASE,VERSION,RISK",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"FOCAL,LESIONS,GROWTH,MANAGEMENT,DIAGNOSIS,CRITERIA,DISEASE,VERSION,RISK",MEDICAL IMAGE ANALYSIS,https://doi.org/10.1101/613869,
5,Road pothole extraction and safety evaluation by integration of point cloud and images derived from mobile mapping sensors,42,,,"Wu Hangbin,Yao Lianbi,Xu Zeran,Li Yayun,Ao Xinran,Chen Qichao,Li Zhengning,Meng Bin","Wu HB,Yao LB,Xu ZR,Li YY,Ao XR,Chen QC,Li ZN,Meng B",Yao LB,10.1016/j.aei.2019.100936,Tongji University,"The automatic detection and extraction of road pothole distress is an important issue regarding healthy road structures, monitoring, and maintenance. In this paper, a new algorithm that integrates the mobile point cloud and images is proposed for the detection of road potholes. The algorithm includes three steps: 2D candidate pothole extraction from the images using a deep learning method, 3D candidate pothole extraction via a point cloud, and pothole determination by depth analysis. Because the texture features of the pothole and asphalt or concrete patches greatly differ from those of a normal road, pothole or patch distress images are used to establish a training set and train and test the deep learning system. Subsequently, the 2D candidate pothole is extracted from the images and labeled via the trained DeepLabv3 + , a state-of-the-art pixel-wise classification (semantic segmentation) network. The edge of the candidate pothole in the image is then used to establish the relationship between the mobile point cloud and images. The original road point cloud around the edge of the candidate pothole is categorized into two groups, that is, interior and exterior points, according to the relationship between the point cloud and images. The exterior points are used to fit the road plane and calculate the accurate 3D shape of the candidate potholes. Finally, the interior points of a candidate pothole are used to analyze the depth distribution to determine if the candidate pothole is a pothole or patch. To verify the proposed method, two cases, including real and simulation cases, are selected. The real case is an expressway in Shanghai with a length of 26.4 km. Based on the proposed method, 77 candidate potholes are extracted by the DeepLabv3 + system; 49 potholes and 28 patches are finally filtered. The affected lanes and pothole locations are analyzed. The simulation case is selected to verify the geometric accuracy of the detected potholes. The results show that the mean accuracy of the detected potholes is similar to 1.5-2.8 cm.","Candidate pothole,Patch,Image segmentation,Point cloud,Depth distribution",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,5.936,"AUTOMATIC,PAVEMENT,CRACK,WAVELET,TRANSFORM,SYSTEM,CLASSIFICATION",ADVANCED ENGINEERING INFORMATICS,,
6,A new machine learning technique for an accurate diagnosis of coronary artery disease,179,,,"Abdar Moloud,Ksiazek Wojciech,Acharya U. Rajendra,Tan Ru-San,Makarenkov Vladimir,Plawiak Pawel","Abdar M,Ksiazek W,Acharya UR,Tan RS,Makarenkov V,Plawiak P",Plawiak P,10.1016/j.cmpb.2019.104992,Cracow University of Technology,"Background and objective: Coronary artery disease (CAD) is one of the commonest diseases around the world. An early and accurate diagnosis of CAD allows a timely administration of appropriate treatment and helps to reduce the mortality. Herein, we describe an innovative machine learning methodology that enables an accurate detection of CAD and apply it to data collected from Iranian patients.
Methods: We first tested ten traditional machine learning algorithms, and then the three-best performing algorithms (three types of SVM) were used in the rest of the study. To improve the performance of these algorithms, a data preprocessing with normalization was carried out. Moreover, a genetic algorithm and particle swarm optimization, coupled with stratified 10-fold cross-validation, were used twice: for optimization of classifier parameters and for parallel selection of features.
Results: The presented approach enhanced the performance of all traditional machine learning algorithms used in this study. We also introduced a new optimization technique called N2Genetic optimizer (a new genetic training). Our experiments demonstrated that N2Genetic-nuSVM provided the accuracy of 93.08% and F1-score of 91.51% when predicting CAD outcomes among the patients included in a well-known Z-Alizadeh Sani dataset. These results are competitive and comparable to the best results in the field.
Conclusions: We showed that machine-learning techniques optimized by the proposed approach, can lead to highly accurate models intended for both clinical and research use. (C) 2019 Elsevier B.V. All rights reserved.","Coronary artery disease (CAD),Machine learning,Normalization,Genetic algorithm,Particle swarm optimization,Feature selection,Classification",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"MYOCARDIAL-INFARCTION,GENETIC,ALGORITHM,NEURAL-NETWORK,HEART-DISEASE,ECG,SIGNALS,COMPUTED-TOMOGRAPHY,AUTOMATED,DETECTION,COGNITIVE,ANALYSIS,PARTICLE,SWARM,CLASSIFICATION",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
7,Group-representative functional network estimation from multi-subject fMRI data via MRF-based image segmentation,179,,,"Tang Bingjing,Iyer Aditi,Rao Vinayak,Kong Nan","Tang BJ,Iyer A,Rao V,Kong N",Kong N,10.1016/j.cmpb.2019.07.004,Purdue University System,"Background and objective: There has been growing interest in using functional connectivity patterns, determined from fMRI data to characterize groups of individuals exhibiting common traits. However, the present challenge lies in efficient and accurate identification of distinct patterns observed consistently across multiple subjects. Existing approaches either impose strong assumptions, require aligning images before processing, or require data-intensive machine learning algorithms with manually labeled training datasets. In this paper, we propose a more principled and flexible approach to address this.
Methods: Our approach redefines the problem of estimating the group-representative functional network as an image segmentation problem. After employing an improved clustering-based ICA scheme to preprocess the dataset of individual functional network images, we use a maximum a posteriori-Markov random field (MAP-MRF) framework to solve the image segmentation problem. In this framework, we propose a probabilistic model of the individual pixels of the fMRI data, with the model involving a latent group-representative functional network image. Given an observed dataset, we apply a novel and efficient variational Bayes algorithm to recover the associated latent group image. Our methodology seeks to overcome limitations in more traditional schemes by exploiting spatial relationships underlying the connectivity maps and accounting for uncertainty in the estimation process.
Results: We validate our approach using synthetic, simulated and real data. First, we generate datasets from the proposed forward model with subject-specific binary masking and measurement noise, as well as from a variant of the model without measurement noise. We use both datasets to evaluate our model, along with two algorithms: coordinate-ascent algorithm and variational Bayes algorithm. We conclude that our proposed model with variational Bayes outperforms other competitors, even under model-misspecification. Using variational Bayes offers a significant improvement in performance, with almost no additional computational overhead. We next test our approach on simulated fMRI data. We show our approach is robust to initialization and can recover a solution close to the ground truth. Finally, we apply our proposed methodology along with baselines to a real dataset of fMRI recordings of individuals from two groups, a control group and a group suffering from depression, with recordings made while individuals were subjected to musical stimuli. Our methodology is able to identify group differences that are less clear under competing methods.
Conclusions: Our model-based approach demonstrates the advantage of probabilistic models and modern algorithms that account for uncertainty in accurate identification of group-representative connectivity maps. The variational Bayes methodology yields highly accurate results without increasing the computational load compared to traditional methods. In addition, it is robust to model misspecification, and increases the ability to avoid local optima in the solution. (C) 2019 Elsevier B.V. All rights reserved.","Functional MRI,Functional connectivity,Independent component analysis,Markov random field,Variational Bayes",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"INDEPENDENT,COMPONENT,ANALYSIS,PARCELLATION,INFERENCES,DISTANCE",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,http://arxiv.org/pdf/1809.01046,
8,Automatic identification of atherosclerosis subjects in a heterogeneous MR brain imaging data set,62,,18-27,"Bento Mariana,Souza Roberto,Salluzzi Marina,Rittner Leticia,Zhang Yunyan,Frayne Richard","Bento M,Souza R,Salluzzi M,Rittner L,Zhang YY,Frayne R",Bento M,10.1016/j.mri.2019.06.007,University of Calgary,"Carotid-artery atherosclerosis (CA) contributes significantly to overall morbidity and mortality in ischemic stroke. We propose a machine learning technique to automatically identify subjects with CA from a heterogeneous cohort of magnetic resonance brain images. The cohort includes 190 subjects with CA, white mater hyperintensites of presumed vascular origin or multiple sclerosis, as well as 211 presumed healthy subjects. We determined a set of handcrafted and convolutional discriminant features to perform this task. A support vector machine (SVM) was used to perform this four-class classification task. Our approach had an accuracy rate of 97.5% (higher than chance accuracy of 52.6% for guessing majority class), sensitivity of 96.4% and specificity of 97.9% in identifying subjects with CA, suggesting that the proposed combination of features may be used as an imaging biomarker for characterizing atherosclerotic disease on brain imaging.","Brain image processing,Carotid artery atherosclerotic disease,Machine learning,Feature extraction,Multi-center data set",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"MULTICENTER,SEGMENTATION,MACHINE,CLASSIFICATION",MAGNETIC RESONANCE IMAGING,,
9,Anatomical context improves deep learning on the brain age estimation task,62,,70-77,"Bermudez Camilo,Plassard Andrew J.,Chaganti Shikha,Huo Yuankai,Aboud Katherine S.,Cutting Laurie E.,Resnick Susan M.,Landman Bennett A.","Bermudez C,Plassard AJ,Chaganti S,Huo YK,Aboud KS,Cutting LE,Resnick SM,Landman BA",Bermudez C,10.1016/j.mri.2019.06.018,"2301 Vanderbilt Pl,POB 351679 Stn B, Nashville, TN 37235 USA.","Deep learning has shown remarkable improvements in the analysis of medical images without the need for engineered features. In this work, we hypothesize that deep learning is complementary to traditional feature estimation. We propose a network design to include traditional structural imaging features alongside deep convolutional ones and illustrate this approach on the task of imaging-based age prediction in two separate contexts: Tl-weighted brain magnetic resonance imaging (MRI) (N = 5121, ages 4-96, healthy controls) and computed tomography (CT) of the head (N = 1313, ages 1-97, healthy controls). In brain MRI, we can predict age with a mean absolute error of 4.08 years by combining raw images along with engineered structural features, compared to 5.00 years using image-derived features alone and 8.23 years using structural features alone. In head CT, we can predict age with a median absolute error of 9.99 years combining features, compared to 11.02 years with image-derived features alone and 13.28 years with structural features alone. These results show that we can complement traditional feature estimation using deep learning to improve prediction tasks. As the field of medical image processing continues to integrate deep learning, it will be important to use the new techniques to complement traditional imaging features instead of fully displacing them.","Deep learning,Convolutional neural networks,Brain age,Medical image processing",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,MAGNETIC RESONANCE IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6689246,
10,A multivoxel pattern analysis framework with mutual connectivity analysis investigating changes in resting state connectivity in patients with HIV associated neurocognitve disorder,62,,121-128,"DSouza Adora M.,Abidin Anas Z.,Schifitto Giovanni,Wismueller Axel","DSouza AM,Abidin AZ,Schifitto G,Wismuller A",DSouza AM,10.1016/j.mri.2019.06.001,University of Rochester,"Functional MRI (fMRI) quantifies brain activity non-invasively by measuring the blood oxygen level dependent (BOLD) response to neuronal activity. It was recently demonstrated, on realistic fMRI simulations, that nonlinear connectivity approaches, such as Mutual Connectivity Analysis with Local Models (MCA-LM), are better suited for extracting connectivity measures than conventional techniques of cross-correlating time-series pairs. In this work, we investigate the application of MCA-LM in extracting meaningful connectivity measures aiding in distinguishing healthy controls from individuals presenting with symptoms of HIV Associated Neurocognitive Disorder (HAND), which occurs as a result of HIV infection of the central nervous system. The pairwise connectivity measures provide a high-dimensional representation of connectivity profiles for subjects and are used as features for classification. We adopt feature selection (FS) techniques reducing the number of redundant and noisy features, while also controlling the complexity of the classifiers. We investigate three FS techniques: 1) Kendall's tau, 2) Information Gain Attribute selection 3) ReliefF and two classifiers:1) AdaBoost and 2) Random Forests. Our results demonstrate that MCA-LM consistently outperforms correlation in terms of Area under the Receiver Operating Characteristic Curve and accuracy. Improved performance with MCA-LM suggests that such a nonlinear approach is better at capturing meaningful connectivity relationships between brain regions. This demonstrates potential for developing novel neuroimaging-derived biomarkers for HAND. Furthermore, FS helps identify connections between anatomical regions that are affected by HAND. In this work, we show that the regions of the basal ganglia and frontal cortex, which are known to be affected by HAND according to current literature, are identified as most discriminative.","Resting-state fMRI,Functional connectivity,Mutual connectivity analysis,BOLD fMRI,Machine learning,Feature selection",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"HUMAN-IMMUNODEFICIENCY-VIRUS,FUNCTIONAL,CONNECTIVITY,ANTIRETROVIRAL,THERAPY,BRAIN,NETWORKS,HEAD,MOTION,FMRI,SCHIZOPHRENIA,ABNORMALITIES,NONLINEARITY,PARCELLATION",MAGNETIC RESONANCE IMAGING,,
11,Ultrasound assisted synthesis of water-in-oil nanoemulsions: Parametric optimization using hybrid ANN-GA approach,144,,,"Kumar Hemant,Kumar Vimal","Kumar H,Kumar V",Kumar V,10.1016/j.cep.2019.107649,Indian Institute of Technology System (IIT System),"Present study deals with the newly investigated CEMNSE (combined energy mixed surfactant nanoemulsion) method for optimizing the operating parameters concerned with the formation of water-in-oil nanoemulsions (W/O NE). The formulation process was intensified by optimizing the operating parameters of CEMNSE method by minimizing functions of two response variables viz. avg. droplet size (nm) and kinematic viscosity (mm(2).s(-1)). A combined approach of ultrasonic cavitation and isothermal dilution method is used in formulating W/O NE. Optimization is carried out with an integral hybrid genetic algorithm (GA) with back propagation artificial neural network (BPANN) and response surface methodology (RSM) based on rotatable central composite design (RCCD). Combined approach process parameters as input to the proposed models are water fraction (0.05-0.11, w/w), surfactant fraction (0.10-0.020, w/w), power density (21.25-46.75, W. cm(-2)), and ultrasonication time (4-10, min.). Hybrid GA model predicted optimum values of avg. droplet size and kinematic viscosity as 53.54 nm and 1.459 min(2).s(-1), respectively, with errors < 2.2%. However, optimized process parameters predicted as water fraction-0.052 (w/w), surfactant fraction-0.105 (w/w), power density-29.94 (W.cm(-2)), and ultrasonication time-9.7 min. Multi objective hybrid GA ascertained robust than conventional methods in this study.","Ultrasonication,Process intensification,Nanoemulsions,Artificial neural network,Genetic algorithm",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Energy & Fuels,Engineering",,4.055,"ARTIFICIAL,NEURAL-NETWORK,RESPONSE-SURFACE,METHODOLOGY,NANO-EMULSIONS,EXPERIMENTAL-DESIGN,STABILITY,RSM,EMULSIFICATION,FORMULATION,DISPERSION,SIZE",CHEMICAL ENGINEERING AND PROCESSING-PROCESS INTENSIFICATION,,
12,Image classification toward breast cancer using deeply-learned quality features,64,,,"Fang Yan,Zhao Jing,Hu Lingzhi,Ying Xiaoping,Pan Yanfang,Wang Xiaoping","Fang Y,Zhao J,Hu LZ,Ying XP,Pan YF,Wang XP",Zhao J,10.1016/j.jvcir.2019.102609,Shaanxi University of Chinese Medicine,"Image classification plays an important role in computer vision and its applications, such as scene categorization, image retrieval. Convolutional neural network based methods have shown competitive performance in image classification, which aims to exploit deep feature of training images. In this paper, based on CNN methods and image quality assessment (IQA) algorithms, we propose a novel method for medical application, that is breast cancer classification. First, we leverage CNN architecture to calculate the number of pixels in the lesions, where maximum pooling layers are used. Then, large density of pixel regions will be assigned with large quality scores, which reflect more texture and grayscale features. Finally, we construct a multi-SVM based image kernel using obtained quality scores to achieve breast cancer classification. Experimental results show our proposed method outperforms single recognition based image classification methods such as pixel grayscale or gradient. (C) 2019 Elsevier Inc. All rights reserved.","Image classification,CNN,Quality score",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Computer Science,,2.915,"OBJECT,DETECTION",JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION,,
13,Hierarchically engineering quality-related perceptual features for understanding breast cancer,64,,,"Wang Xusheng,Chen Xing,Cao Congjun","Wang XS,Chen X,Cao CJ",Wang XS,10.1016/j.jvcir.2019.102644,Xi'an University of Technology,"Breast cancer is generally acknowledged as the second leading cause of cancer death among women. Therefore, accurately understanding breast cancer from X-ray images is an indispensable technique in medical sciences and image analysis. In the work, we propose a novel perceptual deep architecture that hierarchically learns deep features from large-scale X-ray images, wherein human visual perception is naturally encoded. More specifically, given a rich number of breast cancer images, we first employ the well-known BING objectness measure to identify all possible visually/semantically salient patches. Due to the relatively huge number of BING object patches, a weakly-supervised ranking algorithm is designed to select high quality object patches according to human visual perception. Subsequently, an aggregation scheme is utilized to derive the deep features of high quality object patches within each brain cancer image. Based on the aggregated deep feature, a multi-class SVM is trained to classify each breast cancer into multiple levels. Extensive comparative studies and visualization results have demonstrated the effectiveness and efficiency of our proposed deep architecture. (C) 2019 Elsevier Inc. All rights reserved.","Breast cancer,Deep learning,Quality-related,Weakly-supervised,Ranking algorithm",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Computer Science,,2.915,SCENE,JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION,,
14,Machine Learning Accelerates Discovery of Optimal Colloidal Quantum Dot Synthesis,13,10,11122-11128,"Voznyy Oleksandr,Levina Larissa,Fan James Z.,Askerka Mikhail,Jain Ankit,Choi Min-Jae,Ouellette Olivier,Todorovic Petar,Sagar Laxmi K.,Sargent Edward H.","Voznyy O,Levina L,Fan JZ,Askerka M,Jain A,Choi MJ,Ouellette O,Todorovic P,Sagar LK,Sargent EH",Sargent EH,10.1021/acsnano.9b03864,University of Toronto,"Colloidal quantum dots (CQDs) allow broad tuning of the bandgap across the visible and near-infrared spectral regions. Recent advances in applying CQDs in light sensing, photovoltaics, and light emission have heightened interest in achieving further synthetic improvements. In particular, improving monodispersity remains a key priority in order to improve solar cells' open-circuit voltage, decrease lasing thresholds, and improve photodetectors' noise-equivalent power. Here we utilize machinelearning-in-the-loop to learn from available experimental data, propose experimental parameters to try, and, ultimately, point to regions of synthetic parameter space that will enable record-monodispersity PbS quantum dots. The resultant studies reveal that adding a growth-slowing precursor (oleylamine) allows nucleation to prevail over growth, a strategy that enables record-large-bandgap (611 nm exciton) PbS nanoparticles with a well-defined excitonic absorption peak (half-width at half-maximum (hwhm) of 145 meV). At longer wavelengths, we also achieve improved monodispersity, with an hwhm of 55 meV at 950 nm and 24 meV at 1500 nm, compared to the best published to date values of 75 and 26 meV, respectively.","colloidal quantum dots,nanocrystals,synthesis,PbS,machine learning,Bayesian optimization",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"PBS,NANOCRYSTALS,SIZE,MONODISPERSE",ACS NANO,,
15,Data-driven high-fidelity 2D microstructure reconstruction via non-local patch-based image inpainting,178,,207-218,"Anh Tran,Hoang Tran","Tran A,Tran H",Tran A,10.1016/j.actamat.2019.08.007,United States Department of Energy (DOE),"Microstructure reconstruction problems are usually limited to the representation with finitely many number of phases, e.g. binary and ternary. However, images of microstructure obtained through experimental, for example, using microscope, are often represented as a RGB or grayscale image. Because the phase-based representation is discrete, more rigid, and provides less flexibility in modeling the microstructure, as compared to RGB or grayscale image, there is a loss of information in the conversion. In this paper, a microstructure reconstruction method, which produces images at the fidelity of experimental microscopy, i.e. RGB or grayscale image, is proposed without introducing any physics-based microstructure descriptor. Furthermore, the image texture is preserved and the microstructure image is represented with continuous variables (as in RGB or grayscale images), instead of binary or categorical variables, which results in a high-fidelity image of microstructure reconstruction. The advantage of the proposed method is its quality of reconstruction, which can be applied to any other binary or multiphase 2D microstructure. The proposed method can be thought of as a subsampling approach to expand the microstructure dataset, while preserving its image texture. Moreover, the size of the reconstructed image is more flexible, compared to other machine learning microstructure reconstruction method, where the size must be fixed beforehand. In addition, the proposed method is capable of joining the microstructure images taken at different locations to reconstruct a larger microstructure image. A significant advantage of the proposed method is to remedy the data scarcity problem in materials science, where experimental data is scare and hard to obtain. The proposed method can also be applied to generate statistically equivalent microstructures, which has a strong implication in microstructure-related uncertainty quantification applications. The proposed microstructure reconstruction method is demonstrated with the UltraHigh Carbon Steel micrograph DataBase (UHCSDB). (C) 2019 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","microstructure reconstruction,Microstructure assembly,Microscopy,Image inpainting,Micrograph database",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,,"POLYCRYSTALLINE,MICRO,STRUCTURES,AUTOMATED-ANALYSIS,HETEROGENEOUS,MATERIALS,FRAMEWORK,SIMULATION",ACTA MATERIALIA,https://www.sciencedirect.com/science/article/am/pii/S1359645419305178,
16,Predicting molten steel endpoint temperature using a feature-weighted model optimized by mutual learning cuckoo search,83,,,"Yang Qiangda,Zhang Jie,Yi Zhi","Yang QD,Zhang J,Yi Z",Yang QD,10.1016/j.asoc.2010.105675,Northeastern University - China,"A feature-weighted neural network model for the prediction of the endpoint temperature of molten steel (MSET) in a ladle furnace (LF) is proposed in this paper. Accurate prediction of MSET is essential for promoting product quality, reducing production costs and enhancing productivity. Considering that different features have different impacts on the MSET during the process of LF refining, a weight is applied to each feature before feeding the feature to neural networks. A mutual learning cuckoo search (MLCS) algorithm is proposed to simultaneously determine the feature weights and network parameters of the proposed prediction model. The search of each cuckoo in the basic cuckoo search algorithm and many of its variants is performed independently, which may decrease the algorithms' performance. The proposed MLCS algorithm introduces two new search strategies, the mutual learning-based search strategy and the bottom reinforcement learning-based search strategy. The superior performance of MLCS is first confirmed with 20 benchmark optimization problems. Then, MLCS is applied to optimize the feature weights and network parameters in the feature-weighted MSET prediction model. Application to modeling the production data from a 300 t LF in an iron & steel plant in China demonstrates the effectiveness of the proposed feature-weighted neural network model. (C) 2019 Elsevier B.V. All rights reserved.","Modeling,Cuckoo search,Feature weighed,Ladle furnace,Molten steel temperature",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"PARTICLE,SWARM,OPTIMIZATION,LADLE,FURNACE,ALGORITHM,NETWORK,IDENTIFICATION",APPLIED SOFT COMPUTING,,
17,Human identification after plastic surgery using region based score level fusion of local facial features,48,,,"Sabharwal Tanupreet,Gupta Rashmi","Sabharwal T,Gupta R",Sabharwal T,10.1016/j.jisa.2019.102373,GGS Indraprastha University,"Plastic surgery alters original facial features of an individual thereby making Face Recognition after plastic surgery difficult. Cosmetic procedures introduce geometrical deviations which are difficult to analyze by state of the art facial identification procedures. Here a region based score level fusion approach for local facial features is proposed to equalize former and latter surgery images. Steps involved in the recognition process are; firstly identifying the ROIs (areas/regions of interest/concern) of before and after surgery images. ROIs are eyes, nose and mouth regions; feature extraction from identified regions via Speeded Up Robust Features and K Nearest Neighbour techniques; region wise and full face geometrical distance calculation between matched feature vectors of pre and post surgery image samples by a distance metric (sum of squared differences); final recognition rate calculation by weighted score level fusion. The projected procedure gives recognition of 89.7% for local surgical treatment and 87% for global surgery. (C) 2019 Elsevier Ltd. All rights reserved.","Facial recognition after plastic surgery (FRAP'S),American society of plastic surgeons (ASPS),Regions of interest (ROIs),Speeded up robust features (SURF),K-nearest-neighbour (KNN),Weighted score level fusion,Expected error rate (EER),Recognition rate (RR),Computation time (CT)",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.504,,JOURNAL OF INFORMATION SECURITY AND APPLICATIONS,,
18,"The Good, the Bad, and the Unflinchingly Selfish: Pro-sociality can be Well Predicted Using Payoffs and Three Behavioral Types",7,3,,"Epstein Ziv,Peysakhovich Alexander,Rand David","Epstein Z,Peysakhovich A,Rand D",Epstein Z,10.1145/3355947,Massachusetts Institute of Technology (MIT),"The human willingness to pay costs to benefit anonymous others is often explained by social preferences: rather than only valuing their own material payoff, people also include the payoffs of others in their utility function. But how successful is this concept of outcome-based social preferences for actually predicting out-of-sample behavior? We investigate this question by having 1,067 participants each make 20 Dictator Game decisions with randomized parameters (e.g., outcomes for the self, for the other, benefit/cost ratio of pro-sociality). We then use machine learning to try to predict behavior by each participant in each decision. A representative agent model (a small, shared, set of parameters) predicts better than random but still quite poorly (AUC = 0.69). Allowing for full heterogeneity across individuals in the mapping from decision-parameters to outcome yields good predictive performance (AUC = 0.89). However, this heterogeneous model is complicated and unwieldy, thus we also investigate whether a simpler model can yield similar performance. We find that the vast majority of the predictive power (AUC = 0.88) is achieved by a model that allows for three behavioral types. Finally, we show that cannot be well proxied for by other measures in psychology. This final analysis adds further evidence to the literature that human ""cooperative phenotypes"" are indeed meaningful, relatively orthogonal person-level traits.","Machine learning,social preferences,behavioral economics,prosociality",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,,"PREFERENCES,FAIRNESS,MODELS",ACM TRANSACTIONS ON ECONOMICS AND COMPUTATION,,
19,Automated defect detection and classification in ashlar masonry walls using machine learning,106,,,"Valero Enrique,Forster Alan,Bosche Frederic,Hyslop Ewan,Wilson Lyn,Turmel Aurelie","Valero E,Forster A,Bosche F,Hyslop E,Wilson L,Turmel A",Valero E,10.1016/j.autcon.2019.102846,University of Edinburgh,"Methods employed for surveying buildings for condition have traditionally been reliant upon visual assessment and manual recording. Survey of traditional masonry also ostensibly conforms to this approach but, due to the sheer volume of masonry units composing walls, it is often prohibitively time consuming, exceptionally complex and ultimately costly. Notable features of such survey work for ashlar stone types require each stone to be labelled and overlaid with information relative to condition. Further hindering these already costly operations, it has been shown that the accuracy of reporting, including labelling the manifestation of defects and defect diagnosis, is subjective, depending upon the expertise and experience of those evaluating the fabric. Moving beyond these preliminary survey and reporting stages, this situation gives rise to variable repair and maintenance strategies that can have significant cost implications and can debase fundamental conservation activities.
The development of digital technologies, such as terrestrial laser scanning, and advancements in novel computer vision statistical techniques can help produce accurate representation of buildings that can be subsequently rapidly processed, achieving many tangible survey functions with greater inherent objectivity. In this paper, an innovative strategy for automatic detection and classification of defects in digitised ashlar masonry walling is presented. The classification method is based on the use of supervised machine learning algorithms, assisted by surveyors' strategies and expertise to identify defective individual masonry units, through to broader global patterns for groups of stones. The proposed approach has been tested on the main facade of the Chapel Royal in Stirling Castle (Scotland), demonstrating its potential for ashlar masonry forms of wall construction. It is important to recognise that the findings are not limited to this culturally significant building and will be of high value to almost innumerable ashlar-built structures worldwide. The research ultimately attempts to reduce the degree of subjectivity in classifying defects, on a scale and rapidity hitherto beyond traditional project cost constraints. Importantly, it is recognised that through automation more effective utilisation of resources that would have been traditionally spent on survey can be redeployed to support fabric intervention or routine maintenance operations.","Surveying,Digital reality capture,Masonry defects,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"POINT,CLOUDS,3D,REPAIR",AUTOMATION IN CONSTRUCTION,https://www.pure.ed.ac.uk/ws/files/96485213/2019_AutoConML.pdf,
20,"Detecting and measuring areas of choriocapillaris low perfusion in intermediate, non-neovascular age-related macular degeneration",6,4,,"Camino Acner,Guo Yukun,You Qisheng,Wang Jie,Huang David,Bailey Steven T.,Jia Yali","Camino A,Guo YK,You QS,Wang J,Huang D,Bailey ST,Jia YL",Jia YL,10.1117/1.NPh.6.4.041108,Oregon Health & Science University,"Age-related macular degeneration (AMD) is a vision-threatening disease that affects the outer retina and choroid of elderly adults. Because photoreceptors are found in the outer retina and rely primarily on the trophic support of the underlying choriocapillaris, imaging of flow or lack thereof in choriocapillaris by optical coherence tomography angiography (OCTA) has great clinical potential in AMD assessment. We introduce a metric using OCTA, named ""focal perfusion loss"" (FPL) to describe the effects of age and non-neovascular AMD on choriocapillaris flow. Because OCTA imaging of choriocapillaris is vulnerable to artifacts-namely motion, projections, segmentation errors, and shadows-they are removed by postprocessing software. The shadow detection software is a machine learning algorithm recently developed for the evaluation of the retinal circulation and here adapted for choriocapillaris analysis. It aims to exclude areas with unreliable flow signal due to blocking of the OCT beam by objects anterior to the choriocapillaris (e.g., drusen, retinal vessels, vitreous floaters, and iris). We found that both the FPL and the capillary density were able to detect changes in the choriocapillaris of AMD and healthy age-matched subjects with respect to young controls. The dominant cause of shadowing in AMD is drusen, and the shadow exclusion algorithm helps determine which areas under drusen retain sufficient signal for perfusion evaluation and which areas must be excluded. Such analysis allowed us to determine unambiguously that choriocapillaris density under drusen is indeed reduced. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","optical coherence tomography angiography,choriocapillaris,age-related macular degeneration,drusen",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Neurosciences & Neurology,Optics",,4.327,"COHERENCE,TOMOGRAPHY,ANGIOGRAPHY,MORPHOMETRIC-ANALYSIS,MOTION,CORRECTION,OCT,ANGIOGRAPHY,ULTRAHIGH-SPEED,FEATURES",NEUROPHOTONICS,https://europepmc.org/articles/pmc6739623?pdf=render,
21,Artificial intelligence deep learning algorithm for discriminating ungradable optical coherence tomography three-dimensional volumetric optic disc scans,6,4,,"Ran An Ran,Shi Jian,Ngai Amanda K.,Chan Wai-Yin,Chan Poemen P.,Young Alvin L.,Yung Hon-Wah,Tham Clement C.,Cheung Carol Y.","Ran AR,Shi J,Ngai AK,Chan WY,Chan PP,Young AL,Yung HW,Tham CC,Cheung CY",Tham CC; Cheung CY,10.1117/1.NPh.6.4.041110,Chinese University of Hong Kong,"Spectral-domain optical coherence tomography (SDOCT) is a noncontact and noninvasive imaging technology offering three-dimensional (3-D), objective, and quantitative assessment of optic nerve head (ONH) in human eyes in vivo. The image quality of SDOCT scans is crucial for an accurate and reliable interpretation of ONH structure and for further detection of diseases. Traditionally, signal strength (SS) is used as an index to include or exclude SDOCT scans for further analysis. However, it is insufficient to assess other image quality issues such as off-centration, out of registration, missing data, motion artifacts, mirror artifacts, or blurriness, which require specialized knowledge in SDOCT for such assessment. We proposed a deep learning system (DLS) as an automated tool for filtering out ungradable SDOCT volumes. In total, 5599 SDOCT ONH volumes were collected for training (80%) and primary validation (20%). Other 711 and 298 volumes from two independent datasets, respectively, were used for external validation. An SDOCT volume was labeled as ungradable when SS was <5 or when any artifacts influenced the measurement circle or >25% of the peripheral area. Artifacts included (1) off-centration, (2) out of registration, (3) missing signal, (4) motion artifacts, (5) mirror artifacts, and (6) blurriness. An SDOCT volume was labeled as gradable when SS was >= 5, and there was an absence of any artifacts or artifacts only influenced <25% peripheral area but not the retinal nerve fiber layer calculation circle. We developed and validated a 3-D DLS based on squeeze-and-excitation ResNeXt blocks and experimented with different training strategies. The area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy were calculated to evaluate the performance. Heatmaps were generated by gradient-weighted class activation map. Our findings show that the presented DLS achieved a good performance in both primary and external validations, which could potentially increase the efficiency and accuracy of SDOCT volumetric scans quality control by filtering out ungradable ones automatically. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","artificial intelligence,deep learning,optical coherence tomography,image quality control",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Neurosciences & Neurology,Optics",,4.327,"SIGNAL,STRENGTH,ARTIFACTS",NEUROPHOTONICS,https://europepmc.org/articles/pmc6823275?pdf=render,
22,Multi-feature fusion CNNs for Drosophila embryo of interest detection,531,,,"Xu Qingzhen,Wang Zhoutao,Wang Fengyun,Gong Yongyi","Xu QZ,Wang ZT,Wang FY,Gong YY",Gong YY,10.1016/j.physa.2019.121808,Guangdong University of Foreign Studies,"In gene expression, high-resolution Drosophila embryonic images contain abundant temporal and spatial information. The Drosophila embryo of interest detection, with high accuracy and rapidity, is an important preprocessing step in the Drosophila embryonic gene expression computation system. In this paper, we proposed a novel multi-feature fusion (MFF) CNNs framework for the Drosophila embryo of interest detection. Considering the great variety of Drosophila embryonic images, the proposed network takes full advantages of multi-level and multi-scale convolutional features by leveraging the deeply-supervised nets and side-output layers. We built a Drosophila Embryonic Dataset, and train our framework with the Dataset. In the experiment, our method yielded satisfactory results, with advantages in terms of high accuracy (94.9% mean F-measure) and efficiency (40 FPS, i.e. Frame per Second). To the best of our knowledge, it is the first attempt to solve this problem with CNNs and achieves good results. (C) 2019 Elsevier B.V. All rights reserved.","Drosophila embryo,Multi-feature fusion,Convolutional Neural Networks,Gene expression",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Physics,,2.866,"LEVEL,SETS,CONVEXITY",PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS,,
23,An artificial neural network supported regression model for wear rate,138,,211-214,"Argatov Ivan I.,Chai Young S.","Argatov II,Chai YS",Chai YS,10.1016/j.triboint.2019.05.040,Yeungnam University,"It is suggested to use an artificial neural network as an element of a nonlinear regression model. Based on the Archard-Kragelsky model for the linear (or thickness) wear rate, which assumes its nonlinear power-law dependence on contact pressure and sliding velocity, the ANN-supported regression model has been developed. We show that the back-propagation algorithm can be adopted to train the ANN along with tuning the regression parameters. The model's applicability is illustrated on an example of rice husk ash reinforced aluminum alloy matrix composites, which is available in the literature. It is shown that the ANN-supported regression model has a superior performance compared to a standard ANN model with, at the same time, a much lower number of degrees of freedom.","Wear rate,Regression model,Artificial neural network,Metal alloy matrix composites",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.766,"TRIBOLOGICAL,PROPERTIES,PREDICTION,BEHAVIOR,COMPOSITES",TRIBOLOGY INTERNATIONAL,,
24,P300 based character recognition using sparse autoencoder with ensemble of SVMs,39,4,956-966,"Kundu Sourav,Ari Samit","Kundu S,Ari S",Kundu S,10.1016/j.bbe.2019.08.001,National Institute of Technology (NIT System),"In this study, a brain-computer interface (BCI) system known as P300 speller is used to spell the word or character without any muscle activity. For P300 signal classification, feature extraction is an important step. In this work, deep feature learning techniques based on sparse autoencoder (SAE) and stacked sparse autoencoder (SSAE) are proposed for feature extraction. Deep feature provides the abstract information about the signal. This work proposes fusion of deep features with the temporal features, which provides abstract and temporal information about the EEG signal. These deep feature and temporal feature are partially complement of each other to represent the EEG signal. For classification of the EEG signal, an ensemble of support vector machines (ESVM) is adopted as it helps to reduce the classifiers variability. In classifier ensemble system, the score of individual classifier is not at the same level. To transform these scores into a common level, min-max normalization is proposed prior to combining them. Min-max normalization scales the classifiers' score between 0 and 1. The experiments are conducted on three standard public datasets, dataset IIb of BCI Competition II, dataset II of the BCI Competition III and BNCI Horizon dataset. The experimental results show that the proposed method yields better or comparable performance compared to earlier reported techniques. (C) 2019 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences. Published by Elsevier B.V. All rights reserved.","Brain-computer interface,Deep learning,Ensemble of support vector machines,Normalization,P300,Sparse autoencoder",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,3.517,"BRAIN-COMPUTER-INTERFACE,BCI,COMPETITION,2003,COMMUNICATION,ALGORITHM,SET",BIOCYBERNETICS AND BIOMEDICAL ENGINEERING,,
25,Novel data augmentation strategies to boost supervised segmentation of plant disease,165,,,"Douarre Clement,Crispim-Junior Carlos F.,Gelibert Anthony,Tougne Laure,Rousseau David","Douarre C,Crispim-Junior CF,Gelibert A,Tougne L,Rousseau D",Douarre C,10.1016/j.compag.2019.104967,Centre National de la Recherche Scientifique (CNRS),"Annotation of images in supervised learning is notably costly and time-consuming. In order to reduce this cost, our objective was to generate images from a small dataset of annotated images, and then use those synthesized images to help the network's training process. In this article, we tackled for illustration with agricultural material the difficult segmentation task of apple scab on images of apple plant canopy by using convolutional neural networks. We devised two novel methods of generating data for this use case: one based on a plant canopy simulation and the other on Generative Adversatial Networks (GANs). As a result, we found that simulated data could provide an important increase in segmentation performance, up to a 17% increase of F1 score (a measure taking into account precision and recall), compared to segmenting with weights initialized on ImageNet. In this way, we managed to obtain, with small datasets, higher segmentation scores than the ones obtained with bigger datasets if using no such augmentations. Moreover, we left our annotated dataset of scab available for the plant science imaging community. The proposed method is of large applicability for plant diseases observed at a canopy scale.",AGRICULTURE,Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,AGRICULTURE,COMPUTERS AND ELECTRONICS IN AGRICULTURE,https://www.sciencedirect.com/science/article/am/pii/S0168169919304879,
26,"Artificial neural network based multivariable optimization of a hybrid system integrated with phase change materials, active cooling and hybrid ventilations",197,,,"Zhou Yuekuan,Zheng Siqian,Zhang Guoqiang","Zhou YK,Zheng SQ,Zhang GQ",Zhou YK,10.1016/j.enconman.2019.111859,Hong Kong Polytechnic University,"Utilising diversified forms of energy in combination with advanced energy conversions and thermal energy storages is an effective way of developing high energy-efficient renewable systems for green buildings. In this study, a novel hybrid system for the energy cascade utilisation has been proposed, integrating the hybrid ventilations, the active photovoltaic cooling, the radiative cooling and the phase change materials' storages. An enthalpy-based numerical modelling using the finite-difference method, which has been developed earlier, was used to characterize the sophisticated heat transfer process. A generic optimization methodology with competitive computational efficiency was applied by implementing the supervised machine learning and the advanced optimization algorithm. Multivariable optimizations for geometrical and operating parameters have been conducted and contrasted between the teaching-learning-based optimization and the particle swarm optimization. The results illustrate that the developed artificial neural network-based data-driven learning algorithm is more accurate and more computational-efficient than the traditional 'lsqcurvefit' fitting methodology for the characterization of the optimization function. In addition, the optimal case through the teaching-learning-based optimization is more robust than the optimal case through the particle swarm optimization in terms of the equivalent overall energy generation. This study presents a novel hybrid system for the energy cascade utilisation and a new generic optimization methodology, which are important for the promotion of green buildings with high efficiency of renewable energy utilisation.","Phase Change Materials (PCMs),Hybrid ventilations,Active photovoltaic cooling,Machine learning,Particle swarm optimization,Teaching-learning-based optimization",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels,Mechanics",,8.954,"THERMAL,PERFORMANCE,ENERGY,PV,ENHANCEMENT,EFFICIENCY,BUILDINGS,DESIGN,PCM",ENERGY CONVERSION AND MANAGEMENT,,
27,Automated classification of metamorphosed coal from geophysical log data 10 using supervised machine learning techniques,214,,,"Maxwell Kane,Rajabi Mojtaba,Esterle Joan","Maxwell K,Rajabi M,Esterle J",Maxwell K,10.1016/j.coal.2019.103284,University of Queensland,"Identification of the extent of heat altered coals is important for coal mining and resource estimation because alteration directly affects key economic properties such as ash content, volatile matter, specific energy, sulphur, free swell index and beneficiation characteristics. The most reliable method to identify altered coal is through geochemical analysis of drill core samples; however this method is time consuming and costly. Cheaper alternative methods to identify altered coal is by macroscopic observation of non-core drill cuttings, but this is less reliable than core. Geophysical wireline log data is also used to identify altered coal, but with variable success. Over the past decades, Machine Learning methods have proven popular to automatically classify a variety of lithotypes from geophysical log data. However rarely has there been focus on predicting altered coal. In this paper we apply the most recent machine learning methods which include gradient boosted machines, random forests and artificial neural networks to automatically predict altered and non-altered lithotypes using geophysical log data. We use a massive data set comprising of 1230 samples from 263 boreholes from a highly intruded deposit in the Bowen Basin, Eastern Australia. To do this, we calculate each samples distance from intrusion and predict their relative density from geophysical log inputs including gamma ray, caliper and compensated density. We then train our machine learning methods on 80% of the data to predict alteration class using the calculated distance to intrusion, predicted relative density, and geophysical log gamma ray, as primary inputs. We evaluated each of these machine learning methods on the remaining 20% of the data to determine the best performing model. Finally, using the best performing model we further split the altered and non-altered classification into lithotypes using a decision tree based on geological knowledge of the case study area. The results indicate that of the machine learning algorithms the random forest produced the best results with only 11 misclassifications across the entire data set of 1230 samples which represents < 1% error.","Altered coal,Geophysical log data,Random forest,Coal resource",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Geology",,7.173,"IGNEOUS,INTRUSIONS,BASIN,GEOCHEMISTRY,LITHOFACIES,PREDICTION,PETROLOGY,FRACTURE,FACIES,MINE",INTERNATIONAL JOURNAL OF COAL GEOLOGY,,
28,SoulNet: ultrafast optical source optimization utilizing generative neural networks for advanced lithography,18,4,,"Chen Ying,Lin Yibo,Dong Lisong,Gai Tianyang,Chen Rui,Su Yajuan,Wei Yayi,Pan David Z.","Chen Y,Lin YB,Dong LS,Gai TY,Chen R,Su YJ,Wei YY,Pan DZ",Su YJ; Wei YY,10.1117/1.JMM.18.4.043506,Chinese Academy of Sciences,"An optimized source has the ability to improve the process window during lithography in semiconductor manufacturing. Source optimization is always a key technique to improve printing performance. Conventionally, source optimization relies on mathematical-physical model calibration, which is computationally expensive and extremely time-consuming. Machine learning could learn from existing data, construct a prediction model, and speed up the whole process. We propose the first source optimization process based on autoencoder neural networks. The goal of this autoencoder-based process is to increase the speed of the source optimization process with high-quality imaging results. We also make additional technical efforts to improve the performance of our work, including data augmentation and batch normalization. Experimental results demonstrate that our autoencoder-based source optimization achieves about 10 5 x speed up with 4.67% compromise on depth of focus (DOF), when compared to conventional model-based source optimization method. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","source optimization,machine learning,autoencoder neural networks",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Engineering,Science & Technology - Other Topics,Materials Science,Optics",,,"MASK,OPTIMIZATION",JOURNAL OF MICRO-NANOLITHOGRAPHY MEMS AND MOEMS,,
29,Predictions and Strategies Learned from Machine Learning to Develop High-Performing Perovskite Solar Cells,9,46,,"Li Jinxin,Pradhan Basudev,Gaur Surya,Thomas Jayan","Li JX,Pradhan B,Gaur S,Thomas J",Thomas J,10.1002/aenm.201901891,State University System of Florida,"Perovskite solar cells (PSCs) have recently received considerable attention due to the high energy conversion efficiency achieved within a few years of their inception. However, a machine learning (ML) approach to guide the development of high-performing PSCs is still lacking. In this paper ML is used to optimize material composition, develop design strategies, and predict the performance of PSCs. The ML models are developed using 333 data points selected from about 2000 peer reviewed publications. These models guide the design of new perovskite materials and the development of high-performing solar cells. Based on ML guidance, new perovskite compositions are experimentally synthesized to test the practicability of the model. The ML model also shows its ability to predict underlying physical phenomena as well as the performance of PSCs. The PSC model matches well with the theoretical prediction by the Shockley and Queisser limit, which is almost impossible for a human to find from an ensemble of data points. Moreover, strategies for developing high-performing PSCs with different bandgaps are also derived from the model. These findings show that ML is very promising not only for predicting the performance, but also for providing a deeper understanding of the physical phenomena associated with the PSCs.","bandgap prediction,machine learning,perovskite materials,perovskite solar cells",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Energy & Fuels,Materials Science,Physics",,27.97,"HALIDE,PEROVSKITES,EFFICIENT,LEAD",ADVANCED ENERGY MATERIALS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aenm.201901891,
30,Learning from adversarial medical images for X-ray breast mass segmentation,180,,,"Shen Tianyu,Gou Chao,Wang Fei-Yue,He Zilong,Chen Weiguo","Shen TY,Gou C,Wang FY,He ZL,Chen WG",Gou C,10.1016/j.cmpb.2019.105012,Sun Yat Sen University,"Background and Objective: Simulation of diverse lesions in images is proposed and applied to overcome the scarcity of labeled data, which has hindered the application of deep learning in medical imaging. However, most of current studies focus on generating samples with class labels for classification and detection rather than segmentation, because generating images with precise masks remains a challenge. Therefore, we aim to generate realistic medical images with precise masks for improving lesion segmentation in mammagrams.
Methods: In this paper, we propose a new framework for improving X-ray breast mass segmentation performance aided by generated adversarial lesion images with precise masks. Firstly, we introduce a conditional generative adversarial network (cGAN) to learn the distribution of real mass images as well as a mapping between images and corresponding segmentation masks. Subsequently, a number of lesion images are generated from various binary input masks using the generator in the trained cGAN. Then the generated adversarial samples are concatenated with original samples to produce a dataset with increased diversity. Furthermore, we introduce an improved U-net and train it on the previous augmented dataset for breast mass segmentation.
Results: To demonstrate the effectiveness of our proposed method, we conduct experiments on publicly available mammogram database of INbreast and a private database provided by Nanfang Hospital in China. Experimental results show that an improvement up to 7% in Jaccard index can be achieved over the same model trained on original real lesion images.
Conclusions: Our proposed method can be viewed as one of the first steps toward generating realistic X-ray breast mass images with masks for precise segmentation. (C) 2019 Elsevier B.V. All rights reserved.","Medical image synthesis,Generative adversarial network,X-ray breast mass,Lesion segmentation",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"SIMULATION,INSERTION,NODULES,LESIONS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
31,Automated integrated system for stained neuron detection: An end-to-end framework with a high negative predictive rate,180,,,"Yoon Ji-Seok,Choi Eun Young,Saad Maliazurina,Choi Tae-Sun","Yoon JS,Choi EY,Saad M,Choi TS",Choi TS,10.1016/j.cmpb.2019.105028,Gwangju Institute of Science & Technology (GIST),"Background and objective: Mapping the architecture of the brain is essential for identifying the neural computations that affect behavior. Traditionally in histology, stained objects in tissue slices are hand-marked under a microscope in a manually intensive, time-consuming process. An integrated hardware and software system is needed to automate image acquisition, image processing, and object detection. Such a system would enable high throughput tissue analysis to rapidly map an entire brain.
Methods: We demonstrate an automated system to detect neurons using a monkey brain slice immunohistochemically stained for retrogradely labeled neurons. The proposed system obtains a reconstructed image of the sample, and stained neurons are detected in three steps. First, the reconstructed image is pre-processed using adaptive histogram equalization. Second, candidates for stained neurons are segmented from each region via marker-controlled watershed transformation (MCWT) using maximally stable extremal regions (MSERs). Third, the candidates are categorized as neurons or non-neurons using deep transfer learning via pre-trained convolutional neural networks (CNN).
Results: The proposed MCWT algorithm was compared qualitatively against MorphLibJ and an IHC analysis tool, while our unified classification algorithm was evaluated quantitatively using ROC analyses. The proposed classification system was first compared with five previously developed layers (AlexNet, VGG-16, VGG-19, GoogleNet, and ResNet). A comparison with conventional multi-stage frameworks followed using six off-the-shelf classifiers [Bayesian network (BN), support vector machines (SVM), decision tree (DT), bagging (BAG), AdaBoost (ADA), and logistic regression (LR)] and two descriptors (LBP and HOG). The system achieved a 0.918 F1-score with an 86.6% negative prediction value. Remarkably, other metrics such as precision, recall, and F-scores surpassed the 90% threshold compared to traditional methods.
Conclusions: We demonstrate a fully automated, integrated hardware and software system for rapidly acquiring focused images and identifying neurons from a stained brain slice. This system could be adapted for the identification of stained features of any biological tissue. (C) 2019 Elsevier B.V. All rights reserved.","Histological image analysis,Monkey brain tissue,Stained neurons,Marker-controlled-watershed transformation (MCWT),Maximally stable extremal regions (MSERs),Convolutional neural networks (CNN),Machine learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"CLASSIFICATION,NUCLEI,IMAGES,SHAPE",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
32,Mutual Information based hybrid model and deep learning for Acute Lymphocytic Leukemia detection in single cell blood smear images,179,,,"Jha Krishna Kumar,Dutta Himadri Sekhar","Jha KK,Dutta HS",Jha KK,10.1016/j.cmpb.2019.104987,"Calcutta Inst Technol, Howrah, W Bengal, India.","Background and objective: Due to the development in digital microscopic imaging, image processing and classification has become an interesting area for diagnostic research. Various techniques are available in the literature for the detection of Acute Lymphocytic Leukemia from the single cell blood smear images. The purpose of this work is to develop an effective method for leukemia detection.
Methods: This work has developed deep learning based leukemia detection module from the blood smear images. Here, the detection scheme carries out pre-processing, segmentation, feature extraction and classification. The segmentation is done by the proposed Mutual Information (MI) based hybrid model, which combines the segmentation results of the active contour model and fuzzy C means algorithm. Then, from the segmented images, the statistical and the Local Directional Pattern (LDP) features are extracted and provided to the proposed Chronological Sine Cosine Algorithm (SCA) based Deep CNN classifier for the classification.
Results: For the experimentation, the blood smear images are considered from the AA-IDB2 database and evaluated based on metrics, such as True Positive Rate (TPR), True Negative Rate (TNR), and accuracy. Simulation results reveal that the proposed Chronological SCA based Deep CNN classifier has the accuracy of 98.7%.
Conclusions: The performance of the proposed Chronological SCA-based Deep CNN classifier is compared with the state-of-the-art methods. The analysis shows that the proposed classifier has comparatively improved performance and determines the leukemia from the blood smear images. (C) 2019 Published by Elsevier B.V.","Acute Lymphocytic Leukemia,Deep learning classifier,Mutual Information,Fuzzy C means algorithm,Sine Cosine Algorithm",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"CLASSIFICATION,PREDICTION,DIAGNOSIS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
33,Spectral imaging application to discriminate different diets of live rainbow trout (Oncorhynchus mykiss),165,,,"Saberioon Mohammadmehdi,Cisar Petr,Labbe Laurent,Soucek Pavel,Pelissier Pablo","Saberioon M,Cisar P,Labbe L,Soucek P,Pelissier P",Saberioon M,10.1016/j.compag.2019.104949,University of South Bohemia Ceske Budejovice,"The main aim of this study was to evaluate the feasibility of hyperspectral imagery for determining the correlation between fish skin changes and different diets. Rainbow trout (Oncorhynchus mykiss) were fed either a commercial based diet (N = 80) or a 100% plant-based diet (N = 80). Hyperspectral images were made using a push-broom hyperspectral imaging system in the spectral region of 394-1009 nm. All images were calibrated using dark and white reference, and the average spectral data from the region of interest were extracted. Seven spectral pre-treatment methods were used, including Savitzky-Golay (SG), First Derivative (FD), Second Derivative (SD), Standard Normal Variate (SNV), Multiplicative Scatter Correction(MSC) and Continuum removal (CR) then a support vector machine (SVM) with linear kernel was applied to establish the classification models. Overall classification models developed from full wavelengths with different preprocessing methods showed good performance (Correct Classification Rate (CCR) = 0.83, Kappa = 0.66) when coupled with SG and SD or SG and MSC. The overall results indicate that the integration of Vis/NIR hyperspectral imaging system and machine learning algorithms have promise for discriminating different diets based on the live fish skin. These procedures can be used to not only identify the diet used for fish feeding in the case where we are not sure but also monitor different diets impacts on live fish skin for more precise monitoring of fish status during cultivation and ultimately for better implementation of precision fish farming.","Classification,Plant-based diet,Fish-based diet,Skin colour,Pre-processing algorithms,Support vector machine",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,"SKIN,COLOR,CLASSIFICATION,ASTAXANTHIN",COMPUTERS AND ELECTRONICS IN AGRICULTURE,,
34,Preference elicitation: Obtaining gestural guidelines for PACS in neurosurgery,130,,,"Madapana Naveen,Gonzalez Glebys,Taneja Rahul,Rodgers Richard,Zhang Lingsong,Wachs Juan","Madapana N,Gonzalez G,Taneja R,Rodgers R,Zhang LS,Wachs J",Wachs J,10.1016/j.ijmedinf.2019.07.013,Purdue University System,"Objective: Accessing medical records is an integral part of neurosurgical procedures in the Operating Room (OR). Gestural interfaces can help reduce the risks for infections by allowing the surgical staff to browse Picture Archiving and Communication Systems (PACS) without touch. The main objectives of this work are to: a) Elicit gestures from neurosurgeons to analyze their preferences, b) Develop heuristics for gestural interfaces, and c) Produce a lexicon that maximizes surgeons' preferences.
Materials and methods: A gesture elicitation study was conducted with nine neurosurgeons. Initially, subjects were asked to outline the gestures on a drawing board for each of the PACS commands. Next, the subjects performed one of three imaging tasks using gestures instead of the keyboard and mouse. Each gesture was annotated with respect to the presence/absence of gesture descriptors. Next, K-nearest neighbor approach was used to obtain the final lexicon that complies with the preferred/popular descriptors.
Results: The elicitation study resulted in nine gesture lexicons, each comprised of 28 gestures. A paired t-test between the popularity of the overall gesture and the top three descriptors showed that the latter is significantly higher than the former (89.5%-59.7% vs 19.4%, p < 0.001), meaning more than half of the subjects agreed on these descriptors. Next, the gesture heuristics were generated for each command using the popular descriptors. Lastly, we developed a lexicon that complies with surgeons' preferences.
Conclusions: Neurosurgeons do agree on fundamental characteristics of gestures to perform image manipulation tasks. The proposed heuristics could potentially guide the development of future gesture-based interaction of PACS for the OR.","PACS,Radiology,Gestures,MRI scans,Neurosurgery",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"TOUCHLESS,USER-INTERFACE",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,,
35,Automatic detection and diagnosis of sacroiliitis in CT scans as incidental findings,57,,165-175,"Shenkman Yigal,Qutteineh Bilal,Joskowicz Leo,Szeskin Adi,Yusef Azraq,Mayer Arnaldo,Eshed Iris","Shenkman Y,Qutteineh B,Joskowicz L,Szeskin A,Yusef A,Mayer A,Eshed I",Joskowicz L,10.1016/j.media.2019.07.007,Hebrew University of Jerusalem,"Early diagnosis of sacroiliitis may lead to preventive treatment which can significantly improve the patient's quality of life in the long run. Oftentimes, a CT scan of the lower back or abdomen is acquired for suspected back pain. However, since the differences between a healthy and an inflamed sacroiliac joint in the early stages are subtle, the condition may be missed. We have developed a new automatic algorithm for the diagnosis and grading of sacroiliitis CT scans as incidental findings, for patients who underwent CT scanning as part of their lower back pain workout. The method is based on supervised machine and deep learning techniques. The input is a CT scan that includes the patient's pelvis. The output is a diagnosis for each sacroiliac joint. The algorithm consists of four steps: (1) computation of an initial region of interest (ROI) that includes the pelvic joints region using heuristics and a U-Net classifier; (2) refinement of the ROI to detect both sacroiliiac joints using a four-tree random forest; (3) individual sacroiliitis grading of each sacroiliiac joint in each CT slice with a custom slice CNN classifier, and; (4) sacroiliitis diagnosis and grading by combining the individual slice grades using a random forest. Experimental results on 484 sacroiliiac joints yield a binary and a 3-class case classification accuracy of 91.9% and 86%, a sensitivity of 95% and 82%, and an Area-Under-the-Curve of 0.97 and 0.57, respectively. Automatic computer-based analysis of CT scans has the potential of being a useful method for the diagnosis and grading of sacroiliitis as an incidental finding. (C) 2019 Elsevier B.V. All rights reserved.","Sacroiliitis detection and classification,Incidental findings,Machine learning,CT scans",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"ANKYLOSING-SPONDYLITIS,CRITERIA,JOINT",MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/1908.05663,
36,Semi-supervised adversarial model for benign-malignant lung nodule classification on chest CT,57,,237-248,"Xie Yutong,Zhang Jianpeng,Xia Yong","Xie YT,Zhang JP,Xia Y",Xia Y,10.1016/j.media.2019.07.004,Northwestern Polytechnical University,"Classification of benign-malignant lung nodules on chest CT is the most critical step in the early detection of lung cancer and prolongation of patient survival. Despite their success in image classification, deep convolutional neural networks (DCNNs) always require a large number of labeled training data, which are not available for most medical image analysis applications due to the work required in image acquisition and particularly image annotation. In this paper, we propose a semi-supervised adversarial classification (SSAC) model that can be trained by using both labeled and unlabeled data for benign-malignant lung nodule classification. This model consists of an adversarial autoencoder-based unsupervised reconstruction network R, a supervised classification network C, and learnable transition layers that enable the adaption of the image representation ability learned by R to C. The SSAC model has been extended to the multi-view knowledge-based collaborative learning, aiming to employ three SSACs to characterize each nodule's overall appearance, heterogeneity in shape and texture, respectively, and to perform such characterization on nine planar views. The MK-SSAC model has been evaluated on the benchmark LIDC-IDRI dataset and achieves an accuracy of 92.53% and an AUC of 95.81%, which are superior to the performance of other lung nodule classification and semi-supervised learning approaches. (C) 2019 Elsevier B.V. All rights reserved.","Lung nodule classification,Semi-supervised learning,Adversarial learning,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CONVOLUTIONAL,NEURAL-NETWORK,COMPUTED-TOMOGRAPHY,IMAGES,FALSE-POSITIVE,REDUCTION,SEGMENTATION,TEXTURE,CANCER,INFORMATION,SHAPE",MEDICAL IMAGE ANALYSIS,,
37,Diagnostic assessment of deep learning algorithms for diabetic retinopathy screening,501,,511-522,"Li Tao,Gao Yingqi,Wang Kai,Guo Song,Liu Hanruo,Kang Hong","Li T,Gao YQ,Wang K,Guo S,Liu HR,Kang H",Kang H,10.1016/j.ins.2019.06.011,Nankai University,"Diabetic retinopathy (DR), the leading cause of blindness for working-age adults, is generally intervened by early screening to reduce vision loss. A series of automated deep-learning-based algorithms for DR screening have been proposed and achieved high sensitivity and specificity ( > 90%). However, these deep learning models do not perform well in clinical applications due to the limitations of the existing publicly available fundus image datasets. In order to evaluate these methods in clinical situations, we collected 13,673 fundus images from 9598 patients. These images were divided into six classes by seven graders according to image quality and DR level. Moreover, 757 images with DR were selected to annotate four types of DR-related lesions. Finally, we evaluated state-of-the-art deep learning algorithms on collected images, including image classification, semantic segmentation and object detection. Although we obtain an accuracy of 0.8284 for DR classification, these algorithms perform poorly on lesion segmentation and detection, indicating that lesion segmentation and detection are quite challenging. In summary, we are providing a new dataset named DDR for assessing deep learning models and further exploring the clinical applications, particularly for lesion recognition. (C) 2019 Elsevier Inc. All rights reserved.","Diabetic retinopathy,Fundus image,Deep learning,Image classification,Semantic segmentation",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Computer Science,,6.524,"MAJOR,RISK-FACTORS,GLOBAL,PREVALENCE,RETINAL,IMAGES,SEGMENTATION,VALIDATION",INFORMATION SCIENCES,,
38,Multimodal data as a means to understand the learning experience,48,,108-119,"Giannakos Michail N.,Sharma Kshitij,Pappas Ilias O.,Kostakos Vassilis,Velloso Eduardo","Giannakos MN,Sharma K,Pappas IO,Kostakos V,Velloso E",Giannakos MN,10.1016/j.ijinfomgt.2019.02.003,Norwegian University of Science & Technology (NTNU),"Most work in the design of learning technology uses click-streams as their primary data source for modelling & predicting learning behaviour. In this paper we set out to quantify what, if any, advantages do physiological sensing techniques provide for the design of learning technologies. We conducted a lab study with 251 game sessions and 17 users focusing on skill development (i.e., user's ability to master complex tasks). We collected click-stream data, as well as eye-tracking, electroencephalography (EEG), video, and wristband data during the experiment. Our analysis shows that traditional click-stream models achieve 39% error rate in predicting learning performance (and 18% when we perform feature selection), while for fused multimodal the error drops up to 6%. Our work highlights the limitations of standalone click-stream models, and quantifies the expected benefits of using a variety of multimodal data coming from physiological sensing. Our findings help shape the future of learning technology research by pointing out the substantial benefits of physiological sensing.","Human learning,Multimodal learning analytics,User-generated data,Skill acquisition,Multimodal data,Machine learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Information Science & Library Science,,13.074,"EEG,EYE,SYSTEMS,PERFORMANCE,ATTENTION,CLICKERS,INATTENTION,ENGAGEMENT,SCANPATHS,BUSINESS",INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,https://uia.brage.unit.no/uia-xmlui/bitstream/11250/2595128/4/Pappas.pdf,
39,Multilayer feature selection method for polyp classification via computed tomographic colonography,6,4,,"Cao Weiguo,Liang Zhengrong,Pomeroy Marc J.,Ng Kenneth,Zhang Shu,Gao Yongfeng,Pickhardt Perry J.,Barish Matthew A.,Abbasi Almas F.,Lu Hongbing","Cao WG,Liang ZR,Pomeroy MJ,Ng K,Zhang S,Gao YF,Pickhardt PJ,Barish MA,Abbasi AF,Lu HB",Liang ZR,10.1117/1.JMI.6.4.044503,State University of New York (SUNY) System,"Polyp classification is a feature selection and clustering process. Picking the most effective features from multiple polyp descriptors without redundant information is a great challenge in this procedure. We propose a multilayer feature selection method to construct an optimized descriptor for polyp classification with a feature-grouping strategy in a hierarchical framework. First, the proposed method makes good use of image metrics, such as intensity, gradient, and curvature, to divide their corresponding polyp descriptors into several feature groups, which are the preliminary units of this method. Then each preliminary unit generates two ranked descriptors, i.e., their optimized variable groups (OVGs) and preliminary classification measurements. Next, a feature dividing-merging (FDM) algorithm is designed to perform feature merging operation hierarchically and iteratively. Unlike traditional feature selection methods, the proposed FDM algorithm includes two steps for feature dividing and feature merging. At each layer, feature dividing selects the OVG with the highest area under the receiver operating characteristic curve (AUC) as the baseline while other descriptors are treated as its complements. In the fusion step, the FDM merges some variables with gains into the baseline from the complementary descriptors iteratively on every layer until the final descriptor is obtained. This proposed model (including the forward step algorithm and the FDM algorithm) is a greedy method that guarantees clustering monotonicity of all OVGs from the bottom to the top layer. In our experiments, all the selected results from each layer are reported by both graphical illustration and data analysis. Performance of the proposed method is compared to five existing classification methods by a polyp database of 63 samples with pathological reports. The experimental results show that our proposed method outperforms other methods by 4% to 23% gains in terms of AUC scores. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","computer-aided diagnosis,colon polyp,texture descriptor,machine learning,classification,feature selection",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"AMERICAN-CANCER-SOCIETY,SURVEILLANCE",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7144683,
40,The representative structure of graphene oxide nanoflakes from machine learning,3,4,,"Motevalli Benyamin,Parker Amanda J.,Sun Baichuan,Barnard Amanda S.","Motevalli B,Parker AJ,Sun BC,Barnard AS",Motevalli B,10.1088/2399-1984/ab58ac,Commonwealth Scientific & Industrial Research Organisation (CSIRO),"In this paper we revisit the structure of graphene oxide, and determine the pure and truly representative structures for graphene nanoflakes using machine learning. Using 20 396 random configurations relaxed at the electronic structure level, we observe the presence of hydroxyl, ether, double bonds, aliphatic (cyclohexane) disruption, defects and significant out-of-plane distortions that go beyond the Lerf-Klinowski model. Based on an diverse list of 224 chemical, structural and topological features we identify 25 archetypal 'pure' graphene oxide structures which capture all of the complexity and diversity of the entire data set; and three prototypes that are the truly representative averages in 224-dimensional space. Together these 28 structures, which are shown to be largely robust against changes in thermochemical conditions modeled using ab initio thermodynamics, can be downloaded and used collectively as a small data set for with a fraction of the computational cost in future work, or independently as an exemplar of graphene oxide with the required oxidation.","machine learning,graphene oxide,nanoparticles,archetypal analysis,clustering",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Science & Technology - Other Topics,Materials Science,Physics",,3.806,"GRAPHITE,PROTOTYPES,REDUCTION,EVOLUTION,SERIES",NANO FUTURES,https://doi.org/10.1088/2399-1984/ab58ac,
41,An investigation of CNN models for differentiating malignant from benign lesions using small pathologically proven datasets,77,,,"Zhang Shu,Han Fangfang,Liang Zhengrong,Tan Jiaxing,Cao Weiguo,Gao Yongfeng,Pomeroy Marc,Ng Kenneth,Hou Wei","Zhang S,Han FF,Liang ZR,Tan JX,Cao WG,Gao YF,Pomeroy M,Ng K,Hou W",Liang ZR,10.1016/j.compmedimag.2019.101645,State University of New York (SUNY) System,"Cancer has been one of the most threatening diseases to human health. There have been many efforts devoted to the advancement of radiology and transformative tools (e.g. non-invasive computed tomographic or CT imaging) to detect cancer in early stages. One of the major goals is to identify malignant from benign lesions. In recent years, machine deep learning (DL), e.g. convolutional neural network (CNN), has shown encouraging classification performance on medical images. However, DL algorithms always need large datasets with ground truth. Yet in the medical imaging field, especially for cancer imaging, it is difficult to collect such large volume of images with pathological information. Therefore, strategies are needed to learn effectively from small datasets via CNN models. To forward that goal, this paper explores two CNN models by focusing extensively on expansion of training samples from two small pathologically proven datasets (colorectal polyp dataset and lung nodule dataset) and then differentiating malignant from benign lesions. Experimental outcomes indicate that even in very small datasets of less than 70 subjects, malignance can be successfully differentiated from benign via the proposed CNN models, the average AUCs (area under the receiver operating curve) of differentiating colorectal polyps and pulmonary nodules are 0.86 and 0.71, respectively. Our experiments further demonstrate that for these two small datasets, instead of only studying the original raw CT images, feeding additional image features, such as the local binary pattern of the lesions, into the CNN models can significantly improve classification performance. In addition, we find that our explored voxel level CNN model has better performance when facing the small and unbalanced datasets. (C) 2019 Elsevier Ltd. All rights reserved.","Cancer imaging,Machine learning,Convolutional neural network,Polyp characterization,Nodule characterization,Pathologically proven datasets",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,4.295,"CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DIAGNOSIS,LUNG-CANCER,CT,CLASSIFICATION,PREDICTION,GRADIENT,SURVIVAL,NODULES,IMAGES",COMPUTERIZED MEDICAL IMAGING AND GRAPHICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6800808,
42,An hybrid feature space from texture information and transfer learning for glaucoma classification,64,,,"Claro Maila,Veras Rodrigo,Santana Andre,Araujo Flavio,Silva Romuere,Almeida Joao,Leite Daniel","Claro M,Veras R,Santana A,Araujo F,Silva R,Almeida J,Leite D",Claro M,10.1016/j.jvcir.2019.102597,Universidade Federal do Piaui,"Glaucoma is a progressive eye disease due to the increase in intraocular pressure. Accurate early detection may prevent vision loss. Most algorithms in the literature are not feasible for use in screening programs since they are not able to handle a wide diversity of images. We conducted an extensive study to determine the best set of features for image representation. Our feature extraction methodology included the following descriptors: LBP, GLCM, HOG, Tamura, GLRLM, morphology, and seven CNN architectures, that results in 30.682 features. Then, we used the gain ratio to order the features by importance and select the best set for glaucoma classification. Our tests were performed using 1675 images of DRISHTI, RIM-ONE, HRF, JSIEC, and ACRIMA databases. We concluded that a combination of the GLCM and pretrained CNN's has the potential to be used in a computer aid system for glaucoma detection. Our approach achieved an accuracy of 93.61%. (C) 2019 Elsevier Inc. All rights reserved.","Glaucoma detection,Feature selection,Pre-trained CNNs,Transfer learning",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Computer Science,,2.915,"CONVOLUTIONAL,NEURAL-NETWORKS,FUNDUS,IMAGES,DIAGNOSIS,AGREEMENT,CUP",JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION,,
43,Entropy-based feature extraction technique in conjunction with wavelet packet transform for multi-mental task classification,64,5,529-542,"Uyulan Caglar,Erguzel Turker Tekin,Tarhan Nevzat","Uyulan C,Erguzel TT,Tarhan N",Erguzel TT,10.1515/bmt-2018-0105,Uskudar University,"Event-related mental task information collected from electroencephalography (EEG) signals, which are functionally related to different brain areas, possesses complex and non-stationary signal features. It is essential to be able to classify mental task information through the use in brain-computer interface (BCI) applications. This paper proposes a wavelet packet transform (WPT) technique merged with a specific entropy biomarker as a feature extraction tool to classify six mental tasks. First, the data were collected from a healthy control group and the multi-signal information comprised six mental tasks which were decomposed into a number of subspaces spread over a wide frequency spectrum by projecting six different wavelet basis functions. Later, the decomposed subspaces were subjected to three entropy-type statistical measure functions to extract the feature vectors for each mental task to be fed into a backpropagation time-recurrent neural network (BPTT-RNN) model. Cross-validated classification results demonstrated that the model could classify with 85% accuracy through a discrete Meyer basis function coupled with a Renyi entropy biomarker. The classifier model was finally tested in the Simulink platform to demonstrate the Fourier series representation of periodic signals by tracking the harmonic pattern. In order to boost the model performance, ant colony optimization (ACO)-based feature selection method was employed. The overall accuracy increased to 88.98%. The results underlined that the WPT combined with an entropy uncertainty measure methodology is both effective and versatile to discriminate the features of the signal localized in a time-frequency domain.","electroencephalography,feature selection,wavelet entropy,wavelet families,wavelet packet transform",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Engineering,Medical Informatics",,1.404,"BRAIN,INTERFACE,COMPLEXITY,DIMENSION",BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK,,
44,Brain Encoding and Decoding in fMRI with Bidirectional Deep Generative Models,5,5,948-953,"Du Changde,Li Jinpeng,Huang Lijie,He Huiguang","Du CD,Li JP,Huang LJ,He HG",He HG,10.1016/j.eng.2019.03.010,Chinese Academy of Sciences,"Brain encoding and decoding via functional magnetic resonance imaging (fMRI) are two important aspects of visual perception neuroscience. Although previous researchers have made significant advances in brain encoding and decoding models, existing methods still require improvement using advanced machine learning techniques. For example, traditional methods usually build the encoding and decoding models separately, and are prone to overfitting on a small dataset. In fact, effectively unifying the encoding and decoding procedures may allow for more accurate predictions. In this paper, we first review the existing encoding and decoding methods and discuss the potential advantages of a ""bidirectional"" modeling strategy. Next, we show that there are correspondences between deep neural networks and human visual streams in terms of the architecture and computational rules. Furthermore, deep generative models (e.g., variational autoencoders (VAEs) and generative adversarial networks (GANs)) have produced promising results in studies on brain encoding and decoding. Finally, we propose that the dual learning method, which was originally designed for machine translation tasks, could help to improve the performance of encoding and decoding models by leveraging large-scale unpaired data. (C) 2019 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.","Brain encoding and decoding,Functional magnetic resonance imaging,Deep neural networks,Deep generative models,Dual learning",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,,"NEURAL-NETWORKS,NATURAL,IMAGES,RECONSTRUCTION,STATES,REPRESENTATIONS,PATTERNS,FACES",ENGINEERING,https://doi.org/10.1016/j.eng.2019.03.010,
45,Using machine learning to estimate a key missing geochemical variable in mining exploration: Application of the Random Forest algorithm to multisensor core logging data,205,,,"Schnitzler N.,Ross P-S,Gloaguen E.","Schnitzler N,Ross PS,Gloaguen E",Ross PS,10.1016/j.gexplo.2019.106344,University of Quebec,"Mining exploration increasingly relies on large, multivariate databases storing data ranging from drill core geochemical analysis to geophysical data or geological descriptions. Utilizing these large datasets to their full potential implies the use of multivariate statistical analysis such as machine learning. The Random Forest algorithm has proved its efficiency in mining applications. In this study we use it to estimate a key geochemical element, sodium, using a multivariate chemo-physical dataset measured on drill cores in the Matagami mining district of Quebec, Canada. Sodium is important to characterize hydrothermal alteration in volcanogenic massive sulfide settings, since Na depletion can be used to vector towards ore, but this element is not readily measured by portable X-ray fluorescence (pXRF). We first test the algorithm on a database of over 8000 traditional laboratory geochemistry analyses and find a correlation of 0.95 between estimated and measured Na. We then test the algorithm on the multi-sensor core logging data, including density, magnetic susceptibility, and 15 geochemical elements by pXRF, but borrowing Na from traditional geochemistry (n = 260). This yields correlations of 0.66 to 0.75 depending on the training and testing sets. Finally the algorithm is applied to the whole multiparameter database (n = 9675) to estimate Na downcore. There is a good general correspondence with the downcore Na patterns seen through traditional geochemistry, and the estimated Na which has much greater spatial resolution. Random Forest appears to be a very good estimation tool when using large amounts of data and variables, as it uses all variables and automatically prioritizes the most useful. This method also allows visualization of the weight of each variable in the estimation. Future studies should compare RF with other methods.","Artificial intelligence,Geochemistry,Supervised method,Mineral exploration",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Geochemistry & Geophysics,,4.362,"RAY-FLUORESCENCE,MEASUREMENTS,IMPROVING,LITHOLOGICAL,DISCRIMINATION,MASSIVE,SULFIDE,DEPOSIT,ABITIBI,GREENSTONE-BELT,DRILL-CORES,MINERAL,PROSPECTIVITY,COMPOSITIONAL,DATA,HOST,ROCKS,CAMP,DISTRICT",JOURNAL OF GEOCHEMICAL EXPLORATION,http://espace.inrs.ca/id/eprint/9596/1/P3589.pdf,
46,Automatic keyword retrieval from clinical texts: an application of natural language processing to massive data of Chilean suspected diagnosis,147,10,1229-1238,"Villena Fabian,Dunstan Jocelyn","Villena F,Dunstan J",Dunstan J,,"Ave Independencia 1027, Santiago, Chile.","Background: Free-text imposes a challenge in health data analysis since the lack of structure makes the extraction and integration of information difficult, particularly in the case of massive data. An appropriate machine-interpretation of electronic health records in Chile can unleash knowledge contained in large volumes of clinical texts, expanding clinical management and national research capabilities. Aim: To illustrate the use of a weighted frequency algorithm to find keywords. This finding was carried out in the diagnostic suspicion field of the Chilean specialty consultation waiting list, for diseases not covered by the Chilean Explicit Health Guarantees plan. Material and Methods: The waiting lists for a first specialty consultation for the period 2008-2018 were obtained from 17 out of 29 Chilean health services, and total of 2,592,925 diagnostic suspicions were identified. A natural language processing technique called Term Frequency- Inverse Document Frequency was used for the retrieval of diagnostic suspicion keywords. Results: For each specialty, four key words with the highest weighted frequency were determined. Word clouds showing words weighted by their importance were created to obtain a visual representation. These are available at cimt.uchile.cl/lechile/. Conclusions: The algorithm allowed to summarize unstructured clinical free-text data, improving its usefulness and accessibility.","Data Mining,Information Storage and Retrieval,Machine Learning,Medical Informatics,Natural Language Processing",Article,"SOC MEDICA SANTIAGO, BERNARDA MORIN 488 PROVIDENCIA, CASILLA 168 CORREO 55, SANTIAGO 9, 00000, CHILE",General & Internal Medicine,,,,REVISTA MEDICA DE CHILE,https://scielo.conicyt.cl/pdf/rmc/v147n10/0717-6163-rmc-147-10-1229.pdf,
47,3D segmentation of nasopharyngeal carcinoma from CT images using cascade deep learning,77,,,"Daoud Bilel,Morooka Ken'ichi,Kurazume Ryo,Leila Farhat,Mnejja Wafa,Daoud Jamel","Daoud B,Morooka K,Kurazume R,Leila F,Mnejja W,Daoud J",Daoud B,10.1016/j.compmedimag.2019.101644,Kyushu University,"In the paper, we propose a new deep learning-based method for segmenting nasopharyngeal carcinoma (NPC) in the nasopharynx from three orthogonal CT images. The proposed method introduces a cascade strategy composed of two-phase manners. In CT images, there are organs, called non-target organs, which NPC never invades. Therefore, the first phase is to detect and eliminate non-target organ regions from the CT images. In the second phase, NPC is extracted from the remained regions in the CT images. Convolutional neural networks (CNNs) are applied to detect non-target organs and NPCs. The proposed system determines the final NPC segmentation by integrating three results obtained from coronal, axial and sagittal images. Moreover, we construct two CNN-based NPC detection systems using one kind of overlapping patches with a fixed size and various overlapping patches with different sizes. From the experiments using CT images of 70 NPC patients, our proposed systems, especially the system using various patches, achieves the best performance for detecting NPC compared with conventional NPC detection methods. (C) 2019 Elsevier Ltd. All rights reserved.","Nasopharyngeal carcinoma,Convolutional neural network,Image segmentation,Multi-view,Computed tomography images",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,4.295,RADIOTHERAPY,COMPUTERIZED MEDICAL IMAGING AND GRAPHICS,,
48,Multiscale brain MRI super-resolution using deep 3D convolutional networks,77,,,"Pham Chi-Hieu,Tor-Diez Carlos,Meunier Helene,Bednarek Nathalie,Fablet Ronan,Passat Nicolas,Rousseau Francois","Pham CH,Tor-Diez C,Meunier H,Bednarek N,Fablet R,Passat N,Rousseau F",Pham CH,10.1016/j.compmedimag.2019.101647,IMT - Institut Mines-Telecom,"The purpose of super-resolution approaches is to overcome the hardware limitations and the clinical requirements of imaging procedures by reconstructing high-resolution images from low-resolution acquisitions using post-processing methods. Super-resolution techniques could have strong impacts on structural magnetic resonance imaging when focusing on cortical surface or fine-scale structure analysis for instance. In this paper, we study deep three-dimensional convolutional neural networks for the super-resolution of brain magnetic resonance imaging data. First, our work delves into the relevance of several factors in the performance of the purely convolutional neural network-based techniques for the monomodal super-resolution: optimization methods, weight initialization, network depth, residual learning, filter size in convolution layers, number of the filters, training patch size and number of training subjects. Second, our study also highlights that one single network can efficiently handle multiple arbitrary scaling factors based on a multiscale training approach. Third, we further extend our super-resolution networks to the multimodal super-resolution using intermodality priors. Fourth, we investigate the impact of transfer learning skills onto super-resolution performance in terms of generalization among different datasets. Lastly, the learnt models are used to enhance real clinical low-resolution images. Results tend to demonstrate the potential of deep neural networks with respect to practical medical image applications. (C) 2019 Elsevier Ltd. All rights reserved.","Super-resolution,3D convolutional neural network,Brain MRI",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,4.295,"DIFFUSION-WEIGHTED,IMAGES,VOLUME,RECONSTRUCTION,SPATIAL-RESOLUTION,T-1,ESTIMATION,FRAMEWORK,MOTION",COMPUTERIZED MEDICAL IMAGING AND GRAPHICS,https://hal.archives-ouvertes.fr/hal-01635455v2/document,
49,Automated A-line coronary plaque classification of intravascular optical coherence tomography images using handcrafted features and large datasets,24,10,,"Prabhu David,Bezerra Hiram,Kolluru Chaitanya,Gharaibeh Yazan,Mehanna Emile,Wu Hao,Wilson David","Prabhu D,Bezerra H,Kolluru C,Gharaibeh Y,Mehanna E,Wu H,Wilson D",Wilson D,10.1117/1.JBO.24.10.106002,Case Western Reserve University,"We developed machine learning methods to identify fibrolipidic and fibrocalcific A-lines in intravascular optical coherence tomography (IVOCT) images using a comprehensive set of handcrafted features. We incorporated features developed in previous studies (e.g., optical attenuation and A-line peaks). In addition, we included vascular lumen morphology and three-dimensional (3-D) digital edge and texture features. Classification methods were developed using expansive datasets (similar to 7000 images), consisting of both clinical in vivo images and an ex vivo dataset, which was validated using 3-D cryo-imaging/histology. Conditional random field was used to perform 3-D classification noise cleaning of classification results. We tested various multiclass approaches, classifiers, and feature selection schemes and found that a three-class support vector machine with minimal-redundancy-maximal-relevance feature selection gave the best performance. We found that inclusion of our morphological and 3-D features improved overall classification accuracy. On a held-out test set consisting of >1700 images, we obtained an overall accuracy of 81.58%, with the following (sensitivity/ specificity) for each class: other (81.43/89.59), fibrolipidic (94.48/87.32), and fibrocalcific (74.82/95.28). The en face views of classification results showed that automated classification easily captured the preponderance of a disease segment (e.g., a calcified segment had large regions of fibrocalcific classifications). Finally, we demonstrated proof-of-concept for streamlining A-line classification output with existing fibrolipidic and fibrocalcific boundary segmentation methods, to enable fully automated plaque quantification. The results suggest that our classification approach is a viable step toward fully automated IVOCT plaque classification and segmentation for live-time treatment planning and for offline assessment of drug and biologic therapeutics. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","machine learning,intravascular optical coherence tomography,cryo-imaging",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"ATHEROSCLEROTIC,PLAQUES,ARTERY-DISEASE,TISSUE,ACQUISITION,QUANTIFICATION,ANGIOGRAPHY,ULTRASOUND,STANDARDS,CONSENSUS,DOCUMENT",JOURNAL OF BIOMEDICAL OPTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6784787,
50,A method of the neural identification of the moisture content in brick walls of historic buildings on the basis of non-destructive tests,106,,,"Hola Anna,Sadowski Lukasz","Hola A,Sadowski L",Sadowski L,10.1016/j.autcon.2019.102850,Wroclaw University of Science & Technology,"The article proposes a method of neural identification of the moisture content in saline brick walls in historic buildings, which is based on non-destructive testing. The method involves the use of artificial neural networks (ANNs), which are trained, tested and experimentally verified on a set of data constructed for this purpose. The set consists of the results of tests that were obtained using non-destructive methods on a selected representative group of masonry historic buildings. Based on numerical analyses, an appropriate type and structure of ANN, as well as a learning algorithm, were selected. Positive results were obtained, indicating the possibility of using the proposed method in practice. According to the authors, a wider use of the proposed method requires verification on other historic buildings. In order for other researchers to be able to verify the presented approach, a full set of data used for training and testing the ANN was provided.","Historic buildings,Brick walls,Moisture,Non-destructive testing,Artificial neural networks",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"SALT,CRYSTALLIZATION,POROUS,MATERIALS,TOMOGRAPHY,HERITAGE",AUTOMATION IN CONSTRUCTION,,
51,Modeling and developing a smart interface for various drying methods of pomelo fruit (Citrus maxima) peel using machine learning approaches,165,,,"Kirbas Ismail,Tuncer Azim Dogus,Sirin Ceylin,Usta Huseyin","Kirbas I,Tuncer AD,Sirin C,Usta H",Kirbas I,10.1016/j.compag.2019.104928,"Burdur Mehmet Akif Ersoy Univ, Fac Engn Architecture, Dept Comp Engn, Burdur, Turkey.","Freeze-drying is a method used for valuable and heat-sensitive products, ensuring that the product features are best protected. In this study, the pomelo fruit (Citrus maxima) peel samples were dried in two different thicknesses (5 x 1 x 1 cm and 5 x 1 x 0.5 cm) by freeze drying (FD) as well as forced convection (FCD) and microwave drying. According to the experimental results, it was observed that the thin sample dried in a shorter time in all drying methods. Besides, the shortest drying time was seen in microwave drying method. The experimental results were modeled with artificial neural networks which is one of the machine learning approaches. Two different models were developed to predict drying parameters. The first model predicts mass dependent parameters (sample mass, moisture content, and moisture ratio). The second model was developed for drying time predictions. At the same time, it is intended that users can quickly and simply predict the specified parameters thanks to the smart interface developed.","Pomelo peel,Freeze drying,Machine learning,Smart interface,ANN",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,"ARTIFICIAL,NEURAL-NETWORKS,ANN,PREDICTION,BEHAVIORS,QUALITY",COMPUTERS AND ELECTRONICS IN AGRICULTURE,,
52,Ambulatory cardiac bio-signals: From mirage to clinical reality through a decade of progress,130,,,"Periyaswamy Thamizhisai,Balasubramanian Mahendran","Periyaswamy T,Balasubramanian M",Periyaswamy T,10.1016/j.ijmedinf.2019.07.007,Central Michigan University,"Background: Health monitoring is shifting towards continuous, ambulatory and clinically comparable wearable devices. Telemedicine and remote diagnosis could harness the capability of mobile cardiac health information, as the technology on bio-physical signal monitoring has improved significantly.
Objectives: The purpose of this review article is (1) to systematically assess the viability of ambulatory electrocardiography (ECG), (2) to provide a systems level understanding of a broad spectrum of wearable heart signal monitoring approaches and (3) to identify areas of improvement in the existing technology needed to attain clinical grade diagnosis.
Results: Based on the included literature, we have identified (1) that the developments in ECG monitoring through wearable devices are reaching feasibility, and are capable of delivering diagnostic and prognostic information, (2) that reliable sensing is the major bottleneck in the entire process of ambulatory monitoring, (3) that there is a strong need for artificial intelligence and machine learning techniques to parse and infer the biosignals and (4) that aspects of wearer comfort has largely been ignored in the prevailing developments, which can become a key factor for consumer acceptance.
Conclusions: Cardiac health information is crucial for diagnosis and prevention of several disease onsets. Mobile and continuous monitoring can aid avoiding risks involved with acute symptoms. The health information obtained through continuous monitoring can serve as the BigData of heart signals, and can facilitate new treatment methods and devise effective health policies.","Ambulatory electrocardiography,Wearable healthcare,Continuous monitoring,Clinical viability",Review,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"IMPLANTABLE,ELECTRONIC,DEVICES,MOTION,ARTIFACT,REDUCTION,DRY,ELECTRODES,ATRIAL-FIBRILLATION,OUTPATIENT,TELEMETRY,HEALTH-CARE,HEART-RATE,MONITORING,PATCH,EXPERT,CONSENSUS,ADHESIVE,PATCH",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,,
53,Development and Validation of a Bayesian Network Method to Detect External Beam Radiation Therapy Physician Order Errors,105,2,423-431,"Chang Xiao,Li Harold,Kalet Alan M.,Yang Deshan","Chang X,Li H,Kalet AM,Yang DS",Yang DS,10.1016/j.ijrobp.2019.05.034,Washington University (WUSTL),"Purpose: To investigate a Bayesian network (BN)-based method to detect errors in external beam radiation therapy physician orders.
Methods and Materials: A total of 4431 external beam radiation therapy orders from 2008 to 2017 at the authors' institution were obtained from clinical treatment management systems and divided into 3 groups: single prescription, concurrent boost, and sequential boost. Multiple BNs were developed for each group to detect errors in new orders using joint posterior probabilities of the order parameters, given disease information. Each BN was trained with a group of orders using a Bayesian learning algorithm. A procedure was developed to select the optimal BN for each treatment site in each group and to determine site-specific parameters and error detection thresholds. Potential clinical errors, created both manually and automatically, were applied to test error detection performance.
Results: The average true-positive rate (TPR) and false-positive rate (FPR) of error detection were 95.72% and 1.99%, respectively, for the single-prescription cohort with 9 treatment sites. For the concurrent-boost cohort, the TPR and FPR were 92.94% and 14.53%, respectively. For the sequential-boost cohort, the TPR and FPR were 100% and 9.48%, respectively, for the prescribed dose values and 100% and 4.34%, respectively, for the remaining order parameters. For the patient simulation and imaging parameters for 9 treatment sites, the TPR and FPR were 100% and 4.96%, respectively.
Conclusions: The probabilistic BN method was able to perform physician order error detection at a higher accuracy than previously reported in a variety of complex prescription instances, thus warranting further development in incorporating BNs into clinical error detection tools to assist manual physician order checks. (C) 2019 Elsevier Inc. All rights reserved.","SAFETY CONSIDERATIONS,QUALITY,ONCOLOGY,QA",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"SAFETY,CONSIDERATIONS,QUALITY,ONCOLOGY,QA",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,,
54,Learning to detect and understand drug discontinuation events from clinical narratives,26,10,943-951,"Liu Feifan,Pradhan Richeek,Druhl Emily,Freund Elaine,Liu Weisong,Sauer Brian C.,Cunningham Fran,Gordon Adam J.,Peters Celena B.,Yu Hong","Liu FF,Pradhan R,Druhl E,Freund E,Liu WS,Sauer BC,Cunningham F,Gordon AJ,Peters CB,Yu H",Yu H,10.1093/jamia/ocz048,University of Massachusetts System,"Objective: Identifying drug discontinuation (DDC) events and understanding their reasons are important for medication management and drug safety surveillance. Structured data resources are often incomplete and lack reason information. In this article, we assessed the ability of natural language processing (NLP) systems to unlock DDC information from clinical narratives automatically.
Materials and Methods: We collected 1867 de-identified providers' notes from the University of Massachusetts Medical School hospital electronic health record system. Then 2 human experts chart reviewed those clinical notes to annotate DDC events and their reasons. Using the annotated data, we developed and evaluated NLP systems to automatically identify drug discontinuations and reasons at the sentence level using a novel semantic enrichment-based vector representation (SEVR) method for enhanced feature representation.
Results: Our SEVR-based NLP system achieved the best performance of 0.785 (AUC-ROC) for detecting discontinuation events and 0.745 (AUC-ROC) for identifying reasons when testing this highly imbalanced data, outperforming 2 state-of-the-art non-SEVR-basedmodels. Compared with a rule-based baseline system for discontinuation detection, our system improved the sensitivity significantly (57.75% vs 18.31%, absolute value) while retaining a high specificity of 99.25%, leading to a significant improvement in AUC-ROC by 32.83%(absolute value).
Conclusion: Experiments have shown that a high-performance NLP system can be developed to automatically identify DDCs and their reasons from providers' notes. The SEVR model effectively improved the system performance showing better generalization and robustness on unseen test data. Our work is an important step toward identifying reasons for drug discontinuation that will inform drug safety surveillance and pharmacovigilance.","natural language processing,drug surveillance,knowledge representation,electronic health records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"MEDICATION,ADHERENCE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc6748801?pdf=render,
55,Applying machine learning to predict real-world individual treatment effects: insights from a virtual patient cohort,26,10,977-988,"Fang Gang,Annis Izabela E.,Elston-Lafata Jennifer,Cykert Samuel","Fang G,Annis IE,Elston-Lafata J,Cykert S",Fang G,10.1093/jamia/ocz036,University of North Carolina,"Objective: We aimed to investigate bias in applying machine learning to predict real-world individual treatment effects.
Materials and Methods: Using a virtual patient cohort, we simulated real-world healthcare data and applied random forest and gradient boosting classifiers to develop prediction models. Treatment effect was estimated as the difference between the predicted outcomes of a treatment and a control. We evaluated the impact of predictors (ie, treatment predictors [X-1], confounders [X-2], treatment effects modifiers [X-3], and other outcome risk factors [X-4]) with known effects on treatment and outcome using real-world data, and outcome imbalance on predicting individual outcome. Using counterfactuals, we evaluated percentage of patients with biased predicted individual treatment effects
Results: The X-4 had relatively more impact on model performance than X-2 and X-3 did. No effects were observed from X-1. Moderate-to-severe outcome imbalance had a significantly negative impact on model performance, particularly among subgroups in which an outcome occurred. Bias in predicting individual treatment effects was significant and persisted even when the models had a 100% accuracy in predicting health outcome.
Discussion: Inadequate inclusion of the X-2, X-3, and X-4 and moderate-to-severe outcome imbalance may affect model performance in predicting individual outcome and subsequently bias in predicting individual treatment effects. Machine learning models with all features and high performance for predicting individual outcome still yielded biased individual treatment effects.
Conclusions: Direct application of machine learning might not adequately address bias in predicting individual treatment effects. Further method development is needed to advance machine learning to support individualized treatment selection.","precision medicine,machine learning,comparative treatment effectiveness,real-world evidence,virtual patient cohort",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"CLINICAL-TRIALS,PROPENSITY,SCORE,MODEL,CLASSIFICATION,HETEROGENEITY,CHALLENGES,MEDICINE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647181,
56,A new approach and gold standard toward author disambiguation in MEDLINE,26,10,1037-1045,"Vishnyakova Dina,Rodriguez-Esteban Raul,Rinaldi Fabio","Vishnyakova D,Rodriguez-Esteban R,Rinaldi F",Vishnyakova D,10.1093/jamia/ocz028,Roche Holding,"Objective: Author-centric analyses of fast-growing biomedical reference databases are challenging due to author ambiguity. This problem has been mainly addressed through author disambiguation using supervised machine-learning algorithms. Such algorithms, however, require adequately designed gold standards that reflect the reference database properly. In this study we used MEDLINE to build the first unbiased gold standard in a reference database and improve over the existing state of the art in author disambiguation.
Materials and Methods: Following a new corpus design method, publication pairs randomly picked from MEDLINE were evaluated by both crowdsourcing and expert curators. Because the latter showed higher accuracy than crowdsourcing, expert curators were tasked to create a full corpus. The corpus was then used to explore new features that could improve state-of-the-art author disambiguation algorithms that would not have been discoverable with previously existing gold standards.
Results: We created a gold standard based on 1900 publication pairs that shows close similarity to MEDLINE in terms of chronological distribution and information completeness. A machine-learning algorithm that includes new features related to the ethnic origin of authors showed significant improvements over the current state of the art and demonstrates the necessity of realistic gold standards to further develop effective author disambiguation algorithms.
Discussion and Conclusion: An unbiased gold standard can give a more accurate picture of the status of author disambiguation research and help in the discovery of new features for machine learning. The principles and methods shown here can be applied to other reference databases beyond MEDLINE.","author name disambiguation,MEDLINE,text mining,gold standard,machine learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"NAME,DISAMBIGUATION",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647200,
57,Assessing the collective utility of multiple analyses on clinical alcohol use disorder data,26,10,1046-1055,"Kummerfeld Erich,Rix Alexander,Anker Justin J.,Kushner Matt G.","Kummerfeld E,Rix A,Anker JJ,Kushner MG",Kummerfeld E,10.1093/jamia/ocz034,"Inst Hlth Informat, Phillips Wangensteen Bldg,516 Delaware St SE, Minneapolis, MN 55455 USA.","Objective: The objective of this study was to assess the potential of combining graph learning methods with latent variable estimation methods for mining clinically useful information from observational clinical data sets.
Materials and Methods: The data set contained self-reported measures of psychopathology symptoms from a clinical sample receiving treatment for alcohol use disorder. We used the traditional graph learning methods: Graphical Least Absolute Shrinkage and Selection Operator, and Friedman's hill climbing algorithm; traditional latent variable estimation method factor analysis; recently developed graph learning method Greedy Fast Causal Inference; and recently developed latent variable estimation method Find One Factor Clusters. Methods were assessed qualitatively by the content of their findings.
Results: Recently developed graphical methods identified potential latent variables (ie, not represented in the model) influencing particular scores. Recently developed latent effect estimation methods identified plausible cross-score loadings that were not found with factor analysis. A graphical analysis of individual items identified a mistake in wording on 1 questionnaire and provided further evidence that certain scores are not reflective of indirectly measured common causes.
Discussion and Conclusion: Our findings suggest that a combination of Greedy Fast Causal Inference and Find One Factor Clusters can enhance the evidence-based information yield from psychopathological constructs and questionnaires. Traditional methods provided some of the same information but missed other important findings. These conclusions point the way toward more informative interrogations of existing and future data sets than are commonly employed at present.","algorithms,psychopathology,alcoholism,causality,surveys,questionnaires",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"SOCIAL,ANXIETY,DRINKING,MOTIVES,DEPRESSION,VALIDATION,INVENTORY,NETWORKS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6748805,
58,Breast pectoral muscle segmentation in mammograms using a modified holistically-nested edge detection network,57,,1-17,"Rampun Andrik,Lopez-Linares Karen,Morrow Philip J.,Scotney Bryan W.,Wang Hui,Garcia Ocana Inmaculada,Maclair Gregory,Zwiggelaar Reyer,Gonzalez Ballester Miguel A.,Macia Ivan","Rampun A,Lopez-Linares K,Morrow PJ,Scotney BW,Wang H,Ocana IG,Maclair G,Zwiggelaar R,Ballester MAG,Macia I",Rampun A,10.1016/j.media.2019.06.007,Ulster University,"This paper presents a method for automatic breast pectoral muscle segmentation in mediolateral oblique mammograms using a Convolutional Neural Network (CNN) inspired by the Holistically-nested Edge Detection (HED) network. Most of the existing methods in the literature are based on hand-crafted models such as straight-line, curve-based techniques or a combination of both. Unfortunately, such models are insufficient when dealing with complex shape variations of the pectoral muscle boundary and when the boundary is unclear due to overlapping breast tissue. To compensate for these issues, we propose a neural network framework that incorporates multi-scale and multi-level learning, capable of learning complex hierarchical features to resolve spatial ambiguity in estimating the pectoral muscle boundary. For this purpose, we modified the HED network architecture to specifically find 'contour-like' objects in mammograms. The proposed framework produced a probability map that can be used to estimate the initial pectoral muscle boundary. Subsequently, we process these maps by extracting morphological properties to find the actual pectoral muscle boundary. Finally, we developed two different post-processing steps to find the actual pectoral muscle boundary. Quantitative evaluation results show that the proposed method is comparable with alternative state-of-the-art methods producing on average values of 94.8 +/- 8.5% and 97.5 +/- 6.3% for the Jaccard and Dice similarity metrics, respectively, across four different databases. (C) 2019 Elsevier B.V. All rights reserved.","Breast mammography,Pectoral muscle segmentation,Computer aided diagnosis,Convolutional neural networks,Deep learning",Article; Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"AUTOMATIC,DETECTION,BOUNDARY,QUANTIFICATION,IDENTIFICATION,GRADIENT",MEDICAL IMAGE ANALYSIS,https://pure.ulster.ac.uk/ws/files/76985805/AuthorAccepted_Breast_Pectoral_Muscle_Segmentation_in_Mammograms_using_a_Modified_Holistically_nested_Edge_Detection_Network.pdf,
59,Unsupervised learning of probabilistic diffeomorphic registration for images and surfaces,57,,226-236,"Dalca Adrian V.,Balakrishnan Guha,Guttag John,Sabuncu Mert R.","Dalca AV,Balakrishnan G,Guttag J,Sabuncu MR",Dalca AV,10.1016/j.media.2019.07.006,Massachusetts Institute of Technology (MIT),"Classical deformable registration techniques achieve impressive results and offer a rigorous theoretical treatment, but are computationally intensive since they solve an optimization problem for each image pair. Recently, learning-based methods have facilitated fast registration by learning spatial deformation functions. However, these approaches use restricted deformation models, require supervised labels, or do not guarantee a diffeomorphic (topology-preserving) registration. Furthermore, learning-based registration tools have not been derived from a probabilistic framework that can offer uncertainty estimates.
In this paper, we build a connection between classical and learning-based methods. We present a probabilistic generative model and derive an unsupervised learning-based inference algorithm that uses insights from classical registration methods and makes use of recent developments in convolutional neural networks (CNNs). We demonstrate our method on a 3D brain registration task for both images and anatomical surfaces, and provide extensive empirical analyses of the algorithm. Our principled approach results in state of the art accuracy and very fast runtimes, while providing diffeomorphic guarantees. Our implementation is available online at http://voxelmorph.csail.mit.edu. (C) 2019 Elsevier B.V. All rights reserved.","Medical image registration,Diffeomorphic registration,Invertible registration,Probabilistic modeling,Convolutional neural networks,Variational inference,Machine learning",Article; Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,UNCERTAINTY,MEDICAL IMAGE ANALYSIS,https://dspace.mit.edu/bitstream/1721.1/129526/2/1903.03545.pdf,
60,Online optimizing hot forming parameters for alloy parts based on action-dependent heuristic dynamic programming,104,9-12,3745-3757,"Chen Dong-Dong,Lin Y. C.","Chen DD,Lin YC",Lin YC,10.1007/s00170-019-04117-y,Central South University,"The microstructural evolution is complex and time-varying in the practice hot forming process of alloy parts. Therefore, accurately online optimizing forming parameters and controlling microstructural evolution are the urgent tasks. In this work, an action-dependent heuristic dynamic programming (ADHDP) is developed to online optimize processing parameters during hot deformation of alloys. The ADHDP is based on adaptive dynamic programming and only contains action/critic neural networks (ANN/CNN). ANN is utilized to determine the next control signals (processing parameters) of hot deformation, while CNN is used to obtain the approximation of cost-to-go function. The weights of these neural networks are online-updated by back-propagation algorithm. The control goals include the recrystallization volume fraction and average grain size. The proposed ADHDP method is successfully applied to online optimize processing parameters of GH4169 superalloy during hot deformation, and its effectiveness is verified by numerical simulations. According to the optimized processing parameters, the hot compressive tests of GH4169 superalloy are conducted to further verify the validity of the developed method. Furthermore, the microstructures, which are obtained by the proposed method, are more uniform and fine than those obtained by the traditional processing without online optimization.","Alloy,Hot deformation,Action-dependent heuristic dynamic programming,Online optimization,Processing parameter",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"NICKEL-BASED,SUPERALLOY,NI-BASED,SUPERALLOY,DEFORMATION-BEHAVIOR,PROCESSING,MAP,NEURAL-NETWORK,RECRYSTALLIZATION,BEHAVIORS,PHASE-TRANSFORMATION,CONSTITUTIVE,MODELS,TITANIUM-ALLOY,OPTIMIZATION",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,
61,Machine-learning-assisted thin-film growth: Bayesian optimization in molecular beam epitaxy of SrRuO3 thin films,7,10,,"Wakabayashi Yuki K.,Otsuka Takuma,Krockenberger Yoshiharu,Sawada Hiroshi,Taniyasu Yoshitaka,Yamamoto Hideki","Wakabayashi YK,Otsuka T,Krockenberger Y,Sawada H,Taniyasu Y,Yamamoto H",Wakabayashi YK,10.1063/1.5123019,Nippon Telegraph & Telephone Corporation,"Materials informatics exploiting machine learning techniques, e.g., Bayesian optimization (BO), have the potential to reduce the number of thin-film growth runs for optimization of thin-film growth conditions through incremental updates of machine learning models in accordance with newly measured data. Here, we demonstrated BO-based molecular beam epitaxy (MBE) of SrRuO3, one of the most intensively studied materials in the research field of oxide electronics, mainly owing to its unique nature as a ferromagnetic metal. To simplify the intricate search space of entangled growth conditions, we ran the BO for a single condition while keeping the other conditions fixed. As a result, high-crystalline-quality SrRuO3 film exhibiting a high residual resistivity ratio of over 50 as well as strong perpendicular magnetic anisotropy was developed in only 24 MBE growth runs in which the Ru flux rate, growth temperature, and O-3-nozzle-to-substrate distance were optimized. Our BO-based search method provides an efficient experimental design that is not as dependent on the experience and skills of individual researchers, and it reduces experimental time and cost, which will accelerate materials research. (C) 2019 Author(s).","MAGNETIC-PROPERTIES,ANISOTROPY,OXIDES",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,4.841,"MAGNETIC-PROPERTIES,ANISOTROPY,OXIDES",APL MATERIALS,https://aip.scitation.org/doi/pdf/10.1063/1.5123019,
62,Detection of early reflections from a binaural activity map using neural networks,146,4,2529-2539,"Deshpande Nikhil,Braasch Jonas","Deshpande N,Braasch J",Deshpande N,10.1121/1.5129129,Rensselaer Polytechnic Institute,"Human listeners localize sounds to their sources despite competing directional cues from early room reflections. Binaural activity maps computed from a running signal can provide useful information about the presence of room reflections, but must be inspected visually to estimate auditory cues. A model was constructed using machine learning to validate the presence of and perform the extraction of these cues. The model uses the running signal output of a binaurally integrated cross-correlation/autocorrelation mechanism (BICAM) to analyze a lead/lag stimulus and generate a binaural activity map. System reflections are visually presented on the binaural display as correlation peaks with increased amplitude. Three independent neural networks estimate the location of the direct sound, the time delay of the reflection, and the location of the reflection from binaural activity maps displayed by BICAM. Depending on the task, neural network accuracies on test data sets vary from 84.1% to 98.5%. (C) 2019 Acoustical Society of America.","LOCALIZATION,INHIBITION,MODELS",Article,"ACOUSTICAL SOC AMER AMER INST PHYSICS, STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA","Acoustics,Audiology & Speech-Language Pathology",,2.001,"LOCALIZATION,INHIBITION,MODELS",JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA,,
63,Elucidation of Differential Nano-Textural Attributes for Normal Oral Mucosa and Pre-Cancer,25,5,1224-1233,"Nawn Debaleena,Chatterjee Saunak,Anura Anji,Bag Swarnendu,Chakraborty Debjani,Pal Mousumi,Paul Ranjan Rashmi,Chatterjee Jyotirmoy","Nawn D,Chatterjee S,Anura A,Bag S,Chakraborty D,Pal M,Paul RR,Chatterjee J",Nawn D,10.1017/S1431927619014867,Indian Institute of Technology System (IIT System),"Computational analysis on altered micro-nano-textural attributes of the oral mucosa may provide precise diagnostic information about oral potentially malignant disorders (OPMDs) instead of an existing handful of qualitative reports. This study evaluated micro-nano-textural features of oral epithelium from scanning electron microscopic (SEM) images and the sub-epithelial connective tissue from light microscopic (LM) and atomic force microscopic (AFM) images for normal and OPMD (namely oral sub-mucous fibrosis, i.e., OSF). Objective textural descriptors, namely discrete wavelet transform, gray-level co-occurrence matrix (GLCM), and local binary pattern (LBP), were extracted and fed to standard classifiers. Best classification accuracy of 87.28 and 93.21%; sensitivity of 93 and 96%; specificity of 80 and 91% were achieved, respectively, for SEM and AFM. In the study groups, SEM analysis showed a significant (p < 0.01) variation for all the considered textural descriptors, while for AFM, a remarkable alteration (p < 0.01) was only found in GLCM and LBP. Interestingly, sub-epithelial collagen nanoscale and microscale textural information from AFM and LM images, respectively, were complementary, namely microlevel contrast was more in normal (0.251) than OSF (0.193), while nanolevel contrast was more in OSF (0.283) than normal (0.204). This work, thus, illustrated differential micro-nano-textural attributes for oral epithelium and sub-epithelium to distinguish OPMD precisely and may be contributory in early cancer diagnostics.","atomic force microscopy,classification accuracy,micro-nano-textural attributes,oral sub-mucous fibrosis,scanning electron microscopy",Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA","Materials Science,Microscopy",,3.162,"SUBMUCOUS,FIBROSIS,NANOMECHANICAL,SIGNATURE,CLASSIFICATION,PROGRESSION,PREDICTION,IMAGES,CELLS,SCALE",MICROSCOPY AND MICROANALYSIS,,
64,Coronary calcification segmentation in intravascular OCT images using deep learning: application to calcification scoring,6,4,,"Gharaibeh Yazan,Prabhu David,Kolluru Chaitanya,Lee Juhwan,Zimin Vladislav,Bezerra Hiram,Wilson David","Gharaibeh Y,Prabhu D,Kolluru C,Lee J,Zimin V,Bezerra H,Wilson D",Wilson D,10.1117/1.JMI.6.4.045002,Case Western Reserve University,"Major calcifications are of great concern when performing percutaneous coronary interventions because they inhibit proper stent deployment. We created a comprehensive software to segment calcifications in intravascular optical coherence tomography (IVOCT) images and to calculate their impact using the stent-deployment calcification score, as reported by Fujino et al. We segmented the vascular lumen and calcifications using the pretrained SegNet, convolutional neural network, which was refined for our task. We cleaned segmentation results using conditional random field processing. We evaluated the method on manually annotated IVOCT volumes of interest (VOIs) without lesions and with calcifications, lipidous, or mixed lesions. The dataset included 48 VOIs taken from 34 clinical pullbacks, giving a total of 2640 in vivo images. Annotations were determined from consensus between two expert analysts. Keeping VOIs intact, we performed 10-fold cross-validation over all data. Following segmentation noise cleaning, we obtained sensitivities of 0.85 +/- 0.04, 0.99 +/- 0.01, and 0.97 +/- 0.01 for calcified, lumen, and other tissue classes, respectively. From segmented regions, we automatically determined calcification depth, angle, and thickness attributes. Bland-Altman analysis suggested strong correlation between manually and automatically obtained lumen and calcification attributes. Agreement between manually and automatically obtained stent-deployment calcification scores was good (four of five lesions gave exact agreement). Results are encouraging and suggest our classification approach could be applied clinically for assessment and treatment planning of coronary calcification lesions. (c) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.","intravascular optical coherence tomography,deep learning,semantic segmentation,image-guided procedure,transfer learning,calcifications",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"OPTICAL,COHERENCE,TOMOGRAPHY,ELUTING,STENT,IMPLANTATION,AUTOMATIC,CLASSIFICATION,ATHEROSCLEROTIC,PLAQUES,ARTERY-DISEASE,TAXUS-IV,ULTRASOUND,LESION,IMPACT,TISSUE",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6934132,
65,Automatic quantification of HER2 gene amplification in invasive breast cancer from chromogenic in situ hybridization whole slide images,6,4,,"Hossain Md Shakhawat,Hanna Matthew G.,Uraoka Naohiro,Nakamura Tomoya,Edelweiss Marcia,Brogi Edi,Hameed Meera R.,Yamaguchi Masahiro,Ross Dara S.,Yagi Yukako","Hossain MS,Hanna MG,Uraoka N,Nakamura T,Edelweiss M,Brogi E,Hameed MR,Yamaguchi M,Ross DS,Yagi Y",Hossain MS,10.1117/1.JMI.6.4.047501,Tokyo Institute of Technology,"Human epidermal growth factor receptor 2 (HER2), a transmembrane tyrosine kinase receptor encoded by the ERBB2 gene on chromosome 17q12, is a predictive and prognostic biomarker in invasive breast cancer (BC). Approximately 20% of BC are HER2-positive as a result of ERBB2 gene amplification and overexpression of the HER2 protein. Quantification of HER2 is performed routinely on all invasive BCs, to assist in clinical decision making for prognosis and treatment for HER2-positive BC patients by manually counting gene signals. We propose an automated system to quantify the HER2 gene status from chromogenic in situ hybridization (CISH) whole slide images (WSI) in invasive BC. The proposed method selects untruncated and nonoverlapped singular nuclei from the cancer regions using color unmixing and machine learning techniques. Then, HER2 and chromosome enumeration probe 17 (CEP17) signals are detected based on the RGB intensity and counted per nucleus. Finally, the HER2-to-CEP17 signal ratio is calculated to determine the HER2 amplification status following the ASCO/CAP 2018 guidelines. The proposed method reduced the labor and time for the quantification. In the experiment, the correlation coefficient between the proposed automatic CISH quantification method and pathologist manual enumeration was 0.98. The p-values larger than 0.05 from the one-sided paired t-test ensured that the proposed method yields statistically indifferent results to the reference method. The method was established on WSI scanned by two different scanners. Through the experiments, the capability of the proposed system has been demonstrated. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","automatic CISH quantification,HER2-positive breast cancer,HER2 gene amplification,digital pathology,whole slide imaging",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,FISH,JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6868351,
66,Stochastic tissue window normalization of deep learning on computed tomography,6,4,,"Huo Yuankai,Tang Yucheng,Chen Yunqiang,Gao Dashan,Han Shizhong,Bao Shunxing,De Smita,Terry James G.,Carr Jeffrey J.,Abramson Richard G.","Huo YK,Tang YC,Chen YQ,Gao DS,Han SZ,Bao SX,De S,Terry JG,Carr JJ,Abramson RG",Huo YK,10.1117/1.JMI.6.4.044005,Vanderbilt University,"Tissue window filtering has been widely used in deep learning for computed tomography (CT) image analyses to improve training performance (e.g., soft tissue windows for abdominal CT). However, the effectiveness of tissue window normalization is questionable since the generalizability of the trained model might be further harmed, especially when such models are applied to new cohorts with different CT reconstruction kernels, contrast mechanisms, dynamic variations in the acquisition, and physiological changes. We evaluate the effectiveness of both with and without using soft tissue window normalization on multisite CT cohorts. Moreover, we propose a stochastic tissue window normalization (SWN) method to improve the generalizability of tissue window normalization. Different from the random sampling, the SWN method centers the randomization around the soft tissue window to maintain the specificity for abdominal organs. To evaluate the performance of different strategies, 80 training and 453 validation and testing scans from six datasets are employed to perform multiorgan segmentation using standard 2D U-Net. The six datasets cover the scenarios, where the training and testing scans are from (1) same scanner and same population, (2) same CT contrast but different pathology, and (3) different CT contrast and pathology. The traditional soft tissue window and nonwindowed approaches achieved better performance on (1). The proposed SWN achieved general superior performance on (2) and (3) with statistical analyses, which offers better generalizability for a trained model. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","tissue window,computed tomography,deep learning,segmentation",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SETTINGS,LIVER",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6863984,
67,Learning-based deformable image registration: effect of statistical mismatch between train and test images,6,4,,"Ketcha Michael D.,De Silva Tharindu,Han Runze,Uneri Ali,Vogt Sebastian,Kleinszig Gerhard,Siewerdsen Jeffrey H.","Ketcha MD,De Silva T,Han RZ,Uneri A,Vogt S,Kleinszig G,Siewerdsen JH",Siewerdsen JH,10.1117/1.JMI.6.4.044008,Johns Hopkins University,"Convolutional neural networks (CNNs) offer a promising means to achieve fast deformable image registration with accuracy comparable to conventional, physics-based methods. A persistent question with CNN methods, however, is whether they will be able to generalize to data outside of the training set. We investigated this question of mismatch between train and test data with respect to first- and second-order image statistics (e.g., spatial resolution, image noise, and power spectrum). A UNet-based architecture was built and trained on simulated CT images for various conditions of image noise (dose), spatial resolution, and deformation magnitude. Target registration error was measured as a function of the difference in statistical properties between the test and training data. Generally, registration error is minimized when the training data exactly match the statistics of the test data; however, networks trained with data exhibiting a diversity in statistical characteristics generalized well across the range of statistical conditions considered. Furthermore, networks trained on simulated image content with first- and second-order statistics selected to match that of real anatomical data were shown to provide reasonable registration performance on real anatomical content, offering potential new means for data augmentation. Characterizing the behavior of a CNN in the presence of statistical mismatch is an important step in understanding how these networks behave when deployed on new, unobserved data. Such characterization can inform decisions on whether retraining is necessary and can guide the data collection and/or augmentation process for training. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","deformable image registration,convolutional neural networks,image quality",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6916745,
68,Tissue classification in intercostal and paravertebral ultrasound using spectral analysis of radiofrequency backscatter,6,4,,"Klingensmith Jon D.,Haggard Asher L.,Ralston Jack T.,Qiang Beidi,Fedewa Russell J.,Elsharkawy Hesham,Vince David Geoffrey","Klingensmith JD,Haggard AL,Ralston JT,Qiang BD,Fedewa RJ,Elsharkawy H,Vince DG",Klingensmith JD,10.1117/1.JMI.6.4.047001,Southern Illinois University System,"Paravertebral and intercostal nerve blocks have experienced a resurgence in popularity. Ultrasound has become the gold standard for visualization of the needle during injection of the analgesic, but the intercostal artery and vein can be difficult to visualize. We investigated the use of spectral analysis of raw radiofrequency (RF) ultrasound signals for identification of the intercostal vessels and six other tissue types in the intercostal and paravertebral spaces. Features derived from the one-dimensional spectrum, two-dimensional spectrum, and cepstrum were used to train four different machine learning algorithms. In addition, the use of the average normalized spectrum as the feature set was compared with the derived feature set. Compared to a support vector machine (SVM) (74.2%), an artificial neural network (ANN) (68.2%), and multinomial analysis (64.1%), a random forest (84.9%) resulted in the most accurate classification. The accuracy using a random forest trained with the first 15 principal components of the average normalized spectrum was 87.0%. These results demonstrate that using a machine learning algorithm with spectral analysis of raw RF ultrasound signals has the potential to provide tissue characterization in intercostal and paravertebral ultrasound. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","intercostal artery,intercostal vein,intercostal nerve,radiofrequency signals,tissue characterization,ultrasound",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"GUIDED,INTERVENTIONAL,PROCEDURES,GENERAL-ANESTHESIA,PAIN,MEDICINE,BLOCK,SONOANATOMY,DIAGNOSIS,FEATURES,ANATOMY",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6835052,
69,Detecting mammographically occult cancer in women with dense breasts using deep convolutional neural network and Radon Cumulative Distribution Transform,6,4,,"Lee Juhun,Nishikawa Robert M.","Lee J,Nishikawa RM",Lee J,10.1117/1.JMI.6.4.044502,Pennsylvania Commonwealth System of Higher Education (PCSHE),"We have applied the Radon Cumulative Distribution Transform (RCDT) as an image transformation to highlight the subtle difference between left and right mammograms to detect mammographically occult (MO) cancer in women with dense breasts and negative screening mammograms. We developed deep convolutional neural networks (CNNs) as classifiers for estimating the probability of having MO cancer. We acquired screening mammograms of 333 women (97 unilateral MO cancer) with dense breasts and at least two consecutive mammograms and used the immediate prior mammograms, which radiologists interpreted as negative. We used fivefold cross validation to divide our dataset into a training and independent test sets with ratios of 0.8:0.2. We set aside 10% of the training set as a validation set. We applied RCDT on the left and right mammograms of each view. We applied inverse Radon transform to represent the resulting RCDT images in the image domain. We then fine-tuned a VGG16 network pretrained on ImageNet using the resulting images per each view. The CNNs achieved mean areas under the receiver operating characteristic (AUC) curve of 0.73 (standard error, SE = 0.024) and 0.73 (SE = 0.04) for the craniocaudal and mediolateral oblique views, respectively. We combined the scores from two CNNs by training a logistic regression classifier and it achieved a mean AUC of 0.81 (SE = 0.032). In conclusion, we showed that inverse Radon-transformed RCDT images contain information useful for detecting MO cancers and that deep CNNs could learn such information. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","occult breast cancer,dense breast,Radon Cumulative Distribution Transform,computer-aided diagnosis,deep learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6929683,
70,Classification of brain tumor isocitrate dehydrogenase status using MRI and deep learning,6,4,,"Nalawade Sahil,Murugesan Gowtham K.,Vejdani-Jahromi Maryam,Fisicaro Ryan A.,Yogananda Chandan G. Bangalore,Wagner Ben,Mickey Bruce,Maher Elizabeth,Pinho Marco C.,Fei Baowei","Nalawade S,Murugesan GK,Vejdani-Jahromi M,Fisicaro RA,Yogananda CGB,Wagner B,Mickey B,Maher E,Pinho MC,Fei BW",Maldjian JA,10.1117/1.JMI.6.4.046003,University of Texas System,"Isocitrate dehydrogenase (IDH) mutation status is an important marker in glioma diagnosis and therapy. We propose an automated pipeline for noninvasively predicting IDH status using deep learning and T2-weighted (T2w) magnetic resonance (MR) images with minimal preprocessing (N4 bias correction and normalization to zero mean and unit variance). T2w MR images and genomic data were obtained from The Cancer Imaging Archive dataset for 260 subjects (120 high-grade and 140 low-grade gliomas). A fully automated two-dimensional densely connected model was trained to classify IDH mutation status on 208 subjects and tested on another held-out set of 52 subjects using fivefold cross validation. Data leakage was avoided by ensuring subject separation during the slice-wise randomization. Mean classification accuracy of 90.5% was achieved for each axial slice in predicting the three classes of no tumor, IDH mutated, and IDH wild type. Test accuracy of 83.8% was achieved in predicting IDH mutation status for individual subjects on the test dataset of 52 subjects. We demonstrate a deep learning method to predict IDH mutation status using T2w MRI alone. Radiologic imaging studies using deep learning methods must address data leakage (subject duplication) in the randomization process to avoid upward bias in the reported classification accuracy. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","isocitrate dehydrogenase,magnetic resonance imaging,convolutional neural network,deep learning,tumor classification,segmentation",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"MAGNETIC-RESONANCE-SPECTROSCOPY,GRADE,GLIOMAS,IDH,2-HYDROXYGLUTARATE,MUTATIONS,1P%2F19Q",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6903425,
71,Using deep learning for a diffusion-based segmentation of the dentate nucleus and its benefits over atlas-based methods,6,4,,"Noguera Camilo Bermudez,Bao Shunxing,Petersen Kalen J.,Lopez Alexander M.,Reid Jacqueline,Plassard Andrew J.,Zald David H.,Claassen Daniel O.,Dawant Benoit M.,Landman Bennett A.","Noguera CB,Bao SX,Petersen KJ,Lopez AM,Reid J,Plassard AJ,Zald DH,Claassen DO,Dawant BM,Landman BA",Noguera CB,10.1117/1.JMI.6.4.044007,Vanderbilt University,"The dentate nucleus (DN) is a gray matter structure deep in the cerebellum involved in motor coordination, sensory input integration, executive planning, language, and visuospatial function. The DN is an emerging biomarker of disease, informing studies that advance pathophysiologic understanding of neurodegenerative and related disorders. The main challenge in defining the DN radiologically is that, like many deep gray matter structures, it has poor contrast in T1-weighted magnetic resonance (MR) images and therefore requires specialized MR acquisitions for visualization. Manual tracing of the DN across multiple acquisitions is resource-intensive and does not scale well to large datasets. We describe a technique that automatically segments the DN using deep learning (DL) on common imaging sequences, such as T1-weighted, T2-weighted, and diffusion MR imaging. We trained a DL algorithm that can automatically delineate the DN and provide an estimate of its volume. The automatic segmentation achieved higher agreement to themanual labels compared to template registration, which is the current common practice in DN segmentation or multiatlas segmentation of manual labels. Across all sequences, the FA maps achieved the highest mean Dice similarity coefficient (DSC) of 0.83 compared to T1 imaging (DSC = 0.76), T2 imaging (DSC = 0.79), or a multisequence approach (DSC = 0.80). A single atlas registration approach using the spatially unbiased atlas template of the cerebellum and brainstem template achieved a DSC of 0.23, and multi-atlas segmentation achieved a DSC of 0.33. Overall, we propose a method of delineating the DN on clinical imaging that can reproduce manual labels with higher accuracy than current atlas-based tools. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","dentate nucleus,multisequence Imaging,automatic image segmentation,magnetic resonance imaging,deep learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"ESSENTIAL,TREMOR,TISSUE,CLASSIFICATION,CEREBELLAR,NUCLEI,BRAIN-STIMULATION,TRACTOGRAPHY,TRACT,ATAXIA,ADULT",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6895566,
72,Active learning strategy and hybrid training for infarct segmentation on diffusion MRI with a U-shaped network,6,4,,"Olivier Aurelien,Moal Olivier,Moal Bertrand,Munsch Fanny,Okubo Gosuke,Sibon Igor,Dousset Vincent,Tourdias Thomas","Olivier A,Moal O,Moal B,Munsch F,Okubo G,Sibon I,Dousset V,Tourdias T",Moal O,10.1117/1.JMI.6.4.044001,"DESKi, Bordeaux, France.","Automatic and reliable stroke lesion segmentation from diffusion magnetic resonance imaging (MRI) is critical for patient care. Methods using neural networks have been developed, but the rate of false positives limits their use in clinical practice. A training strategy applied to three-dimensional deconvolutional neural networks for stroke lesion segmentation on diffusion MRI was proposed. Infarcts were segmented by experts on diffusion MRI for 929 patients. We divided each database as follows: 60% for a training set, 20% for validation, and 20% for testing. Our hypothesis was a two-phase hybrid learning scheme, in which the network was first trained with whole MRI (regular phase) and then, in a second phase (hybrid phase), alternately with whole MRI and patches. Patches were actively selected from the discrepancy between expert and model segmentation at the beginning of each batch. On the test population, the performances after the regular and hybrid phases were compared. A statistically significant Dice improvement with hybrid training compared with regular training was demonstrated (p < 0.01). The mean Dice reached 0.711 +/- 0.199. False positives were reduced by almost 30% with hybrid training (p < 0.01). Our hybrid training strategy empowered deep neural networks for more accurate infarct segmentations on diffusion MRI. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","ischemic stroke lesion segmentation,deep learning,diffusion-weighted imaging,fully convolutional networks,patches,active learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"STROKE,LESION,SEGMENTATION,ISCHEMIC-STROKE,THROMBECTOMY",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6777650,
73,Heuristic neural network approach in histological sections detection of hydatidiform mole,6,4,,"Palee Patison,Sharp Bernadette,Noriega Leonard,Sebire Neil,Platt Craig","Palee P,Sharp B,Noriega L,Sebire N,Platt C",Noriega L,10.1117/1.JMI.6.4.044501,"Hsch Furtwangen Univ, Fak Wirtschaftinformat, Furtwangen, Germany.","A heuristic-based, multineural network (MNN) image analysis as a solution to the problematical diagnosis of hydatidiform mole (HM) is presented. HM presents as tumors in placental cell structures, many of which exhibit premalignant phenotypes (choriocarcinoma and other conditions). HM is commonly found in women under age 17 or over 35 and can be partial HM or complete HM. Appropriate treatment is determined by correct categorization into PHM or CHM, a difficult task even for expert pathologists. Image analysis combined with pattern recognition techniques has been applied to the problem, based on 15 or 17 image features. The use of limited data for training and validation set was optimized using a k-fold validation technique allowing performance measurement of different MNN configurations. The MNN technique performed better than human experts at the categorization for both the 15- and 17-feature data, promising greater diagnostic consistency, and further improvements with the availability of larger datasets. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","multineural network,image analysis,hydatidiform mole,molar pregnancy,diagnosis",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"BREAST-CANCER,DETECTION,CLASSIFICATION,DIAGNOSIS,IMAGES,MACHINE,FEATURES",JOURNAL OF MEDICAL IMAGING,https://discovery.ucl.ac.uk/10086317/1/044501_1.pdf,
74,Deep learning-based image quality improvement for low-dose computed tomography simulation in radiation therapy,6,4,,"Wang Tonghe,Lei Yang,Tian Zhen,Dong Xue,Liu Yingzi,Jiang Xiaojun,Curran Walter J.,Liu Tian,Shu Hui-Kuo,Yang Xiaofeng","Wang TH,Lei Y,Tian Z,Dong X,Liu YZ,Jiang XJ,Curran WJ,Liu T,Shu HK,Yang XF",Yang XF,10.1117/1.JMI.6.4.043504,Emory University,"Low-dose computed tomography (CT) is desirable for treatment planning and simulation in radiation therapy. Multiple rescanning and replanning during the treatment course with a smaller amount of dose than a single conventional full-dose CT simulation is a crucial step in adaptive radiation therapy. We developed a machine learning-based method to improve image quality of low-dose CT for radiation therapy treatment simulation. We used a residual block concept and a self-attention strategy with a cycle-consistent adversarial network framework. A fully convolution neural network with residual blocks and attention gates (AGs) was used in the generator to enable end-to-end transformation. We have collected CT images from 30 patients treated with frameless brain stereotactic radiosurgery (SRS) for this study. These full-dose images were used to generate projection data, which were then added with noise to simulate the low-mAs scanning scenario. Low-dose CT images were reconstructed from this noise-contaminated projection data and were fed into our network along with the original full-dose CT images for training. The performance of our network was evaluated by quantitatively comparing the high-quality CT images generated by our method with the original full-dose images. When mAs is reduced to 0.5% of the original CT scan, the mean square error of the CT images obtained by our method is similar to 1.6%, with respect to the original full-dose images. The proposed method successfully improved the noise, contract-to-noise ratio, and nonuniformity level to be close to those of full-dose CT images and outperforms a state-of-the-art iterative reconstruction method. Dosimetric studies show that the average differences of dose-volume histogram metrics are <0.1 Gy (p > 0.05). These quantitative results strongly indicate that the denoised low-dose CT images using our method maintains image accuracy and quality and are accurate enough for dose calculation in current CT simulation of brain SRS treatment. We also demonstrate the great potential for low-dose CT in the process of simulation and treatment planning. (c) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","computed tomography,low dose,machine learning,radiation therapy",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"CT,RECONSTRUCTION,ITERATIVE,RECONSTRUCTION,OPTIMIZATION,FEATURES,CANCER",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6811730,
75,Flexible algebraic technique for multiview reconstruction: incremental learning in reflective tomography,58,10,,Bellet Jean-Baptiste,Bellet JB,Bellet JB,10.1117/1.OE.58.10.103102,Centre National de la Recherche Scientifique (CNRS),"Reflective tomography reconstructs a scene from calibrated reflective images, using algorithms from x-ray tomography. Many works on the subject are based on analytical formulas, such as the filtered backprojection. However, these formulas require constraints on the acquisition geometry, such as a circular rotation. We want to avoid such constraints; they may be seriously violated in some practical cases. To tackle this problem, we tune the algebraic reconstruction technique from x-ray tomography. More precisely, we look for a model of the scene such that the x-ray projections of the model approximate recorded calibrated reflective images. The model is computed by an iterative algebraic method: a Kaczmarz algorithm. In this way, we perform incremental supervised learning in optics, where the hypothesis space emulates reflective tomography. We get a flexible method for multiple-view reconstruction based on linear algebra. It accepts a general calibrated acquisition, such as several cameras arbitrarily located/oriented, with visible near-infrared wavelengths. It could reconstruct a scene using several devices simultaneously, such as air-ground cameras combined with ground-ground cameras. The relevance of the approach is numerically shown from calibrated CCD images of the Middlebury datasets. In particular, we get reconstructions from 16 views. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","three-dimensional imaging,optical computational imaging,reflective tomography,algebraic reconstruction technique",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA",Optics,,1.098,,OPTICAL ENGINEERING,https://hal.archives-ouvertes.fr/hal-02316413/document,
76,A Deep Learning Approach for Managing Medical Consumable Materials in Intensive Care Units via Convolutional Neural Networks: Technical Proof-of-Concept Study,7,4,334-346,"Peine Arne,Hallawa Ahmed,Schoeffski Oliver,Dartmann Guido,Fazlic Lejla Begic,Schmeink Anke,Marx Gernot,Martin Lukas","Peine A,Hallawa A,Schoffski O,Dartmann G,Fazlic LB,Schmeink A,Marx G,Martin L",Peine A,10.2196/14806,"Univ Hosp Rhein Westfalische TH Aachen, Dept Intens Care Med & Intermediate Care, Pauwelsstr 30, D-52074 Aachen, Germany.","Background: High numbers of consumable medical materials (eg, sterile needles and swabs) are used during the daily routine of intensive care units (ICUs) worldwide. Although medical consumables largely contribute to total ICU hospital expenditure, many hospitals do not track the individual use of materials. Current tracking solutions meeting the specific requirements of the medical environment, like barcodes or radio frequency identification, require specialized material preparation and high infrastructure investment. This impedes the accurate prediction of consumption, leads to high storage maintenance costs caused by large inventories, and hinders scientific work due to inaccurate documentation. Thus, new cost-effective and contactless methods for object detection are urgently needed.
Objective: The goal of this work was to develop and evaluate a contactless visual recognition system for tracking medical consumable materials in ICUs using a deep learning approach on a distributed client-server architecture.
Methods: We developed Consumabot, a novel client-server optical recognition system for medical consumables, based on the convolutional neural network model MobileNet implemented in Tensorflow. The software was designed to run on single-board computer platforms as a detection unit. The system was trained to recognize 20 different materials in the ICU, while 100 sample images of each consumable material were provided. We assessed the top-1 recognition rates in the context of different real-world ICU settings: materials presented to the system without visual obstruction, 50% covered materials, and scenarios of multiple items. We further performed an analysis of variance with repeated measures to quantify the effect of adverse real-world circumstances.
Results: Consumabot reached a >99% reliability of recognition after about 60 steps of training and 150 steps of validation. A desirable low cross entropy of <0.03 was reached for the training set after about 100 iteration steps and after 170 steps for the validation set. The system showed a high top-1 mean recognition accuracy in a real-world scenario of 0.85 (SD 0.11) for objects presented to the system without visual obstruction. Recognition accuracy was lower, but still acceptable, in scenarios where the objects were 50% covered (P<.001; mean recognition accuracy 0.71; SD 0.13) or multiple objects of the target group were present (P=.01; mean recognition accuracy 0.78; SD 0.11), compared to a nonobstmcted view. The approach met the criteria of absence of explicit labeling (eg, barcodes, radio frequency labeling) while maintaining a high standard for quality and hygiene with minimal consumption of resources (eg, cost, time, training, and computational power).
Conclusions: Using a convolutional neural network architecture, Consumabot consistently achieved good results in the classification of consumables and thus is a feasible way to recognize and register medical consumables directly to a hospital's electronic health record. The system shows limitations when the materials are partially covered, therefore identifying characteristics of the consumables are not presented to the system. Further development of the assessment in different medical circumstances is needed.","convolutional neural networks,deep learning,critical care,intensive care,image recognition,medical economics,medical consumables,artificial intelligence,machine learning",Article,"JMIR PUBLICATIONS, INC, 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA",Medical Informatics,,4.108,COST,JMIR MEDICAL INFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6819012,
77,Machine learning and its potential applications to the genomic study of head and neck cancer-A systematic review,48,9,773-779,"Patil Shankargouda,Habib Awan Kamran,Arakeri Gururaj,Jayampath Seneviratne Chaminda,Muddur Nagaraj,Malik Shuaib,Ferrari Marco,Rahimi Siavash,Brennan Peter A.","Patil S,Awan KH,Arakeri G,Seneviratne CJ,Muddur N,Malik S,Ferrari M,Rahimi S,Brennan PA",Arakeri G,10.1111/jop.12854,"Navodaya Dent Coll & Hosp, Dept Oral & Maxillofacial Surg, Raichur, India.","Background Machine learning (ML) is powerful tool that can identify and classify patterns from large quantities of cancer genomic data that may lead to the discovery of new biomarkers, new drug targets, and a better understanding of important cancer genes. The aim of this systematic review was to evaluate the existing literature and assess the application of machine learning of genomic data in head and neck cancer (HNC). Materials and methods The addressed focused question was ""Does machine learning of genomic data play a role in prognostic prediction of HNC?"" PubMed, EMBASE, Scopus, Web of Science, and gray literature from January 1990 up to and including May 2018 were searched. Two independent reviewers performed the study selection according to eligibility criteria. Results A total of seven studies that met the eligibility criteria were included. The majority of studies were cohort studies, one a case-control study and one a randomized controlled trial. Two studies each evaluated oral cancer and laryngeal cancer, while other one study each evaluated nasopharyngeal cancer and oropharyngeal cancer. The majority of studies employed support vector machine (SVM) as a ML technique. Among the included studies, the accuracy rates for ML techniques ranged from 56.7% to 99.4%. Conclusion Our findings showed that ML techniques for the analysis of genomic data can play a role in the prognostic prediction of HNC.","bioinformatics,genomics,head and neck cancer,machine learning,systematic review",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Dentistry, Oral Surgery & Medicine,Pathology",,3.413,"ARTIFICIAL,NEURAL-NETWORKS,DECISION-SUPPORT,PREDICTION,DIAGNOSIS,MODEL,SVM",JOURNAL OF ORAL PATHOLOGY & MEDICINE,,
78,Carboxylated Single-Walled Carbon Nanotube Sensors with Varying pH for the Detection of Ammonia and Carbon Dioxide Using an Artificial Neural Network,2,10,6445-6451,"Kim Beomseok,Norman Thaddeus J.,Jones Ruth Sang,Moon Dong-il,Han Jin-woo,Meyyappan M.","Kim B,Norman TJ,Jones RS,Moon DI,Han JW,Meyyappan M",Kim B,10.1021/acsanm.9b01401,National Aeronautics & Space Administration (NASA),"Single-walled carbon nanotubes (SWCNTs) have long been advocated for the detection of various gases and vapors. Often, strategies to modify the nanotubes have been shown to be successful in eliciting a more sensitive response from the nanotubes when exposed to the target gas relative to the pristine material. Carboxylation of the SWCNTs is one such strategy commonly used in gas sensor construction. Interestingly, addition of acid or base to the carboxylation process can change the pH of the resulting material and yield inks with varying pH values that can be used in a sensor array. Here we show orthogonal responses to NH3 and CO2 from eight such materials with controlled pH values in the range of 1.9-12.1. The results and the approach will be applicable to sensing other acidic and basic gases and also can expand further to other sensor systems to maximize and obtain orthogonal sensor responses. A neural network architecture is used successfully to convert the measured resistance change into analyte concentration.","carbon dioxide sensor,ammonia sensor,SWCNT-COOH,pH control,high humidity,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,5.1,"GAS,ARRAY",ACS APPLIED NANO MATERIALS,,
79,Using the K-Nearest Neighbors Algorithm for Automated Detection of Myocardial Infarction by Electrocardiogram Data Entries,29,4,730-737,"Savostin A. A.,Ritter D. V,Savostina G. V","Savostin AA,Ritter DV,Savostina GV",Savostin AA,10.1134/S1054661819040151,"Kozybayev North Kazakhstan State Univ, Petropavlovsk 150000, Kazakhstan.","This article presents a new approach to solving the problem of automated detection of myocardial infarction of various localization by electrocardiogram data entries. Only the second standard lead is used in the analysis. The signal in this lead undergoes digital filtering in order to remove low-frequency and high-frequency interference. Then, individual cardio complexes P-QRS-T are extracted from the signal, and the following parameters are calculated for them: minimum value, maximum value, interquartile range, mean absolute deviation, root mean square, mode, and entropy. Using the calculated parameters, a standardized training (learning) dataset is formed. The classifier model represents the k-nearest neighbors algorithm with the Manhattan metric of the distance between the objects and number of neighbors k = 9. After learning, the classifier shows the results by precision pre = 98.60%, by recall rec = 97.34%, by specificity spec = 95.93%, and by accuracy acc = 97.03%. According to the analysis of the obtained results, the suggested classifier model offers certain advantages as compared to existing alternatives.","electrocardiogram,myocardial infarction,classification,k-nearest neighbors algorithm",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,"ECG,SIGNALS,LOCALIZATION,DISEASE",PATTERN RECOGNITION AND IMAGE ANALYSIS,,
80,FEASIBILITY STUDY ON THE FUSION OF PHITS SIMULATIONS AND THE DLNN ALGORITHM FOR A NEW QUANTITATIVE METHOD OF IN-SITU MULTIPLE-CHANNEL DEPTH DISTRIBUTION SPECTROMETRY,184,3-4,328-333,"Sakama M.,Fujimoto K.,Inoue K.,Fukushi M.,Imajyo Y.,Fukuhara T.,Matsuura M.,Yajima T.,Endo M.,Fujisawa M.","Sakama M,Fujimoto K,Inoue K,Fukushi M,Imajyo Y,Fukuhara T,Matsuura M,Yajima T,Endo M,Fujisawa M",Sakama M,10.1093/rpd/ncz093,Tokushima University,"We have recently have developed an in-situ multiple-channel depth distribution spectrometer (DDS) that can easily acquire on-site measurements of the depth distribution of specific radioactivities of Cs-134 and Cs-137 underground. Despite considerable improvements in the hardware developed for this device, the quantitative method for determining of radioactivities with this DDS device cannot yet achieve satisfactory performance for practical use. For example, this method cannot discriminate each gamma-ray spectra of Cs-134 and Cs-137 acquired by the 20 thallium-doped caesium iodine CsI(Tl) scintillation crystal detectors of the DDS device from corresponding depth levels of underground soil. Therefore, we have applied deep learning neural network (DLNN) as a novel radiation measurement technique to discriminate the spectra and to determine the specific radioactivities of Cs-134 and Cs-137. We have developed model soil layers on a virtual space in Monte-Carlo based PHITS simulations and transported gamma-ray radiation generated from a particular single soil layer or multiple layers as radiation sources; next, we performed PHITS calculations of those specific radioactivity measurements for each soil layer using DDS device based on machine learning via the DLNN algorithm. In this study, we obtained informative results regarding the feasibility of the proposal innovative radiation measurement method for further practical use in on-site applications.",,Article; Proceedings Paper,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Environmental Sciences & Ecology,Public, Environmental & Occupational Health,Nuclear Science & Technology,Radiology, Nuclear Medicine & Medical Imaging",,0.966,,RADIATION PROTECTION DOSIMETRY,,
81,A Bayesian Possibilistic C-Means clustering approach for cervical cancer screening,501,,495-510,"Li Fang-Qi,Wang Shi-Lin,Liu Gong-Shen","Li FQ,Wang SL,Liu GS",Wang SL,10.1016/j.ins.2019.05.089,Shanghai Jiao Tong University,"Recently, a lot of attention has been given to the treatment of cervical cancer due to its high lethality and morbidity. Early screening of this disease is of vital importance. In this paper, we propose an automatic cervical cancer screening algorithm that analyzes the related risk factors to provide preliminary diagnostic information for medical practitioners. In cervical cancer screening, a number of risk factors are considered to be highly private or sensitive, and many patients elect not to provide the corresponding information. Such severe amount of missing attributes leads to great difficulties for many automatic screening algorithms. To solve this problem, a Bayesian Possibilistic C-means (BPCM in short) clustering algorithm is proposed to discover the representative patterns from the complete data and to estimate the missing values of a specific sample using its closest representative pattern. After the data completion step, a two-stage fuzzy ensemble learning scheme is proposed to derive the final screening result. In the first stage, the bootstrap aggregation (bagging in short) procedure is adopted to sample the entire class-imbalanced dataset into a number of class-balanced subsets. In the second stage, a number of weak classifiers are trained on each subset and a fuzzy logic based approach is designed to analyze the classification results of the weak classifiers and to obtain the final classification result. Experiments have been conducted on a dataset containing 858 patients. From the experiment results, it can be observed that the proposed BPCM can effectively discover the underlying patterns and is reliable in estimating the missing attribute compared with the traditional approaches. Moreover, by applying the proposed fuzzy ensemble learning scheme, the final classification results on the completed data by BPCM are promising (an accuracy of 76% or a positive sensitivity of 79%) under the severe missing-attribute scenario (only 6% samples with complete data). (C) 2019 Elsevier Inc. All rights reserved.","Cervical cancer screening,Bayesian Possibilistic C-Means clustering,Fuzzy logic,Ensemble learning,Granular computing",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Computer Science,,6.524,"COMPUTER-AIDED,DIAGNOSIS,MISSING,VALUE,IMPUTATION,HETEROGENEOUS,CLASSIFIERS,ALGORITHM,SYSTEM",INFORMATION SCIENCES,,
82,Computer-Aided Diagnosis of Pulmonary Fibrosis Using Deep Learning and CT Images,54,10,627-632,"Christe Andreas,Peters Alan A.,Drakopoulos Dionysios,Heverhagen Johannes T.,Geiser Thomas,Stathopoulou Thomai,Christodoulidis Stergios,Anthimopoulos Marios,Mougiakakou Stavroula G.,Ebner Lukas","Christe A,Peters AA,Drakopoulos D,Heverhagen JT,Geiser T,Stathopoulou T,Christodoulidis S,Anthimopoulos M,Mougiakakou SG,Ebner L",Christe A,10.1097/RLI.0000000000000574,University of Bern,"Objectives The objective of this study is to assess the performance of a computer-aided diagnosis (CAD) system (INTACT system) for the automatic classification of high-resolution computed tomography images into 4 radiological diagnostic categories and to compare this with the performance of radiologists on the same task. Materials and Methods For the comparison, a total of 105 cases of pulmonary fibrosis were studied (54 cases of nonspecific interstitial pneumonia and 51 cases of usual interstitial pneumonia). All diagnoses were interstitial lung disease board consensus diagnoses (radiologically or histologically proven cases) and were retrospectively selected from our database. Two subspecialized chest radiologists made a consensual ground truth radiological diagnosis, according to the Fleischner Society recommendations. A comparison analysis was performed between the INTACT system and 2 other radiologists with different years of experience (readers 1 and 2). The INTACT system consists of a sequential pipeline in which first the anatomical structures of the lung are segmented, then the various types of pathological lung tissue are identified and characterized, and this information is then fed to a random forest classifier able to recommend a radiological diagnosis. Results Reader 1, reader 2, and INTACT achieved similar accuracy for classifying pulmonary fibrosis into the original 4 categories: 0.6, 0.54, and 0.56, respectively, with P > 0.45. The INTACT system achieved an F-score (harmonic mean for precision and recall) of 0.56, whereas the 2 readers, on average, achieved 0.57 (P = 0.991). For the pooled classification (2 groups, with and without the need for biopsy), reader 1, reader 2, and CAD had similar accuracies of 0.81, 0.70, and 0.81, respectively. The F-score was again similar for the CAD system and the radiologists. The CAD system and the average reader reached F-scores of 0.80 and 0.79 (P = 0.898). Conclusions We found that a computer-aided detection algorithm based on machine learning was able to classify idiopathic pulmonary fibrosis with similar accuracy to a human reader.","idiopathic pulmonary fibrosis,computed tomography,nonspecific interstitial pneumonia,usual interstitial pneumonia,interstitial lung diseases,artificial intelligence,machine learning,computer-assisted diagnosis",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,5.958,"AUTOMATIC,LUNG,SEGMENTATION,TOMOGRAPHY,SCANS,NEURAL-NETWORK,CLASSIFICATION,ABNORMALITIES,NODULES",INVESTIGATIVE RADIOLOGY,https://journals.lww.com/investigativeradiology/Fulltext/2019/10000/Computer_Aided_Diagnosis_of_Pulmonary_Fibrosis.2.aspx,
83,Detecting reports of unsafe foods in consumer product reviews,2,3,330-338,"Maharana Adyasha,Cai Kunlin,Hellerstein Joseph,Hswen Yulin,Munsell Michael,Staneva Valentina,Verma Miki,Vint Cynthia,Wijaya Derry,Nsoesie Elaine O.","Maharana A,Cai KL,Hellerstein J,Hswen Y,Munsell M,Staneva V,Verma M,Vint C,Wijaya D,Nsoesie EO",Nsoesie EO,10.1093/jamiaopen/ooz030,Boston University,"Objectives: Access to safe and nutritious food is essential for good health. However, food can become unsafe due to contamination with pathogens, chemicals or toxins, or mislabeling of allergens. Illness resulting from the consumption of unsafe foods is a global health problem. Here, we develop a machine learning approach for detecting reports of unsafe food products in consumer product reviews from Amazon.com.
Materials and Methods: We linked Amazon.com food product reviews to Food and Drug Administration (FDA) food recalls from 2012 to 2014 using text matching approaches in a PostGres relational database. We applied machine learning methods and over- and under-sampling methods to the linked data to automate the detection of reports of unsafe food products.
Results: Our data consisted of 1 297 156 product reviews from Amazon.com. Only 5149 (0.4%) were linked to recalled food products. Bidirectional Encoder Representation from Transformations performed best in identifying unsafe food reviews, achieving an F1 score, precision and recall of 0.74, 0.78, and 0.71, respectively. We also identified synonyms for terms associated with FDA recalls in more than 20 000 reviews, most of which were associated with nonrecalled products. This might suggest that many more products should have been recalled or investigated.
Discussion and Conclusion: Challenges to improving food safety include, urbanization which has led to a longer food chain, underreporting of illness and difficulty in linking contaminated food to illness. Our approach can improve food safety by enabling early identification of unsafe foods which can lead to timely recall thereby limiting the health and economic impact on the public.","food and drug administration,food safety,consumer product safety,machine learning,artificial intelligence",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,,JAMIA OPEN,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6951857,
84,Inferring new relations between medical entities using literature curated term co-occurrences,2,3,378-385,"Spiro Adam,Garcia Jonatan Fernandez,Yanover Chen","Spiro A,Garcia JF,Yanover C",Spiro A,10.1093/jamiaopen/ooz022,"IBM Res, Dept Hlth Informat, Machine Learning Healthcare & Life Sci, Univ Haifa Campus, IL-3498825 Haifa, Israel.","Objectives: Identifying new relations between medical entities, such as drugs, diseases, and side effects, is typically a resource-intensive task, involving experimentation and clinical trials. The increased availability of related data and curated knowledge enables a computational approach to this task, notably by training models to predict likely relations. Such models rely on meaningful representations of the medical entities being studied. We propose a generic features vector representation that leverages co-occurrences of medical terms, linked with PubMed citations.
Materials and Methods: We demonstrate the usefulness of the proposed representation by inferring two types of relations: a drug causes a side effect and a drug treats an indication. To predict these relations and assess their effectiveness, we applied 2 modeling approaches: multi-task modeling using neural networks and single-task modeling based on gradient boosting machines and logistic regression.
Results: These trained models, which predict either side effects or indications, obtained significantly better results than baseline models that use a single direct co-occurrence feature. The results demonstrate the advantage of a comprehensive representation. Discussion: Selecting the appropriate representation has an immense impact on the predictive performance of machine learning models. Our proposed representation is powerful, as it spans multiple medical domains and can be used to predict a wide range of relation types.
Conclusion: The discovery of new relations between various medical entities can be translated into meaningful insights, for example, related to drug development or disease understanding. Our representation of medical entities can be used to train models that predict such relations, thus accelerating healthcare-related discoveries.","machine learning,medical informatics,MeSH headings,literature-based discovery,adverse drug reaction,drug repositioning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,,JAMIA OPEN,https://europepmc.org/articles/pmc6951958?pdf=render,
85,Prediction of Residual Stress Random Fields for Selective Laser Melted A357 Aluminum Alloy Subjected to Laser Shock Peening,141,10,,"Hatamleh Mohammad I.,Mahadevan Jagannathan,Malik Arif,Qian Dong,Kovacevic Radovan","Hatamleh MI,Mahadevan J,Malik A,Qian D,Kovacevic R",Malik A,10.1115/1.4044418,University of Texas System,"Residual stress (RS) is a major processing issue for selective laser melting (SLM) of metal alloys. Postprocessing by way of heat treatment or hot isostatic pressing is usually required for acceptable mechanical properties. In this work, laser shock peening (LSP) treatment on both SLM and cast aluminum A357 alloys are compared with regard to the development of beneficial near-surface compressive RS. Experiments are conducted using high energy nanosecond pulsed laser, together with a fast photodetector connected to a high-resolution oscilloscope and high-speed camera to identify detailed temporal and spatial laser pulse profiles to improve numerical predictions. Constitutive modeling for SLM A357 alloy is performed using finite element simulation and data obtained from X-ray diffraction (XRD) measurements. Since XRD-RS measurements are accompanied with significant machine-reported error, an effective method is introduced to quantify the material constitutive model uncertainty in terms of a joint probability mass function. Conventionally, most constitutive behavior research for LSP involves deterministic material modeling. Predicted RS using deterministic approaches fail to reflect real-world variations in the materials, laser treatment, or RS measurements. A discretized Bayesian inference is used to quantify the rate-dependent plasticity material model parameters as a joint probability function. RS are then characterized as random fields, which provides far greater insight into the practical ability to attain desired residual stresses. Moreover, for identical LSP treatments, it is determined that the material models are significantly different for the SLM and the conventional cast A357 aluminum alloys, resulting in much lower magnitude of compressive RS in the SLM alloy.","laser shock peening,selective laser melting,residual stresses,Bayesian inference,random field,machine learning,additive manufacturing,laser processes,modeling and simulation",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.084,"FEM,SIMULATION,BEHAVIOR,MICROSTRUCTURE,FATIGUE,OPTIMIZATION,PARAMETERS,DEPOSITION,PARTS",JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE ASME,,
86,Decoding crystallography from high-resolution electron imaging and diffraction datasets with deep learning,5,10,,"Aguiar J. A.,Gong M. L.,Unocic R. R.,Tasdizen T.,Miller B. D.","Aguiar JA,Gong ML,Unocic RR,Tasdizen T,Miller BD",Aguiar JA,10.1126/sciadv.aaw1949,United States Department of Energy (DOE),"While machine learning has been making enormous strides in many technical areas, it is still massively underused in transmission electron microscopy. To address this, a convolutional neural network model was developed for reliable classification of crystal structures from small numbers of electron images and diffraction patterns with no preferred orientation. Diffraction data containing 571,340 individual crystals divided among seven families, 32 genera, and 230 space groups were used to train the network. Despite the highly imbalanced dataset, the network narrows down the space groups to the top two with over 70% confidence in the worst case and up to 95% in the common cases. As examples, we benchmarked against alloys to two-dimensional materials to cross-validate our deep-learning model against high-resolution transmission electron images and diffraction patterns. We present this result both as a research tool and deep-learning application for diffraction analysis.","OPEN-ACCESS COLLECTION,OPEN DATABASE,ORIENTATION",Article,"AMER ASSOC ADVANCEMENT SCIENCE, 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA",Science & Technology - Other Topics,,16.45,"OPEN-ACCESS,COLLECTION,OPEN,DATABASE,ORIENTATION",SCIENCE ADVANCES,https://www.osti.gov/biblio/1626012,
87,Prediction of electronic structure in atomistic model using artificial neural network,168,,164-171,"Umeno Y.,Kubo A.","Umeno Y,Kubo A",Umeno Y,10.1016/j.commatsci.2019.06.005,University of Tokyo,"A scheme to predict electronic density of states (DoS) from atomic configurations using the artificial neural network (ANN) is proposed. Integrated DoS (IDoS) was reproduced by discretizing IDoS into and constructing individual ANN elements corresponding to sampling points of the discretization. The validity of this scheme was examined and found successful for typical crystal structures of SiC, C and Si. The proposed scheme paves the way to new approaches to obtain various materials properties without employing electronic state calculations such as first-principles methods.","Artificial neural network,Density of states,Machine learning",Article,"ELSEVIER SCIENCE BV, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"MOLECULAR-DYNAMICS,SIMULATIONS",COMPUTATIONAL MATERIALS SCIENCE,,
88,Towards machine learning approaches for predicting the self-healing efficiency of materials,168,,180-187,"Wang Wenjun,Moreau Nicolette G.,Yuan Yingfang,Race Paul R.,Pang Wei","Wang WJ,Moreau NG,Yuan YF,Race PR,Pang W",Pang W,10.1016/j.commatsci.2019.05.050,University of Aberdeen,"Self-healing materials with an inherent repair mechanism have been widely studied. However, the self-healing efficiencies of most materials can only be measured by laboratory-based experiments, which can be time consuming and expensive. Inspired by modern machine learning approaches, we are interested in predicting the self-healing efficiency of new bio-hybrid materials, as part of our ongoing EPSRC funded ""Manufacturing Immortality"" project. By modelling existing experimental data, predictive models can be built to forecast self-healing efficiency. This has the potential to reduce the time input required by laboratory experiments, guide material and component selection, and inform hypotheses, thereby facilitating the design of novel self-healing materials. In this position paper, we first present preliminary knowledge and quantitative definitions of the self-healing efficiency of materials. We then demonstrate several widely used machine learning approaches and review an experimental case of predictive modelling based on neural networks. Furthermore, and aiming to expedite self-healing material development, we propose an on-line ensemble learning framework as the whole system model for the optimization of predictive computational models. Finally, the rationality of our on-line ensemble learning framework is experimentally studied and validated.","Self-healing efficiency,Predictive model,Regression and classification,Artificial neural network,Online ensemble learning framework",Article,"ELSEVIER SCIENCE BV, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS",Materials Science,,3.222,PHYSICAL-PROPERTIES,COMPUTATIONAL MATERIALS SCIENCE,https://aura.abdn.ac.uk/bitstream/2164/12426/1/Towards_machine_learning_approaches_for_predicting_the_self_healing_efficiency_of_materials.pdf,
89,Suppression of noises using fast independent component analysis (FICA) and signal saturation using fuzzy adaptive histogram equalization (FAHE) for intensive care unit false alarms,145,,400-409,"Chandar V. Ravindra Krishna,Thangamani M.","Chandar VRK,Thangamani M",Chandar VRK,10.1016/j.measurement.2019.02.007,"Paavai Engn Coll, Dept CSE, Namakkal Dt, India.","In the medical field, fake alarms are classically described as alarms with no clinical or therapeutic effects. A variety of studies exist in the clinical literature regarding the alarms monitoring in Arterial Blood Pressure (ABP) Signal and intensive care medicine. In the proposed work measurement of each one of the ABP, signal values are carried out employing the Fast Independent Component Analysis (FICA), which detects areas affected with high-frequency noise. When the noises in the samples are eliminated, then the signal saturation values are decided with the help of the Fuzzy Wavelet Transform (FWT) technique. Then, the automated feature engineering was carried out utilizing the signal for ABP along with a processed signal, which has the count of the times of every monitored heartbeat acquired from the ABP signal. Subsequently, Kullback-Leibler divergence Kernel -Support Vector Machine (KLDK-SVM), Random Forest (RF), and SVM classifiers were trained so as to generate the classification models. The newly introduced scheme can be used to help the medical professional and specialists, letting them become more useful and are responsive to alarms as quickly as possible. (C) 2019 Elsevier Ltd. All rights reserved.","Machine learning,Medical expert systems,Signal processing,Fast Independent Component Analysis (FICA),Fuzzy Wavelet Transform (FWT) patient monitoring,Time series analysis,Pattern recognition,Invalid data segments,Data processing",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,,"ARTERIAL-BLOOD,PRESSURE,RANDOM,FORESTS,CLASSIFICATION,REDUCTION,QUALITY",MEASUREMENT,,
90,A new computational drug repurposing method using established disease-drug pair knowledge,35,19,3672-3678,"Saberian Nafiseh,Peyvandipour Azam,Donato Michele,Ansari Sahar,Draghici Sorin","Saberian N,Peyvandipour A,Donato M,Ansari S,Draghici S",Draghici S,10.1093/bioinformatics/btz156,Wayne State University,"Motivation: Drug repurposing is a potential alternative to the classical drug discovery pipeline. Repurposing involves finding novel indications for already approved drugs. In this work, we present a novel machine learning-based method for drug repurposing. This method explores the anti-similarity between drugs and a disease to uncover new uses for the drugs. More specifically, our proposed method takes into account three sources of information: (i) large-scale gene expression profiles corresponding to human cell lines treated with small molecules, (ii) gene expression profile of a human disease and (iii) the known relationship between Food and Drug Administration (FDA)-approved drugs and diseases. Using these data, our proposed method learns a similarity metric through a supervised machine learning-based algorithm such that a disease and its associated FDA-approved drugs have smaller distance than the other disease-drug pairs.
Results: We validated our framework by showing that the proposed method incorporating distance metric learning technique can retrieve FDA-approved drugs for their approved indications. Once validated, we used our approach to identify a few strong candidates for repurposing.","TARGET INTERACTION PREDICTION,GENE-EXPRESSION SIGNATURES,RAPAMYCIN AY-22,989,REDUCTION,ARTHRITIS,EFFICACY,ALPHA",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,,"TARGET,INTERACTION,PREDICTION,GENE-EXPRESSION,SIGNATURES,RAPAMYCIN,AY-22%2C989,REDUCTION,ARTHRITIS,EFFICACY,ALPHA",BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6761937,
91,Learning Style Compatibility Between Objects in a Real-World 3D Asset Database,38,7,775-784,"Liu Yifan,Tang Ruolan,Ritchie Daniel","Liu YF,Tang RL,Ritchie D",Liu YF,10.1111/cgf.13879,Brown University,"Large 3D asset databases are critical for designing virtual worlds, and using them effectively requires techniques for efficient querying and navigation. One important form of query is search by style compatibility: given a query object, find others that would be visually compatible if used in the same scene. In this paper, we present a scalable, learning-based approach for solving this problem which is designed for use with real-world 3D asset databases; we conduct experiments on 121 3D asset packages containing around 4000 3D objects from the Unity Asset Store. By leveraging the structure of the object packages, we introduce a technique to synthesize training labels for metric learning that work as well as human labels. These labels can grow exponentially with the number of objects, allowing our approach to scale to large real-world 3D asset databases without the need for expensive human training labels. We use these synthetic training labels in a metric learning model that analyzes the in-engine rendered appearance of an object-combining geometry, material, and texture-whereas prior work considers only object geometry, or disjoint geometry and texture features. Through an ablation experiment, we find that using this representation yields better results than using renders which lack texture, materiality, or both.",SIMILARITY,Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,,SIMILARITY,COMPUTER GRAPHICS FORUM,,
92,Machine Learning-Based Soft Sensors for the Estimation of Laundry Moisture Content in Household Dryer Appliances,12,20,,"Zambonin Giuliano,Altinier Fabio,Beghi Alessandro,Coelho Leandro dos Santos,Fiorella Nicola,Girotto Terenzio,Rampazzo Mirco,Reynoso-Meza Gilberto,Susto Gian Antonio","Zambonin G,Altinier F,Beghi A,Coelho LD,Fiorella N,Girotto T,Rampazzo M,Reynoso-Meza G,Susto GA",Zambonin G,10.3390/en12203843,University of Padua,"The aim is to develop soft sensors (SSs) to provide an estimation of the laundry moisture of clothes introduced in a household Heat Pump Washer-Dryer (WD-HP) appliance. The developed SS represents a cost-effective alternative to physical sensors, and it aims at improving the WD-HP performance in terms of drying process efficiency of the automatic drying cycle. To this end, we make use of appropriate Machine Learning models, which are derived by means of Regularization and Symbolic Regression methods. These methods connect easy-to-measure variables with the laundry moisture content, which is a difficult and costly to measure variable. Thanks to the use of SSs, the laundry moisture estimation during the drying process is effectively available. The proposed models have been tested by exploiting real data through an experimental test campaign on household drying machines.","domestic appliances,fabric care,washer-dryer,machine learning,moisture transfer models,soft sensors,symbolic regression",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"DIFFUSION,KINETICS",ENERGIES,https://www.mdpi.com/1996-1073/12/20/3843/pdf,
93,Potential for Prediction of Water Saturation Distribution in Reservoirs Utilizing Machine Learning Methods,12,19,,"Zhang Qitao,Wei Chenji,Wang Yuhe,Du Shuyi,Zhou Yuanchun,Song Hongqing","Zhang QT,Wei CJ,Wang YH,Du SY,Zhou YC,Song HQ",Song HQ,10.3390/en12193597,University of Science & Technology Beijing,"Machine learning technology is becoming increasingly prevalent in the petroleum industry, especially for reservoir characterization and drilling problems. The aim of this study is to present an alternative way to predict water saturation distribution in reservoirs with a machine learning method. In this study, we utilized Long Short-Term Memory (LSTM) to build a prediction model for forecast of water saturation distribution. The dataset deriving from monitoring and simulating of an actual reservoir was utilized for model training and testing. The data model after training was validated and utilized to forecast water saturation distribution, pressure distribution and oil production. We also compared standard Recurrent Neural Network (RNN) and Gated Recurrent Unit (GRU) which are popular machine learning methods with LSTM for better water saturation prediction. The results show that the LSTM method has a good performance on the water saturation prediction with overall AARD below 14.82%. Compared with other machine learning methods such as GRU and standard RNN, LSTM has better performance in calculation accuracy. This study presented an alternative way for quick and robust prediction of water saturation distribution in reservoir.","machine learning,water saturation,long short-term memory,artificial neural network,computational time",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"NEURAL-NETWORKS,OIL,PRODUCTION,MODEL",ENERGIES,https://www.mdpi.com/1996-1073/12/19/3597/pdf,
94,BioWolf: A Sub-10-mW 8-Channel Advanced Brain-Computer Interface Platform With a Nine-Core Processor and BLE Connectivity,13,5,893-906,"Kartsch Victor,Tagliavini Giuseppe,Guermandi Marco,Benatti Simone,Rossi Davide,Benini Luca","Kartsch V,Tagliavini G,Guermandi M,Benatti S,Rossi D,Benini L",Kartsch V,10.1109/TBCAS.2019.2927551,University of Bologna,"Advancements in digital signal processing (DSP) and machine learning techniques have boosted the popularity of brain-computer interfaces (BCIs), where electroencephalography is a widely accepted method to enable intuitive human-machine interaction. Nevertheless, the evolution of such interfaces is currently hampered by the unavailability of embedded platforms capable of delivering the required computational power at high energy efficiency and allowing for a small and unobtrusive form factor. To fill this gap, we developed BioWolf, a highly wearable (40mm 20 mm 2 mm) BCI platform based on Mr. Wolf, a parallel ultra low power system-on-chip featuring nine RISC-V cores with DSP-oriented instruction set extensions. BioWolf also integrates a commercial 8-channel medical-grade analog-to-digital converter, and an ARM-Cortex M4 microcontroller unit (MCU) with bluetooth low-energy connectivity. To demonstrate the capabilities of the system, we implemented and tested a BCI featuring canonical correlation analysis (CCA) of steady-state visual evoked potentials. The system achieves an average information transfer rate of 1.46 b/s (aligned with the state-of-the-art of bench-top systems). Thanks to the reduced power envelope of the digital computational platform, which consumes less than the analog front-end, the total power budget is just 6.31mW, providing up to 38h operation (65mAh battery). To our knowledge, our design is the first to explore the significant energy boost of a parallel MCU with respect to single-core MCUs for CCA-based BCI.","Blockchain,Protocols,Privacy,Charging stations,Electric vehicle charging,Public key,Elliptic curves,Body sensor networks,brain-computer interfaces,digital signal processing,electroencephalography,internet of things,low-power electronics,multicore processing",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"VISUAL-EVOKED,POTENTIALS,ACQUISITION-SYSTEM,EEG,MANAGEMENT,DESIGN,SOC",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
95,Monitoring of friction stir welding based on vision system coupled with Machine learning algorithm,144,,135-143,"Sudhagar S.,Sakthivel M.,Ganeshkumar P.","Sudhagar S,Sakthivel M,Ganeshkumar P",Sudhagar S,10.1016/j.measurement.2019.05.018,"Sri Shakthi Inst Engn & Technol, Dept Mech Engn, Coimbatore, Tamil Nadu, India.","The increase in utilization of FSW process demands online monitoring system for early detection and control of defects. This research attempts to develop a system for detection and classification of defective welds using weld surface image. Welding joints are produced at different welding condition by varying tool rotational speed, welding speed, tool shoulder diameter and pin diameter. The weld surfaces produced at different welding condition are captured using digital camera and processed to extract features. The features from weld surface image has been extracted using maximally stable extremal region algorithm and which is used as input for classification of weld joint. The Support Vector Machines is used for classification of weld using features from surface image. Support Vector Machines is trained with different kernel functions and found that linear and quadratic kernel function classify defect weld and good weld with accuracy of 95.8%. (C) 2019 Elsevier Ltd. All rights reserved.","Friction stir welding,Machine learning,Image processing,Support Vector Machine",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"QUALITY,INSPECTION,SYSTEM,WELDED-JOINTS,MECHANICAL-PROPERTIES,ACOUSTIC-EMISSION,DEFECT,DETECTION,WAVELET,PACKET,CLASSIFICATION,TORQUE,MICROSTRUCTURE,IDENTIFICATION",MEASUREMENT,,
96,Using Gaussian process regression to simulate the vibrational Raman spectra of molecular crystals,21,10,,"Raimbault Nathaniel,Grisafi Andrea,Ceriotti Michele,Rossi Mariana","Raimbault N,Grisafi A,Ceriotti M,Rossi M",Rossi M,10.1088/1367-2630/ab4509,Max Planck Society,"Vibrational properties of molecular crystals are constantly used as structural fingerprints, in order to identify both the chemical nature and the structural arrangement of molecules. The simulation of these properties is typically very costly, especially when dealing with response properties of materials to e.g. electric fields, which require a good description of the perturbed electronic density. In this work, we use Gaussian process regression (GPR) to predict the static polarizability and dielectric susceptibility of molecules and molecular crystals. Wecombine this framework with ab initio molecular dynamics to predict their anharmonic vibrational Raman spectra. Westress the importance of data representation, symmetry, and locality, by comparing the performance of different flavors of GPR. In particular, we show the advantages of using a recently developed symmetry-adapted version of GPR. As an examplary application, we choose Paracetamol as an isolated molecule and in different crystal forms. Weobtain accurate vibrational Raman spectra in all cases with fewer than 1000 training points, and obtain improvements when using a GPR trained on the molecular monomer as a baseline for the crystal GPR models. Finally, we show that our methodology is transferable across polymorphic forms: we can train the model on data for one crystal structure, and still be able to accurately predict the spectrum for a second polymorph. This procedure provides an independent route to access electronic structure properties when performing force-evaluations on empirical force-fields or machine-learned potential energy surfaces.","Gaussian process regression,tensorial properties,Raman,molecular crystals,ab initio",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"RELATE,2,SETS,FORCE-CONSTANTS,DENSITY,ROTATION",NEW JOURNAL OF PHYSICS,http://arxiv.org/pdf/1906.07485,
97,Research on Temperature Compensation of Silicon based Piezoresistive Pressure Sensor based on DE-SVM,32,10,1493-1498,",,,,","Wen Changbao,Wang Meng,Zhong Chenhao,Su Jianbin,Ju Yongfeng",,,Wen Changbao,"In order to solve the problem that silicon-based piezoresistive pressure sensors are susceptible to ambient temperature,a temperature compensation scheme for silicon-based piezoresistive pressure sensors based on DE-SVM is proposed. The scheme mainly consists of the training data preprocessing module, the DE parameter optimization module, the SVM training module, the data acquisition module, the measurement data preprocessing module and the SVM correction module. It takes the nonlinear regression function of the SVM algorithm as the core. The SVM parameters are optimized by the DE algorithm. The temperature correction module is obtained after training,and the measurement data is input to the module. Finally the corrected pressure value is output. The result from the test of single sensor shows that the maximum error and mean square error are reduced by 93.87% and 99.89% respectively after its pressure value is corrected by DE-SVM model. In the case of multi-sensor composed of seven silicon-based piezoresistive pressure sensors, the maximum error and the mean square error are reduced by 93.17% and 99.27%, respectively. Moreover, the average relative error decreased from 14.06% to 0.45%. Finally, the temperature points not included in the training data are tested by the established model. The model still performs well.","DE-SVM; detection technology; temperature compensation; DE-SVM; silicon based ,material,; piezoresistive pressure sensor",Article,,,,,,,,
98,Advances in safety assessment and risk management for deepwater oil and gas exploitation,43,5,136-145,",,","Chen Guoming,Zhu Gaogeng,Zhu Yuan",,,Chen Guoming,"Deepwater oil and gas is becoming great concerns in terms of the energy development in China. The exploration and exploitation of the deepwater oil and gas has been recently promoted to the plan of building a powerful ocean country and energy safety. However, the harsh and complicated offshore environment as well as the technological conditions still exit during the exploitation process. In view of the main operation scene, the research on major accidents was systematically carried out including the risk assessment, risk evolution, consequence assessment, accident control and so on. Firstly, the risk evolution methodology during the drilling operation was proposed and the reliability assessment model for the critical barriers was constructed. In addition, with regard to the potential risk during the deepwater oil and gas exploitation process, the robust risk assessment approach and the digital control scheme were developed by integrating the machine learning algorithms and data-driven models with the consequence modeling considering multi-object-based parameters. Altogether, we review the above achievements and also give the future research directions in this area.",deepwater; oil and gas exploitation; risk; blowout; leakage; fire and explosion,Review,,,,,,,,
99,Optimization of Rolling Force Self - learning Model in Unsteady Process of Hot Rolling,40,10,1408-1412,",,,","Peng Wen,Ji Yafeng,Chen Xiaorui,Zhang Dianhua",,,Peng Wen,"In order to improve the predicted precision of rolling force in unsteady process,an optimization method for rolling force self-learning model was proposed. The self-learning coefficient in the model was decomposed into the layer learning coefficient and rolling state learning coefficient,which characterized the genetic characteristics of rolling force prediction deviation between racks,and the effect of actual roll state on the model prediction. In the process of coefficient updating,the learning coefficients were updated according to the layer distance so that the prediction error of rolling force could be reduced, especially when the rolling specifications were switched. The proposed self-learning method has been successfully applied into a hot rolling process. Compared with the original model,the predicted deviation of the optimized self-learning method is reduced from 2.8% to 1.4%,and the mean square error is reduced from 3.3% to 1.7%,which effectively improve the accuracy and robustness of rolling force in unsteady process.",hot rolling; rolling force; unsteady process; layer distance; prediction deviation,Article,,,,,,,,
100,Generative Adversarial Networks for Facilitating Stain-Independent Supervised and Unsupervised Segmentation: A Study on Kidney Histology,38,10,2293-2302,"Gadermayr Michael,Gupta Laxmi,Appel Vitus,Boor Peter,Klinkhammer Barbara M.,Merhof Dorit","Gadermayr M,Gupta L,Appel V,Boor P,Klinkhammer BM,Merhof D",Gadermayr M,10.1109/TMI.2019.2899364,"Salzburg Univ Appl Sci, Sch Informat Technol & Syst Management, A-5412 Puch Bei Hallein, Austria.","A major challenge in the field of segmentation in digital pathology is given by the high effort for manual data annotations in combination with many sources introducing variability in the image domain. This requires methods that are able to cope with variability without requiring to annotate a large amount of samples for each characteristic. In this paper, we develop approaches based on adversarial models for image-to-image translation relying on unpaired training. Specifically, we propose approaches for stain-independent supervised segmentation relying on image-to-image translation for obtaining an intermediate representation. Furthermore, we develop a fully-unsupervised segmentation approach exploiting image-to-image translation to convert from the image to the label domain. Finally, both approaches are combined to obtain optimum performance in unsupervised segmentation independent of the characteristics of the underlying stain. Experiments on patches showing kidney histology proof that stain-translation can be performed highly effectively and can be used for domain adaptation to obtain independence of the underlying stain. It is even capable of facilitating the underlying segmentation task, thereby boosting the accuracy if an appropriate intermediate stain is selected. Combining domain adaptation with unsupervised segmentation finally showed the most significant improvements.","Image segmentation,Training,Adaptation models,Training data,Task analysis,Data models,Pipelines,Histology,adversarial networks,segmentation,unsupervised,kidney,image-to-image translation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,COLOR,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
